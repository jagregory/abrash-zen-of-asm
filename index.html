<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="Michael Abrash">
  <meta name="dcterms.date" content="1990-01-01">
  <title>Zen of Assembly Language: Volume I, Knowledge</title>
  <link type="text/css" rel="stylesheet" href="book.css" />
  <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->
  <style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
  </style>
</head>
<body>
<header>
<h1 class="title">Zen of Assembly Language: Volume I, Knowledge</h1>
<h2 class="author">Michael Abrash</h2>
</header>
<nav id="TOC">
<ul>
<li><a href="#acknowledgements">Acknowledgements</a></li>
<li><a href="#trademarks">Trademarks</a></li>
<li><a href="#introduction-pushing-the-envelope">Introduction: Pushing the Envelope</a><ul>
<li><a href="#why-assembly-language">Why Assembly Language?</a></li>
<li><a href="#what-youll-need">What You’ll Need</a></li>
<li><a href="#odds-and-ends">Odds and Ends</a></li>
<li><a href="#the-path-to-the-zen-of-assembler">The Path to the Zen of Assembler</a></li>
</ul></li>
<li><a href="#chapter-1-zen">Chapter 1: Zen?</a><ul>
<li><a href="#the-zen-of-assembler-in-a-nutshell">The Zen of Assembler in a Nutshell</a></li>
<li><a href="#assembler-is-fundamentally-different-from-other-languages">Assembler is Fundamentally Different from Other Languages</a></li>
<li><a href="#knowledge">Knowledge</a></li>
<li><a href="#the-flexible-mind">The Flexible Mind</a></li>
<li><a href="#where-to-begin">Where to Begin?</a></li>
</ul></li>
<li><a href="#chapter-2-assume-nothing">Chapter 2: Assume Nothing</a><ul>
<li><a href="#the-zen-timer">The Zen Timer</a></li>
<li><a href="#the-zen-timer-is-a-means-not-an-end">The Zen Timer is a Means, Not an End</a></li>
<li><a href="#starting-the-zen-timer">Starting the Zen Timer</a></li>
<li><a href="#time-and-the-pc">Time and the PC</a></li>
<li><a href="#stopping-the-zen-timer">Stopping the Zen Timer</a></li>
<li><a href="#reporting-timing-results">Reporting Timing Results</a></li>
<li><a href="#notes-on-the-zen-timer">Notes on the Zen Timer</a></li>
<li><a href="#a-sample-use-of-the-zen-timer">A Sample Use of the Zen Timer</a></li>
<li><a href="#the-long-period-zen-timer">The Long-Period Zen Timer</a></li>
<li><a href="#stopping-the-clock">Stopping the Clock</a></li>
<li><a href="#a-sample-use-of-the-long-period-zen-timer">A Sample Use of the Long-Period Zen Timer</a></li>
<li><a href="#further-reading">Further Reading</a></li>
<li><a href="#armed-with-the-zen-timer-onward-and-upward">Armed With the Zen Timer, Onward and Upward</a></li>
</ul></li>
<li><a href="#chapter-3-context">Chapter 3: Context</a><ul>
<li><a href="#from-the-bottom-up">From the Bottom Up</a></li>
<li><a href="#the-traditional-model">The Traditional Model</a></li>
<li><a href="#cycle-eaters">Cycle-Eaters</a></li>
<li><a href="#code-is-data">Code is Data</a></li>
<li><a href="#inside-the-8088">Inside the 8088</a></li>
<li><a href="#stepchild-of-the-8086">Stepchild of the 8086</a></li>
<li><a href="#which-model-to-use">Which Model to Use?</a></li>
</ul></li>
<li><a href="#chapter-4-things-mother-never-told-you-under-the-programming-interface">Chapter 4: Things Mother Never Told You: Under the Programming Interface</a><ul>
<li><a href="#cycle-eaters-revisited">Cycle-Eaters Revisited</a></li>
<li><a href="#the-8-bit-bus-cycle-eater">The 8-Bit Bus Cycle-Eater</a></li>
<li><a href="#the-prefetch-queue-cycle-eater">The Prefetch Queue Cycle-Eater</a></li>
<li><a href="#dynamic-ram-refresh-the-invisible-hand">Dynamic Ram Refresh: The Invisible Hand</a></li>
<li><a href="#wait-states">Wait States</a></li>
<li><a href="#cycle-eaters-a-summary">Cycle-Eaters: A Summary</a></li>
<li><a href="#what-does-it-all-mean">What Does It All Mean?</a></li>
</ul></li>
<li><a href="#chapter-5-night-of-the-cycle-eaters">Chapter 5: Night of the Cycle-Eaters</a><ul>
<li><a href="#no-were-not-in-kansas-anymore">No, We’re Not in Kansas Anymore</a></li>
<li><a href="#theres-still-no-such-beast-as-a-true-execution-time">…There’s Still No Such Beast as a True Execution Time</a></li>
<li><a href="#the-true-nature-of-instruction-execution">The True Nature of Instruction Execution</a></li>
<li><a href="#back-to-the-programming-interface">Back to the Programming Interface</a></li>
</ul></li>
<li><a href="#chapter-6-the-8088">Chapter 6: The 8088</a><ul>
<li><a href="#an-overview-of-the-8088">An Overview of the 8088</a></li>
<li><a href="#resources-of-the-8088">Resources of the 8088</a></li>
<li><a href="#registers">Registers</a></li>
<li><a href="#the-8088s-register-set">The 8088’s Register Set</a></li>
<li><a href="#the-general-purpose-registers">The General-Purpose Registers</a></li>
<li><a href="#the-segment-registers">The Segment Registers</a></li>
<li><a href="#the-instruction-pointer">The Instruction Pointer</a></li>
<li><a href="#the-flags-register">The Flags Register</a></li>
<li><a href="#theres-more-to-life-than-registers">There’s More to Life Than Registers</a></li>
</ul></li>
<li><a href="#chapter-7-memory-addressing">Chapter 7: Memory Addressing</a><ul>
<li><a href="#definitions">Definitions</a></li>
<li><a href="#the-memory-architecture-of-the-8088">The Memory Architecture of the 8088</a></li>
<li><a href="#segments-and-offsets">Segments and Offsets</a></li>
<li><a href="#segment-handling">Segment Handling</a></li>
<li><a href="#offset-handling">Offset Handling</a></li>
<li><a href="#mod-reg-rm-addressing"><em>mod-reg-rm</em> Addressing</a></li>
<li><a href="#non-mod-reg-rm-memory-addressing">Non-<em>mod-reg-rm</em> Memory Addressing</a></li>
<li><a href="#initializing-memory">Initializing Memory</a></li>
<li><a href="#a-brief-note-on-io-addressing">A Brief Note on I/O Addressing</a></li>
</ul></li>
<li><a href="#chapter-8-strange-fruit-of-the-8080">Chapter 8: Strange Fruit of the 8080</a><ul>
<li><a href="#the-8080-legacy">The 8080 Legacy</a></li>
<li><a href="#accumulator-specific-instructions">Accumulator-Specific Instructions</a></li>
<li><a href="#pushing-and-popping-the-8080-flags">Pushing and Popping the 8080 Flags</a></li>
<li><a href="#a-brief-digression-on-optimization">A Brief Digression on Optimization</a></li>
</ul></li>
<li><a href="#chapter-9-around-and-about-the-instruction-set">Chapter 9: Around and About the Instruction Set</a><ul>
<li><a href="#shortcuts-for-handling-zero-and-constants">Shortcuts for Handling Zero and Constants</a></li>
<li><a href="#inc-and-dec"><code>inc</code> and <code>dec</code></a></li>
<li><a href="#carrying-results-along-in-a-flag">Carrying Results Along in a Flag</a></li>
<li><a href="#byte-to-word-and-word-to-doubleword-conversion">Byte-To-Word and Word-To-Doubleword Conversion</a></li>
<li><a href="#xchg-is-handy-when-registers-are-tight"><code>xchg</code> is Handy When Registers Are Tight</a></li>
<li><a href="#destination-register">Destination: Register</a></li>
<li><a href="#neg-and-not"><code>neg</code> and <code>not</code></a></li>
<li><a href="#rotates-and-shifts">Rotates and Shifts</a></li>
<li><a href="#ascii-and-decimal-adjust">ASCII and Decimal Adjust</a></li>
<li><a href="#mnemonics-that-cover-multiple-instructions">Mnemonics That Cover Multiple Instructions</a></li>
</ul></li>
<li><a href="#chapter-10-string-instructions-the-magic-elixir">Chapter 10: String Instructions: The Magic Elixir</a><ul>
<li><a href="#a-quick-tour-of-the-string-instructions">A Quick Tour of the String Instructions</a></li>
<li><a href="#hither-and-yon-with-the-string-instructions">Hither and Yon With the String Instructions</a></li>
</ul></li>
<li><a href="#chapter-11-string-instruction-applications">Chapter 11: String Instruction Applications</a><ul>
<li><a href="#string-handling-with-lods-and-stos">String Handling With <code>lods</code> and <code>stos</code></a></li>
<li><a href="#block-handling-with-movs">Block Handling With <code>movs</code></a></li>
<li><a href="#searching-with-scas">Searching With <code>scas</code></a></li>
<li><a href="#comparing-memory-to-memory-with-cmps">Comparing Memory to Memory With <code>cmps</code></a></li>
<li><a href="#a-note-about-returning-values">A Note About Returning Values</a></li>
<li><a href="#putting-string-instructions-to-work-in-unlikely-places">Putting String Instructions to Work in Unlikely Places</a></li>
<li><a href="#a-note-on-handling-blocks-larger-than-64-k-bytes">A Note on Handling Blocks Larger Than 64 K Bytes</a></li>
</ul></li>
<li><a href="#chapter-12-dont-jump">Chapter 12: Don’t Jump!</a><ul>
<li><a href="#how-slow-is-it">How Slow Is It?</a></li>
<li><a href="#branching-and-calculation-of-the-target-address">Branching and Calculation of the Target Address</a></li>
<li><a href="#branching-and-the-prefetch-queue">Branching and the Prefetch Queue</a></li>
<li><a href="#branching-and-the-second-byte-of-the-branched-to-instruction">Branching and the Second Byte of the Branched-To Instruction</a></li>
</ul></li>
<li><a href="#chapter-13-not-branching">Chapter 13: Not-Branching</a><ul>
<li><a href="#think-functionally">Think Functionally</a></li>
<li><a href="#rep-looping-without-branching"><code>rep</code>: Looping Without Branching</a></li>
<li><a href="#look-up-tables-calculating-without-branching">Look-Up Tables: Calculating Without Branching</a></li>
<li><a href="#take-the-branch-less-travelled-by">Take the Branch Less Travelled By</a></li>
<li><a href="#yes-virginia-there-is-a-faster-32-bit-negate">Yes, Virginia, There <em>Is</em> a Faster 32-Bit Negate!</a></li>
<li><a href="#arrange-your-code-to-eliminate-branches">Arrange Your Code to Eliminate Branches</a></li>
<li><a href="#loop-may-not-be-bad-but-lord-knows-its-not-good-in-line-code"><code>loop</code> May Not Be Bad, but Lord Knows It’s Not Good: In-Line Code</a></li>
<li><a href="#a-note-on-self-modifying-code">A Note on Self-Modifying Code</a></li>
</ul></li>
<li><a href="#chapter-14-if-you-must-branch">Chapter 14: If You Must Branch…</a><ul>
<li><a href="#dont-go-far">Don’t Go Far</a></li>
<li><a href="#replacing-call-and-ret-with-jmp">Replacing <code>call</code> and <code>ret</code> With <code>jmp</code></a></li>
<li><a href="#use-int-only-when-you-must">Use <code>int</code> Only When You Must</a></li>
<li><a href="#forward-references-can-waste-time-and-space">Forward References Can Waste Time and Space</a></li>
<li><a href="#saving-space-with-branches">Saving Space With Branches</a></li>
<li><a href="#double-duty-tests">Double-Duty Tests</a></li>
<li><a href="#the-looping-instructions">The Looping Instructions</a></li>
<li><a href="#only-jcxz-can-test-and-branch-in-a-single-bound">Only <code>jcxz</code> Can Test <em>and</em> Branch in a Single Bound</a></li>
<li><a href="#jump-and-call-tables">Jump and Call Tables</a></li>
<li><a href="#forward-references-rear-their-collective-ugly-head-once-more">Forward References Rear Their Collective Ugly Head Once More</a></li>
</ul></li>
<li><a href="#chapter-15-other-processors">Chapter 15: Other Processors</a><ul>
<li><a href="#why-optimize-for-the-8088">Why Optimize for the 8088?</a></li>
<li><a href="#which-processors-matter">Which Processors Matter?</a></li>
<li><a href="#things-mother-never-told-you-part-ii">Things Mother Never Told You, Part II</a></li>
<li><a href="#new-instructions-and-features">New Instructions and Features</a></li>
<li><a href="#optimization-rules-the-more-things-change">Optimization Rules: The More Things Change…</a></li>
<li><a href="#popf-and-the-80286"><code>popf</code> and the 80286</a></li>
<li><a href="#coprocessors-and-peripherals">Coprocessors and Peripherals</a></li>
</ul></li>
<li><a href="#chapter-16-onward-to-the-flexible-mind">Chapter 16: Onward to the Flexible Mind</a><ul>
<li><a href="#a-taste-of-what-youve-learned">A Taste of What You’ve Learned</a></li>
<li><a href="#zenning">Zenning</a></li>
<li><a href="#knowledge-and-beyond">Knowledge and Beyond</a></li>
</ul></li>
<li><a href="#expanded-listings">Expanded Listings</a><ul>
<li><a href="#listing-2-1">Listing 2-1</a></li>
<li><a href="#listing-2-2">Listing 2-2</a></li>
<li><a href="#listing-2-3">Listing 2-3</a></li>
<li><a href="#listing-2-4">Listing 2-4</a></li>
<li><a href="#listing-2-5">Listing 2-5</a></li>
<li><a href="#listing-2-6">Listing 2-6</a></li>
<li><a href="#listing-2-7">Listing 2-7</a></li>
<li><a href="#listing-2-8">Listing 2-8</a></li>
<li><a href="#listing-3-1">Listing 3-1</a></li>
<li><a href="#listing-3-2">Listing 3-2</a></li>
<li><a href="#listing-4-1">Listing 4-1</a></li>
<li><a href="#listing-4-2">Listing 4-2</a></li>
<li><a href="#listing-4-3">Listing 4-3</a></li>
<li><a href="#listing-4-4">Listing 4-4</a></li>
<li><a href="#listing-4-5">Listing 4-5</a></li>
<li><a href="#listing-4-6">Listing 4-6</a></li>
<li><a href="#listing-4-7">Listing 4-7</a></li>
<li><a href="#listing-4-8">Listing 4-8</a></li>
<li><a href="#listing-4-9">Listing 4-9</a></li>
<li><a href="#listing-4-10">Listing 4-10</a></li>
<li><a href="#listing-4-11">Listing 4-11</a></li>
<li><a href="#listing-4-12">Listing 4-12</a></li>
<li><a href="#listing-5-1">Listing 5-1</a></li>
<li><a href="#listing-7-1">Listing 7-1</a></li>
<li><a href="#listing-7-2">Listing 7-2</a></li>
<li><a href="#listing-7-3">Listing 7-3</a></li>
<li><a href="#listing-7-4">Listing 7-4</a></li>
<li><a href="#listing-7-5">Listing 7-5</a></li>
<li><a href="#listing-7-6">Listing 7-6</a></li>
<li><a href="#listing-7-7">Listing 7-7</a></li>
<li><a href="#listing-7-8">Listing 7-8</a></li>
<li><a href="#listing-7-9">Listing 7-9</a></li>
<li><a href="#listing-7-10">Listing 7-10</a></li>
<li><a href="#listing-7-11">Listing 7-11</a></li>
<li><a href="#listing-7-12">Listing 7-12</a></li>
<li><a href="#listing-7-13">Listing 7-13</a></li>
<li><a href="#listing-7-14">Listing 7-14</a></li>
<li><a href="#listing-7-15">Listing 7-15</a></li>
<li><a href="#listing-7-16">Listing 7-16</a></li>
<li><a href="#listing-7-17">Listing 7-17</a></li>
<li><a href="#listing-7-18">Listing 7-18</a></li>
<li><a href="#listing-7-19">Listing 7-19</a></li>
<li><a href="#listing-7-20">Listing 7-20</a></li>
<li><a href="#listing-7-21">Listing 7-21</a></li>
<li><a href="#listing-8-1">Listing 8-1</a></li>
<li><a href="#listing-8-2">Listing 8-2</a></li>
<li><a href="#listing-8-3">Listing 8-3</a></li>
<li><a href="#listing-8-4">Listing 8-4</a></li>
<li><a href="#listing-8-5">Listing 8-5</a></li>
<li><a href="#listing-8-6">Listing 8-6</a></li>
<li><a href="#listing-8-7">Listing 8-7</a></li>
<li><a href="#listing-8-8">Listing 8-8</a></li>
<li><a href="#listing-8-9">Listing 8-9</a></li>
<li><a href="#listing-8-10">Listing 8-10</a></li>
<li><a href="#listing-8-11">Listing 8-11</a></li>
<li><a href="#listing-8-12">Listing 8-12</a></li>
<li><a href="#listing-8-13">Listing 8-13</a></li>
<li><a href="#listing-8-14">Listing 8-14</a></li>
<li><a href="#listing-8-15">Listing 8-15</a></li>
<li><a href="#listing-8-16">Listing 8-16</a></li>
<li><a href="#listing-8-17">Listing 8-17</a></li>
<li><a href="#listing-9-1">Listing 9-1</a></li>
<li><a href="#listing-9-2">Listing 9-2</a></li>
<li><a href="#listing-9-3">Listing 9-3</a></li>
<li><a href="#listing-9-4">Listing 9-4</a></li>
<li><a href="#listing-9-5">Listing 9-5</a></li>
<li><a href="#listing-9-6">Listing 9-6</a></li>
<li><a href="#listing-9-7">Listing 9-7</a></li>
<li><a href="#listing-9-8">Listing 9-8</a></li>
<li><a href="#listing-9-9">Listing 9-9</a></li>
<li><a href="#listing-9-10">Listing 9-10</a></li>
<li><a href="#listing-9-11">Listing 9-11</a></li>
<li><a href="#listing-9-12">Listing 9-12</a></li>
<li><a href="#listing-9-13">Listing 9-13</a></li>
<li><a href="#listing-9-14">Listing 9-14</a></li>
<li><a href="#listing-9-15">Listing 9-15</a></li>
<li><a href="#listing-9-16">Listing 9-16</a></li>
<li><a href="#listing-9-17">Listing 9-17</a></li>
<li><a href="#listing-9-18">Listing 9-18</a></li>
<li><a href="#listing-9-19">Listing 9-19</a></li>
<li><a href="#listing-9-20">Listing 9-20</a></li>
<li><a href="#listing-9-21">Listing 9-21</a></li>
<li><a href="#listing-9-22">Listing 9-22</a></li>
<li><a href="#listing-9-23">Listing 9-23</a></li>
<li><a href="#listing-9-24">Listing 9-24</a></li>
<li><a href="#listing-9-25">Listing 9-25</a></li>
<li><a href="#listing-9-26">Listing 9-26</a></li>
<li><a href="#listing-10-1">Listing 10-1</a></li>
<li><a href="#listing-10-2">Listing 10-2</a></li>
<li><a href="#listing-10-3">Listing 10-3</a></li>
<li><a href="#listing-10-4">Listing 10-4</a></li>
<li><a href="#listing-10-5">Listing 10-5</a></li>
<li><a href="#listing-10-6">Listing 10-6</a></li>
<li><a href="#listing-10-7">Listing 10-7</a></li>
<li><a href="#listing-10-8">Listing 10-8</a></li>
<li><a href="#listing-10-9">Listing 10-9</a></li>
<li><a href="#listing-10-10">Listing 10-10</a></li>
<li><a href="#listing-10-11">Listing 10-11</a></li>
<li><a href="#listing-10-12">Listing 10-12</a></li>
<li><a href="#listing-10-13">Listing 10-13</a></li>
<li><a href="#listing-10-14">Listing 10-14</a></li>
<li><a href="#listing-10-15">Listing 10-15</a></li>
<li><a href="#listing-10-16">Listing 10-16</a></li>
<li><a href="#listing-10-17">Listing 10-17</a></li>
<li><a href="#listing-10-18">Listing 10-18</a></li>
<li><a href="#listing-10-19">Listing 10-19</a></li>
<li><a href="#listing-11-1">Listing 11-1</a></li>
<li><a href="#listing-11-2">Listing 11-2</a></li>
<li><a href="#listing-11-3">Listing 11-3</a></li>
<li><a href="#listing-11-4">Listing 11-4</a></li>
<li><a href="#listing-11-5">Listing 11-5</a></li>
<li><a href="#listing-11-6">Listing 11-6</a></li>
<li><a href="#listing-11-7">Listing 11-7</a></li>
<li><a href="#listing-11-8">Listing 11-8</a></li>
<li><a href="#listing-11-9">Listing 11-9</a></li>
<li><a href="#listing-11-10">Listing 11-10</a></li>
<li><a href="#listing-11-11">Listing 11-11</a></li>
<li><a href="#listing-11-12">Listing 11-12</a></li>
<li><a href="#listing-11-13">Listing 11-13</a></li>
<li><a href="#listing-11-14">Listing 11-14</a></li>
<li><a href="#listing-11-15">Listing 11-15</a></li>
<li><a href="#listing-11-16">Listing 11-16</a></li>
<li><a href="#listing-11-17">Listing 11-17</a></li>
<li><a href="#listing-11-18">Listing 11-18</a></li>
<li><a href="#listing-11-19">Listing 11-19</a></li>
<li><a href="#listing-11-20">Listing 11-20</a></li>
<li><a href="#listing-11-21">Listing 11-21</a></li>
<li><a href="#listing-11-22">Listing 11-22</a></li>
<li><a href="#listing-11-23">Listing 11-23</a></li>
<li><a href="#listing-11-24">Listing 11-24</a></li>
<li><a href="#listing-11-25">Listing 11-25</a></li>
<li><a href="#listing-11-26">Listing 11-26</a></li>
<li><a href="#listing-11-27">Listing 11-27</a></li>
<li><a href="#listing-11-28">Listing 11-28</a></li>
<li><a href="#listing-11-29">Listing 11-29</a></li>
<li><a href="#listing-11-30">Listing 11-30</a></li>
<li><a href="#listing-11-31">Listing 11-31</a></li>
<li><a href="#listing-11-32">Listing 11-32</a></li>
<li><a href="#listing-11-33">Listing 11-33</a></li>
<li><a href="#listing-11-34">Listing 11-34</a></li>
<li><a href="#listing-12-1">Listing 12-1</a></li>
<li><a href="#listing-12-2">Listing 12-2</a></li>
<li><a href="#listing-12-3">Listing 12-3</a></li>
<li><a href="#listing-12-4">Listing 12-4</a></li>
<li><a href="#listing-12-5">Listing 12-5</a></li>
<li><a href="#listing-13-1">Listing 13-1</a></li>
<li><a href="#listing-13-2">Listing 13-2</a></li>
<li><a href="#listing-13-3">Listing 13-3</a></li>
<li><a href="#listing-13-4">Listing 13-4</a></li>
<li><a href="#listing-13-5">Listing 13-5</a></li>
<li><a href="#listing-13-6">Listing 13-6</a></li>
<li><a href="#listing-13-7">Listing 13-7</a></li>
<li><a href="#listing-13-8">Listing 13-8</a></li>
<li><a href="#listing-13-9">Listing 13-9</a></li>
<li><a href="#listing-13-10">Listing 13-10</a></li>
<li><a href="#listing-13-11">Listing 13-11</a></li>
<li><a href="#listing-13-12">Listing 13-12</a></li>
<li><a href="#listing-13-13">Listing 13-13</a></li>
<li><a href="#listing-13-14">Listing 13-14</a></li>
<li><a href="#listing-13-15">Listing 13-15</a></li>
<li><a href="#listing-13-16">Listing 13-16</a></li>
<li><a href="#listing-13-17">Listing 13-17</a></li>
<li><a href="#listing-13-18">Listing 13-18</a></li>
<li><a href="#listing-13-19">Listing 13-19</a></li>
<li><a href="#listing-13-20">Listing 13-20</a></li>
<li><a href="#listing-13-21">Listing 13-21</a></li>
<li><a href="#listing-13-22">Listing 13-22</a></li>
<li><a href="#listing-13-23">Listing 13-23</a></li>
<li><a href="#listing-13-24">Listing 13-24</a></li>
<li><a href="#listing-13-25">Listing 13-25</a></li>
<li><a href="#listing-13-26">Listing 13-26</a></li>
<li><a href="#listing-13-27">Listing 13-27</a></li>
<li><a href="#listing-14-1">Listing 14-1</a></li>
<li><a href="#listing-14-2">Listing 14-2</a></li>
<li><a href="#listing-14-3">Listing 14-3</a></li>
<li><a href="#listing-14-4">Listing 14-4</a></li>
<li><a href="#listing-14-5">Listing 14-5</a></li>
<li><a href="#listing-14-6">Listing 14-6</a></li>
<li><a href="#listing-14-7">Listing 14-7</a></li>
<li><a href="#listing-14-8">Listing 14-8</a></li>
<li><a href="#listing-14-9">Listing 14-9</a></li>
<li><a href="#listing-14-10">Listing 14-10</a></li>
<li><a href="#listing-14-11">Listing 14-11</a></li>
<li><a href="#listing-14-12">Listing 14-12</a></li>
<li><a href="#listing-14-13">Listing 14-13</a></li>
<li><a href="#listing-14-14">Listing 14-14</a></li>
<li><a href="#listing-14-15">Listing 14-15</a></li>
<li><a href="#listing-14-16">Listing 14-16</a></li>
<li><a href="#listing-15-1">Listing 15-1</a></li>
<li><a href="#listing-15-2">Listing 15-2</a></li>
<li><a href="#listing-15-3">Listing 15-3</a></li>
<li><a href="#listing-15-4">Listing 15-4</a></li>
<li><a href="#listing-15-5">Listing 15-5</a></li>
<li><a href="#lztest">LZTEST</a></li>
<li><a href="#lztime.bat">LZTIME.BAT</a></li>
<li><a href="#lztime">LZTIME</a></li>
<li><a href="#lztimer">LZTIMER</a></li>
<li><a href="#pztest">PZTEST</a></li>
<li><a href="#pztime.bat">PZTIME.BAT</a></li>
<li><a href="#pztimer">PZTIMER</a></li>
</ul></li>
<li><a href="#appendix-a-80868088-instruction-set-reference">Appendix A: 8086/8088 Instruction Set Reference</a><ul>
<li><a href="#notes-on-the-instruction-set-reference">Notes on the Instruction Set Reference</a></li>
<li><a href="#aaa-ascii-adjust-after-addition">AAA ASCII adjust after addition</a></li>
<li><a href="#aad-ascii-adjust-before-division">AAD ASCII adjust before division</a></li>
<li><a href="#aam-ascii-adjust-after-multiplication">AAM ASCII adjust after multiplication</a></li>
<li><a href="#aas-ascii-adjust-after-subtraction">AAS ASCII adjust after subtraction</a></li>
<li><a href="#adc-arithmetic-add-with-carry">ADC Arithmetic add with carry</a></li>
<li><a href="#add-arithmetic-add-ignore-carry">ADD Arithmetic add (ignore carry)</a></li>
<li><a href="#and-logical-and">AND Logical and</a></li>
<li><a href="#call-call-subroutine">CALL Call subroutine</a></li>
<li><a href="#cbw-convert-signed-byte-in-al-to-signed-word-in-ax">CBW Convert signed byte in AL to signed word in AX</a></li>
<li><a href="#clc-clear-carry-flag">CLC Clear Carry flag</a></li>
<li><a href="#cld-clear-direction-flag">CLD Clear Direction flag</a></li>
<li><a href="#cli-clear-interrupt-flag">CLI Clear Interrupt flag</a></li>
<li><a href="#cmc-complement-carry-flag">CMC Complement Carry flag</a></li>
<li><a href="#cmp-compare-by-subtracting-without-saving-result">CMP Compare by subtracting without saving result</a></li>
<li><a href="#cmps-compare-string">CMPS Compare string</a></li>
<li><a href="#cwd-convert-signed-word-in-ax-to-signed-doubleword-in-dxax">CWD Convert signed word in AX to signed doubleword in DX:AX</a></li>
<li><a href="#daa-decimal-adjust-after-addition">DAA Decimal adjust after addition</a></li>
<li><a href="#das-decimal-adjust-after-subtraction">DAS Decimal adjust after subtraction</a></li>
<li><a href="#dec-decrement-operand">DEC Decrement operand</a></li>
<li><a href="#div-unsigned-divide">DIV Unsigned divide</a></li>
<li><a href="#hlt-halt">HLT Halt</a></li>
<li><a href="#idiv-signed-divide">IDIV Signed divide</a></li>
<li><a href="#imul-signed-multiply">IMUL Signed multiply</a></li>
<li><a href="#in-input-byte-from-io-port">IN Input byte from I/O port</a></li>
<li><a href="#inc-increment-operand">INC Increment operand</a></li>
<li><a href="#int-software-interrupt">INT Software interrupt</a></li>
<li><a href="#into-execute-int-4-if-overflow-flag-set">INTO Execute int 4 if Overflow flag set</a></li>
<li><a href="#iret-return-from-interrupt">IRET Return from interrupt</a></li>
<li><a href="#j-jump-on-condition">J? Jump on condition</a></li>
<li><a href="#jcxz-jump-if-cx-0">JCXZ Jump if CX = 0</a></li>
<li><a href="#jmp-jump">JMP Jump</a></li>
<li><a href="#lahf-load-ah-from-8080-flags">LAHF Load AH from 8080 flags</a></li>
<li><a href="#lds-load-ds-pointer">LDS Load DS pointer</a></li>
<li><a href="#lea-load-effective-address">LEA Load effective address</a></li>
<li><a href="#les-load-es-pointer">LES Load ES pointer</a></li>
<li><a href="#lods-load-string">LODS Load string</a></li>
<li><a href="#loop-loop-while-cx-not-equal-to-0">LOOP Loop while CX not equal to 0</a></li>
<li><a href="#loopnz-loop-while-cx-not-equal-to-0-and-zero-flag-equal-to-0">LOOPNZ Loop while CX not equal to 0 and Zero flag equal to 0</a></li>
<li><a href="#loopz-loop-while-cx-not-equal-to-0-and-zero-flag-equal-to-1">LOOPZ Loop while CX not equal to 0 and Zero flag equal to 1</a></li>
<li><a href="#loope-loop-while-cx-not-equal-to-0-and-last-result-was-equal">LOOPE Loop while CX not equal to 0 and last result was equal</a></li>
<li><a href="#mov-move-copy-right-operand-into-left-operand">MOV Move (copy) right operand into left operand</a></li>
<li><a href="#movs-move-string">MOVS Move string</a></li>
<li><a href="#mul-unsigned-multiply">MUL Unsigned multiply</a></li>
<li><a href="#neg-negate-twos-complement-i.e.multiply-by-1">NEG Negate (two’s complement; i.e. multiply by 1)</a></li>
<li><a href="#nop-no-operation">NOP No operation</a></li>
<li><a href="#not-logical-not-ones-complement">NOT Logical not (one’s complement)</a></li>
<li><a href="#or-logical-or">OR Logical or</a></li>
<li><a href="#out-output-byte-to-io-port">OUT Output byte to I/O port</a></li>
<li><a href="#pop-pop-from-top-of-stack">POP Pop from top of stack</a></li>
<li><a href="#popf-pop-top-of-stack-into-flags-reg">POPF Pop top of stack into FLAGS reg</a></li>
<li><a href="#push-push-onto-top-of-stack">PUSH Push onto top of stack</a></li>
<li><a href="#pushf-push-flags-register-onto-top-of-stack">PUSHF Push FLAGS register onto top of stack</a></li>
<li><a href="#rcl-rotate-through-carry-left">RCL Rotate through carry left</a></li>
<li><a href="#rcr-rotate-through-carry-right">RCR Rotate through carry right</a></li>
<li><a href="#ret-return-from-subroutine-call">RET Return from subroutine call</a></li>
<li><a href="#rol-rotate-left">ROL Rotate left</a></li>
<li><a href="#ror-rotate-right">ROR Rotate right</a></li>
<li><a href="#sahf-store-ah-to-8080-flags">SAHF Store AH to 8080 flags</a></li>
<li><a href="#sar-shift-arithmetic-right">SAR Shift arithmetic right</a></li>
<li><a href="#sbb-arithmetic-subtract-with-borrow">SBB Arithmetic subtract with borrow</a></li>
<li><a href="#scas-scan-string">SCAS Scan string</a></li>
<li><a href="#shl-shift-logical-left">SHL Shift logical left</a></li>
<li><a href="#shr-shift-logical-right">SHR Shift logical right</a></li>
<li><a href="#stc-set-carry-flag">STC Set Carry flag</a></li>
<li><a href="#std-set-direction-flag">STD Set Direction flag</a></li>
<li><a href="#sti-set-interrupt-flag">STI Set Interrupt flag</a></li>
<li><a href="#stos-store-string">STOS Store string</a></li>
<li><a href="#sub-arithmetic-subtraction-no-borrow">SUB Arithmetic subtraction (no borrow)</a></li>
<li><a href="#test-compare-by-anding-without-saving-result">TEST Compare by anding without saving result</a></li>
<li><a href="#wait-wait-for-interrupt-or-test-signal">WAIT Wait for interrupt or test signal</a></li>
<li><a href="#xchg-exchange-operands">XCHG Exchange operands</a></li>
<li><a href="#xlat-translate-from-table">XLAT Translate from table</a></li>
<li><a href="#xor-exclusive-or">XOR Exclusive or</a></li>
</ul></li>
<li><a href="#appendix-b-ascii-table-and-pc-character-set">Appendix B: ASCII Table And PC Character Set</a></li>
<li><a href="#about-this-version">About this version</a><ul>
<li><a href="#the-ron-welch-version">The Ron Welch version</a></li>
</ul></li>
</ul>
</nav>
<section id="acknowledgements" class="level1">
<h1>Acknowledgements</h1>
<p>Special thanks to Jeff Duntemann, who made it all happen, to Noah Oremland, who proofed every word, encouraged me, and even laughed at my jokes, and to Amy Davis of Scott, Foresman &amp; Co., who made this book possible. Thanks also to Tom Blakeslee, John T. Cockerham, Dan Gochnauer, Dan Illowsky, Bob Jervis, Dave Miller, Ted Mirecki, Phil Mummah, Kent Porter, and Tom Wilson for information, feedback and encouragement. Finally, thanks to Orion Instruments for the use of an OmniLab.</p>
<p>For Shay and Emily.</p>
</section>
<section id="trademarks" class="level1">
<h1>Trademarks</h1>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Term</th>
<th style="text-align: left;">Company</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">OS/2</td>
<td style="text-align: left;">Microsoft Corp.</td>
</tr>
<tr class="even">
<td style="text-align: left;">Microsoft Macro Assembler</td>
<td style="text-align: left;">Microsoft Corp.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Microsoft Linker</td>
<td style="text-align: left;">Microsoft Corp.</td>
</tr>
<tr class="even">
<td style="text-align: left;">Symdeb</td>
<td style="text-align: left;">Microsoft Corp.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">CodeView</td>
<td style="text-align: left;">Microsoft Corp.</td>
</tr>
<tr class="even">
<td style="text-align: left;">MS-DOS</td>
<td style="text-align: left;">Microsoft Corp.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Turbo C</td>
<td style="text-align: left;">Borland International, Inc.</td>
</tr>
<tr class="even">
<td style="text-align: left;">Turbo Debugger</td>
<td style="text-align: left;">Borland International, Inc.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Turbo Linker</td>
<td style="text-align: left;">Borland International, Inc.</td>
</tr>
<tr class="even">
<td style="text-align: left;">Turbo Assembler</td>
<td style="text-align: left;">Borland International, Inc.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Sidekick</td>
<td style="text-align: left;">Borland International, Inc.</td>
</tr>
<tr class="even">
<td style="text-align: left;">OPTASM</td>
<td style="text-align: left;">SLR Systems</td>
</tr>
<tr class="odd">
<td style="text-align: left;">OmniLab</td>
<td style="text-align: left;">Orion Instruments, Inc.</td>
</tr>
<tr class="even">
<td style="text-align: left;">IBM</td>
<td style="text-align: left;">International Business Machines Corp.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">PC</td>
<td style="text-align: left;">International Business Machines Corp.</td>
</tr>
<tr class="even">
<td style="text-align: left;">AT</td>
<td style="text-align: left;">International Business Machines Corp.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">PS/2</td>
<td style="text-align: left;">International Business Machines Corp.</td>
</tr>
<tr class="even">
<td style="text-align: left;">PCjr</td>
<td style="text-align: left;">International Business Machines Corp.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Unix</td>
<td style="text-align: left;">AT&amp;T</td>
</tr>
<tr class="even">
<td style="text-align: left;">MacIntosh</td>
<td style="text-align: left;">Apple</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Wordstar</td>
<td style="text-align: left;">Micropro International</td>
</tr>
<tr class="even">
<td style="text-align: left;">Visicalc</td>
<td style="text-align: left;">Visicorp</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Amiga</td>
<td style="text-align: left;">Commodore</td>
</tr>
</tbody>
</table>
</section>
<section id="introduction-pushing-the-envelope" class="level1">
<h1>Introduction: Pushing the Envelope</h1>
<p>This is the book I wished for with all my heart seven years ago, when I started programming the IBM PC: the book that unlocks the secrets of writing superb assembly-language code. There was no such book then, so I had to learn the hard way, through experimentation and through trial and error. Over the years, I waited in vain for that book to appear; I looked everywhere without success for a book about advanced assembly-language programming, a book written specifically for assembly-language programmers who want to get better, rather than would-be assembly-language programmers. I’m sure many of you have waited for such a book as well. Well, wait no longer: this is that book.</p>
<p><em>The Zen of Assembly Language</em> assumes that you’re already familiar with assembly language. Not an expert, but at least acquainted with the registers and instructions of the 8088, and with the use of one of the popular PC assemblers. Your familiarity with assembly language will allow us to skip over the droning tutorials about the use of the assembler and the endless explanations of binary arithmetic that take up hundreds of pages in introductory books. We’re going to jump into high-performance programming right from the start, and when we come up for air 16 chapters from now, your view of assembly language will be forever altered for the better. Then we’ll leap right back into Volume II, applying our newfound knowledge of assembly language to ever-more-sophisticated programming tasks.</p>
<p>In short, <em>The Zen of Assembler</em> is about nothing less than how to become the best assembly-language programmer you can be.</p>
<section id="why-assembly-language" class="level2">
<h2>Why Assembly Language?</h2>
<p>For years, people have been predicting — hoping for — the demise of assembly language, claiming that the world is ready to move on to less primitive approaches to programming… and for years, the best programs around have been written in assembly language. Why is this? Simply because assembly language is hard to work with, but — properly used — produces programs of unparalleled performance. Mediocre programmers have a terrible time working with assembly language; on the other hand, assembly language is, without fail, the language that PC gurus use when they need the best possible code.</p>
<p>Which brings us to you.</p>
<p>Do you want to be a guru? I’d imagine so, if you’re reading this book. You’ve set yourself an ambitious and difficult goal, and your success is far from guaranteed. There’s no sure-fire recipe for becoming a guru, any more than there’s a recipe for becoming a chess grand master. There is, however, one way you can greatly improve your chances: become an expert assembly language programmer. Assembly language won’t by itself make you a guru — but without it you’ll never reach your full potential as a programmer.</p>
<p>Why is assembly language so important in this age of optimizing compilers and program generators? Assembly language is fundamentally different from all other languages, as we’ll see throughout <em>The Zen of Assembly Language</em>. Assembly language lets you use every last resource of the PC to push the performance envelope; only in assembly language can you press right up against the inherent limits of the PC.</p>
<p>If you aren’t pushing the envelope, there’s generally no reason to program in assembler. High-level languages are certainly easier to use, and nowadays most high-level languages let you get at the guts of the PC — display memory, DOS functions, interrupt vectors, and so on — without having to resort to assembler. If, in the other hand, you’re striving for the sort of performance that will give your programs snappy interfaces and crackling response times, you’ll find assembly language to be almost magical, for no other language even approaches assembler for sheer speed.</p>
<p>Of course, no one tests the limits of the PC with their first assembler program; that takes time and practice. While many PC programmers know something about assembler, few are experts. The typical programmer has typed in the assembler code from an article or two, read a book about assembler programming, and perhaps written a few assembler programs of his own — but doesn’t yet feel that he has mastered the language. If you fall into this category, you’ve surely sensed the remarkable potential of assembler, but you’re also keenly aware of how hard it is to write good assembler code and how much you have yet to learn. In all likelihood, you’re not sure how to sharpen your assembler skills and take that last giant step toward mastery of your PC.</p>
<p>This book is for you.</p>
<p>Welcome to the most exciting and esoteric aspect of the IBM PC. <em>The Zen of Assembly Language</em> will teach you how to create blindingly fast code for the IBM PC. More important still, it will teach you how to continue to develop your assembler programming skills on your own. <em>The Zen of Assembly Language</em> will show you a way to learn what you need to know as the need arises, and it is that way of learning that will serve you well for years to come. There are facts and code aplenty in this book and in the companion volume, but it is a way of thinking and learning that lies at the heart of <em>The Zen of Assembly Language</em>.</p>
<p>Don’t take the title to mean that this is a mystical book in any way. In the context of assembly-language programming, Zen is a technique that brings intuition and non-obvious approaches to bear on difficult problems and puzzles. If you would rather think of high-performance assembler programming as something more mundane, such as right-brained thinking or plain old craftsmanship, go right ahead; good assembler programming is a highly individualized process.</p>
<p><em>The Zen of Assembly Language</em> is specifically about assembly language for the IBM PC (and, by definition, compatible computers). In particular, the bulk of this volume will focus on the capabilities of the 8088 processor that lies at the heart of the PC. However, many of the findings and almost all of the techniques I’ll discuss can also be applied to assembly-language programming for the other members of Intel’s 808X processor family, including the 80286 and 80386 processors, as we’ll see toward the end of this volume. <em>The Zen of Assembly Language</em> doesn’t much apply to computers built around other processors, such as the 68XXX family, the Z80, the 8080, or the 6502, since a great deal of the Zen of assembly language in the case of the IBM PC derives from the highly unusual architecture of the 808X family. (In fact, the processors in the 808X family lend themselves beautifully to assembly language, much more so than other currently-popular processors.)</p>
<p>While I will spend a chapter looking specifically at the 80286 found in the AT and PS/2 Models 50 and 60 and at the 80386 found in the PS/2 Model 80, I’ll concentrate primarily on the 8088 processor found in the IBM PC and XT, for a number of reasons. First, there are at least 15,000,000 8088-based computers around, ensuring that good 8088 code isn’t going to go out of style anytime soon. Second, the 8088 is far and away the slowest of the processors used in IBM-compatible computers, so no matter how carefully code is tailored to the subtleties of the 8088, it’s still going to run much faster on an 80286 or 80386. Third, many of the concepts I’ll present regarding the 8088 apply to the 80286 and 80386 as well, but to a different degree. Given that there are simply too many processors around to cover in detail (and the 80486 on the way), I’d rather pay close attention to the 8088, the processor for which top-quality code is most critical, and provide you with techniques that will allow you to learn on your own how best to program other processors.</p>
<p>We’ll return to this topic in Chapter 15, when we will in fact discuss other 808X-family processors, but for now, take my word for it: when it comes to optimization, the 8088 is the processor of choice.</p>
</section>
<section id="what-youll-need" class="level2">
<h2>What You’ll Need</h2>
<p>The tools you’ll need to follow this book are simple: a text editor to create ASCII program files, the Microsoft Macro Assembler version 5.0 or a compatible assembler (Turbo Assembler is fine) to assemble programs, and the Microsoft Linker or a compatible linker to link programs into an executable form.</p>
<p>There are several types of reference material you should have available as you pursue assembler mastery. You will certainly want a general reference on 8088 assembler. <em>The 8086 Book</em>, written by Rector and Alexy and published by Osborne/McGraw-Hill, is a good reference, although you should beware of its unusually high number of typographic errors. Also useful is the spiral-bound reference manual that comes with MASM, which contains an excellent summary of the instruction sets of the 8088, 8086, 80186, 80286, and 80386. IBM’s hardware, BIOS, and DOS technical reference manuals are also useful references, containing as they do detailed information about the resources available to assembler programmers.</p>
<p>If you’re the type who digs down to the hardware of the PC in the pursuit of knowledge, you’ll find Intel’s handbooks and reference manuals to be invaluable (albeit none too easy to read), since Intel manufactures the 8088 and many of the support chips used in the PC. There’s simply no way to understand what a hardware component is capable of doing in the context of the PC without a comprehensive description of everything that part can do, and that’s exactly what Intel’s literature provides.</p>
<p>Finally, keep an eye open for articles on assembly-language programming. Articles provide a steady stream of code from diverse sources, and are your best sources of new approaches to assembler programming.</p>
<p>By the way, the terms “assembler” and “assembly-language” are generally interchangeable. While “assembly-language” is perhaps technically more accurate, since “assembler” also refers to the software that assembles assembly-language code, “assembler” is a widely-used shorthand that I’ll use throughout this book. Similarly, I’ll use “the Zen of assembler” as shorthand for “the Zen of assembly language.”</p>
</section>
<section id="odds-and-ends" class="level2">
<h2>Odds and Ends</h2>
<p>I’d like to identify the manufacturers of the products I’ll refer to in this volume. Microsoft makes the Microsoft Macro Assembler (MASM), the Microsoft Linker (LINK), CodeView (CV), and Symdeb (SYMDEB). Borland International makes Turbo Assembler (TASM), Turbo C (TC), Turbo Link (TLINK), and Turbo Debugger (TD). SLR Systems makes OPTASM, an assembler. Finally, Orion Instruments makes OmniLab, which integrates high-performance oscilloscope, logic analyzer, stimulus generator, and disassembler instrumentation in a single PC-based package.</p>
<p>In addition, I’d like to point out that while I’ve made every effort to ensure that the code in this volume works as it should, no one’s perfect. Please let me know if you find bugs. Also, please let me know what works for you and what doesn’t in this book; teaching is not a one-way street. You can write me at:</p>
<p>1599 Bittern Drive</p>
<p>Sunnyvale, CA 94087</p>
</section>
<section id="the-path-to-the-zen-of-assembler" class="level2">
<h2>The Path to the Zen of Assembler</h2>
<p><em>The Zen of Assembly Language</em> consists of four major parts, contained in two volumes. Parts I and II are in this volume, Volume I, while Parts III and IV are in Volume II, <em>The Zen of Assembly Language: The Flexible Mind</em>. While the book you’re reading stands on its own as a tutorial in high-performance assembler code, the two volumes together cover the whole of superior assembler programming, from hardware to implementation. I strongly recommend that you read both. The four parts of <em>The Zen of Assembly Language</em> are organized as follows.</p>
<p>Part I introduces the concept of the Zen of assembler, and presents the tools we’ll use to delve into assembler code performance.</p>
<p>Part II covers various and sundry pieces of knowledge about assembler programming, examines the resources available when programming the PC, and probes fundamental hardware aspects that affect code performance.</p>
<p>Part III (in Volume II) examines the process of creating superior code, combining the detailed knowledge of Part II with varied and often unorthodox coding approaches.</p>
<p>Part IV (also in Volume II) illustrates the Zen of assembler in the form of a working animation program.</p>
<p>In general, Parts I and II discuss the raw stuff of performance, while Parts III and IV show how to integrate that raw performance with algorithms and applications, although there is considerable overlap. The four parts together teach all aspects of the Zen of assembler: concept, knowledge, the flexible mind, and implementation. Together, we will follow that path down the road to mastery of the IBM PC.</p>
<p>Shall we begin?</p>
<p>Michael Abrash</p>
<p>Sunnyvale, CA</p>
<p>May 29, 1989</p>
</section>
</section>
<section id="chapter-1-zen" class="level1">
<h1>Chapter 1: Zen?</h1>
<p>What is the Zen of assembler? Many things: a set of programming skills that lets you write incredibly fast programs, a technique for turning ideas into code, a process of looking at problems in new ways and finding fresh solutions, and more. Perhaps a brief story would be the best way to introduce the Zen of assembler.</p>
<section id="the-zen-of-assembler-in-a-nutshell" class="level2">
<h2>The Zen of Assembler in a Nutshell</h2>
<p>Some time ago, I was asked to work over a critical assembler subroutine in order to make it run as fast as possible. The task of the subroutine was to construct a nibble out of four bits read from different bytes, rotating and combining the bits so that they ultimately ended up neatly aligned in bits 3-0 of a single byte. (In case you’re curious, the object was to construct a 16-color pixel from bits scattered over 4 bytes.) I examined the subroutine line by line, saving a cycle here and a cycle there, until the code truly seemed to be optimized. When I was done, the key part of the code looked something like this:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="fu">LoopTop:</span>
  <span class="kw">lodsb</span>          <span class="co">;get the next byte to extract a bit from</span>
  <span class="kw">and</span>    <span class="kw">al</span>,<span class="kw">ah</span>   <span class="co">;isolate the bit we want</span>
  <span class="kw">rol</span>    <span class="kw">al</span>,<span class="kw">cl</span>   <span class="co">;rotate the bit into the desired position</span>
  <span class="kw">or</span>     <span class="kw">bl</span>,<span class="kw">al</span>   <span class="co">;insert the bit into the final nibble</span>
  <span class="kw">dec</span>    <span class="kw">cx</span>      <span class="co">;the next bit goes 1 place to the right</span>
  <span class="kw">dec</span>    <span class="kw">dx</span>      <span class="co">;count down the number of bits</span>
  <span class="kw">jnz</span>    LoopTop <span class="co">;process the next bit, if any</span></code></pre>
<p>Now, it’s hard to write code that’s much faster than seven assembler instructions, only one of which accesses memory, and most programmers would have called it a day at this point; still, something bothered me, so I spent a bit of time going over the code again. Suddenly, the answer struck me — the code was rotating each bit into place separately, so that a multi-bit rotation was being performed every time through the loop, for a total of four separate time-consuming multi-bit rotations! <em>While the instructions themselves were individually optimized, the overall approach did not make the best possible use of the instructions.</em></p>
<p>I changed the code to the following:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="fu">LoopTop:</span>
  <span class="kw">lodsb</span>          <span class="co">;get the next byte to extract a bit from</span>
  <span class="kw">and</span>    <span class="kw">al</span>,<span class="kw">ah</span>   <span class="co">;isolate the bit we want</span>
  <span class="kw">or</span>     <span class="kw">bl</span>,<span class="kw">al</span>   <span class="co">;insert the bit into the final nibble</span>
  <span class="kw">rol</span>    <span class="kw">bl</span>,<span class="dv">1</span>    <span class="co">;make room for the next bit</span>
  <span class="kw">dec</span>    <span class="kw">dx</span>      <span class="co">;count down the number of bits</span>
  <span class="kw">jnz</span>    LoopTop <span class="co">;process the next bit, if any</span>
  <span class="kw">rol</span>    <span class="kw">bl</span>,<span class="kw">cl</span>   <span class="co">;rotate all four bits into their final</span>
                 <span class="co">; positions at the same time</span></code></pre>
<p>This moved the costly multi-bit rotation out of the loop, so that it was performed just once, rather than four times. While the new code may not look much different from the original, and in fact still contains exactly the same number of instructions, the performance of the entire subroutine improved by about 10% from just this one change. (Incidentally, that wasn’t the end of the optimization; I eliminated the <code class="sourceCode nasm"><span class="kw">dec</span></code> and <code class="sourceCode nasm"><span class="kw">jnz</span></code> instructions by expanding the four iterations of the loop into in-line code — but that’s a tale for another chapter.)</p>
<p>The point is this: to write truly superior assembler programs, you need to know what the various instructions do and which instructions execute fastest… and more. You must also learn to look at your programming problems from a variety of perspectives, so that you can put those fast instructions to work in the most effective ways. And, that, in a nutshell, is the Zen of assembler.</p>
</section>
<section id="assembler-is-fundamentally-different-from-other-languages" class="level2">
<h2>Assembler is Fundamentally Different from Other Languages</h2>
<p>Is it really so hard as all that to write good assembler code for the IBM PC? Yes! Thanks to the decidedly quirky nature of the 8088 processor, assembly language differs fundamentally from other languages, and is undeniably harder to work with. On the other hand, the potential of assembler code is much greater than that of other languages, as well. The Zen of assembler is the way to tap that potential.</p>
<p>To understand why this is, consider how a program gets written. A programmer examines the requirements of an application, designs a solution at some level of abstraction, and then makes that design come alive in a code implementation. If not handled properly, the transformation that takes place between conception and implementation can reduce performance tremendously; for example, a programmer who implements a routine to search a list of 100,000 sorted items with a linear rather than binary search will end up with a disappointingly slow program.</p>
<p>No matter how well an implementation is derived from the corresponding design, however, high-level languages like C and Pascal inevitably introduce additional transformation inefficiencies, as shown in Figure 1.1.</p>
<figure>
<img src="images/fig1.1RT.png" />
</figure>
<p>High-level languages provide artificial environments that lend themselves relatively well to human programming skills, in order to ease the transition from design to implementation. The price for this ease of implementation is a considerable loss of efficiency in transforming source code into machine language. This is particularly true given that the 8088, with its specialized memory-addressing instructions and segmented memory architecture, does not lend itself particularly well to compiler design.</p>
<p>Assembler, on the other hand, is simply a human-oriented representation of machine language. As a result, assembler provides a difficult programming environment — the bare hardware and systems software of the computer — <em>but properly constructed assembler programs suffer no transformation loss</em>, as shown in Figure 1.2.</p>
<figure>
<img src="images/fig1.2RT.png" />
</figure>
<p>The key, of course, is the programmer, since in assembler the programmer must essentially perform the transformation from the application specification to machine language entirely on his own. (The assembler merely handles the direct translation from assembler to machine language.)</p>
<p>The first part of the Zen of assembler, then, is self-reliance. An assembler is nothing more than a tool to let you design machine-language programs without having to think in hexadecimal codes, so assembly-language programmers — unlike all other programmers — must take full responsibility for the quality of their code. Since assemblers provide little help at any level higher than the generation of machine language, the assembler programmer must be capable both of coding any programming construct directly and of controlling the PC at the lowest practical level — the operating system, the BIOS, the hardware where necessary. High-level languages handle most of this transparently to the programmer, but in assembler everything is fair — and necessary — game, which brings us to another aspect of the Zen of assembler.</p>
<p>Knowledge.</p>
</section>
<section id="knowledge" class="level2">
<h2>Knowledge</h2>
<p>In the IBM PC world, you can never have enough knowledge, and every item you add to your store will make your programs better. Thorough familiarity with both the operating system and BIOS interfaces is important; since those interfaces are well-documented and reasonably straightforward, my advice is to get IBM’s documentation and a good book or two and bring yourself up to speed. Similarly, familiarity with the hardware of the IBM PC is required. While that topic covers a lot of ground — display adapters, keyboards, serial ports, printer ports, timer and DMA channels, memory organization, and more — most of the hardware is well-documented, and articles about programming major hardware components appear frequently, so this sort of knowledge can be acquired readily enough.</p>
<p>The single most critical aspect of the hardware, and the one about which it is hardest to learn, is the 8088 processor. The 8088 has a complex, irregular instruction set, and, unlike most processors, the 8088 is neither straightforward nor well-documented as regards true code performance. What’s more, assembler is so difficult to learn that most articles and books which present assembler code settle for code that works, rather than code that pushes the 8088 to its limits. In fact, since most articles and books are written for inexperienced assembler programmers, there is very little information of any sort available about how to generate high-quality assembler code for the 8088. As a result, knowledge about programming the 8088 effectively is by far the hardest knowledge to gather. A good portion of this book is devoted to seeking out such knowledge. Be forewarned, though: no matter how much you learn about programming the IBM PC in assembler, there’s always more to discover.</p>
</section>
<section id="the-flexible-mind" class="level2">
<h2>The Flexible Mind</h2>
<p>Is the never-ending collection of information all there is to the Zen of assembler, then? Hardly. Knowledge is simply a necessary base on which to build. Let’s take a moment to examine the objectives of good assembler programming, and the remainder of the Zen of assembler will fall into place.</p>
<p>Basically, there are only two possible objectives to high-performance assembler programming: given the requirements of the application, keep to a minimum either the number of processor cycles the program takes to run or the number of bytes in the program, or some combination of both. We’ll look at ways to achieve both objectives, but we’ll more often be concerned with saving cycles than saving bytes, for the PC offers relatively more memory than it does processing horsepower. In fact, we’ll find that 2-to-3 times performance improvements <em>over tight assembler code</em> are often possible if we’re willing to expend additional bytes in order to save cycles. It’s not always desirable to use such techniques to speed up code, due to the heavy memory requirements — but it is almost always possible.</p>
<p>You will notice that my short list of objectives for high-performance assembler programming does not include traditional objectives such as easy maintenance and speed of development. Those are indeed important considerations — to persons and companies that develop and distribute software. People who actually <em>buy</em> software, on the other hand, care only about how well that software performs, not how it was developed. Nowadays, developers spend so much time focusing on such admittedly important issues as code maintainability and reusability, source code control, choice of development environment, and the like that they forget rule #1: from the user’s perspective, performance is fundamental. Comment your code, design it carefully, and write non-time-critical portions in a high-level language, if you wish — but when you write the portions that interact with the user and/or affect response time, performance must be your paramount objective, and assembler is the path to that goal.</p>
<p>Knowledge of the sort described earlier is absolutely essential to fulfilling either of the objectives of assembler programming. What that knowledge doesn’t by itself do is meet the need to write code that both performs to the requirements of the application at hand and operates in the PC environment as efficiently as possible. Knowledge makes that possible, but your programming instincts make it happen. And it is that intuitive, on-the-fly integration of a program specification and a sea of facts about the PC that is the heart of the Zen of assembler.</p>
<p>As with Zen of any sort, mastering the Zen of assembler is more a matter of learning than of being taught. You will have to find your own path of learning, although I will start you on your way with this book. The subtle facts and examples I provide will help you gain the necessary experience, but you must continue the journey on your own. Each program you create will expand your programming horizons and increase the options available to you in meeting the next challenge. The ability of your mind to find surprising new and better ways to craft superior code from a concept — the flexible mind, if you will — is the linchpin of good assembler code, and you will develop this skill only by doing.</p>
<p>Never underestimate the importance of the flexible mind. Good assembler code is better than good compiled code. Many people would have you believe otherwise, but they’re wrong. That doesn’t mean high-level languages are useless; far from it. High-level languages are the best choice for the majority of programmers, and for the bulk of the code of most applications. When the <em>best</em> code — the fastest or smallest code possible — is needed, though, assembler is the only way to go.</p>
<p>Simple logic dictates that no compiler can know as much about what a piece of code needs to do or adapt as well to those needs as the person who wrote the code. Given that superior information and adaptability, an assembly-language programmer can generate better code than a compiler, all the more so given that compilers are constrained by the limitations of high-level languages and by the process of transformation from high-level to machine language. Consequently, carefully optimized assembler is not just the language of choice but the <em>only</em> choice for the 1% to 10% of all code — usually consisting of small, well-defined subroutines — that determines overall program performance, and is the only choice for code that must be as compact as possible, as well. In the run-of-the-mill, non-time-critical portions of your programs, it makes no sense to waste time and effort on writing optimized assembler code — concentrate your efforts on loops and the like instead — but in those areas where you need the finest code quality, accept no substitutes.</p>
<p>Note that I said that an assembler programmer <em>can</em> generate better code than a compiler, not <em>will</em> generate better code. While it is true that good assembler code is better than good compiled code, it is also true that bad assembler code is often much worse than bad compiled code; since the assembler programmer has so much control over the program, he or she has unlimited opportunity to waste cycles and bytes. The sword cuts both ways, and good assembler code requires more, not less, forethought and planning than good code written in a high-level language.</p>
<p>The gist of all this is simply that good assembler programming is done in the context of a solid overall framework unique to each program, and the flexible mind is the key to creating that framework and holding it together.</p>
</section>
<section id="where-to-begin" class="level2">
<h2>Where to Begin?</h2>
<p>To summarize, the Zen of assembler is a combination of knowledge, perspective, and way of thought that makes possible the genesis of first-rate assembler programs. Given that, where to begin our explorations of the Zen of assembler? Development of the flexible mind is an obvious step. Still, the flexible mind is no better than the knowledge at its disposal. We have much knowledge to acquire before we can begin to discuss the flexible mind, and in truth we don’t even know yet how to acquire knowledge about 8088 assembler, let alone what that knowledge might be. The first step in the journey toward the Zen of assembler, then, would seem to be learning how to learn.</p>
</section>
</section>
<section id="chapter-2-assume-nothing" class="level1">
<h1>Chapter 2: Assume Nothing</h1>
<p>When you’re pushing the envelope in assembler, you’re likely to become more than a little compulsive about finding approaches that let you wring more speed from your computer. In the process, you’re bound to make mistakes, which is fine — so long as you watch for those mistakes and learn from them.</p>
<p>A case in point: a few years back, I came across an article about 8088 assembly language called “Optimizing for Speed.” Now, “optimize” is not a word to be used lightly; Webster’s Ninth New Collegiate Dictionary defines optimize as “to make as perfect, effective, or functional as possible,” which certainly leaves little room for error. The author had, however, chosen a small, well-defined 8088 assembly-language routine to refine, consisting of about 30 instructions that did nothing more than expand 8 bits to 16 bits by duplicating each bit. (We’ll discuss this code and various optimizations to it at length in Chapter 7.)</p>
<p>The author of “Optimizing” had clearly fine-tuned the code with care, examining alternative instruction sequences and adding up cycles until he arrived at an implementation he calculated to be nearly 50% faster than the original routine. In short, he had used all the information at his disposal to improve his code, and had, as a result, saved cycles by the bushel. There was, in fact, only one slight problem with the optimized version of the routine…</p>
<p>It ran slower than the original version!</p>
<p>As diligent as the author had been, he had nonetheless committed a cardinal sin of 8088 assembly-language programming: he had assumed that the information available to him was both correct and complete. While the execution times provided by Intel for its processors are indeed correct, they are incomplete; the other — and often more important — part of code performance is instruction <em>fetch</em> time, a topic to which I will return in later chapters.</p>
<p>Had the author taken the time to measure the true performance of his code, he wouldn’t have put his reputation on the line with relatively low-performance code. What’s more, had he measured the performance of his code and found it to be unexpectedly slow, curiosity might well have led him to experiment further and thereby add to his store of reliable information about the 8088, and there you have an important part of the Zen of assembler: after crafting the best code possible, check it in action to see if it’s really doing what you think it is. If it’s not behaving as expected, that’s all to the good, since solving mysteries is the path to knowledge. You’ll learn more in this way, I assure you, than from any manual or book on assembly-language.</p>
<p><em>Assume nothing</em>. I cannot emphasize this strongly enough — when you care about performance, do your best to improve the code and then <em>measure</em> the improvement. If you don’t measure performance, you’re just guessing, and if you’re guessing, you’re not very likely to write top-notch code.</p>
<p>Ignorance about true performance can be costly. When I wrote video games for a living, I spent days at a time trying to wring more performance from my graphics drivers. I rewrote whole sections of code just to save a few cycles, juggled registers, and relied heavily on blurry-fast register-to-register shifts and adds. As I was writing my last game, I discovered that the program ran perceptibly faster if I used look-up tables instead of shifts and adds for my calculations. It <em>shouldn’t</em> have run faster, according to my cycle counting, but it did. In truth, instruction fetching was rearing its head again, as it often does when programming the 8088, and the fetching of the shifts and adds was taking as much as four times the nominal execution time of those instructions.</p>
<p>Ignorance can also be responsible for considerable wasted effort. I recall a debate in the letters column of one computer magazine about exactly how quickly text can be drawn on a Color/Graphics Adapter screen without causing snow. The letter writers counted every cycle in their timing loops, just as the author in the story that started this chapter had. Like that author, the letter writers had failed to take the prefetch queue into account. In fact, they had neglected the effects of video wait states as well, so the code they discussed was actually <em>much</em> slower than their estimates. The proper test would, of course, have been to run the code to see if snow resulted, since the only true measure of code performance is observing it in action.</p>
<section id="the-zen-timer" class="level2">
<h2>The Zen Timer</h2>
<p>One key to mastering the Zen of assembler is clearly a tool with which to measure code performance. The most accurate way to measure performance is with expensive hardware, but reasonable measurements at no cost can be made with the PC’s 8253 timer chip, which counts at a rate of slightly over 1,000,000 times per second. The 8253 can be started at the beginning of a block of code of interest and stopped at the end of that code, with the resulting count indicating how long the code took to execute with an accuracy of about 1 microsecond. (A microsecond is one -millionth of a second, and is abbreviated us). To be precise, the 8253 counts once every 838.1 nanoseconds. (A nanosecond is one-billionth of a second, and is abbreviated ns).</p>
<p><a href="#listing-2-1">Listing 2-1</a> shows 8253-based timer software, consisting of three subroutines: <code class="sourceCode nasm">ZTimerOn</code>, <code class="sourceCode nasm">ZTimerOff</code>, and <code class="sourceCode nasm">ZTimerReport</code>. For the remainder of this book, I’ll refer to these routines collectively as the “Zen timer.”</p>
</section>
<section id="the-zen-timer-is-a-means-not-an-end" class="level2">
<h2>The Zen Timer is a Means, Not an End</h2>
<p>We’re going to spend the rest of this chapter seeing what the Zen timer can do, examining how it works, and learning how to use it. The Zen timer will be our primary tool for the remainder of <em>The Zen of Assembly Language</em>, so it’s essential that you learn what the Zen timer can do and how to use it. On the other hand, it is by no means essential that you understand exactly how the Zen timer works. (Interesting, yes; essential, no.)</p>
<p>In other words, the Zen timer isn’t really part of the knowledge we seek; rather, it’s one tool with which we’ll acquire that knowledge. Consequently, you shouldn’t worry if you don’t fully grasp the inner workings of the Zen timer. Instead, focus on learning how to use the timer, since we will use it heavily throughout <em>The Zen of Assembly Language</em>.</p>
</section>
<section id="starting-the-zen-timer" class="level2">
<h2>Starting the Zen Timer</h2>
<p><code class="sourceCode nasm">ZTimerOn</code> is called at the start of a segment of code to be timed. <code class="sourceCode nasm">ZTimerOn</code> saves the context of the calling code, disables interrupts, sets timer 0 of the 8253 to mode 2 (divide-by-N mode), sets the initial timer count to 0, restores the context of the calling code, and returns. (I’d like to note that while Intel’s documentation for the 8253 seems to indicate that a timer won’t reset to 0 until it finishes counting down, in actual practice timers seems to reset to 0 as soon as they’re loaded.)</p>
<p>Two aspects of <code class="sourceCode nasm">ZTimerOn</code> are worth discussing further. One point of interest is that <code class="sourceCode nasm">ZTimerOn</code> disables interrupts. (<code class="sourceCode nasm">ZTimerOff</code> later restores interrupts to the state they were in when <code class="sourceCode nasm">ZTimerOn</code> was called.) Were interrupts not disabled by <code class="sourceCode nasm">ZTimerOn</code>, keyboard, mouse, timer, and other interrupts could occur during the timing interval, and the time required to service those interrupts would incorrectly and erratically appear to be part of the execution time of the code being measured. As a result, code timed with the Zen timer should not expect any hardware interrupts to occur during the interval between any call to <code class="sourceCode nasm">ZTimerOn</code> and the corresponding call to <code class="sourceCode nasm">ZTimerOff</code>, and should not enable interrupts during that time.</p>
</section>
<section id="time-and-the-pc" class="level2">
<h2>Time and the PC</h2>
<p>A second interesting point about <code class="sourceCode nasm">ZTimerOn</code> is that it may introduce some small inaccuracy into the system clock time whenever it is called. To understand why this is so, we need to examine the way in which both the 8253 and the PC’s system clock (which keeps the current time) work.</p>
<p>The 8253 actually contains three timers, as shown in Figure 2.1. All three timers are driven by the system board’s 14.31818 megahertz crystal, divided by 12 to yield a 1.19318-MHz clock to the timers, so the timers count once every 838.1 ns. Each of the three timers counts down in a programmable way, generating a signal on its output pin when it counts down to 0. Each timer is capable of being halted at any time via a 0 level on its gate input; when a timer’s gate input is 1, that timer counts constantly. All in all, the 8253’s timers are inherently very flexible timing devices; unfortunately, much of that flexibility depends on how the timers are connected to external circuitry, and in the PC the timers are connected with specific purposes in mind.</p>
<p>Timer 2 drives the speaker, although it can be used for other timing purposes when the speaker is not in use. As shown in Figure 2.1, timer 2 is the only timer with a programmable gate input in the PC; that is, timer 2 is the only timer which can be started and stopped under program control in the manner specified by Intel. On the other hand, the <em>output</em> of timer 2 is connected to nothing other than the speaker. In particular, timer 2 cannot generate an interrupt to get the 8088’s attention.</p>
<figure>
<img src="images/fig2.1RT.png" />
</figure>
<p>Timer 1 is dedicated to providing dynamic RAM refresh, and should not be tampered with lest system crashes result.</p>
<p>Finally, timer 0 is used to drive the system clock. As programmed by the BIOS at power-up, every 65,536 (64 K) counts, or 54.925 milliseconds, timer 0 generates a rising edge on its output line. (A millisecond is one-thousandth of a second, and is abbreviated ms). This line is connected to the hardware interrupt 0 (IRQ0) line on the system board, so every 54.925 ms timer 0 causes hardware interrupt 0 to occur.</p>
<p>The interrupt vector for IRQ0 is set by the BIOS at power-up time to point to a BIOS routine, <code class="sourceCode nasm">TIMER_INT</code>, that maintains a time-of-day count. <code class="sourceCode nasm">TIMER_INT</code> keeps a 16-bit count of IRQ0 interrupts in the BIOS data area at address 0000:046C (all addresses are given in segment:offset hexadecimal pairs); this count turns over once an hour (less a few microseconds), and when it does, <code class="sourceCode nasm">TIMER_INT</code> updates a 16-bit hour count at address 0000:046E in the BIOS data area. This routine is the basis for the current time and date that DOS supports via functions 2Ah (2A hexadecimal) through 2Dh and by way of the DATE and TIME commands. Each timer channel of the 8253 can operate in any of 6 modes. Timer 0 normally operates in mode 3, square wave mode. In square wave mode, the initial count is counted down two at a time; when the count reaches zero, the output state is changed. The initial count is again counted down two at a time, and the output state is toggled back when the count reaches zero. The result is a square wave that changes state more slowly than the input clock by a factor of the initial count. In its normal mode of operation, timer 0 generates an output pulse that is low for about 27.5 ms and high for about 27.5 ms; this pulse is sent to the 8259 interrupt controller, and its rising edge generates a timer interrupt once every 54.925 ms.</p>
<p>Square wave mode is not very useful for precision timing because it counts down by 2 twice per timer interrupt, thereby rendering exact timings impossible. Fortunately, the 8253 offers another timer mode, mode 2 (divide-by-N mode), which is both a good substitute for square wave mode and a perfect mode for precision timing.</p>
<p>Divide-by-N mode counts down by 1 from the initial count. When the count reaches zero, the timer turns over and starts counting down again without stopping, and a pulse is generated for a single clock period. While the pulse is not held for nearly as long as in square wave mode, it doesn’t matter, since the 8259 interrupt controller is configured in the PC to be edge-triggered and hence cares only about the existence of a pulse from timer 0, not the duration of the pulse. As a result, timer 0 continues to generate timer interrupts in divide-by-N mode, and the system clock continues to maintain good time.</p>
<p>Why not use timer 2 instead of timer 0 for precision timing? After all, timer 2 has a programmable gate input and isn’t used for anything but sound generation. The problem with timer 2 is that its output can’t generate an interrupt; in fact, timer 2 can’t do anything but drive the speaker. We need the interrupt generated by the output of timer 0 to tell us when the count has overflowed, and we will see shortly that the timer interrupt also makes it possible to time much longer periods than the Zen timer shown in <a href="#listing-2-1">Listing 2-1</a> supports.</p>
<p>In fact, the Zen timer shown in <a href="#listing-2-1">Listing 2-1</a> can only time intervals of up to about 54 ms in length, since that is the period of time that can be measured by timer 0 before its count turns over and repeats. 54 ms may not seem like a very long time, but an 8088 can perform more than 1000 divides in 54 ms, and division is the single instruction the 8088 performs most slowly. If a measured period turns out to be longer than 54 ms (that is, if timer 0 has counted down and turned over), the Zen timer will display a message to that effect. A long-period Zen timer for use in such cases will be presented later in this chapter.</p>
<p>The Zen timer determines whether timer 0 has turned over by checking to see whether an IRQ0 interrupt is pending. (Remember, interrupts are off while the Zen timer runs, so the timer interrupt cannot be recognized until the Zen timer stops and enables interrupts.) If an IRQ0 interrupt is pending, then timer 0 has turned over and generated a timer interrupt. Recall that <code class="sourceCode nasm">ZTimerOn</code> initially sets timer 0 to 0, in order to allow for the longest possible period — about 54 ms — before timer 0 reaches 0 and generates the timer interrupt.</p>
<p>Now we’re ready to look at the ways in which the Zen timer can introduce inaccuracy into the system clock. Since timer 0 is initially set to 0 by the Zen timer, and since the system clock ticks only when timer 0 counts off 54.925 ms and reaches 0 again, an average inaccuracy of one-half of 54.925 ms, or about 27.5 ms, is incurred each time the Zen timer is started. In addition, a timer interrupt is generated when timer 0 is switched from mode 3 to mode 2, advancing the system clock by up to 54.925 ms, although this only happens the first time the Zen timer is run after a warm or cold boot. Finally, up to 54.925 ms can again be lost when <code class="sourceCode nasm">ZTimerOff</code> is called, since that routine again sets the timer count to zero. Net result: the system clock will run up to 110 ms (about a ninth of a second) slow each time the Zen timer is used.</p>
<p>Potentially far greater inaccuracy can be incurred by timing code that takes longer than about 110 ms to execute. Recall that all interrupts, including the timer interrupt, are disabled while timing code with the Zen timer. The 8259 interrupt controller is capable of remembering at most one pending timer interrupt, so all timer interrupts after the first one during any given Zen timing interval are ignored. Consequently, if a timing interval exceeds 54.9 ms, the system clock effectively stops 54.9 ms after the timing interval starts and doesn’t restart until the timing interval ends, losing time all the while.</p>
<p>The effects on the system time of the Zen timer aren’t a matter for great concern, as they are temporary, lasting only until the next warm or cold boot. Systems that have battery-backed clocks, such as ATs, automatically reset the correct time whenever the computer is booted, and systems without battery-backed clocks prompt for the correct date and time when booted. Also, even repeated use of the Zen timer usually makes the system clock slow by at most a total of a few seconds, unless code that takes much longer than 54 ms to run is timed (in which case the Zen timer will notify you that the code is too long to time.)</p>
<p>Nonetheless, it’s a good idea to reboot your computer at the end of each session with the Zen timer in order to make sure that the system clock is correct.</p>
</section>
<section id="stopping-the-zen-timer" class="level2">
<h2>Stopping the Zen Timer</h2>
<p>At some point after <code class="sourceCode nasm">ZTimerOn</code> is called, <code class="sourceCode nasm">ZTimerOff</code> must always be called to mark the end of the timing interval. <code class="sourceCode nasm">ZTimerOff</code> saves the context of the calling program, latches and reads the timer 0 count, converts that count from the countdown value that the timer maintains to the number of counts elapsed since <code class="sourceCode nasm">ZTimerOn</code> was called, and stores the result. Immediately after latching the timer 0 count — and before enabling interrupts — <code class="sourceCode nasm">ZTimerOff</code> checks the 8259 interrupt controller to see if there is a pending timer interrupt, setting a flag to mark that the timer overflowed if there is indeed a pending timer interrupt.</p>
<p>After that, <code class="sourceCode nasm">ZTimerOff</code> executes just the overhead code of <code class="sourceCode nasm">ZTimerOn</code> and <code class="sourceCode nasm">ZTimerOff</code> 16 times and averages and saves the results, in order to determine how many of the counts in the timing result just obtained were incurred by the overhead of the Zen timer rather than by the code being timed.</p>
<p>Finally, <code class="sourceCode nasm">ZTimerOff</code> restores the context of the calling program, including the state of the interrupt flag that was in effect when <code class="sourceCode nasm">ZTimerOn</code> was called to start timing, and returns.</p>
<p>One interesting aspect of <code class="sourceCode nasm">ZTimerOff</code> is the manner in which timer 0 is stopped in order to read the timer count. We don’t actually have to stop timer 0 to read the count; the 8253 provides a special latched read feature for the specific purpose of reading the count while a time is running. (That’s a good thing, too; we’ve no documented way to stop timer 0 if we wanted to, since its gate input isn’t connected. Later in this chapter, though, we’ll see that timer 0 can be stopped after all.) We simply tell the 8253 to latch the current count, and the 8253 does so without breaking stride.</p>
</section>
<section id="reporting-timing-results" class="level2">
<h2>Reporting Timing Results</h2>
<p><code class="sourceCode nasm">ZTimerReport</code> may be called to display timing results at any time after both <code class="sourceCode nasm">ZTimerOn</code> and <code class="sourceCode nasm">ZTimerOff</code> have been called. <code class="sourceCode nasm">ZTimerReport</code> first checks to see whether the timer overflowed (counted down to 0 and turned over) before <code class="sourceCode nasm">ZTimerOff</code> was called; if overflow did occur, <code class="sourceCode nasm">ZTimerOff</code> prints a message to that effect and returns. Otherwise, <code class="sourceCode nasm">ZTimerReport</code> subtracts the reference count (representing the overhead of the Zen timer) from the count measured between the calls to <code class="sourceCode nasm">ZTimerOn</code> and <code class="sourceCode nasm">ZTimerOff</code>, converts the result from timer counts to microseconds, and prints the resulting time in microseconds to the standard output.</p>
<p>Note that <code class="sourceCode nasm">ZTimerReport</code> need not be called immediately after <code class="sourceCode nasm">ZTimerOff</code>. In fact, after a given call to <code class="sourceCode nasm">ZTimerOff</code>, <code class="sourceCode nasm">ZTimerReport</code> can be called at any time right up until the next call to <code class="sourceCode nasm">ZTimerOn</code>.</p>
<p>You may want to use the Zen timer to measure several portions of a program while it executes normally, in which case it may not be desirable to have the text printed by <code class="sourceCode nasm">ZTimerReport</code> interfere with the program’s normal display. There are many ways to deal with this. One approach is removal of the invocations of the DOS print string function (INT 21h with AH equal to 9) from <code class="sourceCode nasm">ZTimerReport</code>, instead running the program under a debugger that supports screen flipping (such as Symdeb or Codeview), placing a breakpoint at the start of <code class="sourceCode nasm">ZTimerReport</code>, and directly observing the count in microseconds as <code class="sourceCode nasm">ZTimerReport</code> calculates it.</p>
<p>A second approach is modification of <code class="sourceCode nasm">ZTimerReport</code> to place the result at some safe location in memory, such as an unused portion of the BIOS data area.</p>
<p>A third approach is alteration of <code class="sourceCode nasm">ZTimerReport</code> to print the result over a serial port to a terminal or to another PC acting as a terminal. Similarly, Symdeb (and undoubtedly other debuggers as well) can be run from a remote terminal by running Mode to set up the serial port, then starting Symdeb and executing the command <code class="cmd">=com1</code> or <code class="cmd">=com2</code>.</p>
<p>Yet another approach is modification of <code class="sourceCode nasm">ZTimerReport</code> to send the result to the printer via either DOS function 5 or BIOS interrupt 17h.</p>
<p>A final approach is to modify <code class="sourceCode nasm">ZTimerReport</code> to print the result to the auxiliary output via DOS function 4, and to then write and load a special device driver named <code class="sourceCode nasm">AUX</code>, to which DOS function 4 output would automatically be directed. This device driver could send the result anywhere you might desire. The result might go to the secondary display adapter, over a serial port, or to the printer, or could simply be stored in a buffer within the driver, to be dumped at a later time. (Credit for this final approach goes to Michael Geary, and thanks go to David Miller for passing the idea on to me.)</p>
<p>You may well want to devise still other approaches better suited to your needs than those I’ve presented. Go to it! I’ve just thrown out a few possibilities to get you started.</p>
</section>
<section id="notes-on-the-zen-timer" class="level2">
<h2>Notes on the Zen Timer</h2>
<p>The Zen timer subroutines are designed to be near-called from assembly-language code running in the public segment <code class="sourceCode nasm">Code</code>. The Zen timer subroutines can, however, be called from any assembler or high-level language code that generates OBJ files that are compatible with the Microsoft Linker, simply by modifying the segment that the timer code runs in to match the segment used by the code being timed, or by changing the Zen timer routines to far procedures and making far calls to the Zen timer code from the code being timed. All three subroutines preserve all registers and all flags except the interrupt flag, so calls to these routines are transparent to the calling code.</p>
<p>If you do change the Zen timer routines to far procedures in order to call them from code running in another segment, be sure to make <em>all</em> the Zen timer routines far, including <code class="sourceCode nasm">ReferenceZTimerOn</code> and <code class="sourceCode nasm">ReferenceZTimerOff</code>. (You’ll have to put <code class="sourceCode nasm">far <span class="dt">ptr</span></code> overrides on the calls from <code class="sourceCode nasm">ZTimerOff</code> to the latter two routines if you do make them far.) If the reference routines aren’t the same type — near or far — as the other routines, they won’t reflect the true overhead incurred by starting and stopping the Zen timer.</p>
<p>Please be aware that the inaccuracy that the Zen timer can introduce into the system clock time does not affect the accuracy of the performance measurements reported by the Zen timer itself. The 8253 counts once every 838 ns, giving us a count resolution of about 1 us, although factors such as the prefetch queue (as discussed below), dynamic RAM refresh, and internal timing variations in the 8253 make it perhaps more accurate to describe the Zen timer as measuring code performance with an accuracy of better than 10 us. In fact, we’ll see in Chapter 5 why the Zen timer is actually most accurate in assessing code performance when timing intervals longer than about 100 us. At any rate, we’re most interested using in the Zen timer to assess the relative performance of various code sequences — that is, using it to compare and tweak code — and the timer is more than accurate enough for that purpose.</p>
<p>The Zen timer works on all PC-compatible computers I’ve tested it on, including XTs, ATs, PS/2 computers, and 80386-based AT-compatible machines. Of course, I haven’t been able to test it on <em>all</em> PC-compatibles, but I don’t expect any problems; computers on which the Zen timer doesn’t run can’t truly be called “PC-compatible.”</p>
<p>On the other hand, there is certainly no guarantee that code performance as measured by the Zen timer will be the same on compatible computers as on genuine IBM machines, or that either absolute or relative code performance will be similar even on different IBM models; in fact, quite the opposite is true. For example, every PS/2 computer, even the relatively slow Model 30, executes code much faster than does a PC or XT. As another example, I set out to do the timings for this book on an XT -compatible computer, only to find that the computer wasn’t quite IBM-compatible as regarded code performance. The differences were minor, mind you, but my experience illustrates the risk of assuming that a specific make of computer will perform in a certain way without actually checking.</p>
<p>Not that this variation between models makes the Zen timer one whit less useful — quite the contrary. The Zen timer is an excellent tool for evaluating code performance over the entire spectrum of PC-compatible computers.</p>
</section>
<section id="a-sample-use-of-the-zen-timer" class="level2">
<h2>A Sample Use of the Zen Timer</h2>
<p><a href="#listing-2-2">Listing 2-2</a> shows a test-bed program for measuring code performance with the Zen timer. This program sets DS equal to CS (for reasons we’ll discuss shortly), includes the code to be measured from the file TESTCODE, and calls <code class="sourceCode nasm">ZTimerReport</code> to display the timing results. Consequently, the code being measured should be in the file TESTCODE, and should contain calls to <code class="sourceCode nasm">ZTimerOn</code> and <code class="sourceCode nasm">ZTimerOff</code>.</p>
<p><a href="#listing-2-3">Listing 2-3</a> shows some sample code to be timed. This listing measures the time required to execute 1000 loads of AL from the memory variable <code class="sourceCode nasm">MemVar</code>. Note that <a href="#listing-2-3">Listing 2-3</a> calls <code class="sourceCode nasm">ZTimerOn</code> to start timing, performs 1000 <code class="sourceCode nasm"><span class="kw">mov</span></code> instructions in a row, and calls <code class="sourceCode nasm">ZTimerOff</code> to end timing. When <a href="#listing-2-2">Listing 2-2</a> is named TESTCODE and included by <a href="#listing-2-3">Listing 2-3</a>, <a href="#listing-2-2">Listing 2-2</a> calls <code class="sourceCode nasm">ZTimerReport</code> to display the execution time after the code in <a href="#listing-2-3">Listing 2-3</a> has been run.</p>
<p>It’s worth noting that <a href="#listing-2-3">Listing 2-3</a> begins by jumping around the memory variables <code class="sourceCode nasm">MemVar</code>. This approach lets us avoid reproducing <a href="#listing-2-2">Listing 2-2</a> in its entirety for each code fragment we want to measure; by defining any needed data right in the code segment and jumping around that data, each listing becomes self-contained and can be plugged directly into <a href="#listing-2-2">Listing 2-2</a> as TESTCODE. <a href="#listing-2-2">Listing 2-2</a> sets DS equal to CS before doing anything else precisely so that data can be embedded in code fragments being timed. Note that only after the initial jump is performed in <a href="#listing-2-3">Listing 2-3</a> is the Zen timer started, since we don’t want to include the execution time of start-up code in the timing interval. That’s why the calls to <code class="sourceCode nasm">ZTimerOn</code> and <code class="sourceCode nasm">ZTimerOff</code> are in TESTCODE, not in <a href="#pztest">PZTEST.ASM</a>; this way, we have full control over which portion of TESTCODE is timed, and we can keep set-up code and the like out of the timing interval.</p>
<p><a href="#listing-2-3">Listing 2-3</a> is used by naming it TESTCODE, assembling both <a href="#listing-2-2">Listing 2-2</a> (which includes TESTCODE) and <a href="#listing-2-1">Listing 2-1</a> with MASM, and linking the two resulting OBJ files together by way of the Microsoft Linker. <a href="#listing-2-4">Listing 2-4</a> shows a batch file, <a href="#pztime.bat">PZTIME.BAT</a>, which does all that; when run, this batch file generates and runs the executable file PZTEST.EXE. <a href="#pztime.bat">PZTIME.BAT</a> (<a href="#listing-2-4">Listing 2-4</a>) assumes that the file <a href="#pztimer">PZTIMER.ASM</a> contains <a href="#listing-2-1">Listing 2-1</a> and the file <a href="#pztest">PZTEST.ASM</a> contains <a href="#listing-2-2">Listing 2-2</a>. The command line parameter to <a href="#pztime.bat">PZTIME.BAT</a> is the name of the file to be copied to TESTCODE and included into <a href="#pztest">PZTEST.ASM</a>. (Note that Turbo Assembler can be substituted for MASM by replacing “masm” with “tasm” and “link” with “tlink” in <a href="#listing-2-4">Listing 2-4</a>. The same is true of <a href="#listing-2-7">Listing 2-7</a>.)</p>
<p>Assuming that <a href="#listing-2-3">Listing 2-3</a> is named LST2-3 and <a href="#listing-2-4">Listing 2-4</a> is named <a href="#pztime.bat">PZTIME.BAT</a>, the code in <a href="#listing-2-3">Listing 2-3</a> would be timed with the command:</p>
<pre class="cmd"><code>pztime LST2-3</code></pre>
<p>which performs all assembly and linking and reports the execution time of the code in <a href="#listing-2-3">Listing 2-3</a>.</p>
<p>When the above command is executed on a PC, the time reported by the Zen timer is 3619 us, or about 3.62 us per load of AL from memory. (While the exact number is 3.619 us per load of AL, I’m going to round off that last digit from now on. No matter how many repetitions of a given instruction are timed, there’s just too much noise in the timing process, between dynamic RAM refresh, the prefetch queue, and the internal state of the 8088 at the start of timing, for that last digit to have any significance.) Given the PC’s 4.77-MHz clock, this works out to about 17 cycles per <code class="sourceCode nasm"><span class="kw">mov</span></code>, which is actually a good bit longer than Intel’s specified 10-cycle execution time for this instruction. (See Appendix A for official execution times.) Fear not, the Zen timer is right — <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,[MemVar]</code> really does take 17 cycles as used in <a href="#listing-2-3">Listing 2-3</a>. Exactly why that is so is just what this book (and particularly the next three chapters) is all about.</p>
<p>In order to perform any of the timing tests in this book, enter <a href="#listing-2-1">Listing 2-1</a> and name it <a href="#pztimer">PZTIMER.ASM</a>, enter <a href="#listing-2-2">Listing 2-2</a> and name it <a href="#pztest">PZTEST.ASM</a>, and enter <a href="#listing-2-4">Listing 2-4</a> and name it <a href="#pztime.bat">PZTIME.BAT</a>. Then simply enter the listing you wish to run into the file <em>filename</em> and enter the command:</p>
<pre class="cmd"><code>pztime filename</code></pre>
<p>In fact, that’s exactly how I timed each of the listings in this book. Code fragments you write yourself can be timed in just the same way. If you wish to time code directly in place in your programs, rather than in the test-bed program of <a href="#listing-2-2">Listing 2-2</a>, simply insert calls to <code class="sourceCode nasm">ZTimerOn</code>, <code class="sourceCode nasm">ZTimerOff</code>, and <code class="sourceCode nasm">ZTimerReport</code> in the appropriate places and link <a href="#pztimer">PZTIMER</a> to your program.</p>
</section>
<section id="the-long-period-zen-timer" class="level2">
<h2>The Long-Period Zen Timer</h2>
<p>With a few exceptions, the Zen timer presented above will serve us well for the remainder of this book, since we’ll be focusing on relatively short code sequences that generally take much less than 54 ms to execute. Occasionally, however, we will need to time longer intervals. What’s more, it is very likely that you will want to time code sequences longer than 54 ms at some point in your programming career. Accordingly, I’ve also developed a Zen timer for periods longer than 54 ms. The long-period Zen timer (so named by contrast with the precision Zen timer just presented) shown in <a href="#listing-2-5">Listing 2-5</a> can measure periods up to one hour in length.</p>
<p>The key difference between the long-period Zen timer and the precision Zen timer is that the long-period timer leaves interrupts enabled during the timing period. As a result, timer interrupts are recognized by the PC, allowing the BIOS to maintain an accurate system clock time over the timing period. Theoretically, this enables measurement of arbitrarily long periods. Practically speaking, however, there is no need for a timer that can measure more than a few minutes, since the DOS time of day and date functions (or, indeed, the DATE and TIME commands in a batch file) serve perfectly well for longer intervals. Since very long timing intervals aren’t needed, the long-period Zen timer uses a simplified means of calculating elapsed time that is limited to measuring intervals of an hour or less. If a period longer than an hour is timed, the long-period Zen timer prints a message to the effect that it is unable to time an interval of that length.</p>
<p>For implementation reasons the long-period Zen timer is also incapable of timing code that starts before midnight and ends after midnight; if that eventuality occurs, the long-period Zen timer reports that it was unable to time the code because midnight was crossed. If this happens to you, just time the code again, secure in the knowledge that at least you won’t run into the problem again for 23-odd hours.</p>
<p>You should not use the long-period Zen timer to time code that requires interrupts to be disabled for more than 54 ms at a stretch during the timing interval, since when interrupts are disabled the long-period Zen timer is subject to the same 54 ms maximum measurement time as the precision Zen timer.</p>
<p>While allowing the timer interrupt to occur allows long intervals to be timed, that same interrupt makes the long-period Zen timer less accurate than the precision Zen timer, since the time the BIOS spends handling timer interrupts during the timing interval is included in the time measured by the long-period timer. Likewise, any other interrupts that occur during the timing interval, most notably keyboard and mouse interrupts, will increase the measured time.</p>
<p>The long-period Zen timer has some of the same effects on the system time as does the precision Zen timer, so it’s a good idea to reboot the system after a session with the long-period Zen timer. The long-period Zen timer does not, however, have the same potential for introducing major inaccuracy into the system clock time during a single timing run, since it leaves interrupts enabled and therefore allows the system clock to update normally.</p>
</section>
<section id="stopping-the-clock" class="level2">
<h2>Stopping the Clock</h2>
<p>There’s a potential problem with the long-period Zen timer. The problem is this: in order to measure times longer than 54 ms, we must maintain not one but two timing components, the timer 0 count and the BIOS time-of-day count. The time-of-day count measures the passage of 54.9 ms intervals, while the timer 0 count measures time within those 54.9 ms intervals. We need to read the two time components simultaneously in order to get a clean reading. Otherwise, we may read the timer count just before it turns over and generates an interrupt, then read the BIOS time-of-day count just after the interrupt has occurred and caused the time-of-day count to turn over, with a resulting 54 ms measurement inaccuracy. (The opposite sequence — reading the time-of-day count and then the timer count — can result in a 54 ms inaccuracy in the other direction.)</p>
<p>The only way to avoid this problem is to stop timer 0, read both the timer and time-of-day counts while the timer’s stopped, and then restart the timer. Alas, the gate input to timer 0 isn’t program-controllable in the PC, so there’s no documented way to stop the timer. (The latched read feature we used in <a href="#listing-2-1">Listing 2-1</a> doesn’t stop the timer; it latches a count, but the timer keeps running.) What to do?</p>
<p>As it turns out, an undocumented feature of the 8253 makes it possible to stop the timer dead in its tracks. Setting the timer to a new mode, waiting for an initial count to be loaded, causes the timer to stop until the count is loaded. Surprisingly, the timer count remains readable and correct while the timer is waiting for the initial load.</p>
<p>In my experience, this approach works beautifully with fully 8253-compatible chips. However, there’s no guarantee that it will always work, since it programs the 8253 in an undocumented way. What’s more, IBM chose not to implement compatibility with this particular 8253 feature in the custom chips used in PS/2 computers. On PS/2 computers, we have no choice but to latch the timer 0 count and then stop the BIOS count (by disabling interrupts) as quickly as possible. We’ll just have to accept the fact that on PS/2 computers we may occasionally get a reading that’s off by 54 ms, and leave it at that.</p>
<p>I’ve set up <a href="#listing-2-5">Listing 2-5</a> so that it can assemble to either use or not use the undocumented timer-stopping feature, as you please. The <code class="sourceCode nasm">PS2</code> equate selects between the two modes of operation. If <code class="sourceCode nasm">PS2</code> is 1 (as it is in <a href="#listing-2-5">Listing 2-5</a>), then the latch-and-read method is used; if <code class="sourceCode nasm">PS2</code> is 0, then the undocumented timer-stop approach is used. The latch-and-read method will work on all PC-compatible computers, but may occasionally produce results that are incorrect by 54 ms. The timer-stop approach avoids synchronization problem, but doesn’t work on all computers.</p>
<p>Moreover, because it uses an undocumented feature, the timer-stop approach could conceivably cause erratic 8253 operation, which could in turn seriously affect your computer’s operation until the next reboot. In non-8253-compatible systems, I’ve observed not only wildly incorrect timing results, but also failure of a floppy drive to operate properly after the long-period Zen timer with <code class="sourceCode nasm">PS2</code> set to 0 has run, so be alert for signs of trouble if you do set <code class="sourceCode nasm">PS2</code> to 0.</p>
<p>Rebooting should clear up any timer-related problems of the sort described above. (This gives us another reason to reboot at the end of each code-timing session.) You should <em>immediately</em> reboot and set the <code class="sourceCode nasm">PS2</code> equate to 1 if you get erratic or obviously incorrect results with the long-period Zen timer when <code class="sourceCode nasm">PS2</code> is set to 0. If you want to set <code class="sourceCode nasm">PS2</code> to 0, it would be a good idea to time a few of the listings in <em>The Zen of Assembly Language</em> with <code class="sourceCode nasm">PS2</code> set first to 1 and then to 0, to make sure that the results match. If they’re consistently different, you should set <code class="sourceCode nasm">PS2</code> to 1.</p>
<p>While the the non-PS/2 version is more dangerous than the PS/2 version, it also produces more accurate results when it does work. If you have a non-PS/2 PC-compatible computer, the choice between the two timing approaches is yours.</p>
<p>If you do leave the <code class="sourceCode nasm">PS2</code> equate at 1 in <a href="#listing-2-5">Listing 2-5</a>, you should repeat each code-timing run several times before relying on the results to be accurate to more than 54 ms, since variations may result from the possible lack of synchronization between the timer 0 count and the BIOS time-of-day count. In fact, it’s a good idea to time code more than once no matter which version of the long-period Zen timer you’re using, since interrupts, which must be enabled in order for the long-period timer to work properly, may occur at any time and can alter execution time substantially.</p>
<p>Finally, please note that the <em>precision</em> Zen timer works perfectly well on both PS/2 and non-PS/2 computers. The PS/2 and 8253 considerations we’ve just discussed apply only to the long-period Zen timer.</p>
</section>
<section id="a-sample-use-of-the-long-period-zen-timer" class="level2">
<h2>A Sample Use of the Long-Period Zen Timer</h2>
<p>The long-period Zen timer has exactly the same calling interface as the precision Zen timer, and can be used in place of the precision Zen timer simply by linking it to the code to be timed in place of linking the precision timer code. Whenever the precision Zen timer informs you that the code being timed takes too long for the precision timer to handle, all you have to do is link in the long-period timer instead.</p>
<p><a href="#listing-2-6">Listing 2-6</a> shows a test-bed program for the long-period Zen timer. While this program is similar to <a href="#listing-2-2">Listing 2-2</a>, it’s worth noting that <a href="#listing-2-6">Listing 2-6</a> waits for a few seconds before calling <code class="sourceCode nasm">ZTimerOn</code>, thereby allowing any pending keyboard interrupts to be processed. Since interrupts must be left on in order to time periods longer than 54 ms, the interrupts generated by keystrokes, (including the upstroke of the Enter key press that starts the program) -or any other interrupts, for that matter -could incorrectly inflate the time recorded by the long-period Zen timer. In light of this, resist the temptation to type ahead, move the mouse, or the like while the long-period Zen timer is timing.</p>
<p>As with the precision Zen timer, the program in <a href="#listing-2-6">Listing 2-6</a> is used by naming the file containing the code to be timed TESTCODE, then assembling both <a href="#listing-2-6">Listing 2-6</a> and <a href="#listing-2-5">Listing 2-5</a> with MASM and linking the two files together by way of the Microsoft Linker. <a href="#listing-2-7">Listing 2-7</a> shows a batch file, named <a href="#lztime.bat">LZTIME.BAT</a>, which does all of the above, generating and running the executable file LZTEST.EXE. <a href="#lztime.bat">LZTIME.BAT</a> assumes that the file <a href="#lztimer">LZTIMER.ASM</a> contains <a href="#listing-2-5">Listing 2-5</a> and the file <a href="#lztest">LZTEST.ASM</a> contains <a href="#listing-2-6">Listing 2-6</a>.</p>
<p><a href="#listing-2-8">Listing 2-8</a> shows sample code that can be timed with the test-bed program of <a href="#listing-2-6">Listing 2-6</a>. <a href="#listing-2-8">Listing 2-8</a> measures the time required to execute 20,000 loads of AL from memory, a length of time too long for the precision Zen timer to handle.</p>
<p>When <a href="#lztime.bat">LZTIME.BAT</a> is run on a PC with the following command line (assuming the code in <a href="#listing-2-8">Listing 2-8</a> is the file LST2-8):</p>
<pre class="cmd"><code>lztime lst2-8</code></pre>
<p>the result is 72,544 us, or about 3.63 us per load of AL from memory. This is just slightly longer than the time per load of AL measured by the precision Zen timer, as we would expect given that interrupts are left enabled by the long-period Zen timer. The extra fraction of a microsecond measured per multiply reflects the time required to execute the BIOS code that handles the 18.2 timer interrupts that occur each second.</p>
<p>Note that the above command takes about 10 minutes to finish on a PC, with most of that time spent assembling <a href="#listing-2-8">Listing 2-8</a>. Why? Because MASM is notoriously slow at assembling <code class="sourceCode nasm">rept</code> blocks, and the block in <a href="#listing-2-8">Listing 2-8</a> is repeated 20000 times.</p>
</section>
<section id="further-reading" class="level2">
<h2>Further Reading</h2>
<p>For those of you who wish to pursue the mechanics of code measurement further, one good article about measuring code performance with the 8253 timer is “<em>Programming Insight: High-Performance Software Analysis on the IBM PC</em>,” by Byron Sheppard, which appeared in the January, 1987 issue of <em>Byte</em>. For complete if somewhat cryptic information on the 8253 timer itself, I refer you to Intel’s <em>Microsystem Components Handbook</em>, which is also a useful reference for a number of other PC components, including the 8259 Programmable Interrupt Controller and the 8237 DMA Controller. For details about the way the 8253 is used in the PC, as well as a great deal of additional information about the PC’s hardware and BIOS resources, I suggest you consult IBM’s series of technical reference manuals for the PC, XT, AT, Model 30, Models 50 and 60, and Model 80.</p>
<p>For our purposes, however, it’s not critical that you understand exactly how the Zen timer works. All you really need to know is what the Zen timer can do and how to use it, and we’ve accomplished that in this chapter.</p>
</section>
<section id="armed-with-the-zen-timer-onward-and-upward" class="level2">
<h2>Armed With the Zen Timer, Onward and Upward</h2>
<p>The Zen timer is not perfect. For one thing, the finest resolution to which it can measure an interval is at best about 1 us, a period of time in which a 25-MHz 80386 computer can execute as many as 12 instructions (although a PC would be hard-pressed to manage two instructions in a microsecond). Another problem is that the timing code itself interferes with the state of the prefetch queue at the start of the code being timed, because the timing code is not necessarily fetched and does not necessarily access memory in exactly the same time sequence as the code immediately preceding the code under measurement normally does. This prefetch effect can introduce as much as 3 to 4 us of inaccuracy. (The nature of this problem will become more apparent when we discuss the prefetch queue.) Similarly, the state of the prefetch queue at the end of the code being timed affects how long the code that stops the timer takes to execute. Consequently, the Zen timer tends to be more accurate for longer code sequences, since the relative magnitude of the inaccuracy introduced by the Zen timer becomes less over longer periods.</p>
<p>Imperfections notwithstanding, the Zen timer is a good tool for exploring 8088 assembly language, and it’s a tool we’ll use well for the remainder of this book. With the timer in hand, let’s begin our trek toward the Zen of assembler, dispelling old assumptions and acquiring new knowledge along the way.</p>
</section>
</section>
<section id="chapter-3-context" class="level1">
<h1>Chapter 3: Context</h1>
<p>One of my favorite stories — and I am not making this up — concerns a C programmer who wrote a function to clear the screen. His function consisted of just two statements: a call to another function that printed a space character, and a <code class="sourceCode c"><span class="kw">for</span></code> statement that repeated that function call 2000 times. While this fellow’s function cleared the screen perfectly well, it didn’t do it particularly quickly or attractively; in fact, the whole process was perfectly visible to the naked eye, with the cursor racing from the top to the bottom of the screen. Nonetheless, the programmer was incensed when someone commented that the function seemed rather slow. How could it possibly be any faster, he wondered, when it was already the irreducible minimum of two statements long?</p>
<p>Of course, the function wasn’t two statements long in any meaningful sense; its true length would have to be measured in terms of all the machine-language instructions generated by those two C statements, as well as all the instructions executed by the function that printed the space character. By comparison with a single <code class="sourceCode nasm">rep <span class="kw">stosw</span></code> instruction, which is the preferred way to clear the screen, this fellow’s screen clear function was undoubtedly very long indeed.</p>
<p>The programmer’s mistake was one of context. While his solution seemed optimal by the standards of the C environment he was programming in, it was considerably less ideal when applied to the PC, the environment in which the code actually had to run. While human-oriented abstractions such as high-level languages and system software have their virtues — most notably the ability to mask the complexities of processors and hardware — speed is not necessarily among those virtues.</p>
<p>We certainly don’t want to make the same mistake, so we’ll begin our search for knowledge by establishing a context for assembler programming, a usable framework within which to work for the remainder of this book. This is more challenging than it might at first glance seem, for the PC looks quite different to an assembler programmer — especially an assembler programmer interested in performance — than it does to a high-level language programmer. The difference is that a good assembler programmer sees the PC as it really is — hardware, software, warts and all — a perspective all too few programmers ever have the opportunity to enjoy.</p>
<section id="from-the-bottom-up" class="level2">
<h2>From the Bottom Up</h2>
<p>In this volume, we’re going to explore the knowledge needed for top-notch assembler programming. We’ll start at the bottom, with the hardware of the PC, and we’ll work our way up through the 8088’s registers, memory addressing capabilities, and instruction set. In Volume II of <em>The Zen of Assembly Language</em>, we’ll move on to putting that knowledge to work in the context of higher-level optimization, algorithm implementation, program design, and the like. We’re not going to spend time on topics, such as BIOS and DOS calls, that are well documented elsewhere, for we’ve a great deal of new ground to cover.</p>
<p>The next three chapters, which discuss the ways in which the hardware of the PC affects performance, are the foundation for everything that follows… and they also cover the most difficult material in <em>The Zen of Assembly Language</em>. Don’t worry if you don’t understand everything you read in the upcoming chapters; the same topics will come up again and again, from a variety of perspectives, throughout <em>The Zen of Assembly Language</em>. Read through Chapters 3 through 5 once now, absorbing as much as you can. After you’ve finished Volume I, come back to these chapters and read them again.</p>
<p>You’ll be amazed at how much sense they make — and at how much you’ve learned.</p>
<p>Let’s begin our explorations.</p>
</section>
<section id="the-traditional-model" class="level2">
<h2>The Traditional Model</h2>
<p>Figure 3.1 shows the traditional assembler programming model of the PC. In this model, the assembler program is separated from the hardware by layers of system software, such as DOS, the BIOS, and device drivers. Although this model recognizes that it is possible for assembler programs to make end runs around the layers to access any level of system software or the hardware directly, programs are supposed to request services from the highest level that can fulfill a given request (preferably DOS), thereby gaining hardware independence, which brings with it portability to other systems with different hardware but the same system software.</p>
<figure>
<img src="images/fig3.1RT.png" />
</figure>
<p>This model has many admirable qualities, and should be followed whenever possible. For example, because the DOS file system masks incompatibilities between the dozens of disk and disk controller models on the market, there’s generally nothing to be gained and much to be lost by programming a disk controller directly. Similarly, the BIOS sometimes hides differences between makes of keyboards, so keystrokes should not be taken directly from the hardware unless that’s absolutely necessary. Every assembler programmer should be thoroughly aware of the services provided by DOS and the BIOS, and should use them whenever they’re good enough for a given purpose.</p>
<p>A moment’s thought will show, however, that it’s not always desirable to follow the model of Figure 3.1. Disk-backup software programs the disk controller directly and sells handsomely, while keyboard macro programs and many pop-up programs read the keyboard directly. Part of your job as a programmer is knowing when to break the rules embodied by Figure 3.1, and breaking the rules is tempting because this model has major failings when it comes to performance.</p>
<p>One shortcoming of the model of Figure 3.1 is that DOS and the BIOS provide inadequate services in some areas, and no services at all in others. For instance, the half-hearted support DOS and the BIOS provide for serial communications is an insult to the potential of the PC’s communications hardware. Likewise, the graphics primitives offered by the BIOS are so slow and limited as to be virtually useless. While device drivers can extend DOS’s capabilities in some areas, many of the drivers are themselves embarrassingly slow and limited. As an example, the ANSI.SYS driver, which provides extended screen control in text mode, is so sluggish that a single screen update can take a second and more — quite a contrast with the instant screen updates most text editors and word processors offer.</p>
<p>When you use a system service, you’re accepting someone else’s solution to a problem; while it may be a good solution, you don’t know that unless you check. After all, you may well be a better programmer than the author of the system software, and you’re bound to be better attuned to your particular needs than he was. In short, you should know the system services well and use them fully, but you should also learn when it pays to replace them with your own code.</p>
</section>
<section id="cycle-eaters" class="level2">
<h2>Cycle-Eaters</h2>
<p>The second shortcoming of the model shown in Figure 3.1 is that it makes the hardware seem to be just another system resource, and a rather remote and uninteresting resource, at that. Nothing could be further from the truth! After all, in order to be useful programs must ultimately perform input from and output to the real world, and all input and output requires interaction with the hardware. True, DOS and the BIOS may handle much of your I/O, but DOS and the BIOS themselves are nothing more than assembly-language programs.</p>
<p>Also, programs access memory almost continuously, and memory is of course part of the PC’s hardware. It’s hard to write a code sequence of more than a few dozen instructions in which memory isn’t accessed at least once as either a stack operand or as a direct instruction operand. I/O ports are also accessed heavily in some applications. Every single memory and I/O access of any kind must interact with the hardware via the PC’s data bus.</p>
<p>It’s easy to think of the PC’s hardware and bus as being transparent to programs; hardware appears to be available on demand, while the bus seems to be nothing more than a path for data to take on the way to and from the hardware. Not so. While the PC bus is in fact generally transparent to programs, the many demands on the bus and the relatively low rate at which the bus, the 8088, and the PC’s memory together can support data transfers can have a significant effect on performance, as we’ll see shortly. Moreover, there are a number of memory and I/O devices for the PC that can’t access data fast enough to keep up with the PC bus; to compensate, they make the 8088 wait, sometimes for several cycles, while they catch up. Inevitably, program performance suffers from these characteristics of the hardware and bus.</p>
<p>For the remainder of this book, I’m going to refer to PC bus-and hardware-resident gremlins that affect code performance as “cycle-eaters.” There are cycle-eaters of many sorts, of which the prefetch queue and display adapter cycle-eaters are perhaps the best-known; 8-bit cards in ATs and dynamic RAM refresh are other examples. Cycle-eaters are undeniably difficult to pin down. Once you’ve identified and understood them, though, you’ll be among the elite few who can deal with the most powerful — and least understood — aspect of assembler programming.</p>
<p>Just how important are cycle-eaters? Well, thanks to the display adapter cycle-eater, the code in <a href="#listing-3-1">Listing 3-1</a>, which accesses memory on an Enhanced Graphics Adapter (EGA), runs in 26.06 ms. That’s more than twice as long as the 11.24 ms of <a href="#listing-3-2">Listing 3-2</a>, which is identical to <a href="#listing-3-1">Listing 3-1</a> except that it accesses normal system memory rather than display memory. That’s a difference in performance as great as that between an 8-MHz AT and a 16-MHz 80386 machine! Clearly, cycle-eaters cannot be ignored, and in the chapters to come we’ll spend considerable time tracking them down and devising ways to work around them.</p>
<p>Given cycle-eaters and our understanding of layered system software as simply another sort of code, the programming model shown in Figure 3.2 is more appropriate than that of Figure 3.1. All system and application software, whether generated from high-level or assembler source code, ultimately becomes a series of machine-language instructions for the 8088. The 8088 executes each of those instructions in turn, accessing memory and devices as needed by way of the PC bus. In this three-level structure, the 8088 provides software with a programming interface, and in turn rests on the PC’s hardware. Thanks to cycle-eaters, the PC’s hardware and bus emerge as important factors in performance.</p>
<figure>
<img src="images/fig3.2RT.png" />
</figure>
<p>The primary virtue of Figure 3.2 is that it moves us away from the comfortable, human-oriented perspective of Figure 3.1 and forces us to view program execution at a level closer to the true nature of the beast, as consisting of nothing more than the performance of a sequence of instructions that command the 8088 to perform actions; in some cases, those actions involve accessing memory and/or devices over the PC bus. From the software side, we can now see that all code consists of machine-language instructions in the end, so the distinction between high-level languages, system software, and assembler vanishes. From the hardware side, we can see that the 8088 is not the lowest level, and we can begin to appreciate the many ways in which hardware can directly affect code performance.</p>
<p>We need to see still more of the beast, however, and the place we’ll start is with the equivalence of code and data.</p>
</section>
<section id="code-is-data" class="level2">
<h2>Code is Data</h2>
<p>Code is nothing more than data that the 8088 interprets as instructions. The most obvious case of this is self-modifying code, where the 8088 treats its code as data in order to modify it, then executes those same bytes as instructions. There are many other examples, though — after all, what is a compiler but a program that transforms source code data into machine-language data? Both code and data consist of byte values stored in system memory; the only thing that differentiates code from any other sort of data is that the bytes that code is made of have a special meaning to the 8088, in that when fetched as instructions they instruct the 8088 to perform a series of (presumably related) actions. In other words, the meaning of byte values as code rather than data is strictly a matter of context.</p>
<p>Why is this important? It’s important because the 8088 is really two processors in one, and therein lies a tale.</p>
</section>
<section id="inside-the-8088" class="level2">
<h2>Inside the 8088</h2>
<p>Internally, the 8088 consists of two complementary processors: the Bus Interface Unit (BIU) and the Execution Unit (EU), as shown in Figure 3.3. The EU is what we normally think of as being a processor; it contains the flags, the general-purpose registers, and the Arithmetic Logic Unit (ALU), and executes instructions. In fact, the EU performs just about every function you could want from a processor — except one. The one thing the EU does not do is access memory or perform I/O. That’s the BIU’s job, so whenever the EU needs a memory or I/O access performed, it sends a request to the BIU, which carries out the access, transferring the data according to the EU’s specifications. The two units are capable of operating in parallel whenever they’ve got independent tasks to perform; put another way, the BIU can access memory or I/O at the same time that the EU is processing an instruction, so long as neither task is dependent on the other.</p>
<figure>
<img src="images/fig3.3RT.png" />
</figure>
<p>Each BIU memory access transfers 1 byte, since the 8088 has an 8-bit external data bus. The 8088 is designed so that each byte access takes a minimum of 4 cycles; given the PC’s 4.77-MHz processor clock, which results in a 209.5 ns cycle time, the 8088 supports a maximum data transfer rate of 1 byte/838 ns, or about 1.2 bytes/us. That’s an important number, and we’ll come back to it shortly.</p>
<p>The EU is capable of working with both 8-and 16-bit memory operands. Because the 8088 can only access memory a byte at a time, however, the BIU splits each of the EU’s 16-bit memory requests into a pair of 8-bit accesses. Since each 8-bit access requires a minimum of 4 cycles to execute, each 16-bit memory request takes at least 8 cycles, or 1.676 us. The instruction timings shown in Appendix A reflect the additional overhead of word memory accesses by indicating that 4 additional cycles per memory access should be added to the stated instruction execution times when word rather than byte memory operands are used.</p>
<p>The BIU contains all the memory-related logic of the 8088, including the segment registers and the Instruction Pointer, which points to the next instruction to be executed. Since code is just another sort of data, it makes sense that the Instruction Pointer resides in the BIU; after all, code bytes are read from memory just as data bytes are. In fact, the BIU takes on a bit of autonomy when it comes to fetching instructions. Whenever the EU isn’t making any memory or I/O requests, the BIU uses the otherwise idle time to fetch the bytes at the addresses immediately following the current instruction, on the reasonable theory that those addresses are likely to contain the next instructions that the EU will want. The BIU of the 8088 can store up to 4 potential instruction bytes in an internal prefetch queue, and other 8086-family processors can store more bytes still.</p>
<p>Instruction prefetching isn’t always advantageous. In particular, if the instruction the 8088 is currently executing results in a branch of any sort, the bytes in the instruction queue are of no value, since they are the bytes the 8088 would have executed had the branch <em>not</em> been performed. As a result, all the 8088 can do when a branch occurs is discard all the bytes in the prefetch queue and start fetching instructions all over again.</p>
<p>Nonetheless, the prefetching scheme often allows the BIU to have the next instruction byte waiting when the EU comes calling for it. Bear in mind that the EU and BIU can operate at the same time; it’s only when the EU is waiting for the BIU to finish a memory or I/O operation for it that the EU is held up. The virtue of the 8088’s internal architecture, then, is that the EU can increase its effective processing time because the BIU often coprocesses with it. Since instruction fetches occur in a constant stream — usually much more frequently than memory operand accesses — instruction prefetching is the most important sort of coprocessing the BIU performs.</p>
<p>It’s worth noting at this point that the execution time specified by Intel for any given instruction running on the 8088 (as shown in Appendix A) assumes that the BIU has already prefetched that instruction and has it ready and waiting for the EU. <em>If the next instruction is not waiting for the EU when the EU completes the current instruction, at least some of the time required to fetch the next instruction must be added to its specified execution time in order to arrive at the actual execution time.</em></p>
<p>The degree to which the EU and BIU can coprocess during instruction fetching is not uniform for all types of code; in fact, it varies considerably depending on the mix of instructions being executed. Multiplication and division instructions are ideal for coprocessing, since the BIU can prefetch until the queue is full while these very long instructions execute. Among other instructions, oddly enough, it is code that performs many memory accesses that allows the EU and BIU to coprocess most effectively, because the 8088 is relatively slow at executing instructions that access memory (as we’ll see in Chapter 7). While a single memory-accessing instruction is being executed, the BIU can often prefetch 1 to 4 instruction bytes (depending on the instruction being performed) and still leave time for the memory access to occur. Execution of a memory-accessing instruction and prefetching of the next instruction can generally proceed simultaneously, so such instructions often run at close to full speed.</p>
<p>Ironically, code that primarily performs register-only operations and rarely accesses memory affords little opportunity for prefetching, because register-only instructions execute so rapidly that the BIU can’t fetch instruction bytes nearly as rapidly as the EU can execute them. To see why this is so, recall that the 8088 can fetch 1 byte every 4 cycles, or 0.838 us. The <code class="sourceCode nasm"><span class="kw">shr</span></code> instruction is 2 bytes long, so it takes 1.676 us to fetch each <code class="sourceCode nasm"><span class="kw">shr</span></code> instruction. However, the EU can <em>execute</em> a <code class="sourceCode nasm"><span class="kw">shr</span></code> in just 2 cycles, or 0.419 us, four times as rapidly as the BIU can fetch the same instruction.</p>
<p>The instruction queue can be depleted quickly by register-only instructions. <em>Given enough such instructions in a row, the overall time required to complete a series of register-only instructions is determined almost entirely by the time required to fetch the instructions from memory.</em> This is precisely the respect in which Figure 3.2 fails us; because of the prefetch queue, the instructions the 8088 executes must be viewed as data, stored along with other program data and accessed through the same PC bus and BIU, as shown in Figure 3.4. Seen in this light, it becomes apparent that instruction fetches are subject to the same cycle-eaters as are memory operand accesses. What’s more, the BIU emerges as potentially the greatest cycle-eater of all, as code and data bytes struggle to get through the BIU fast enough to keep the EU busy, a phenomenon I’ll refer to as the prefetch queue cycle-eater from now on. As we will see, designing code to work around the prefetch queue cycle-eater and keep the EU busy is a difficult but rewarding task.</p>
<figure>
<img src="images/fig3.4RT.png" />
</figure>
</section>
<section id="stepchild-of-the-8086" class="level2">
<h2>Stepchild of the 8086</h2>
<p>You might justifiably wonder why Intel would design a processor with an EU that can execute instructions faster than the BIU can possibly fetch them. The answer is that they didn’t; they designed the 8086, then created the 8088 as a poor man’s 8086.</p>
<p>The 8086 is completely software compatible with the 8088, and in fact differs from the 8088 in only one important respect, the width of the external data bus (the bus that goes off-chip to memory and peripherals); where the 8088 has an 8-bit wide external data bus, the 8086 has a 16-bit wide bus. (The 8086 also has a 6-rather than 4-byte prefetch queue, which gives it a bit of an advantage in keeping the EU busy.) Both the 8086 and 8088 have 16-bit EUs and 16-bit internal data buses, but while the 8086’s BIU can fulfill most 16-bit memory requests with a single memory access, the 8088’s BIU must convert 16-bit memory requests into 8-bit memory accesses. Figure 3.5, which charts internal and external data bus sizes for processors from the 8080 through the 80386, shows that the 8088 is something of an aberration in that it is the only widely-used processor in the 8086 family with mismatched internal and external data bus sizes. (The 80386SX, which may well become a successful low-cost substitute for the 80386, also has mismatched internal and external bus sizes, and as a result suffers from many of the same performance constraints as does the 8088.)</p>
<figure>
<img src="images/fig3.5RT.png" />
</figure>
<p>There is a significant price to be paid for the 8088’s mismatched bus sizes. Why? Well, the 8086 was designed to support efficient and balanced memory access, with the external data bus in general in use as much as possible without that bus becoming a bottleneck. In other words, the 16-bit external data bus of the 8086 was designed to provide a memory access rate roughly equal to the processing rate of which the 16-bit EU is capable. While the 8088 offers the same internal 16-bit architecture as the 8086, the 8-bit external data bus of the 8088 can provide at best only half the memory access rate of the 8086, so the balance of the 8086 is lost.</p>
<p>The obvious effect of the 8088’s mismatched bus sizes is that accesses to word-sized memory operands take 4 cycles longer on an 8088 than on an 8086, but that’s actually not the most significant fallout of the 8-bit external data bus. More significant is the prefetch queue cycle-eater, which is the result of the inability of the 8088’s BIU to fetch instructions and operands over the 8-bit external data bus as fast as the 16-bit EU can process them, thereby limiting the performance of the 8088’s fastest instructions. By contrast, the 8086, for which the EU was originally designed, has little trouble keeping the EU supplied with instructions and data; the 8086’s BIU fetches 2 instruction bytes in the same time it takes the 8088 to fetch a single byte, making the 8086 instruction fetching rate <em>twice</em> that of the 8088.</p>
<p>How significant is the performance impact of the 8088’s 8-bit external data bus? While normal code is estimated to run only about one-third faster on an 8086 than on an 8088, high-performance 8086 code can — as we’ve already seen — run as much as four times more slowly on an 8088 once the prefetch queue empties, because code performance is limited by the rate at which the BIU can transfer data a byte at a time. In the case where both the 8088 and 8086 prefetch queues are emptied, the 8086 runs fast assembler code only twice as fast as the 8088, but the 8086 has a bigger prefetch queue than the 8088 and fetches instructions twice as fast, so the 8086 queue empties much more slowly — and in any case, twice as fast is nothing to sniff at.</p>
<p>In short, the 8086 is just like the 8088 — except that it’s somewhere between 0% and 300% faster, depending on what code happens to be executing, with a typical performance advantage of somewhere between 33% and 100% for high-performance assembler code.</p>
<p>Why then does the 8088 exist, and why has it become so popular? An 8-bit-bus version of the 8086 (that is, the 8088) was desirable in the late 1970s because at that time it was significantly more expensive to build a computer with a 16-bit data bus than with an 8-bit data bus. The 8088 allowed the construction of low-cost, low-performance computers that would run 8086 software, albeit more slowly. As it turned out, the cost advantage of an 8-bit memory data bus quickly became relatively insignificant, and the 8088 might have vanished into obscurity had IBM not selected it for the PC; then we might never have had the pleasure of wrestling with the prefetch queue cycle-eater. However, IBM <em>did</em> select the 8088 for the PC, and the rest is history.</p>
<p>Incidentally, an imbalance between processing speed and memory access speed remains a factor today with the 80286-based IBM AT and with many 80386-based computers. The memory in those computers often does not run at the speeds the processors are capable of, and assembler code encounters the same sorts of performance losses when running on those computers as it does on the 8088. We’ll return to that topic in Chapter 15.</p>
</section>
<section id="which-model-to-use" class="level2">
<h2>Which Model to Use?</h2>
<p>Each of the three programming models I’ve presented offers a useful perspective on assembler programming for the PC. However, it is the model shown in Figure 3.4 that best reflects the true nature of the 8088; consequently, that model is the most useful of the three for tapping the unique potential of assembler. While we’ll use elements of all three models in <em>The Zen of Assembly Language</em>, we’ll concentrate on the perspective of Figure 3.4 as we explore high-performance assembler programming.</p>
<p>Keep the following concepts in mind as you read on:</p>
<ul>
<li><em>All code is machine language in the end</em>: don’t assume that anyone else’s code, even system software, is best suited for your needs.</li>
<li><em>1.2 bytes/us</em>: at its best, the 8088’s BIU can transfer data no faster than this.</li>
<li><em>The 8088 is not the lowest level</em>: know how the PC’s hardware and bus affect memory access speed.</li>
<li><em>Code is data</em>: when the BIU and the PC’s hardware and bus affect memory access speed, they affect code fetching as well as data access, since code is just another sort of data in system memory.</li>
</ul>
<p>Short and simple as the above list may seem, in it you will find every one of the concepts that form the foundation of the Zen of assembler — and with them the key to high-performance code.</p>
</section>
</section>
<section id="chapter-4-things-mother-never-told-you-under-the-programming-interface" class="level1">
<h1>Chapter 4: Things Mother Never Told You: Under the Programming Interface</h1>
<p>Over the last few chapters we’ve seen that programming has many levels, ranging from the familiar (high-level languages, DOS calls, and the like) to the esoteric (cycle-eaters). In this chapter we’re going to jump right in at the lowest level by examining the cycle-eaters that live beneath the programming interface.</p>
<p>Why start at the lowest level? Simply because cycle-eaters affect the performance of all assembler code, and yet are almost unknown to most programmers. A full understanding of virtually everything else we’ll discuss in <em>The Zen of Assembly Language</em> requires an understanding of cycle-eaters and their implications. That’s no simple task, and in fact it is in precisely that area that most books and articles about assembler programming fall short.</p>
<p>Nearly all literature on assembler programming discusses only the programming interface: the instruction set, the registers, the flags, and the BIOS and DOS calls. Those topics cover the functionality of assembler programs most thoroughly — but it’s performance above all else that we’re after. No one ever tells you about the raw stuff of performance, which lies <em>beneath</em> the programming interface, in the dimly-seen realm-populated by instruction prefetching, dynamic RAM refresh, and wait states — where software meets hardware. This area is the domain of hardware engineers, and is almost never discussed as it relates to code performance. And yet it is only by understanding the mechanisms operating at this level that we can fully understand and properly improve the performance of our code.</p>
<p>Which brings us to cycle-eaters.</p>
<section id="cycle-eaters-revisited" class="level2">
<h2>Cycle-Eaters Revisited</h2>
<p>You’ll recall that cycle-eaters are gremlins that live on the bus or in peripherals, slowing the performance of 8088 code so that it doesn’t execute at full speed. Because cycle-eaters live outside the Execution Unit of the 8088, they can <em>only</em> affect the 8088 when the 8088 performs a bus access (a memory or I/O read or write). Internally, the 8088 is a 16-bit processor, capable of running at full speed at all times — unless external data is required. External data must traverse the 8088’s external data bus and the PC’s data bus 1 byte at a time to and from peripherals, with cycle-eaters lurking along every step of the way. What’s more, external data includes not only memory operands <em>but also instruction bytes</em>, so even instructions with no memory operands can suffer from cycle-eaters. Since some of the 8088’s fastest instructions are register-only instructions, that’s important indeed.</p>
<p>The major cycle-eaters are:</p>
<ul>
<li>The 8088’s 8-bit external data bus.</li>
<li>The prefetch queue.</li>
<li>Dynamic RAM refresh.</li>
<li>Wait states, notably display memory wait states and, in the AT and 80386 computers, system memory wait states.</li>
</ul>
<p>The locations of these cycle-eaters in the PC are shown in Figure 4.1. We’ll cover each of the cycle-eaters in turn in this chapter. The material won’t be easy, since cycle-eaters are among the most subtle aspects of assembler programming. By the same token, however, this will be one of the most important and rewarding chapters in this book. Don’t worry if you don’t catch everything in this chapter, but do read it all even if the going gets a bit tough. Cycle-eaters play a key role in later chapters, so some familiarity with them is highly desirable. Then, too, those later chapters illustrate cycle-eaters in action, which should help clear up any aspects of cycle-eaters about which you’re uncertain.</p>
<figure>
<img src="images/fig4.1RT.png" />
</figure>
</section>
<section id="the-8-bit-bus-cycle-eater" class="level2">
<h2>The 8-Bit Bus Cycle-Eater</h2>
<p><em>Look! Down on the motherboard! It’s a 16-bit processor! It’s an 8-bit processor! It’s…</em></p>
<p><em>…an 8088!</em></p>
<p>Fans of the 8088 call it a 16-bit processor. Fans of other 16-bit processors call the 8088 an 8-bit processor. Unbiased as we are, we know that the truth of the matter is that the 8088 is a 16-bit processor that often <em>performs</em> like an 8-bit processor.</p>
<p>As we saw in Chapter 3, the 8088 is internally a full 16-bit processor, equivalent to an 8086. In terms of the instruction set, the 8088 is clearly a 16-bit processor, capable of performing any given 16-bit operation — addition, subtraction, even multiplication or division — with a single instruction. Externally, however, the 8088 is unequivocally an 8-bit processor, since the external data bus is only 8 bits wide. In other words, the programming interface is 16 bits wide, but the hardware interface is only 8 bits wide, as shown in Figure 4.2. The result of this mismatch is simple: word-sized data can be transferred between the 8088 and memory or peripherals at only one-half the maximum rate of the 8086, which is to say one-half the maximum rate for which the Execution Unit of the 8088 was designed.</p>
<figure>
<img src="images/fig4.2RT.png" />
</figure>
<p>As shown in Figure 4.1, the 8-bit bus cycle-eater lies squarely on the 8088’s external data bus. Technically, it might be more accurate to place this cycle-eater in the Bus Interface Unit, which breaks 16-bit memory accesses into paired 8-bit accesses, but it is really the limited width of the external data bus that constricts data flow into and out of the 8088. True, the PC’s bus is also only 8 bits wide, but that’s just to match the 8088’s 8-bit bus; even if the PC’s bus were 16 bits wide, data could still pass into and out of the 8088 only 1 byte at a time.</p>
<p>Each bus access by the 8088 takes 4 clock cycles, or 0.838 us in the PC, and transfers 1 byte. That means that the maximum rate at which data can be transferred into and out of the 8088 is 1 byte every 0.838 us. While 8086 bus accesses also take 4 clock cycles, each 8086 bus access can transfer either 1 byte or 1 word, for a maximum transfer rate of 1 <em>word</em> every 0.838 us. Consequently, for word-sized memory accesses the 8086 has an effective transfer rate of 1 byte every 0.419 us. By contrast, every word-sized access on the 8088 requires two 4-cycle-long bus accesses, one for the high byte of the word and one for the low byte of the word. As a result, the 8088 has an effective transfer rate for word-sized memory accesses of just 1 word every 1.676 us — and that, in a nutshell, is the 8-bit bus cycle-eater.</p>
<section id="the-impact-of-the-8-bit-bus-cycle-eater" class="level3">
<h3>The Impact of the 8-Bit Bus Cycle-Eater</h3>
<p>One obvious effect of the 8-bit bus cycle-eater is that word-sized accesses to memory operands on the 8088 take 4 cycles longer than byte-sized accesses. That’s why the instruction timings in Appendix A indicate that for code running on an 8088 an additional 4 cycles are required for every word-sized access to a memory operand. For instance:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ax</span>,<span class="dt">word</span> <span class="dt">ptr</span> [MemVar]</code></pre>
<p>takes 4 cycles longer to read the word at address <code class="sourceCode nasm">MemVar</code> than:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,<span class="dt">byte</span> <span class="dt">ptr</span> [MemVar]</code></pre>
<p>takes to read the byte at address <code class="sourceCode nasm">MemVar</code>. (Actually, the difference between the two isn’t very likely to be exactly 4 cycles, for reasons that will become clear when we discuss the prefetch queue and dynamic RAM refresh cycle-eaters later in this chapter.)</p>
<p>What’s more, in some cases one instruction can perform multiple word-sized accesses, incurring that 4-cycle penalty on each access. For example, adding a value to a word-sized memory variable requires 2 word-sized accesses — one to read the destination operand from memory prior to adding to it, and one to write the result of the addition back to the destination operand — and thus incurs not one but two 4-cycle penalties. As a result:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">add</span> <span class="dt">word</span> <span class="dt">ptr</span> [MemVar],<span class="kw">ax</span></code></pre>
<p>takes about 8 cycles longer to execute than:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">add</span> <span class="dt">byte</span> <span class="dt">ptr</span> [MemVar],<span class="kw">al</span></code></pre>
<p>String instructions can suffer from the 8-bit bus cycle-eater to a greater extent than other instructions. Believe it or not, a single <code class="sourceCode nasm">rep <span class="kw">movsw</span></code> instruction can lose as much as:</p>
<p><strong>524,280 cycles = 131,070 word-sized memory accesses x 4 cycles</strong></p>
<p>to the 8-bit bus cycle-eater! In other words, one 8088 instruction (admittedly, an instruction that does a great deal) can take over one-tenth of a second longer on an 8088 than on an 8086, simply because of the 8-bit bus. <em>One-tenth of a second!</em> That’s a phenomenally long time in computer terms; in one-tenth of a second, the 8088 can perform more than 50,000 additions and subtractions.</p>
<p>The upshot of all this is simply that the 8088 can transfer word-sized data to and from memory at only half the speed of the 8086, which inevitably causes performance problems when coupled with an Execution Unit that can process word-sized data every bit as fast as an 8086. These problems show up with any code that uses word-sized memory operands. More ominously, as we will see shortly, the 8-bit bus cycle-eater can cause performance problems with other sorts of code as well.</p>
</section>
<section id="what-to-do-about-the-8-bit-bus-cycle-eater" class="level3">
<h3>What to Do About the 8-Bit Bus Cycle-Eater?</h3>
<p>The obvious implication of the 8-bit bus cycle-eater is that byte-sized memory variables should be used whenever possible. After all, the 8088 performs <em>byte-sized</em> memory accesses just as quickly as the 8086. For instance, <a href="#listing-4-1">Listing 4-1</a>, which uses a byte-sized memory variable as a loop counter, runs in 10.03 us per loop. That’s 20% faster than the 12.05 us per loop execution time of <a href="#listing-4-2">Listing 4-2</a>, which uses a word-sized counter. Why the difference in execution times? Simply because each word-sized <code class="sourceCode nasm"><span class="kw">dec</span></code> performs 4 byte-sized memory accesses (2 to read the word-sized operand and 2 to write the result back to memory), while each byte-sized <code class="sourceCode nasm"><span class="kw">dec</span></code> performs only 2 byte-sized memory accesses in all.</p>
<p>I’d like to make a brief aside concerning code optimization in the listings in this book. Throughout this book I’ve modeled the sample code after working code so that the timing results are applicable to real-world programming. In <a href="#listing-4-1">Listings 4-1</a> and <a href="#listing-4-2">4-2</a>, for instance, I could have shown a still greater advantage for byte-sized operands simply by performing 1000 <code class="sourceCode nasm"><span class="kw">dec</span></code> instructions in a row, with no branching at all. However, <code class="sourceCode nasm"><span class="kw">dec</span></code> instructions don’t exist in a vacuum, so in the listings I used code that both decremented the counter and tested the result. The difference is that between decrementing a memory location (simply an instruction) and using a loop counter (a functional instruction sequence). If you come across code in <em>The Zen of Assembly Language</em> that seems less than optimal, my desire to provide code that’s relevant to real programming problems may be the reason. On the other hand, optimal code is an elusive thing indeed; by no means should you assume that the code in this book is ideal! Examine it, question it, and improve upon it, for an inquisitive, skeptical mind is an important part of the Zen of assembler.</p>
<p>Back to the 8-bit bus cycle-eater. As I’ve said, you should strive to use byte-sized memory variables whenever possible. That does <em>not</em> mean that you should use 2 byte-sized memory accesses to manipulate a word-sized memory variable in preference to 1 word-sized memory access, as, for instance, with:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">dl</span>,<span class="dt">byte</span> <span class="dt">ptr</span> [MemVar]
<span class="kw">mov</span> <span class="kw">dh</span>,<span class="dt">byte</span> <span class="dt">ptr</span> [MemVar<span class="dv">+1</span>]</code></pre>
<p>versus:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">dx</span>,<span class="dt">word</span> <span class="dt">ptr</span> [MemVar]</code></pre>
<p>Recall that every access to a memory byte takes at least 4 cycles; that limitation is built right into the 8088. The 8088 is also built so that the second byte-sized memory access to a 16-bit memory variable takes just those 4 cycles and no more. There’s no way you can manipulate the second byte of a word-sized memory variable faster with a second separate byte-sized instruction in less than 4 cycles. As a matter of fact, you’re bound to access that second byte much more slowly with a separate instruction, thanks to the overhead of instruction fetching and execution, address calculation, and the like.</p>
<p>For example, consider <a href="#listing-4-3">Listing 4-3</a>, which performs 1000 word-sized reads from memory. This code runs in 3.77 us per word read. That’s 45% faster than the 5.49 us per word read of <a href="#listing-4-4">Listing 4-4</a>, which reads the same 1000 words as <a href="#listing-4-3">Listing 4-3</a> but does so with 2000 byte-sized reads. Both listings perform exactly the same number of memory accesses — 2000 accesses, each byte-sized, as all 8088 memory accesses must be. (Remember that the Bus Interface Unit must perform two byte-sized memory accesses in order to handle a word-sized memory operand.) However, <a href="#listing-4-3">Listing 4-3</a> is considerably faster because it expends only 4 additional cycles to read the second byte of each word, while <a href="#listing-4-4">Listing 4-4</a> performs a second <code class="sourceCode nasm"><span class="kw">lodsb</span></code>, requiring 13 cycles, to read the second byte of each word.</p>
<p>In short, if you must perform a 16-bit memory access, let the 8088 break the access into two byte-sized accesses for you. The 8088 is more efficient at that task than your code can possibly be.</p>
<p>Chapter 9 has further examples of ways in which you can take advantage of the 8088’s relative speed at handling the second byte of a word-sized memory operand to improve your code. However, that advantage only exists relative to the time taken to access 2 byte-sized memory operands; you’re still better off using single byte-sized memory accesses rather than word-sized accesses whenever possible. Word-sized variables should be stored in registers to the greatest feasible extent, since registers are inside the 8088, where 16-bit operations are just as fast as 8-bit operations because the 8-bit cycle-eater can’t get at them. In fact, it’s a good idea to keep as many variables of all sorts in registers as you can. Instructions with register-only operands execute very rapidly, partially because they avoid both the time-consuming memory accesses and the lengthy address calculations associated with memory operands.</p>
<p>There is yet another reason why register operands are preferable to memory operands, and it’s an unexpected effect of the 8-bit bus cycle-eater. Instructions with only register operands tend to be shorter (in terms of bytes) than instructions with memory operands, and when it comes to performance, shorter is usually better. In order to explain why that is true and how it relates to the 8-bit bus cycle-eater, I must diverge for a moment.</p>
<p>For the last few pages, you may well have been thinking that the 8-bit bus cycle-eater, while a nuisance, doesn’t seem particularly subtle or difficult to quantify. After all, Appendix A tells us exactly how many cycles each instruction loses to the 8-bit bus cycle-eater, doesn’t it?</p>
<p>Yes and no. It’s true that in general we know approximately how much longer a given instruction will take to execute with a word-sized memory operand than with a byte-sized operand, although the dynamic RAM refresh and wait state cycle-eaters can raise the cost of the 8-bit bus cycle-eater considerably, as we’ll see later in this chapter. However, <em>all</em> word-sized memory accesses lose 4 cycles to the 8-bit bus cycle-eater, and there’s one sort of word-sized memory access we haven’t discussed yet: instruction fetching. The ugliest manifestation of the 8-bit bus cycle-eater is in fact the prefetch queue cycle-eater.</p>
</section>
</section>
<section id="the-prefetch-queue-cycle-eater" class="level2">
<h2>The Prefetch Queue Cycle-Eater</h2>
<p>Simply put, here’s the prefetch queue cycle-eater: the 8088’s 8-bit external data bus keeps the Bus Interface Unit from fetching instruction bytes as fast as the 16-bit Execution Unit can execute them, so the Execution Unit often lies idle while waiting for the next instruction byte to be fetched.</p>
<p>Exactly why does this happen? Recall that the 8088 is an 8086 internally, but accesses word-sized memory data at only one-half the maximum rate of the 8086 due to the 8088’s 8-bit external data bus. Unfortunately, instructions are among the word-sized data the 8086 fetches, meaning that the 8088 can fetch instructions at only one-half the speed of the 8086. On the other hand, the 8086-equivalent Execution Unit of the 8088 can <em>execute</em> instructions every bit as fast as the 8086. The net result is that the Execution Unit burns up instruction bytes much faster than the Bus Interface Unit can fetch them, and ends up idling while waiting for instructions bytes to arrive.</p>
<p>The BIU can fetch instruction bytes at a maximum rate of one byte every 4 cycles-<em>and that 4-cycle per instruction byte rate is the ultimate limit on overall instruction execution time, regardless of EU speed</em>. While the EU may execute a given instruction that’s already in the prefetch queue in less than 4 cycles per byte, over time the EU can’t execute instructions any faster than they can arrive-and they can’t arrive faster than 1 byte every 4 cycles.</p>
<p>Clearly, then, the prefetch queue cycle-eater is nothing more than one aspect of the 8-bit bus cycle-eater. 8088 code often runs at less than the Execution Unit’s maximum speed because the 8-bit data bus can’t keep up with the demand for instruction bytes. That’s straightforward enough-so why all the fuss about the prefetch queue cycle-eater?</p>
<p>What makes the prefetch queue cycle-eater tricky is that it’s undocumented and unpredictable. That is, with a word-sized memory access, such as:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span> [<span class="kw">bx</span>],<span class="kw">ax</span></code></pre>
<p>it’s well-documented that an extra 4 cycles will always be required to write the upper byte of AX to memory. Not so with the prefetch queue. For instance, the instructions:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">shr</span> <span class="kw">ax</span>,<span class="dv">1</span>
<span class="kw">shr</span> <span class="kw">ax</span>,<span class="dv">1</span>
<span class="kw">shr</span> <span class="kw">ax</span>,<span class="dv">1</span>
<span class="kw">shr</span> <span class="kw">ax</span>,<span class="dv">1</span>
<span class="kw">shr</span> <span class="kw">ax</span>,<span class="dv">1</span></code></pre>
<p>should execute in 10 cycles, according to the specifications in Appendix A, since each <code class="sourceCode nasm"><span class="kw">shr</span></code> takes 2 cycles to execute. Those specifications contain Intel’s official instruction execution times, but in this case-and in many others-the specifications are drastically wrong. Why? Because they describe execution time <em>once an instruction reaches the prefetch queue</em>. They say nothing about whether a given instruction will be in the prefetch queue when it’s time for that instruction to run, or how long it will take that instruction to reach the prefetch queue if it’s not there already. Thanks to the low performance of the 8088’s external data bus, that’s a glaring omission -but, alas, an unavoidable one. Let’s look at why the official execution times are wrong, and why that can’t be helped.</p>
<section id="official-execution-times-are-only-part-of-the-story" class="level3">
<h3>Official Execution Times are Only Part of the Story</h3>
<p>The sequence of 5 <code class="sourceCode nasm"><span class="kw">shr</span></code> instructions in the last example is 10 bytes long. That means that it can never execute in less than 24 cycles even if the 4-byte prefetch queue is full when it starts, since 6 instruction bytes would still remain to be fetched, at 4 cycles per fetch. If the prefetch queue is empty at the start, the sequence <em>could</em> take 40 cycles. In short, thanks to instruction fetching the code won’t run at its documented speed, and could take up to 4 times as long as it is supposed to.</p>
<p>Why does Intel document Execution Unit execution time rather than overall instruction execution time, which includes both instruction fetch time and Execution Unit execution time? As described in Chapter 3, instruction fetching isn’t performed as part of instruction execution by the Execution Unit, but instead is carried on in parallel by the Bus Interface Unit whenever the external data bus isn’t in use or whenever the EU runs out of instruction bytes to execute. Sometimes the BIU is able to use spare bus cycles to prefetch instruction bytes before the EU needs them, so instruction fetching takes no time at all, practically speaking. At other times the EU executes instructions faster than the BIU can fetch them and instruction fetching becomes a significant part of overall execution time. As a result, <em>the effective fetch time for a given instruction varies greatly depending on the code mix preceding that instruction</em>. Similarly, the state in which a given instruction leaves the prefetch queue affects the overall execution time of the following instructions.</p>
<p>In other words, while the execution time for a given instruction is constant, the fetch time for that instruction depends on the context in which the instruction is executing -the amount of prefetching the preceding instructions allowed -and can vary from a full 4 cycles per instruction byte to no time at all. As we’ll see later, other cycle-eaters, such as DRAM refresh and display memory wait states, can cause prefetching variations even during different executions of the <em>same</em> code sequence. Given that, it’s meaningless to talk about the prefetch time of a given instruction except in the context of a specific code sequence.</p>
<p>So now you know why the official instruction execution times are often wrong, and why Intel can’t provide better specifications. You also know now why it is that you must time your code if you want to know how fast it really is.</p>
</section>
<section id="there-is-no-such-beast-as-a-true-instruction-execution-time" class="level3">
<h3>There is No Such Beast as a True Instruction Execution Time</h3>
<p>The effect of the code preceding an instruction on the execution time of that instruction makes the Zen timer trickier to use than you might expect, and complicates the interpretation of the results reported by the Zen timer. For one thing, the Zen timer is best used to time code sequences that are more than a few instructions long; below 10 us or so, prefetch queue effects and the limited resolution of the clock driving the timer can cause problems.</p>
<p>Some slight prefetch queue-induced inaccuracy usually exists even when the Zen timer is used to time longer code sequences, since the calls to the Zen timer usually alter the code’s prefetch queue from its normal state. (As we’ll see in Chapter 12, branches — jumps, calls, returns and the like — empty the prefetch queue.) Ideally, the Zen timer is used to measure the performance of an entire subroutine, so the prefetch queue effects of the branches at the start and end of the subroutine are similar to the effects of the calls to the Zen timer when you’re measuring the subroutine’s performance.</p>
<p>Another way in which the prefetch queue cycle-eater complicates the use of the Zen timer involves the practice of timing the performance of a few instructions over and over. I’ll often repeat one or two instructions 100 or 1000 times in a row in listings in this book in order to get timing intervals that are long enough to provide reliable measurements. However, as we just learned, the actual performance of any 8088 instruction depends on the code mix preceding any given use of that instruction, which in turns affects the state of the prefetch queue when the instruction starts executing. Alas, the execution time of an instruction preceded by dozens of identical instructions reflects just one of many possible prefetch states (and not a very likely state at that), and some of the other prefetch states may well produce distinctly different results.</p>
<p>For example, consider the code in <a href="#listing-4-5">Listings 4-5</a> and <a href="#listing-4-6">4-6</a>. <a href="#listing-4-5">Listing 4-5</a> shows our familiar <code class="sourceCode nasm"><span class="kw">shr</span></code> case. Here, because the prefetch queue is always empty, execution time should work out to about 4 cycles per byte, or 8 cycles per <code class="sourceCode nasm"><span class="kw">shr</span></code>, as shown in Figure 4.3. (Figure 4.3 illustrates the relationship between instruction fetching and execution in a simplified way, and is not intended to show the exact timings of 8088 operations.) That’s quite a contrast to the official 2-cycle execution time of <code class="sourceCode nasm"><span class="kw">shr</span></code>. In fact, the Zen timer reports that <a href="#listing-4-5">Listing 4-5</a> executes in 1.81 us per byte, or slightly <em>more</em> than 4 cycles per byte. (The extra time is the result of the dynamic RAM refresh cycle-eater, which we’ll discuss shortly.) Going strictly by <a href="#listing-4-5">Listing 4-5</a>, we would conclude that the “true” execution time of <code class="sourceCode nasm"><span class="kw">shr</span></code> is 8.64 cycles.</p>
<figure>
<img src="images/fig4.3RT.png" />
</figure>
<p>Now let’s examine <a href="#listing-4-6">Listing 4-6</a>. Here each <code class="sourceCode nasm"><span class="kw">shr</span></code> follows a <code class="sourceCode nasm"><span class="kw">mul</span></code> instruction. Since <code class="sourceCode nasm"><span class="kw">mul</span></code> instructions take so long to execute that the prefetch queue is always full when they finish, each <code class="sourceCode nasm"><span class="kw">shr</span></code> should be ready and waiting in the prefetch queue when the preceding <code class="sourceCode nasm"><span class="kw">mul</span></code> ends. As a result, we’d expect that each <code class="sourceCode nasm"><span class="kw">shr</span></code> would execute in 2 cycles; together with the 118 cycle execution time of multiplying 0 times 0, the total execution time should come to 120 cycles per <code class="sourceCode nasm"><span class="kw">shr</span></code>/<code class="sourceCode nasm"><span class="kw">mul</span></code> pair, as shown in Figure 4.4. And, by God, when we run <a href="#listing-4-6">Listing 4-6</a> we get an execution time of 25.14 us per <code class="sourceCode nasm"><span class="kw">shr</span></code>/<code class="sourceCode nasm"><span class="kw">mul</span></code> pair, or <em>exactly</em> 120 cycles! According to these results, the “true” execution time of <code class="sourceCode nasm"><span class="kw">shr</span></code> would seem to be 2 cycles, quite a change from the conclusion we drew from <a href="#listing-4-5">Listing 4-5</a>.</p>
<figure>
<img src="images/fig4.4RT.png" />
</figure>
<p>The key point is this: we’ve seen one code sequence in which <code class="sourceCode nasm"><span class="kw">shr</span></code> took 8-plus cycles to execute, and another in which it took only 2 cycles. Are we talking about two different forms of <code class="sourceCode nasm"><span class="kw">shr</span></code> here? Of course not — the difference is purely a reflection of the differing states in which the preceding code left the prefetch queue. In <a href="#listing-4-5">Listing 4-5</a>, each <code class="sourceCode nasm"><span class="kw">shr</span></code> after the first few follows a slew of other <code class="sourceCode nasm"><span class="kw">shr</span></code> instructions which have sucked the prefetch queue dry, so overall performance reflects instruction fetch time. By contrast, each <code class="sourceCode nasm"><span class="kw">shr</span></code> in <a href="#listing-4-6">Listing 4-6</a> follows a <code class="sourceCode nasm"><span class="kw">mul</span></code> instruction which leaves the prefetch queue full, so overall performance reflects Execution Unit execution time.</p>
<p>Clearly, either instruction fetch time <em>or</em> Execution Unit execution time — or even a mix of the two, if an instruction is partially prefetched — can determine code performance. Some people operate under a rule of thumb by which they assume that the execution time of each instruction is 4 cycles times the number of bytes in the instruction. While that’s often true for register-only code, it frequently doesn’t hold for code that accesses memory. For one thing, the rule should be 4 cycles times the number of <em>memory accesses</em>, not instruction bytes, since all accesses take 4 cycles. For another, memory-accessing instructions often have slower Execution Unit execution times than the 4 cycles per memory access rule would dictate, because the 8088 isn’t very fast at calculating memory addresses, as we’ll see in Chapter 7. Also, the 4 cycles per instruction byte rule isn’t true for register-only instructions that are already in the prefetch queue when the preceding instruction ends.</p>
<p>The truth is that it never hurts performance to reduce either the cycle count or the byte count of a given bit of code, but there’s no guarantee that one or the other will improve performance either. For example, consider <a href="#listing-4-7">Listing 4-7</a>, which consists of a series of 4-cycle, 2-byte <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,<span class="dv">0</span></code> instructions, and which executes at the rate of 1.81 us per instruction. Now consider <a href="#listing-4-8">Listing 4-8</a>, which replaces the 4-cycle <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,<span class="dv">0</span></code> with the 3-cycle (but still 2-byte) <code class="sourceCode nasm"><span class="kw">sub</span> <span class="kw">al</span>,<span class="kw">al</span></code>. Despite its 1-cycle-per-instruction advantage, <a href="#listing-4-8">Listing 4-8</a> runs at exactly the same speed as <a href="#listing-4-7">Listing 4-7</a>. The reason: both instructions are 2 bytes long, and in both cases it is the 8-cycle instruction fetch time, not the 3-or 4-cycle Execution Unit execution time, that limits performance.</p>
<p>As you can see, it’s easy to be drawn into thinking you’re saving cycles when you’re not. You can only improve the performance of a specific bit of code by reducing the factor - either instruction fetch time or execution time, or sometimes a mix of the two — that’s limiting the performance of that code.</p>
<p>In case you missed it in all the excitement, the variability of prefetching means that our method of testing performance by executing 1000 instructions in a row by no means produces “true” instruction execution times, any more than the official execution times in Appendix A are “true” times. The fact of the matter is that a given instruction takes at least as long to execute as the time given for it in Appendix A, but may take as much as 4 cycles per byte longer, depending on the state of the prefetch queue when the preceding instruction ends. The only true execution time for an instruction is a time measured in a certain context, and that time is meaningful <em>only</em> in that context.</p>
<p>Look at it this way. We’ve firmly established that there’s no number you can attach to a given instruction that’s always that instruction’s true execution time. In fact, as we’ll see in the rest of this chapter and in the next, there are other cycle-eaters that can work with the prefetch queue cycle-eater to cause the execution time of an instruction to vary to an even greater extent than we’ve seen so far. That’s okay, though, because the execution time of a single instruction is not what we’re really after.</p>
<p>What we <em>really</em> want is to know how long useful working code takes to run, not how long a single instruction takes, and the Zen timer gives us the tool we need to gather that information. Granted, it would be easier if we could just add up neatly documented instruction execution times — but that’s not going to happen. Without actually measuring the performance of a given code sequence, you simply don’t know how fast it is. For crying out loud, even the people who <em>designed</em> the 8088 at Intel couldn’t tell you exactly how quickly a given 8088 code sequence executes on the PC just by looking at it! Get used to the idea that execution times are only meaningful in context, learn the rules of thumb in this book, and use the Zen timer to measure your code.</p>
</section>
<section id="approximating-overall-execution-times" class="level3">
<h3>Approximating Overall Execution Times</h3>
<p>Don’t think that because overall instruction execution time is determined by both instruction fetch time and Execution Unit execution time, the two times should be added together when estimating performance. For example, practically speaking, each <code class="sourceCode nasm"><span class="kw">shr</span></code> in <a href="#listing-4-5">Listing 4-5</a> does not take 8 cycles of instruction fetch time plus 2 cycles of Execution Unit execution time to execute. Figure 4.3 shows that while a given <code class="sourceCode nasm"><span class="kw">shr</span></code> is executing, the fetch of the next <code class="sourceCode nasm"><span class="kw">shr</span></code>is starting, and since the two operations are overlapped for 2 cycles, there’s no sense in charging the time to both instructions. You could think of the extra instruction fetch time for <code class="sourceCode nasm"><span class="kw">shr</span></code> in <a href="#listing-4-5">Listing 4-5</a> as being 6 cycles, which yields an overall execution time of 8 cycles when added to the 2 cycles of Execution Unit execution time.</p>
<p>Alternatively, you could think of each <code class="sourceCode nasm"><span class="kw">shr</span></code> in <a href="#listing-4-5">Listing 4-5</a> as taking 8 cycles to fetch, and then executing in effectively 0 cycles while the next <code class="sourceCode nasm"><span class="kw">shr</span></code> is being fetched. Whichever perspective you prefer is fine. The important point is that the time during which the execution of one instruction and the fetching of the next instruction overlap should only be counted toward the overall execution time of one of the instructions. For all intents and purposes, one of the two instructions runs at no performance cost whatsoever while the overlap exists.</p>
<p>As a working definition, we’ll consider the execution time of a given instruction in a particular context to start when the first byte of the instruction is sent to the Execution Unit and end when the first byte of the next instruction is sent to the EU. We’ll discuss this further in Chapter 5.</p>
</section>
<section id="what-to-do-about-the-prefetch-queue-cycle-eater" class="level3">
<h3>What to Do About the Prefetch Queue Cycle-Eater?</h3>
<p>Reducing the impact of the prefetch queue cycle-eater is one of the overriding principles of high-performance assembler code. How can you do this? One effective technique is to minimize access to memory operands, since such accesses compete with instruction fetching for precious memory accesses. You can also greatly reduce instruction fetch time simply by your choice of instructions: <em>keep your instructions short</em>. Less time is required to fetch instructions that are 1 or 2 bytes long than instructions that are 5 or 6 bytes long. Reduced instruction fetching lowers minimum execution time (minimum execution time is 4 cycles times the number of instruction bytes) and often leads to faster overall execution.</p>
<p>While short instructions minimize overall prefetch time, they ironically actually often suffer relatively more from the prefetch queue bottleneck than do long instructions. Short instructions generally have such fast execution times that they drain the prefetch queue despite their small size. For example, consider the <code class="sourceCode nasm"><span class="kw">shr</span></code> of <a href="#listing-4-5">Listing 4-5</a>, which runs at only 25% of its Execution Unit execution time even though it’s only 2 bytes long, thanks to the prefetch queue bottleneck. Short instructions are nonetheless generally faster than long instructions, thanks to the combination of fewer instruction bytes and faster Execution Unit execution times, and should be used as much as possible — just don’t expect them to run at their documented speeds.</p>
<p>More than anything, the above rules mean using the registers as heavily as possible, both because register-only instructions are short and because they don’t perform memory accesses to read or write operands. (Using the registers is a topic we’ll return to repeatedly in <em>The Zen of Assembly Language</em>.) However, using the registers is a rule of thumb, not a commandment. In some circumstances, it may actually be <em>faster</em> to access memory. (The look-up table technique, which we’ll encounter in Chapter 7, is one such case.) What’s more, the performance of the prefetch queue (and hence the performance of each instruction) differs from one code sequence to the next, and can even differ during different executions of the same code sequence.</p>
<p>All in all, writing good assembler code is as much an art as a science. As a result, you should follow the rules of thumb described in <em>The Zen of Assembly Language</em> — and then time your code to see how fast it really is. You should experiment freely, but always remember that actual, measured performance is the bottom line.</p>
<p>The prefetch queue cycle-eater looms over the performance of all 8088 code. We’ll encounter it again and again in this book, and in every case it will make our code slower than it would otherwise be. An understanding of the prefetch queue cycle-eater provides deep insight into what makes some 8088 code much faster than other, seemingly similar 8088 code, and is a key to good assembler programming. You’ll never conquer this cycle-eater, but with experience and the Zen timer you can surely gain the advantage.</p>
</section>
<section id="holding-up-the-8088" class="level3">
<h3>Holding Up the 8088</h3>
<p>Over the last two chapters I’ve taken you further and further into the depths of the PC, telling you again and again that you must understand the computer at the lowest possible level in order to write good code. At this point, you may well wonder, “Have we gotten low enough?”</p>
<p>Not quite yet. The 8-bit bus and prefetch queue cycle-eaters are low-level indeed, but we’ve one level yet to go. Dynamic RAM refresh and wait states — our next topics — together form the lowest level at which the hardware of the PC affects code performance. Below this level, the PC is of interest only to hardware engineers.</p>
<p>Before we begin our discussion of dynamic RAM refresh, let’s step back for a moment to take an overall look at this lowest level of cycle-eaters. In truth, the distinctions between wait states and dynamic RAM refresh don’t much matter to a programmer. What is important is that you understand this: <em>under certain circumstances devices on the PC bus can stop the 8088 for 1 or more cycles, making your code run more slowly than it seemingly should</em>.</p>
<p>Unlike all the cycle-eaters we’ve encountered so far, wait states and dynamic RAM refresh are strictly external to the 8088, as shown in Figure 4.1. Adapters on the PC’s bus, such as video and memory cards, can insert wait states on any 8088 bus access, the idea being that they won’t be able to complete the access properly unless the access is stretched out. Likewise, the channel of the DMA controller dedicated to dynamic RAM refresh can request control of the bus at any time, although the 8088 must relinquish the bus before the DMA controller can take over. This means that your code can’t directly control wait states or dynamic RAM refresh. However, code <em>can</em> sometimes be designed to minimize the effects of these cycle-eaters, and even when the cycle-eaters slow your code without there being a thing in the world you can do about it, you’re still better off understanding that you’re losing performance and knowing why your code doesn’t run as fast as it’s supposed to than you were programming in ignorance.</p>
<p>Let’s start with DRAM refresh, which affects the performance of every program that runs on the PC.</p>
</section>
</section>
<section id="dynamic-ram-refresh-the-invisible-hand" class="level2">
<h2>Dynamic Ram Refresh: The Invisible Hand</h2>
<p>Dynamic RAM (DRAM) refresh is sort of an act of God. By that I mean that DRAM refresh invisibly and inexorably steals up to 8.33% of all available memory access time from your programs. While you <em>could</em> stop DRAM refresh, you wouldn’t want to, since that would be a sure prescription for crashing your computer. In the end, thanks to DRAM refresh, almost all code runs a bit slower on the PC than it otherwise would, and that’s that.</p>
<p>A bit of background: a static RAM (SRAM) chip is a memory chip which retains its contents indefinitely so long as power is maintained. By contrast, each of several blocks of bits in a dynamic RAM (DRAM) chip retains its contents for only a short time after it’s accessed for a read or write. In order to get a DRAM chip to store data for an extended period, each of the blocks of bits in that chip must be accessed regularly, so that the chip’s stored data is kept refreshed and valid. So long as this is done often enough, a DRAM chip will retain its contents indefinitely.</p>
<p>All of the PC’s system memory consists of DRAM chips. (Some PC-compatible computers are built with SRAM chips, but IBM PCs, XTs, and ATs use only DRAM chips for system memory.) Each DRAM chip in the PC must be completely refreshed once every 4 ms (give or take a little) in order to ensure the integrity of the data it stores. Obviously, it’s highly desirable that the memory in the PC retain the correct data indefinitely, so each DRAM chip in the PC <em>must</em> always be refreshed within 4 ms of the last refresh. Since there’s no guarantee that a given program will access each and every DRAM once every 4 ms, the PC contains special circuitry and programming for providing DRAM refresh.</p>
<section id="how-dram-refresh-works-in-the-pc" class="level3">
<h3>How Dram Refresh Works in the Pc</h3>
<p>Timer 1 of the 8253 timer chip is programmed at power-up to generate a signal once every 72 cycles, or once every 15.08 us. That signal goes to channel 0 of the 8237 DMA controller, which requests the bus from the 8088 upon receiving the signal. (DMA stands for <em>direct memory access</em>, the ability of a device other than the 8088 to control the bus and access memory directly, without any help from the 8088.) As soon as the 8088 is between memory accesses, it gives control of the bus to the 8237, which in conjunction with special circuitry on the PC’s motherboard then performs a single 4-cycle read access to 1 of 256 possible addresses, advancing to the next address on each successive access. (The read access is only for the purpose of refreshing the DRAM; the data read isn’t used.)</p>
<p>The 256 addresses accessed by the refresh DMA accesses are arranged so that taken together they properly refresh all the memory in the PC. By accessing one of the 256 addresses every 15.08 us, all of the PC’s DRAM is refreshed in:</p>
<p><strong>3.86 ms = 256 x 15.08 us</strong></p>
<p>just about the desired 4 ms time I mentioned earlier. (Only the first 640 Kb of memory is refreshed; video adapters and other adapters above 640 Kb containing memory that requires refreshing must provide their own DRAM refresh.)</p>
<p>Don’t sweat the details here. The important point is this: for at least 4 out of every 72 cycles, the PC’s bus is given over to DRAM refresh and is not available to the 8088, as shown in Figure 4.5. That means that as much as 5.56% of the PC’s already inadequate bus capacity is lost. However, DRAM refresh doesn’t necessarily stop the 8088 for 4 cycles. The Execution Unit of the 8088 can keep processing while DRAM refresh is occurring, unless the EU needs to access memory. Consequently, DRAM refresh can slow code performance anywhere from 0% to 5.56% (and actually a bit more, as we’ll see shortly), depending on the extent to which DRAM refresh occupies cycles during which the 8088 would otherwise be accessing memory.</p>
<figure>
<img src="images/fig4.5RT.png" />
</figure>
</section>
<section id="the-impact-of-dram-refresh" class="level3">
<h3>The Impact of Dram Refresh</h3>
<p>Let’s look at examples from opposite ends of the spectrum in terms of the impact of DRAM refresh on code performance. First, consider the series of <code class="sourceCode nasm"><span class="kw">mul</span></code> instructions in <a href="#listing-4-9">Listing 4-9</a>. Since a 16-bit <code class="sourceCode nasm"><span class="kw">mul</span></code> executes in between 118 and 133 cycles and is only 2 bytes long, there should be plenty of time for the prefetch queue to fill after each instruction, even after DRAM refresh has taken its slice of memory access time. Consequently, the prefetch queue should be able to keep the Execution Unit well-supplied with instruction bytes at all times. Since <a href="#listing-4-9">Listing 4-9</a> uses no memory operands, the Execution Unit should never have to wait for data from memory, and DRAM refresh should have no impact on performance. (Remember that the Execution Unit can operate normally during DRAM refreshes so long as it doesn’t need to request a memory access from the Bus Interface Unit.)</p>
<p>Running <a href="#listing-4-9">Listing 4-9</a>, we find that each <code class="sourceCode nasm"><span class="kw">mul</span></code> executes in 24.72 us, or exactly 118 cycles. Since that’s the shortest time in which <code class="sourceCode nasm"><span class="kw">mul</span></code> can execute, we can see that no performance is lost to DRAM refresh. <a href="#listing-4-9">Listing 4-9</a> clearly illustrates that DRAM refresh only affects code performance when a DRAM refresh forces the Execution Unit of the 8088 to wait for a memory access.</p>
<p>Now let’s look at the series of <code class="sourceCode nasm"><span class="kw">shr</span></code> instructions shown in <a href="#listing-4-10">Listing 4-10</a>. Since <code class="sourceCode nasm"><span class="kw">shr</span></code> executes in 2 cycles but is 2 bytes long, the prefetch queue should be empty while <a href="#listing-4-10">Listing 4-10</a> executes, with the 8088 prefetching instruction bytes non-stop. As a result, the time per instruction of <a href="#listing-4-10">Listing 4-10</a> should precisely reflect the time required to fetch the instruction bytes.</p>
<p>Since 4 cycles are required to read each instruction byte, we’d expect each <code class="sourceCode nasm"><span class="kw">shr</span></code> to execute in 8 cycles, or 1.676 us, if there were no DRAM refresh. In fact, each <code class="sourceCode nasm"><span class="kw">shr</span></code> in <a href="#listing-4-10">Listing 4-10</a> executes in 1.81 us, indicating that DRAM refresh is taking 7.4% of the program’s execution time. That’s nearly 2% more than our worst-case estimate of the loss to DRAM refresh overhead! In fact, the result indicates that DRAM refresh is stealing not 4 but 5.33 cycles out of every 72 cycles. How can this be?</p>
<p>The answer is that a given DRAM refresh can actually hold up CPU memory accesses for as many as 6 cycles, depending on the timing of the DRAM refresh’s DMA request relative to the 8088’s internal instruction execution state. When the code in <a href="#listing-4-10">Listing 4-10</a> runs, each DRAM refresh holds up the CPU for either 5 or 6 cycles, depending on where the 8088 is in executing the current <code class="sourceCode nasm"><span class="kw">shr</span></code> instruction when the refresh request occurs. Now we see that things can get even worse than we thought: <em>DRAM refresh can steal as much as 8.33% of available memory access time</em> — <em>6 out of every 72 cycles</em> — <em>from the 8088</em>.</p>
<p>Which of the two cases we’ve examined reflects reality? While either <em>can</em> happen, the latter case — significant performance reduction, ranging as high as 8.33% — is far more likely to occur. This is especially true for high-performance assembler code, which uses fast instructions that tend to cause non-stop instruction fetching.</p>
</section>
<section id="what-to-do-about-the-dram-refresh-cycle-eater" class="level3">
<h3>What to Do About the Dram Refresh Cycle-Eater?</h3>
<p><em>Hmmm.</em> When we discovered the prefetch queue cycle-eater, we learned to use short instructions. When we discovered the 8-bit bus cycle-eater, we learned to use byte-sized memory operands whenever possible, and to keep word-sized variables in registers. What can we do to work around the DRAM refresh cycle-eater?</p>
<p>Nothing.</p>
<p>As I’ve said before, DRAM refresh is an act of God. DRAM refresh is a fundamental, unchanging part of the PC’s operation, and there’s nothing you or I can do about it. If refresh were any less frequent, the reliability of the PC would be compromised, so tinkering with either timer 1 or DMA channel 0 to reduce DRAM refresh overhead is out. Nor is there any way to structure code to minimize the impact of DRAM refresh. Sure, some instructions are affected less by DRAM refresh than others, but how many multiplies and divides in a row can you really use? I suppose that code <em>could</em> conceivably be structured to leave a free memory access every 72 cycles, so DRAM refresh wouldn’t have any effect. In the old days when code size was measured in bytes, not K bytes, and processors were less powerful — and complex — programmers did in fact use similar tricks to eke every last bit of performance from their code. When programming the PC, however, the prefetch queue cycle-eater would make such careful code synchronization a difficult task indeed, and any modest performance improvement that did result could never justify the increase in programming complexity and the limits on creative programming that such an approach would entail. There’s no way around it: useful code accesses memory frequently and at irregular intervals, and over the long haul DRAM refresh always exacts its price.</p>
<p>If you’re still harboring thoughts of reducing the overhead of DRAM refresh, consider this. Instructions that tend not to suffer very much from DRAM refresh are those that have a high ratio of execution time to instruction fetch time, and those aren’t the fastest instructions of the PC. It certainly wouldn’t make sense to use slower instructions just to reduce DRAM refresh overhead, for it’s <em>total</em> execution time — DRAM refresh, instruction fetching, and all — that matters.</p>
<p>The important thing to understand about DRAM refresh is that it generally slows your code down, and that the extent of that performance reduction can vary considerably and unpredictably, depending on how the DRAM refreshes interact with your code’s pattern of memory accesses. When you use the Zen timer and get a fractional cycle count for the execution time of an instruction, that’s often DRAM refresh at work. (The display adapter cycle-eater is another possible culprit.) Whenever you get two timing results that differ less or more than they seemingly should, that’s usually DRAM refresh too. Thanks to DRAM refresh, variations of up to 8.33% in PC code performance are par for the course.</p>
</section>
</section>
<section id="wait-states" class="level2">
<h2>Wait States</h2>
<p>Wait states are cycles during which a bus access by the 8088 to a device on the PC’s bus is temporarily halted by that device while the device gets ready to complete the read or write. Wait states are well and truly the lowest level of code performance. Everything we have discussed (and will discuss) — even DMA accesses — can be affected by wait states.</p>
<p>Wait states exist because the 8088 must to be able to coexist with any adapter, no matter how slow (within reason). The 8088 expects to be able to complete each bus access — a memory or I/O read or write — in 4 cycles, but adapters can’t always respond that quickly, for a number of reasons. For example, display adapters must split access to display memory between the 8088 and the circuitry that generates the video signal based on the contents of display memory, so they often can’t immediately fulfill a request by the 8088 for a display memory read or write. To resolve this conflict, display adapters can tell the 8088 to wait during bus accesses by inserting one or more wait states, as shown in Figure 4.6. The 8088 simply sits and idles as long as wait states are inserted, then completes the access as soon as the display adapter indicates its readiness by no longer inserting wait states. The same would be true of any adapter that couldn’t keep up with the 8088.</p>
<figure>
<img src="images/fig4.6RT.png" />
</figure>
<p>Mind you, this is all transparent to the code running on the 8088. An instruction that encounters wait states runs exactly as if there were no wait states, but slower. Wait states are nothing more or less than wasted time as far as the 8088 and your program are concerned.</p>
<p>By understanding the circumstances in which wait states can occur, you can avoid them when possible. Even when it’s not possible to work around wait states, it’s still to your advantage to understand how they can cause your code to run more slowly.</p>
<p>First, let’s learn a bit more about wait states by contrast with DRAM refresh. Unlike DRAM refresh, wait states do not occur on any regularly scheduled basis, and are of no particular duration. Wait states can only occur when an instruction performs a memory or I/O read or write. Both the presence of wait states and the number of wait states inserted on any given bus access are entirely controlled by the device being accessed. When it comes to wait states, the 8088 is passive, merely accepting whatever wait states the accessed device chooses to insert during the course of the access. All of this makes perfect sense given that the whole point of the wait state mechanism is to allow a device to stretch out any access to itself for however much time it needs to perform the access.</p>
<p>Like DRAM refresh, wait states don’t stop the 8088 completely. The Execution Unit can continue processing while wait states are inserted, so long as the EU doesn’t need to perform a bus access. However, in the PC wait states most often occur when an instruction accesses a memory operand, so in fact the Execution Unit usually is stopped by wait states. (Instruction fetches rarely wait in a PC because system memory is zero-wait-state. AT memory routinely inserts 1 wait state, however, as we’ll see in Chapter 15.)</p>
<p>As it turns out, wait states pose a serious problem in just one area in the PC. While any adapter <em>can</em> insert wait states, in the PC only display adapters do so to the extent that performance is seriously affected.</p>
<section id="the-display-adapter-cycle-eater" class="level3">
<h3>The Display Adapter Cycle-Eater</h3>
<p>Display adapters must serve two masters, and that creates a fundamental performance problem. Master #1 is the circuitry that drives the display screen. This circuitry must constantly read display memory in order to obtain the information used to draw the characters or dots displayed on the screen. Since the screen must be redrawn between 50 and 70 times per second, and since each redraw of the screen can require as many as 36,000 reads of display memory (more in Super-VGA modes), master #1 is a demanding master indeed. No matter how demanding master #1 gets, though, its needs must <em>always</em> be met — otherwise the quality of the picture on the screen would suffer.</p>
<p>Master #2 is the 8088, which reads from and writes to display memory in order to manipulate the bytes that the video circuitry reads to form the picture on the screen. Master #2 is less important than master #1, since the 8088 affects display quality only indirectly. In other words, if the video circuitry has to wait for display memory accesses, the picture will develop holes, snow, and the like, but if the 8088 has to wait for display memory accesses, the program will just run a bit slower — no big deal.</p>
<p>It matters a great deal which master is more important, for while both the 8088 and the video circuitry must gain access to display memory, only one of the two masters can read or write display memory at any one time. Potential conflicts are resolved by flat-out guaranteeing the video circuitry however many accesses to display memory it needs, with the 8088 waiting for whatever display memory accesses are left over.</p>
<p>It turns out that the 8088 has to do a lot of waiting, for three reasons. First, the video circuitry can take as much as about 90% of the available display memory access time, as shown in Figure 4.7, leaving as little as about 10% of all display memory accesses for the 8088. (These percentages vary considerably among the many EGA and VGA clones.)</p>
<figure>
<img src="images/fig4.7RT.png" />
</figure>
<p>Second, because dots (or <em>pixels</em>, short for “picture elements”) must be drawn on the screen at a constant speed, display adapters can provide memory accesses only at fixed intervals. As a result, time can be lost while the 8088 synchronizes with the start of the next display adapter memory access, even if the video circuitry isn’t accessing display memory at that time, as shown in Figure 4.8.</p>
<figure>
<img src="images/fig4.8RT.png" />
</figure>
<p>Finally, the time it takes a display adapter to complete a memory access is related to the speed of the clock which generates pixels on the screen rather than to the memory access speed of the 8088. Consequently, the time taken for display memory to complete an 8088 read or write access is often longer than the time taken for system memory to complete an access, even if the 8088 lucks into hitting a free display memory access just as it becomes available, again as shown in Figure 4.8. Any or all of the three factors I’ve described can result in wait states, slowing the 8088 and creating the display adapter cycle-eater.</p>
<p>If some of this is Greek to you, don’t worry. The important point is that display memory is not very fast compared to normal system memory. How slow is it? <em>Incredibly</em> slow. Remember how slow the PC<em>jr</em> was? In case you’ve forgotten, I’ll refresh your memory: the PC<em>jr</em> was at best only half as fast as the PC. The PC<em>jr</em> had an 8088 running at 4.77 MHz, just like the PC — why do you suppose it was so much slower? I’ll tell you why: <em>all the memory in the PC</em>jr<em>was display memory.</em></p>
<p>Enough said.</p>
<p>All the memory in the PC is <em>not</em> display memory, however, and unless you’re thickheaded enough to put code in display memory, the PC isn’t going to run as slowly as a PCjr. (Putting code or other non-video data in unused areas of display memory sounds like a neat idea — until you consider the effect on instruction prefetching of cutting the 8088’s already-poor memory access performance in half. Running your code from display memory is sort of like running on the hypothetical 8084 — an 8086 with a <em>4-bit</em> bus. Not recommended!) Given that your code and data reside in normal system memory below the 640 K mark, how great an impact does the display adapter cycle-eater have on performance?</p>
<p>The answer varies considerably depending on what display adapter and what display mode we’re talking about. The display adapter cycle-eater is worst with the Enhanced Graphics Adapter (EGA) and the Video Graphics Array (VGA). While the Color/Graphics Adapter (CGA), Monochrome Display Adapter (MDA), and Hercules Graphics Card (HGC) all suffer from the display adapter cycle-eater as well, they suffer to a lesser degree. Since the EGA and particularly the VGA represent the standard for PC graphics now and for the foreseeable future, and since those are the hardest graphics adapter to wring performance from, we’ll restrict our discussion to the EGA and VGA for the remainder of this chapter.</p>
</section>
<section id="the-impact-of-the-display-adapter-cycle-eater" class="level3">
<h3>The Impact of the Display Adapter Cycle-Eater</h3>
<p>Even on the EGA and VGA, the effect of the display adapter cycle-eater depends on the display mode selected. In text mode, the display adapter cycle-eater is rarely a major factor. It’s not that the cycle-eater isn’t present; however, a mere 4000 bytes control the entire text mode display, and even with the display adapter cycle-eater it just doesn’t take that long to manipulate 4000 bytes. Even if the display adapter cycle-eater were to cause the 8088 to take as much as 5 us per display memory access — more than ten times normal — it would still take only:</p>
<p><strong>40 ms = 4000 x 2 x 5 us</strong></p>
<p>to read <em>and</em> write every byte of display memory. That’s a lot of time as measured in 8088 cycles, but it’s less than the blink of an eye in human time, and video performance only matters in human time. After all, the whole point of drawing graphics is to convey visual information, and if that information can be presented faster than the eye can see, that is by definition fast enough.</p>
<p>That’s not to say that the display adapter cycle-eater <em>can’t</em> matter in text mode. In Chapter 2 I recounted the story of a debate among letter-writers to a magazine about exactly how quickly characters could be written to display memory without causing snow. The writers carefully added up Intel’s instruction cycle times to see how many writes to display memory they could squeeze into a single horizontal retrace interval. (On a CGA, it’s only during the short horizontal retrace interval and the longer vertical retrace interval that display memory can be accessed in 80-column text mode without causing snow.) Of course, now we know that their cardinal sin was to ignore the prefetch queue; even if there were no wait states, their calculations would have been overly optimistic. There <em>are</em> display memory wait states as well, however, so the calculations were not just optimistic but wildly optimistic.</p>
<p>Text mode situations such as the above notwithstanding, where the display adapter cycle-eater really kicks in is in graphics mode, and most especially in the high-resolution graphics modes of the EGA and VGA. The problem here is not that there are necessarily more wait states per access in high-resolution graphics modes (that varies from adapter to adapter and mode to mode). Rather, the problem is simply that are many more bytes of display memory per screen in these modes than in lower-resolution graphics modes and in text modes, so many more display memory accesses — each incurring its share of display memory wait states — are required in order to draw an image of a given size. When accessing the many thousands of bytes used in the high-resolution graphics modes, the cumulative effects of display memory wait states can seriously impact code performance, even as measured in human time.</p>
<p>For example, if we assume the same 5 us per display memory access for the EGA’s high-res graphics mode that we assumed for text mode, it would take:</p>
<p><strong>260 ms = 26,000 x 2 x 5 us</strong></p>
<p>to scroll the screen once in the EGA’s hi-res graphics mode, mode 10h. That’s more than one-quarter of a second — noticeable by human standards, an eternity by computer standards.</p>
<p>That sounds pretty serious, but we did make an unfounded assumption about memory access speed. Let’s get some hard numbers. <a href="#listing-4-11">Listing 4-11</a> accesses display memory at the 8088’s maximum speed, by way of a <code class="sourceCode nasm">rep <span class="kw">movsw</span></code> with display memory as both source and destination. The code in <a href="#listing-4-11">Listing 4-11</a> executes in 3.18 us per access to display memory — not as long as we had assumed, but a long time nonetheless.</p>
<p>For comparison, let’s see how long the same code takes when accessing normal system RAM instead of display memory. The code in <a href="#listing-4-12">Listing 4-12</a>, which performs a <code class="sourceCode nasm">rep <span class="kw">movsw</span></code> from the code segment to the code segment, executes in 1.39 us per display memory access. That means that on average 1.79 us (more than 8 cycles!) are lost to the display adapter cycle-eater on each access. In other words, the display adapter cycle-eater can <em>more than double</em> the execution time of 8088 code!</p>
<p>Bear in mind that we’re talking about a worst case here; the impact of the display adapter cycle-eater is proportional to the percent of time a given code sequence spends accessing display memory. A line-drawing subroutine, which executes perhaps a dozen instructions for each display memory access, generally loses less performance to the display adapter cycle-eater than does a block-copy or scrolling subroutine that uses <code class="sourceCode nasm">rep <span class="kw">movs</span></code> instructions. Scaled and three-dimensional graphics, which spend a great deal of time performing calculations (often using <em>very</em> slow floating-point arithmetic), tend to suffer still less.</p>
<p>In addition, code that accesses display memory infrequently tends to suffer only about half of the maximum display memory wait states, because on average such code will access display memory halfway between one available display memory access slot and the next. As a result, code that accesses display memory less intensively than the code in <a href="#listing-4-11">Listing 4-11</a> will on average lose 4 or 5 rather than 8-plus cycles to the display adapter cycle-eater on each memory access.</p>
<p>Nonetheless, the display adapter cycle-eater always takes its toll on graphics code. Interestingly, that toll becomes relatively much higher on ATs and 80386 machines, because while those computers can execute many more instructions per microsecond than can the PC, it takes just as long to access display memory on those computers as on the PC. Remember, the limited speed of access to a graphics adapter is an inherent characteristic of the adapter, so the fastest computer around can’t access display memory one iota faster than the adapter will allow. We’ll discuss this further in Chapter 15.</p>
</section>
<section id="what-to-do-about-the-display-adapter-cycle-eater" class="level3">
<h3>What to Do About the Display Adapter Cycle-Eater?</h3>
<p>What can we do about the display adapter cycle-eater? Well, we can minimize display memory accesses whenever possible. In particular, we can try to avoid read/modify/write display memory operations of the sort used to mask individual pixels and clip images. Why? Because read/modify/write operations require two display memory accesses (one read and one write) each time display memory is manipulated. Instead, we should try to use writes of the sort that set all the pixels in a given byte of display memory at once, since such writes don’t require accompanying read accesses. The key here is that only half as many display memory accesses are required to write a byte to display memory as are required to read a byte from display memory, mask part of it off and alter the rest, and write the byte back to display memory. Half as many display memory accesses means half as many display memory wait states.</p>
<p>Along the same line, the display adapter cycle-eater makes the popular exclusive-or animation technique, which requires paired reads and writes of display memory, less-than-ideal for the PC. Exclusive-or animation should be avoided in favor of simply writing images to display memory whenever possible, as we’ll see in Chapter 11.</p>
<p>Another principle for display adapter programming is to perform multiple accesses to display memory very rapidly, in order to make use of as many of the scarce accesses to display memory as possible. This is especially important when many large images need to be drawn quickly, since only by using virtually every available display memory access can many bytes be written to display memory in a short period of time. Repeated string instructions are ideal for making maximum use of display memory accesses; of course, repeated string instructions can only be used on whole bytes, so this is another point in favor of modifying display memory a byte at a time.</p>
<p>These concepts certainly need examples and clarification, along with some working code; that’s coming up in Volume II of <em>The Zen of Assembly Language</em>. Why not now? Well, in Volume II we’ll be able to devote a whole chapter to display adapter programming, and by that point we’ll have the benefit of an understanding of the flexible mind, which is certainly a plus for this complex topic.</p>
<p>For now, all you really need to know about the display adapter cycle-eater is that you can lose more than 8 cycles of execution time on each access to display memory. For intensive access to display memory, the loss really can be as high as 8-plus cycles, while for average graphics code the loss is closer to 4 cycles; in either case, the impact on performance is significant. There is only one way to discover just how significant the impact of the display adapter cycle-eater is for any particular graphics code, and that is of course to measure the performance of that code.</p>
<p>If you’re interested in the detailed operation of the display adapter cycle-eater, I suggest you read my article, “The Display Adapter Bottleneck,” in the January, 1987 issue of <em>PC Tech Journal</em>.</p>
</section>
</section>
<section id="cycle-eaters-a-summary" class="level2">
<h2>Cycle-Eaters: A Summary</h2>
<p>We’ve covered a great deal of sophisticated material in this chapter, so don’t feel bad if you haven’t understood everything you’ve read; it will all become clear as you read on. What’s really important is that you come away from this chapter understanding that:</p>
<ul>
<li>The 8-bit bus cycle-eater causes each access to a word-sized operand to be 4 cycles longer than an equivalent access to a byte-sized operand.</li>
<li>The prefetch queue cycle-eater can cause instruction execution times to be as much as four times longer than the times specified in Appendix A.</li>
<li>The DRAM refresh cycle-eater slows most PC code, with performance reductions ranging as high as 8.33%.</li>
<li>The display adapter cycle-eater typically doubles and can more than triple the length of the standard 4-cycle access to display memory, with intensive display memory access suffering most.</li>
</ul>
<p>This basic knowledge about cycle-eaters puts you in a good position to understand the results reported by the Zen timer, and that means that you’re well on your way to writing highperformance assembler code. We will put this knowledge to work throughout the remainder of <em>The Zen of Assembly Language</em>.</p>
</section>
<section id="what-does-it-all-mean" class="level2">
<h2>What Does It All Mean?</h2>
<p>There you have it: life under the programming interface. It’s not a particularly pretty picture, for the inhabitants of that strange realm where hardware and software meet are little-known cycle-eaters that sap the speed from your unsuspecting code. Still, some of those cycle-eaters can be minimized by keeping instructions short, using the registers, using byte-sized memory operands, and accessing display memory as little as possible. None of the cycle-eaters can be eliminated, and dynamic RAM refresh can scarcely be addressed at all; still, aren’t you better off knowing how fast your code <em>really</em> runs — and why — than you were reading the official execution times and guessing?</p>
<p>So far we’ve only examined cycle-eaters singly. Unfortunately, cycle-eaters don’t work alone, and together they’re still more complex and unpredictable than they are taken one at a time. The intricate relationship between the cycle-eaters is our next topic.</p>
</section>
</section>
<section id="chapter-5-night-of-the-cycle-eaters" class="level1">
<h1>Chapter 5: Night of the Cycle-Eaters</h1>
<blockquote>
<p>When sorrows come, they come not single spies,</p>
<p>But in battalions.</p>
<p>— William Shakespeare, <em>Hamlet</em></p>
</blockquote>
<p>Thus far we’ve explored what might be called the science of assembler programming. We’ve dissected in considerable detail the many factors that affect code performance, increasing our understanding of the PC greatly in the process. We’ve approached the whole business in a logical fashion, measuring 8 cycles here, accounting for 6 cycles there, always coming up with reasonable explanations for the phenomena we’ve observed. In short, we’ve acted as if assembler programming for the PC can be reduced to a well-understood, cut-and-dried cookbook discipline once we’ve learned enough.</p>
<p>I’m here to tell you it ain’t so.</p>
<p>Assembler programming for the PC can’t be reduced to a science, and the cycle-eaters are the reasons why. The 8-bit bus and prefetch queue cycle-eaters give every code sequence on the PC unique and hard-to-predict performance characteristics. Throw in the DRAM refresh and display adapter cycle-eaters and you’ve got virtually infinite possibilities not only for the performance of different code sequences but also for the performance of the <em>same</em> code sequence at different times! There is simply <em>no way</em> to know in advance exactly how fast a specific instance of an instruction will execute, and there’s no way to be sure what code is the fastest for a particular purpose. Instead, what we must do is use the Zen timer to gain experience and develop rules of thumb, write code by feel as much as by prescription, and measure the actual performance of what we write.</p>
<p>In other words, we must become Zen programmers.</p>
<p>As you read this, you may understand but not believe. Surely, you think, there must be a way to know what the best code is for a given task. How can it not be possible to come up with a purely rational solution to a problem that involves that most rational of man’s creations, the computer?</p>
<p>The answer lies in the nature of the computer in question. While it’s true that it’s not impossible to understand the exact performance of a given piece of code on the IBM PC, because of the 8-bit bus and prefetch queue cycle-eaters it <em>is</em> extremely complex and requires expensive hardware. And then, when you fully understand the performance of that piece of code, what have you got? Only an understanding of one out of millions of possible code sequences, each of which is a unique problem requiring just as much analysis as did the first code sequence.</p>
<p>That’s bad enough, but the two remaining cycle-eaters make the problem of understanding code performance more complex still. The DRAM refresh and display adapter cycle-eaters don’t affect the execution of each instruction equally; they occur periodically and have varying impacts on performance when they do occur, thereby causing instruction performance to vary as a function not only of the sequence of instructions but also of time. In other words, the understanding you gain of a particular code sequence <em>may not even be valid the next time that code runs</em>, thanks to the varying effects of the DRAM refresh and display adapter cycle-eaters.</p>
<p>In short, it is true that the exact performance of assembler code is indeed a solvable problem in the classic sense, since everything about the performance of a given execution of a given chunk of code is knowable given enough time, effort, and expensive hardware. It is equally true, however, that the exact performance of assembler code over time is such a complex problem that it might as well be unsolvable, since that hard-won knowledge would be so specific as to be of no use. We are going to spend the rest of this chapter proving that premise. First we’ll look at some of the interactions between the cycle-eaters; those interactions make the prediction of code performance still more complex than we’ve seen thus far. After that we’ll look at every detail of 170 cycles in the life of the PC. What we’ll find is that if we set out to understand the exact performance of an entire assembler program, we could well spend the rest of our lives at that task — and would be no better off than we were before.</p>
<p>The object of this chapter is to convince you that when it comes to writing assembler code there’s no complete solution, no way to understand every detail or get precise, unvarying answers about performance. We <em>can</em> come close, though, by understanding the basic operation of the PC, developing our intuition, following rules of thumb such as keeping instructions short, and always measuring code performance. Those approaches are precisely what this book is about, and are the foundation of the Zen of assembler.</p>
<section id="no-were-not-in-kansas-anymore" class="level2">
<h2>No, We’re Not in Kansas Anymore</h2>
<p>You may be feeling a bit lost at this point. That’s certainly understandable, for the last two chapters have covered what is surely the most esoteric aspect of assembler programming. I must tell you that this chapter will be more of the same.</p>
<p>Follow along as best you can, but don’t be concerned if some of the material is outside your range right now. Both the following chapters and experience will give you a better feel for what this chapter is about. It’s important that you be exposed to these concepts now, though, so you can recognize them when you run into them later. The key concept to come away from this chapter with is that the cycle-eaters working together make for such enormous variability of code performance that there’s no point in worrying about exactly what’s happening in the execution of a given instruction or sequence of instructions. Instead, we must use rules of thumb and a programming feel developed with experience, and we must focus on overall performance as measured with the Zen timer.</p>
<section id="cycle-eaters-by-the-battalion" class="level3">
<h3>Cycle-Eaters by the Battalion</h3>
<p>Taken individually the cycle-eaters are formidable, as we saw in the last chapter. Cycle-eaters don’t line up neatly and occur one at a time, though. They’re like the proverbial 900-pound gorilla — they occur whenever they want. Frequently one cycle-eater will occur during the course of another cycle-eater, with compound (and complex) effects.</p>
<p>For example, it’s perfectly legal to put code in display memory and execute that code. However, as the instruction bytes of that code are fetched they’ll be subjected to the display adapter cycle-eater, meaning that each instruction byte could easily take twice as long as usual to fetch. Naturally, this will worsen the already serious effects of the prefetch queue cycle-eater. (Remember that the prefetch queue cycle-eater is simply the inability of the 8088 to fetch instruction bytes quickly enough.) In this case, the display adapter and prefetch queue cycle-eaters together could make overall execution times five to ten times longer than the times listed in Appendix A!</p>
<p>As another example, the DRAM refresh and 8-bit bus cycle-eaters can work together to increase the variability of code performance. When DRAM refresh occurs during an instruction that accesses a word-sized memory operand, the instruction’s memory accesses are held up until the DRAM refresh is completed. However, the exact amount by which the instruction’s accesses are delayed (and which access is delayed, as well) depends on exactly where in the course of execution the instruction was when the DRAM refresh came along. If the DRAM refresh happens just as the 8088 was about to begin a bus access, the 8088 can be held up for a long time. If, however, the DRAM refresh happens while the 8088 is performing internal operations, such as address calculations or instruction decoding, the impact on performance will be less.</p>
<p>The point is not, Lord knows, that you should understand how every cycle-eater affects every other cycle-eater and how together and separately they affect each instruction in your code. Quite the opposite, in fact. <em>I</em> certainly don’t understand all the interactions between cycle-eaters and code performance, and frankly I don’t ever expect (or want) to. Rather, what I’m telling you (again) is that a complete understanding of the performance of a given code sequence is so complex and varies so greatly with context that there’s no point worrying about it. As a result, high-performance assembler code comes from programming by intuition and experience and then measuring performance, not from looking up execution times and following rigid rules. In a way that’s all to the good: experienced, intuitive assembler programmers are worth a great deal, because no compiler can rival a good assembler programmer’s ability to deal with cycle-eaters and the complexity of code execution on the 8088.</p>
<p>One fallout of the near-infinite variability of code performance is that the exact performance of a given instruction is for all intents and purposes undefined. There are so many factors affecting performance, and those factors can vary so easily with time and context, that there’s just no use to trying to tag a given instruction with a single execution time. In other words…</p>
</section>
</section>
<section id="theres-still-no-such-beast-as-a-true-execution-time" class="level2">
<h2>…There’s Still No Such Beast as a True Execution Time</h2>
<p>Thanks to the combined efforts of the cycle-eaters, it’s more true than ever that there’s no such thing as a single “true” execution time for a given instruction. As you’ll recall, I said that in the last chapter. Why do I keep bringing it up? Because I don’t want you to look at the times reported by our tests of 1000 repetitions of the same instruction and think that those times are the true execution times of that instruction — they aren’t, any more than the official cycle times in Appendix A are the true times. <em>There is no such thing as a true execution time on the 8088.</em> There are only execution times in context.</p>
<p>Do you remember the varying performances of <code class="sourceCode nasm"><span class="kw">shr</span></code> in different contexts in Chapter 4? Well, that was just for repeated instances of one or two instructions. Imagine how much variation cycle-eaters could induce in the performance of a sequence of ten or twenty different instructions, especially if some of the instructions accessed word-sized display memory operands. You should always bear in mind that the times reported by the Zen timer are accurate only for the particular code sequence you’ve timed, not for all instances of a given instruction in all code sequences.</p>
<p>There’s just no way around it: <em>you must measure the performance of your code to know how fast it is.</em> Yes, I know — it would be awfully nice just to be able to look up instruction execution times and be done with it. That’s not the way the 8088 works, though — and the odd architecture of the 8088 is what the Zen of assembler is all about.</p>
<section id="cycles-in-the-life-of-a-pc" class="level3">
<h3>Cycles in the Life of a Pc</h3>
<p>Next, we’re going to examine every detail of instruction execution on the PC over a period of 170 cycles. One reason for doing this is to convince any of you who may still harbor the notion that there must be some way to come up with hard-and-fast execution times that you’re on a fool’s quest. Another reason is to illustrate many of the concepts we’ve developed over the last two chapters.</p>
<p>A third reason is simple curiosity. We’ll spend most of this book measuring instruction execution times and inferring how cycle-eaters and instruction execution are interacting. Why not take a look at the real thing? It won’t answer any fundamental questions, but it will give us a feel for what’s going on under the programming interface.</p>
</section>
<section id="the-test-set-up" class="level3">
<h3>The Test Set-Up</h3>
<p>The code we’ll observe is shown in <a href="#listing-5-1">Listing 5-1</a>. This code is an endless loop in which the value stored in the variable <code class="sourceCode nasm">i</code> is copied to the variable <code class="sourceCode nasm">j</code> over and over by way of AH. The <code class="sourceCode nasm"><span class="kw">DS</span>:</code> override prefixes on the variables, while not required, make it clear that both variables are accessed by way of DS.</p>
<p>The detailed performance of the code in <a href="#listing-5-1">Listing 5-1</a> was monitored with the logic analyzer capability of the OmniLab multipurpose electronic test instrument manufactured by Orion Instruments. (Not coincidentally, I was part of the team that developed the OmniLab software.) OmniLab’s probes were hooked up to a PC’s 8088 and bus, <a href="#listing-5-1">Listing 5-1</a> was started, and a snapshot of code execution was captured and studied.</p>
<p>By the way, OmniLab, a high-performance but relatively low-priced instrument, costs (circa 1989) about $9,000. Money is one reason why you probably won’t want to analyze code performance in great detail yourself!</p>
<p>The following lines of the 8088 were monitored with OmniLab: the 16 lines that carry addresses, 8 of which also carry data, the READY line (used to hold the 8088 up during DRAM refresh), and the QS1 and QS0 lines (which signal transfers of instruction bytes from the prefetch queue to the Execution Unit). The /MEMR and /MEMW lines on the PC bus were monitored in order to observe memory accesses. The 8088 itself provides additional information about bus cycle timing and type, but the lines described above will show us program execution in plenty of detail for our purposes.</p>
<p>Odds are that you, the reader, are not a hardware engineer. After all, this <em>is</em> a book about software, however far it may seem to stray at times. Consequently, I’m not going to show the execution of <a href="#listing-5-1">Listing 5-1</a> in the form of the timing diagrams of which hardware engineers are so fond. Timing diagrams are fine for observing the state of a single line, but are hard to follow at an overall level, which is precisely what we want to see. Instead, I’ve condensed the information I collected with OmniLab into an event time-line, shown in Figure 5.1.</p>
<figure>
<img src="images/fig5.1aRT.png" />
</figure>
<figure>
<img src="images/fig5.1bRT.png" />
</figure>
<figure>
<img src="images/fig5.1cRT.png" />
</figure>
</section>
<section id="the-results" class="level3">
<h3>The Results</h3>
<p>Figure 5.1 shows 170 consecutive 8088 cycles. To the left of the cycle time-line Figure 5.1 shows the timing of instruction byte transfers from the prefetch queue to the Execution Unit. This information was provided by the QS1 and QS0 pins of the 8088. To the right of the cycle time-line Figure 5.1 shows the timing of bus read and write accesses. The timing of these accesses was provided by the /MEMR and /MEMW lines of the PC bus, and the data and addresses were provided by the address/data lines of the 8088. One note for the technically oriented: since bus accesses take 4 cycles from start to finish, I considered the read and write accesses to complete on the last cycle during which /MEMR or /MEMW was active.</p>
<p>Take a minute to look Figure 5.1 over, before we begin our discussion. Bear in mind that Figure 5.1 is actually a simplified, condensed version of the information that actually appeared on the 8088’s pins. In other words, if you choose to analyze cycle-by-cycle performance yourself, the data will be considerably <em>harder</em> to interpret than Figure 5.1!</p>
</section>
<section id="code-execution-isnt-all-that-exciting" class="level3">
<h3>Code Execution Isn’t All That Exciting</h3>
<p>The first thing that surely strikes you about Figure 5.1 is that it’s awfully tedious, even by assembler standards. During the entire course of the figure only seven instructions are executed — not much to show for all the events listed. The monotony of picking apart code execution is one reason why such a detailed level of understanding of code performance isn’t desirable.</p>
</section>
<section id="the-8088-really-does-coprocess" class="level3">
<h3>The 8088 Really Does Coprocess</h3>
<p>The next notable aspect of Figure 5.1 is that you can truly see the two parts of the 8088 — the Execution Unit and the Bus Interface Unit — coprocessing. The left side of the time-line shows the times at which the EU receives instruction bytes to execute, indicating the commencement and continuation of instruction execution. The right side of the time-line shows the times at which the BIU reads or writes bytes from or to memory, indicating instruction fetches and accesses to memory operands.</p>
<p>The two sides of the time-line overlap considerably. For example, at cycle 10 the EU receives the opcode byte of <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ds</span>:[j],<span class="kw">ah</span></code> from the prefetch queue at the same time that the BIU prefetches the <em>mod-reg-rm</em> byte for the same instruction. (We’ll discuss <em>mod-reg-rm</em> bytes in detail in Chapter 7.) Clearly, the two parts of the 8088 are processing independently during cycle 10.</p>
<p>The EU and BIU aren’t always able the process independently, however. The EU spends a considerable amount of time waiting for the BIU to provide the next instruction byte, thanks to the prefetch queue cycle-eater. This is apparent during cycles 129 through 135, where the EU must wait 6 cycles for the <em>mod-reg-rm</em> byte of <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ah</span>,<span class="kw">ds</span>:[i]</code> to arrive. Back at cycle 84, the EU only had to wait 1 cycle for the same byte to arrive. Why the difference?</p>
<p>The difference is the result of the DRAM refresh that occurred at cycle 118, preempting the bus and delaying prefetching so that the <em>mod-reg-rm</em> byte of <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ah</span>,<span class="kw">ds</span>:[i]</code> wasn’t available until cycle 135. What’s particularly interesting is that this variation occurs even though the sequence of instructions is exactly the same at cycle 83 as at cycle 129. In this case, it’s the DRAM refresh cycle-eater that causes identical instructions in identical code sequences to execute at different speeds. Another time, it might be the display adapter cycle-eater that causes the variation, or the prefetch queue cycle-eater, or a combination of the three. This is an important lesson in the true nature of code execution: <em>the same instruction sequence may execute at different speeds at different times.</em></p>
</section>
<section id="when-does-an-instruction-execute" class="level3">
<h3>When Does an Instruction Execute?</h3>
<p>One somewhat startling aspect of Figure 5.1 is that it makes it clear that there is no such thing as the time interval during which a given instruction — and only that instruction — executes. There is the time at which a given byte of an instruction is prefetched, there is a time at which a given byte of an instruction is sent to the EU, and there is a time at which each memory operand byte of an instruction is accessed. None of those times really marks the start or end of an instruction, though, and the instruction fetches and memory accesses of one instruction usually overlap those of other instructions.</p>
<figure>
<img src="images/fig5.2RT.png" />
</figure>
<p>Figure 5.2 illustrates the full range of action of each of the instructions in Figure 5.1. (In Figure 5.2, and in Figure 5.3 as well, the two sides of the time-line are equivalent; there is no specific meaning to text on, say, the left side as there is in Figure 5.1. I simply alternate sides in order to keep one instruction from running into the next.)</p>
<p>For example, at cycle 143 the last instruction byte of <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ah</span>,<span class="kw">ds</span>:[i]</code> is sent to the EU. At cycle 144 the opcode of the next instruction, <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ds</span>:[j],<span class="kw">ah</span></code>, is prefetched. Not until cycle 150 is the operand of <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ah</span>,<span class="kw">ds</span>:[i]</code> read, and not until cycle 154 is the opcode byte of <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ds</span>:[j],<span class="kw">ah</span></code> sent to the EU. Which instruction is executing between cycles 143 and 154?</p>
<p>It’s easiest to consider execution to start when the opcode byte of an instruction is sent to the EU and end when the opcode byte of the next instruction is sent to the EU, as shown in Figure 5.3.</p>
<figure>
<img src="images/fig5.3aRT.png" />
</figure>
<p>Under this approach, the current instruction is charged with any instruction fetch time for the opcode byte of the next instruction that isn’t overlapped with EU execution of the current instruction. This is consistent with our conclusion in Chapter 4 that execution time is, practically speaking, EU execution time plus any instruction fetch time that’s not overlapped with the EU execution time of another instruction. Therefore, <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ah</span>,<span class="kw">ds</span>:[i]</code> executes during cycles 129 through 153.r</p>
<figure>
<img src="images/fig5.3bRT.png" />
</figure>
<p>In truth, though, the first hint of <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ah</span>,<span class="kw">ds</span>:[i]</code> occurs at cycle 122, when the opcode byte is fetched. In fact, since read accesses to memory take 4 cycles, the 8088 must have begun fetching the opcode byte earlier still. Figure 5.2 assumes that the 8088 starts bus accesses 2 cycles before the cycle during which /MEMR or /MEMW becomes inactive. That assumption may be off by a cycle, but none of our conclusions would be altered if that were the case. Consequently, the instruction <strong>mov ah,ds:[i]</strong> occupies the attention of at least some part of the 8088 from around cycle 120 up through cycle 153, or 34 cycles, as shown in Figure 5.2.</p>
<p>Figure 5.3 shows that <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ah</span>,<span class="kw">ds</span>:[i]</code> doesn’t take 34 cycles to execute, however. The instruction fetching that occurs during cycles 120 through 128 is overlapped with the execution of the preceding instruction, so those cycles aren’t counted against the execution time of <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ah</span>,<span class="kw">ds</span>:[i]</code>. The instruction does take 25 cycles to execute, though, illustrating the power of the cycle-eaters: according to Appendix A, <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ah</span>,<span class="kw">ds</span>:[i]</code> should execute in 14 cycles, so just two of the cycle-eaters, the prefetch queue and DRAM refresh, have nearly doubled the actual execution time of the instruction in this context.</p>
</section>
</section>
<section id="the-true-nature-of-instruction-execution" class="level2">
<h2>The True Nature of Instruction Execution</h2>
<p>Figure 5.1 makes it perfectly clear that at the lowest level code execution is really nothing more than two parallel chains of execution, one taking place in the EU and one taking place in the BIU. What’s more, the BIU interleaves instruction fetches for one instruction with memory operand accesses for another instruction. Thus, instruction execution really consists of three interleaved streams of events.</p>
<p>Unfortunately, assembler itself tests the limits of human comprehension of processor actions. Thinking in terms of the interleaved streams of events shown in Figure 5.1 is too much for any mere mortal. It’s ridiculous to expect that an assembler programmer could visualize interleaved instruction fetches, EU execution, and memory operand fetches as he writes code, and in fact no one even tries to do so.</p>
<p>And that is yet another reason why an understanding of code performance at the level shown in Figure 5.1 isn’t desirable.</p>
<figure>
<img src="images/fig5.3cRT.png" />
</figure>
<section id="variability" class="level3">
<h3>Variability</h3>
<p>This brings us to an excellent illustration of the variability of performance, even for the same instruction in the same code sequence executing at different times. As we just discovered, the <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ah</span>,<span class="kw">ds</span>:[i]</code> instruction that starts at cycle 129 takes 25 cycles to execute. However, the same instruction starting at cycle 33 takes 27 cycle to execute. Starting at cycle 83, <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ah</span>,<span class="kw">ds</span>:[i]</code> takes just 21 cycles to execute. <em>That’s three significantly different times for the same instruction executing in the same instruction sequence!</em></p>
<p>How can this be? In this case it’s the DRAM refresh cycle-eater that’s stirring things up by periodically holding up 8088 bus accesses for 4 cycles or more. This alters the 8088’s prefetching and memory access sequence, with a resultant change in execution time. As we discussed earlier, the DRAM refresh read at cycle 118 takes up valuable bus access time, keeping the 8088 from fetching the <em>mod-reg-rm</em> byte of <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ah</span>,<span class="kw">ds</span>:[i]</code> ahead of time and thereby pushing the succeeding bus accesses a few cycles later in time.</p>
<p>The DRAM refresh and display adapter cycle-eaters can cause almost any code sequence to vary in much the same way over time. That’s why the Zen timer reports fractional times. It is also the single most important reason why a micro-analysis of code performance of the sort done in Figure 5.1 is not only expensive and time-consuming but also pointless. If a given instruction following the same sequence of instructions can vary in performance by 20%, 50%, 100% or even more from one execution to the next, what sort of performance number can you give that instruction other than as part of the overall instruction sequence? What point is there in trying to understand the instruction’s exact performance during any one of those executions?</p>
<p>The answer, briefly stated, is: <em>no point at all.</em></p>
</section>
<section id="you-never-know-unless-you-measure-in-context" class="level3">
<h3>You Never Know Unless You Measure (In Context!)</h3>
<p>I hope I’ve convinced you that the actual performance of 8088 code is best viewed as the interaction of many highly variable forces, the net result of which is measurable but hardly predictable. But just in case I haven’t, consider this…</p>
<p>Figure 5.1 illustrates the execution of one of the simplest imaginable code sequences. The exact pattern of code execution repeats after 144 cycles, so even with DRAM refresh we have an execution pattern that repeats after only 6 instructions. That’s not likely to be the case with real code, which rarely features the endless alternation of two instructions. In real code the code mix changes endlessly, so DRAM refresh and the prefetch queue cycle-eater normally result in a far greater variety of execution sequences than in Figure 5.1.</p>
<p>Also, only two of the four cycle-eaters are active in Figure 5.1. Since <a href="#listing-5-1">Listing 5-1</a> uses no word-sized operands, the 8-bit bus cycle-eater has no effect other than slowing instruction prefetching. Likewise, <a href="#listing-5-1">Listing 5-1</a> doesn’t access display memory, so the display adapter cycle-eater doesn’t affect performance. Imagine if we threw those cycle-eaters into Figure 5.1 as well!</p>
<p>Worse still, in the real world interrupts occur often and asynchronously, flushing the prefetch queue and often changing the fetching, execution, and memory operand access patterns of whatever code happens to be running. Most notable among these interrupts is the timer interrupt, which occurs every 54.9 ms. Because the timer interrupt may occur after any instruction and doesn’t always take the same amount of time, it can cause execution to settle into new patterns. For example, after I captured the sequence shown in Figure 5.1 I took another snapshot of the execution of <a href="#listing-5-1">Listing 5-1</a>. <em>The second snapshot did not match the first.</em> The timer interrupt had kicked execution into a different pattern, in which the same instructions were executed, with the same results — but not at exactly the same speeds.</p>
<p>Other interrupts, such as those from keyboards, mice, and serial ports, can similarly alter program performance. Of course, interrupts and cycle-eaters don’t change the <em>effects</em> of code — <code class="sourceCode nasm"><span class="kw">add</span> <span class="kw">ax</span>,<span class="dv">1</span></code> always adds 1 to AX, and so on — but they can drastically change the performance of a given instruction in a given context. That’s why we focus on the overall performance of code sequences in context, as measured with the Zen timer, rather than on the execution times of individual instructions.</p>
</section>
<section id="the-longer-the-better" class="level3">
<h3>The Longer the Better</h3>
<p>Now is a good time to point out that the longer the instruction sequence you measure, the less variability you’ll normally get from one execution to the next. Over time, the perturbations caused by the DRAM refresh cycle-eater tend to average out, since DRAM refresh occurs on a regular basis. Similarly, a lengthy code sequence that accesses display memory multiple times will tend to suffer a fairly consistent loss of performance to the display adapter cycle-eater. By contrast, a short code sequence that accesses display memory just once may vary greatly in performance from one run to the next, depending on how many wait states occur on the one access during a given run.</p>
<p>In short, you should time either long code sequences or repeated executions of shorter code sequences. While there’s no strict definition of “long” in this context, the effects of the DRAM refresh and display adapter cycle-eaters should largely even out in sequences longer than about 100 us. While you can certainly use the Zen timer to measure shorter intervals, you should take multiple readings in such cases to make sure that the variations the cycle-eaters can cause from one run to the next aren’t skewing your readings.</p>
</section>
<section id="odds-and-ends-1" class="level3">
<h3>Odds and Ends</h3>
<p>There are a few more interesting observations to be made about Figure 5.1. For one thing, we can clearly see that while bus accesses are sometimes farther apart than 4 cycles, they are never any closer together. This confirms our earlier observation that bus cycles take a minimum of 4 cycles.</p>
<p>On the other hand, instruction bytes can be transferred from the prefetch queue to the Execution Unit at a rate of 1 byte per cycle when the EU needs them that quickly. This reinforces the notion that the EU can use up instruction bytes faster than the BIU can fetch them. In fact, we can see the EU waiting for an instruction byte fetch from cycle 130 to cycle 135, as discussed earlier. It’s worth noting that after the instruction byte transfer to the EU at cycle 135, the next two instruction byte transfers occur at cycles 139 and 143, each occurring 4 cycles after the previous transfer. That mimics the 4 cycles separating the fetches of those instruction bytes, and that’s no coincidence. During these cycles the EU does nothing but wait for the BIU to fetch instruction bytes — the most graphic demonstration yet of the prefetch queue cycle-eater.</p>
<p>The prefetch queue cycle-eater can be observed in another way in Figure 5.1. A careful reading of Figure 5.1 will make it apparent that the prefetch queue never contains more than 2 bytes at any time. In other words, the prefetch queue not only never fills, it never gets more than 2 bytes ahead of the Execution Unit. Moreover, we can see at cycles 33 and 34 that the EU can empty those 2 bytes from the prefetch queue in just 2 cycles. There’s no doubt but what the BIU often fights a losing battle in trying to keep the EU supplied with instruction bytes.</p>
</section>
</section>
<section id="back-to-the-programming-interface" class="level2">
<h2>Back to the Programming Interface</h2>
<p>It’s not important that you grasp everything in this chapter, so long as you understand that the factors affecting the performance of an instruction in a given context are complex and vary with time. These complex and varied factors make it virtually impossible to know beforehand at what speed code will actually run. They also make it both impractical and pointless to understand exactly — down to the cycles — why a particular instruction or code sequence performs as well or poorly as it does.</p>
<p>As a result, high-performance assembler programming must be an intuitive art, rather than a cut-and-dried cookbook process. That’s why this book is called <em>The Zen of Assembly Language</em>, not <em>The Assembly Language Programming Reference Guide</em>. That’s also why you <em>must</em> time your code if you want to know how fast it is.</p>
<p>Cycle-eaters underlie the programming interface, the topic we’ll tackle next. Together, cycle-eaters and the programming interface constitute the knowledge aspect of the Zen of assembler. Ultimately, the concept of the flexible mind rests on knowledge, and algorithms and implementation rest on the flexible mind. In short, cycle-eaters are the foundation of the Zen of assembler, and as such they will pop up frequently in the following chapters in a variety of contexts. The constant application of our understanding of the various cycle-eaters to working code should clear up any uncertainties you may still have about the cycle-eaters.</p>
<p>Next, we’ll head up out of the land of the cycle-eaters to the programming interface, the far more familiar domain of registers, instructions, memory addressing, DOS calls and the like. After our journey to the land of the cycle-eaters, however, don’t be surprised if the programming interface looks a little different. Assembler code never looks quite the same to a programmer who understands the true nature of performance.</p>
</section>
</section>
<section id="chapter-6-the-8088" class="level1">
<h1>Chapter 6: The 8088</h1>
<section id="an-overview-of-the-8088" class="level2">
<h2>An Overview of the 8088</h2>
<p>In a nutshell, the 8088 is a 16-bit processor with an 8-bit data bus capable of addressing 1 Mb of memory in total but no more than four 64Kb byte blocks at a time and that via a remarkably awkward segmented memory scheme. The register space is limited, but the instruction set is powerful and flexible, albeit highly irregular. The 4.77-MHz clock speed of the 8088 as implemented in the IBM PC is slow by today’s standards, and both instruction execution and memory access are relatively slow as well. What the whole 8088 package as used in the PC amounts to is a fairly low-performance processor that is hard to program.</p>
<p>Why am I saying such unflattering things about the 8088? Because I want you to understand how hard it is to write good 8088 code. As you may have guessed, there is a saving grace to the 8088; as implemented in the PC the 8088 can support just enough performance and memory to run some splendid software — software carefully crafted to work around the 8088’s weaknesses and take maximum advantage of its strengths. Those strengths and weaknesses lie hidden in the 8088’s instruction set, and we will spend the rest of this book ferreting them out.</p>
<p>Before we begin, you must understand one thing; the 8088 is a hodgepodge of a processor. Not a <em>random</em> hodgepodge, mind you — there are good reasons why the 8088 is what it is — but a hodgepodge nonetheless. Internally, the 8088 is a 16-bit processor, thanks to its derivation from the 8086, as discussed in Chapter 3. Externally, the 8088 is an 8-bit processor, owing to its genesis in the 1970s, when the cost difference between 8- and 16-bit buses was significant. The design of the 8086, including the register set and several instructions, was heavily influenced by the 8-bit 8080 processor, as we’ll see in Chapter 8. Finally, the memory architecture of the 8088 is a remnant of an era when both chip space and the number of pins per chip were severely limited and memory was extremely expensive. The 8088 is an excellent representative of the transitional state of the microcomputer industry a decade ago; striving for state-of-the-art while maintaining a link with the past, all in too little silicon. From a programmer’s perspective, though, the 8088 is simply a bit of a mess.</p>
<p>That certainly doesn’t mean the 8088 isn’t worth bothering with nowadays, as attested by 10 million or so 8088-based computers. It does, however, mean that programming the 8088 properly in assembler is not simple, since code that takes maximum advantage of the unique nature of the 8088 is generally much faster than code that uses the processor in a straightforward manner. We must take the time to understand the strengths and weaknesses of the 8088 intimately, then learn how to best structure our code in light of that knowledge.</p>
</section>
<section id="resources-of-the-8088" class="level2">
<h2>Resources of the 8088</h2>
<p>Over the next nine chapters, we’ll look at the capabilities and resources of the 8088. We’ll learn a great deal about high-performance assembler programming, and we’ll also lay the groundwork for the higher level assembler programming techniques of Volume II.</p>
<p>We’ll spend the remainder of this chapter looking at the registers and flags of the 8088. In Chapter 7 we’ll cover the 8088’s memory-addressing capabilities, and in Chapter 8 we’ll start to cover the 8088’s large and varied instruction set. The resources of the 8088 are both fascinating and essential, for in their infinite permutations and combinations — they are your set of tools for creating the best possible code for the IBM PC.</p>
</section>
<section id="registers" class="level2">
<h2>Registers</h2>
<p>The register set of a processor is a key to understanding the processor’s personality, since registers are typically where most of the action in a processor takes place. The 8088’s register set is something of a mixed bag. Since the 8088 is a 16-bit processor internally, register-only instructions (instructions without memory operands) tend to be fast and compact, so the 8088’s registers are no more regular than anything else about the processor. Each register offers unique, specialized (and hard to remember) functions; together, these oddball register functions make up what my friend and editor Jeff Duntemann calls “the register hidden agenda,” the not obvious but powerful register capabilities that considerably increase both the difficulty and the potential power of 8088 assembler programming.</p>
<p>Let me give you an example. Many years ago, a friend who had just made the transition from programming the Apple II to programming the IBM PC, had a program that crashed every so often for no apparent reason. We spent a good deal of time examining his program before we could isolate the cause of his problems. As it turned out, he was using SP as a working register for short stretches, storing values in it, performing arithmetic with it, and all-in-all using SP as if it were just another general-purpose register.</p>
<p>While SP can theoretically be used as a general-purpose register, in fact it is almost always dedicated to maintaining the stack. My friend’s problem was that keyboard and timer interrupts, which use the stack, were occurring while he had SP loaded with values that didn’t point to a valid stack, so interrupts were pushing return addresses and flags into random areas of memory. When I asked him how he could possibly have made such an obvious mistake, he explained that his approach would have worked perfectly well on the Apple II, where there are no interrupts.</p>
<p>There are two important points here. One is by not understanding SP’s portion of the register hidden agenda — the role of SP as a stack pointer in an interrupt-driven system — my friend had wasted considerable development time. The second point is that, had he understood the register hidden agenda better, he could have extended his odd approach to generate some genuinely innovative code.</p>
<p>How? Well, SP really is a general purpose register when it’s not being used to maintain a stack. My friend’s mistake had been his assumption that the stack is inactive when no calls, returns, pushes, or pops are occurring; this assumption is incorrect because interrupts may take place at any time. Suppose, though, that he had simply disabled interrupts for those brief periods when he needed an eighth general-purpose register for speed. Why, then his use of SP would have been not only acceptable but nearly brilliant!</p>
<p>Alas, disabling interrupts and using SP would not have been truly brilliant, for nonmaskable interrupts, used to signal parity errors and used by some display adapters as well, can occur and use the stack even when interrupts are disabled. In general, I recommend that you not use SP as a general-purpose register, even with interrupts disabled. Although the chances of a nonmaskable interrupt occurring are slim, they are nonetheless real.</p>
<p>All of which simply serves to reinforce the notion that the more we know about the 8088, the better our code will be. That’s why we’ll cover the 8088’s other resources for most of the rest of this volume. The more thorough your understanding of the 8088, the greater the potential of your assembler code.</p>
</section>
<section id="the-8088s-register-set" class="level2">
<h2>The 8088’s Register Set</h2>
<p>Figure 6.1 shows the 8088’s register set to be a mix of general and special-purpose registers. The 8088 offers only seven truly general-purpose</p>
<figure>
<img src="images/fig6.1RT.png" />
</figure>
<p>registers — AX, BX, CX, DX, SI, DI, and BP — a small set that seems even smaller because four of these registers double as memory-addressing registers and because the slow speed of memory assess dictates use of registers whenever possible. Only certain registers can be used for many functions; for example, only BX, BP, SI, and DI can be used to generate memory-addressing offsets, and then only in certain combinations. Likewise, only AX, BX, CX, and DX can be accessed as either as single 16-bit registers or paired 8-bit registers.</p>
<p>Let’s take a quick tour of the registers, looking at the unique capabilities of each.</p>
</section>
<section id="the-general-purpose-registers" class="level2">
<h2>The General-Purpose Registers</h2>
<p>Any of the eight general-purpose registers — AX, BX, CX, DX, SI, DI, BP, or SP — may serve as an operand to virtually any instruction that accepts operands, such as <code class="sourceCode nasm"><span class="kw">add</span></code>, <code class="sourceCode nasm"><span class="kw">push</span></code>, <code class="sourceCode nasm"><span class="kw">shl</span></code>, or <code class="sourceCode nasm"><span class="kw">call</span></code>. Put another way, any general-purpose register may be used as an operand by any instruction that uses mod-reg-rm addressing, the most commonly-used addressing mode of the 8088, which we’ll discuss in the next chapter. Most of the logical, arithmetic, and data movement operations of the 8088 can use any of the general-purpose registers, and it is the general-purpose registers that are most often used as instruction operands.</p>
<p>Four of the eight general-purpose registers — AX, BX, CX, DX — can be accessed either as paired 8-bit registers or as single 16-bit registers. For example, the upper byte of BX can be accessed as BH for 8-bit operations, and the lower byte can be accessed as BL. The eight 8-bit general-purpose registers — AH, AL, BH, BL, CH, CL, DH, and DL — can be used as 8-bit operands with any instructions that use <em>mod-reg-rm</em> addressing, just as the eight 16-bit general-purpose registers can be used as 16-bit operands with those instructions.</p>
<section id="the-ax-register" class="level3">
<h3>The AX register</h3>
<p>The AX register is the l6-bit accumulator. The lower byte of AX can be accessed as the AL register, which is the 8-bit accumulator; the upper byte of AX can be accessed as the AH register, which is not an accumulator of any sort. The accumulator is always both one of the source operands and the destination for multiply and divide instructions. The accumulator must also be the source for <code class="sourceCode nasm"><span class="kw">out</span></code> instructions and the destination for <code class="sourceCode nasm"><span class="kw">in</span></code> instructions, and is the source or destination register for the string instructions <code class="sourceCode nasm"><span class="kw">lods</span></code>, <code class="sourceCode nasm"><span class="kw">stos</span></code>, and <code class="sourceCode nasm"><span class="kw">scas</span></code>, as we’ll see in Chapter 10. There are special instructions for sign-extending the accumulator to larger data types; <code class="sourceCode nasm"><span class="kw">cbw</span></code> for converting a signed byte in AL to a signed word in AX, and <code class="sourceCode nasm"><span class="kw">cwd</span></code> for converting a signed word in AX to a signed doubleword in DX:AX. Finally, there are a number of accumulator-specific instructions that are particularly efficient; we’ll discuss those instructions in Chapters 8 and 9.</p>
<p>There are several instructions that use part or all of the AX register in odd ways. In Chapter 7 we’ll discuss <code class="sourceCode nasm"><span class="kw">xlat</span></code>, the only instruction that can use AL for memory addressing. In Chapter 8 we’ll discuss <code class="sourceCode nasm"><span class="kw">lahf</span></code> and <code class="sourceCode nasm"><span class="kw">sahf</span></code>, which transfer the lower byte of the flags register to and from AH. In Chapter 8 we’ll also discuss a special form of <code class="sourceCode nasm"><span class="kw">xchg</span></code> that requires that AX be one operand. Finally, the decimal- and ASCII-adjust instructions — <code class="sourceCode nasm"><span class="kw">aaa</span></code>, <code class="sourceCode nasm"><span class="kw">aad</span></code>, <code class="sourceCode nasm"><span class="kw">aam</span></code>, <code class="sourceCode nasm"><span class="kw">aas</span></code>, <code class="sourceCode nasm"><span class="kw">daa</span></code>, and <code class="sourceCode nasm"><span class="kw">das</span></code> — alter AL or AX in specific ways to compensate for the effects of ASCII or BCD arithmetic. These instructions are so different from the other members of the 8088 instruction set that we’ll defer further discussion of them until Chapter 9.</p>
</section>
<section id="the-bx-register" class="level3">
<h3>The BX register</h3>
<p>The BX register is the only register among the dual 8/16-bit registers that can be used for memory addressing (with the sole exception of AL in the case of <code class="sourceCode nasm"><span class="kw">xlat</span></code>). The lower byte of BX is accessible as BL and the upper byte is accessible as BH; neither BH nor BL alone can be used for memory addressing.</p>
<p>Like the other general-purpose registers, BX (or BH or BL) may serve as an operand to any instruction that uses <em>mod-reg-rm</em> addressing. In addition, BX (but not BH or BL) can be used as a base register for memory addressing. That is, the contents of BX can be used to generate the address of a memory operand, as discussed in the next chapter, by any instruction that uses <em>mod-reg-rm</em> addressing, and by <code class="sourceCode nasm"><span class="kw">xlat</span></code> as well.</p>
</section>
<section id="the-cx-register" class="level3">
<h3>The CX register</h3>
<p>The CX register is designed for specialized counting purposes. The lower byte of CX is accessible as CL and the upper byte as CH; CL can be used for certain specialized 8-bit counting purposes, but CH cannot. CX is used as a counter by the <code class="sourceCode nasm"><span class="kw">loop</span></code>, <code class="sourceCode nasm"><span class="kw">loopz</span></code>, <code class="sourceCode nasm"><span class="kw">loopnz</span></code>, and <code class="sourceCode nasm"><span class="kw">jcxz</span></code> instructions, which we’ll look at in Chapter 14, and is also used as a counter by the string instructions when they’re used with the <code class="sourceCode nasm">rep</code> prefix, as we’ll see in Chapter 10, CL can be used to specify a rotation or shift count for any of the rotate or shift instructions, such as<code class="sourceCode nasm"><span class="kw">ror</span></code>, <code class="sourceCode nasm"><span class="kw">shl</span></code>, and <code class="sourceCode nasm"><span class="kw">rcl</span></code>, as described in Chapter 9.</p>
</section>
<section id="the-dx-register" class="level3">
<h3>The DX register</h3>
<p>The DX register is the least specialized of the general-purpose registers; the only unique functions of DX are serving as the upper word of the destination on l6-bit by l6-bit multiplies, serving as the upper word of the source and the destination for the remainder on 32-bit by l6-bit divides, addressing I/O ports when used with <code class="sourceCode nasm"><span class="kw">in</span></code> and <code class="sourceCode nasm"><span class="kw">out</span></code>, and serving as the upper word of the destination for <code class="sourceCode nasm"><span class="kw">cbw</span></code>. The lower byte of DX is accessible as DL, and the upper byte is accessible as DH.</p>
</section>
<section id="the-si-register" class="level3">
<h3>The SI register</h3>
<p>The SI register specializes as the source memory-addressing register for the string instructions <code class="sourceCode nasm"><span class="kw">lods</span></code> and <code class="sourceCode nasm">mob</code> and as the destination memory-addressing register for the string instruction <code class="sourceCode nasm"><span class="kw">cmps</span></code>, as we’ll see in Chapter 10.</p>
<p>Like the other general-purpose registers, SI may serve as an operand to any instruction that uses <em>mod-reg-rm</em> addressing. In addition, SI can be used as an index register for memory addressing by any instruction that uses <em>mod-reg-rm</em> addressing, as we’ll see in the next chapter, and, of course, by the above-mentioned string instructions as well.</p>
</section>
<section id="the-di-register" class="level3">
<h3>The DI register</h3>
<p>The DI register Specializes as the destination memory-addressing register for the string instructions <code class="sourceCode nasm"><span class="kw">stos</span></code> and <code class="sourceCode nasm"><span class="kw">movs</span></code>, and as the source memory-addressing register for the string instructions <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code>, as we’ll see in Chapter 10.</p>
<p>Like the other general-purpose registers, DI may serve as an operand to any instruction that uses <em>mod-reg-rm</em> addressing. In addition, DI can be used as an index register for memory addressing by any instruction that uses <em>mod-reg-rm</em> addressing, as we’ll see in the next chapter, and by the above-mentioned string instructions as well.</p>
</section>
<section id="the-bp-register" class="level3">
<h3>The BP register</h3>
<p>The BP register specializes as the stack frame-addressing register. Like the other general-purpose registers, BP may serve as an operand to any instruction that uses <em>mod-reg-rm</em> addressing. Like BX, BP can also be used as a base register for memory addressing by any instruction that uses <em>mod-reg-rm</em> addressing, as discussed in the next chapter. However, while BX normally addresses the data segment, BP normally addresses the stack segment. This makes BP ideal for addressing parameters and temporary variables stored in stack frames, a topic to which we’ll return in the next chapter.</p>
</section>
<section id="the-sp-register" class="level3">
<h3>The SP register</h3>
<p>The SP register is technically a general-purpose register, but in actual practice it almost always serves as the highly specialized stack pointer, and is rarely used as a general-purpose register. SP points to the offset of the top of the stack in the stack segment, and is automatically incremented and decremented as the stack is accessed via <code class="sourceCode nasm"><span class="kw">push</span></code>, <code class="sourceCode nasm"><span class="kw">pop</span></code>, <code class="sourceCode nasm"><span class="kw">call</span></code>, <code class="sourceCode nasm"><span class="kw">ret</span></code>, <code class="sourceCode nasm"><span class="kw">int</span></code>, and <code class="sourceCode nasm"><span class="kw">iret</span></code> instructions.</p>
<p>Like the other general-purpose registers, SP may serve as an operand to any instruction that uses <em>mod-reg-rm</em> addressing. In general, SP is modified through the above-mentioned stack-oriented instructions, but SP also may be subtracted from, added to, or loaded directly in order to allocate or deallocate a temporary storage block on the stack or switch to a new stack.</p>
<p>One note: never push SP directly, as in</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">push</span>    <span class="kw">sp</span></code></pre>
<p>The reason is that the 80286 doesn’t handle the pushing of SP in quite the same way as the 8088 does; the 80286 pushes SP before decrementing it by 2, whereas the 8088 pushes SP <em>after</em> decrementing it. As a result, code that uses <code class="sourceCode nasm"><span class="kw">push</span> <span class="kw">sp</span></code> may not work in the same way on all computers. In normal code you’ll rarely need to push SP, but if you do, you can simply pass the value through another register, as in</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>     <span class="kw">ax</span>,<span class="kw">sp</span>
<span class="kw">push</span>    <span class="kw">ax</span></code></pre>
<p>The above sequence will work exactly the same way on any 8086-family processor…</p>
</section>
</section>
<section id="the-segment-registers" class="level2">
<h2>The Segment Registers</h2>
<p>Each of the four segment registers — CS, DS, ES, and SS — points to the start of a 64-Kb block, or segment, within which certain types of memory accesses may be performed. For instance, the stack must always reside in the segment pointed to by SS. Except as noted, segment registers can only be copied to or loaded from a memory operand, the stack, or a general-purpose register. Segment registers cannot be used as operands to instructions such as <code class="sourceCode nasm"><span class="kw">add</span></code>, <code class="sourceCode nasm"><span class="kw">dec</span></code> or <code class="sourceCode nasm"><span class="kw">and</span></code> a property that complicates considerably the handling of blocks of memory larger than 64 Kb.</p>
<p>Since a segment register stores a 16-bit value just as a general-purpose register does, it sometimes becomes tempting to use one of the segment registers (almost always ES or DS, although SS could conceivably be used under certain circumstances) for temporary storage. Be aware, however, that because segment registers take on more specialized meanings in the protected modes of the 80286 and 80386 processors, you should avoid using this technique in code that may at sometime need to be ported to protected mode. That doesn’t mean you shouldn’t use segment registers for temporary storage, as we’ll see in the next chapter, just that you should be aware of the possible complications.</p>
<p>We’ll discuss segments and segment registers at length in the next chapter; what’s coming up next is just a quick glance at the segment registers and their uses.</p>
<section id="the-cs-register" class="level3">
<h3>The CS register</h3>
<p>The CS register points to the code segment, the 64-Kb block within which IP points to the offset of the next instruction byte to be executed. The CS:IP pair cannot ever point to the wrong place for even one instruction; if it did, an incorrect instruction byte would be fetched and executed next. Consequently, both CS and IP must be set whenever CS is changed, and the setting of both registers must be accomplished by a single instruction. Although CS can be pushed, copied to memory, or copied to a general-purpose register, it can’t be loaded directly from any of those sources. The only instructions that can load CS are the far versions of <code class="sourceCode nasm"><span class="kw">jmp</span></code>, <code class="sourceCode nasm"><span class="kw">call</span></code> and <code class="sourceCode nasm"><span class="kw">ret</span></code> as well as <code class="sourceCode nasm"><span class="kw">int</span></code> and <code class="sourceCode nasm"><span class="kw">iret</span></code>, what all those instructions have in common is that they load both CS and IP at the same time. Both <code class="sourceCode nasm"><span class="kw">int</span></code> and the far version of <code class="sourceCode nasm"><span class="kw">call</span></code> push both CS and IP on the stack so that <code class="sourceCode nasm"><span class="kw">iret</span></code> or <code class="sourceCode nasm"><span class="kw">ret</span></code> can return to the instruction following the <code class="sourceCode nasm"><span class="kw">int</span></code> or <code class="sourceCode nasm"><span class="kw">call</span></code>.</p>
<p>In addition, segment override prefixes can be used to select CS as the segment accessed by many memory operands that normally access DS.</p>
</section>
<section id="the-ds-register" class="level3">
<h3>The DS register</h3>
<p>The DS register points to the data segment, the segment within which most memory operands reside by default. (Note, however, that many memory-addressing instructions can access any of the four segments with the help of a segment override prefix.)</p>
<p>DS can be copied to or loaded from a memory operand, the stack, or a general-purpose register. It can also be loaded, along with any general- purpose register, from a doubleword operand with the <code class="sourceCode nasm"><span class="kw">lds</span></code> instruction.</p>
</section>
<section id="the-es-register" class="level3">
<h3>The ES register</h3>
<p>The ES register points to the extra segment, the segment within which certain string instruction operands must reside. In addition, segment override prefixes can be used to select ES as the segment accessed by many memory operands that normally access DS.</p>
<p>ES can be copied to or loaded from a memory operand, the stack, or a general-purpose register. ES can also be loaded, along with any general-purpose register, from a doubleword operand with the <code class="sourceCode nasm"><span class="kw">les</span></code> instruction.</p>
</section>
<section id="the-ss-register" class="level3">
<h3>The SS register</h3>
<p>The SS register points to the stack segment, the segment within which SP points to the top of the stack. The instruction <code class="sourceCode nasm"><span class="kw">push</span></code> stores its operand in the stack segment, and <code class="sourceCode nasm"><span class="kw">pop</span></code> retrieves its operand from the stack segment. In addition, <code class="sourceCode nasm"><span class="kw">call</span></code>, <code class="sourceCode nasm"><span class="kw">ret</span></code>, <code class="sourceCode nasm"><span class="kw">int</span></code>, and <code class="sourceCode nasm"><span class="kw">iret</span></code> all access the stack Memory accesses performed with BP as a base register also default to accessing the stack segment. Finally, segment override prefixes can be used to select SS as the segment accessed by many memory operands that normally access DS.</p>
<p>Although SS can be loaded directly, like DS and ES, you must always remember that SS and SP operate as a pair and together must point to a valid stack whenever stack operations might occur. As discussed above, interrupts can occur at any time, so when you load SS, interrupts must be off until both SS and SP have been loaded to point to the new stack. Intel thoughtfully provided a feature designed to take care of such problems. Whenever you load a segment register via <code class="sourceCode nasm"><span class="kw">mov</span></code> or <code class="sourceCode nasm"><span class="kw">pop</span></code>, interrupts are automatically disabled until the following instruction has finished. For example, in the following code</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">ss</span>,<span class="kw">dx</span>
<span class="kw">mov</span>   <span class="kw">sp</span>,<span class="kw">ax</span></code></pre>
<p>interrupts are disabled from the start of the first <code class="sourceCode nasm"><span class="kw">mov</span></code> until the end of the second. After the second <code class="sourceCode nasm"><span class="kw">mov</span></code>, interrupts are again enabled or disabled as they were before the first <code class="sourceCode nasm"><span class="kw">mov</span></code>, depending on the state of the interrupt flag.</p>
<p>Unfortunately, there was a bug in early 8088 chips that caused the automatic interrupt disabling described above to malfunction. Consequently, it’s safest to explicitly disable interrupts when loading SS:SP, as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">cli</span>
<span class="kw">mov</span>   <span class="kw">ss</span>,<span class="kw">dx</span>
<span class="kw">mov</span>   <span class="kw">sp</span>,<span class="kw">ax</span>
<span class="kw">sti</span></code></pre>
</section>
</section>
<section id="the-instruction-pointer" class="level2">
<h2>The Instruction Pointer</h2>
<p>IF, the instruction pointer, is an internal 8088 register that is not directly accessible as an instruction operand. IF contains the offset in the code segment at which the next instruction to be executed resides. After one instruction is started, IP is normally advanced to point to the next instruction; however, branching instructions, such as <code class="sourceCode nasm"><span class="kw">jmp</span></code> and <code class="sourceCode nasm"><span class="kw">call</span></code>, load IF with the offset of the instruction being branched to. The instructions <code class="sourceCode nasm"><span class="kw">call</span></code> and <code class="sourceCode nasm"><span class="kw">int</span></code> automatically push IP, allowing <code class="sourceCode nasm"><span class="kw">ret</span></code> or <code class="sourceCode nasm"><span class="kw">iret</span></code> to continue execution at the instruction following the <code class="sourceCode nasm"><span class="kw">call</span></code> or <code class="sourceCode nasm"><span class="kw">int</span></code>.</p>
<p>As we’ve discussed, in one sense the instruction pointer points to the next instruction to be<em>fetched</em> from memory rather than the next instruction to be executed. This distinction arises because the bus interface unit (BID) of the 8088 can prefetch several instructions ahead of the instruction being carried out by the execution unit (EU). From the programmer’s perspective, though, the instruction pointer always simply points to the next instruction byte to be executed; the 8088 handles all the complications of prefetching internally in order to present us with this consistent programming interface.</p>
</section>
<section id="the-flags-register" class="level2">
<h2>The Flags Register</h2>
<p>The flags register contains the nine bit-sized status flags of the 8088, as shown in Figure 6.2. Six of these flags — CF, PF, AF, ZF, SF, and OF, collectively known as the status flags — reflect the status of logical and arithmetic operations; two — IF and DF — control aspects of the 8088’s operation; and one — TF — is used only by debugging software.</p>
<figure>
<img src="images/fig6.2RT.png" />
</figure>
<p>The flags are generally tested singly (or occasionally in pairs or even three at a time, as when testing signed operands); however, many arithmetic and logical instructions set all six status flags to indicate result statuses, and a few instructions work directly with all or half of the flags register at once. For example, <code class="sourceCode nasm"><span class="kw">pushf</span></code> pushes the flags register onto the stack, and <code class="sourceCode nasm"><span class="kw">popf</span></code> pops the word on top of the stack into the flags register. (We’ll encounter an interesting complication with <code class="sourceCode nasm"><span class="kw">popf</span></code> on the 80286 in Chapter 15.) In Chapter 8 we’ll discuss <code class="sourceCode nasm"><span class="kw">lahf</span></code> and <code class="sourceCode nasm"><span class="kw">sahf</span></code>, which copy the lower byte of the flags register to and from the AH register. Interrupts, both software (via <code class="sourceCode nasm"><span class="kw">int</span></code>) and hardware (via the INTR pin), push the flags register on the stack, followed by CS and IP; <code class="sourceCode nasm"><span class="kw">iret</span></code> reverses the action of an interrupt, popping the three words on top of the stack into IP, CS, and the flags register.</p>
<p>One more note: bear in mind that the six status flags are not set by every instruction. On some processors the status flags always reflect the contents of the accumulator, but not so with the 8088, where only specific instructions affect specific flags. For example, <code class="sourceCode nasm"><span class="kw">inc</span></code> affects all the status flags <em>except</em> the carry flag; although that can be a nuisance, it can also be used to good advantage in summing multi-word memory operands, as we’ll see in Chapter 9.</p>
<p>Along the same line, some instructions, such as division, leave some or all of the status flags in undefined states; that is, the flags are changed, but there is no guarantee as to what values they are changed to. Because <code class="sourceCode nasm"><span class="kw">mov</span></code> and most branching instructions don’t affect the status flags at all, you can, if you’re clever, carry the result of an operation along for several instructions, a technique we’ll look at in Chapter 9.</p>
<p>Let’s briefly examine each flag.</p>
<section id="the-carry-flag-cf" class="level3">
<h3>The Carry flag (CF)</h3>
<p>The carry flag (CF for short) is set to 1 by additions that result in sums too large to fit in the destination and by subtractions that result in differences less than 0, and is set to 0 by arithmetic and logical operations that produce results small enough to fit in the destination when viewed as unsigned integers. (The logical operations <code class="sourceCode nasm"><span class="kw">and</span></code>, <code class="sourceCode nasm"><span class="kw">or</span></code>, and <code class="sourceCode nasm"><span class="kw">xor</span></code> always set CF to 0, since they always produce results that fit in the destination.) Also, when a shift or rotate instruction shifts a bit out of an operand’s most significant bit (msb) or least significant bit (lsb), that bit is transferred to CF. As a special case, both the carry and overflow flags are set to 1 by multiplication, except when the result is small enough to fit in the lower half of the destination (considered as a signed number for <code class="sourceCode nasm"><span class="kw">imul</span></code> and as an unsigned number for <code class="sourceCode nasm"><span class="kw">mul</span></code>).</p>
<p>The primary purpose of CF is to support addition, subtraction, rotation, and shifting of multi-byte or multi-word operands. In these applications, CF conveys the msb or lsb of one 8- or 16-bit operation to the next operation, as for example in the 32-bit right shift</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">shr</span>   <span class="kw">dx</span>,<span class="dv">1</span>  <span class="co">;shift upper 16 bits</span>
<span class="kw">rcr</span>   <span class="kw">ax</span>,<span class="dv">1</span>  <span class="co">;shift lower 16 bits, including the bit</span>
            <span class="co">; shifted down from the upper 16 bits</span></code></pre>
<p>Note that this makes CF the only flag that can participate directly in arithmetic operations.</p>
<p>CF can also be tested with the <code class="sourceCode nasm"><span class="kw">jc</span></code> (which can be thought of as standing for “jump carry”) and the <code class="sourceCode nasm"><span class="kw">jnc</span></code> (“jump no carry”) conditional jump instructions. The instruction <code class="sourceCode nasm"><span class="kw">jc</span></code> is also known as both <code class="sourceCode nasm"><span class="kw">jb</span></code> (“jump below”) and <code class="sourceCode nasm"><span class="kw">jnae</span></code> (“jump not above or equal”). All three instructions assemble to the same machine code. Likewise, <code class="sourceCode nasm"><span class="kw">jnc</span></code> is also known as both <code class="sourceCode nasm"><span class="kw">jae</span></code> (“jump above or equal”) and <code class="sourceCode nasm"><span class="kw">jnb</span></code> (“jump not below”). The carry and zero flags together can be tested with <code class="sourceCode nasm"><span class="kw">ja</span></code> and <code class="sourceCode nasm"><span class="kw">jbe</span></code>. <code class="sourceCode nasm"><span class="kw">ja</span></code> is also known as <code class="sourceCode nasm"><span class="kw">jnbe</span></code> (“jump not below or equal”), and <code class="sourceCode nasm"><span class="kw">jbe</span></code> is also known as <code class="sourceCode nasm"><span class="kw">jna</span></code> (“jump not above”). These conditional jumps are often used to determine unsigned greater than/less than/equal relationships between operands.</p>
<p>Alone among the six status flags , CF can be set, reset, and toggled directly with the <code class="sourceCode nasm"><span class="kw">clc</span></code> (“clear carry”), <code class="sourceCode nasm"><span class="kw">stc</span></code> (“set carry”), and <code class="sourceCode nasm"><span class="kw">cmc</span></code> (“complement carry”) instructions. This can be useful for returning a status from a subroutine, or for modifying the action of <code class="sourceCode nasm">ade</code>, <code class="sourceCode nasm"><span class="kw">sbb</span></code>, <code class="sourceCode nasm">rei</code>, or any other instruction that includes CF in its calculations.</p>
<p>Note that CF is <em>not</em> affected by <code class="sourceCode nasm"><span class="kw">inc</span></code> or <code class="sourceCode nasm"><span class="kw">dec</span></code>, although it is affected by add and sub. (We’ll see one use for this trait of <code class="sourceCode nasm"><span class="kw">inc</span></code> and <code class="sourceCode nasm"><span class="kw">dec</span></code> in Chapter 9.) Also, be aware that since <code class="sourceCode nasm"><span class="kw">neg</span></code> is logically equivalent to subtracting an operand from 0, CF is always set by <code class="sourceCode nasm"><span class="kw">neg</span></code>, except when the operand is 0. (Zero minus anything other than zero always causes borrow).</p>
</section>
<section id="the-parity-flag-pf" class="level3">
<h3>The Parity flag (PF)</h3>
<p>The parity flag (PF for short) is set to 1 whenever the least significant byte of the result of an arithmetic or logical operation contains an even number of bits that are set to 1, and it is set to 0 whenever the least significant byte contains an odd number of bits that are 1.</p>
<p>PF can be tested only with the <code class="sourceCode nasm"><span class="kw">jp</span></code> (“jump parity”) and <code class="sourceCode nasm"><span class="kw">jnp</span></code> (“jump no parity”) conditional jump instructions. The instruction <code class="sourceCode nasm"><span class="kw">jp</span></code> is also known as <code class="sourceCode nasm"><span class="kw">jpe</span></code> (“jump parity even”), and <code class="sourceCode nasm"><span class="kw">jnp</span></code> is also known as <code class="sourceCode nasm"><span class="kw">jpo</span></code> (“jump parity odd”). Generally, PF is useful for generating and testing parity bits for data storage and transmission. Apart from that, I know of no good uses for PF, although such uses may well exist.</p>
</section>
<section id="the-auxiliary-carry-flag-af" class="level3">
<h3>The Auxiliary Carry flag (AF)</h3>
<p>The auxiliary carry flag (AF for short) is set to 1 if arithmetic or logical operation results in carry out of bit 3 of the destination and is set to 0 otherwise. Alone among the six status flags, AF cannot be tested by any conditional jump instruction. In fact, the only instructions that pay any attention at all to AF are <code class="sourceCode nasm"><span class="kw">aaa</span></code>, <code class="sourceCode nasm"><span class="kw">aas</span></code>, <code class="sourceCode nasm"><span class="kw">daa</span></code>, and <code class="sourceCode nasm"><span class="kw">das</span></code>, which use AF to help sort out the results of ASCII or BCD arithmetic. Apart from ASCII and BCD arithmetic, which we’ll discuss in Chapter 9, I’ve never found a use for AF.</p>
</section>
<section id="the-zero-flag-zf" class="level3">
<h3>The Zero flag (ZF)</h3>
<p>The zero flag (ZF for short) is set to 1 if an arithmetic or logical operation produces a 0 result or to 0 otherwise. ZF is generally used to test for equality of two operands or for zero results via the <code class="sourceCode nasm"><span class="kw">jz</span></code> (“jump zero”) and <code class="sourceCode nasm"><span class="kw">jnz</span></code> (“jump not zero”) conditional jumps, also known as <code class="sourceCode nasm"><span class="kw">je</span></code> (“jump equal”) and <code class="sourceCode nasm"><span class="kw">jne</span></code> (“jump not equal”), respectively. As discussed above, ZF and CF can be tested together with a variety of conditional jumps. The zero, sign, and overflow flags together can be tested with <code class="sourceCode nasm"><span class="kw">jg</span></code> (“jump greater”), also known as <code class="sourceCode nasm"><span class="kw">jnle</span></code> (“jump not less or equal”) and with <code class="sourceCode nasm"><span class="kw">jle</span></code>, also known as <code class="sourceCode nasm"><span class="kw">jng</span></code> (“jump not greater”). These conditional jumps are often used to determine signed greater than/less than/equal relationships between operands.</p>
</section>
<section id="the-sign-flag-sf" class="level3">
<h3>The Sign flag (SF)</h3>
<p>The sign flag (SF for short) is set to the state of the most significant bit of the result of an arithmetic or logical operation. For signed arithmetic, the most Significant bit is the sign of the operand, so an SF setting of 1 indicates a negative result.</p>
<p>SF is generally used to test for negative results via the <code class="sourceCode nasm"><span class="kw">js</span></code> (“jump sign”) and <code class="sourceCode nasm"><span class="kw">jns</span></code> (“jump no sign”) conditional jumps. As discussed above, the sign zero, and overflow flags together can be tested with <code class="sourceCode nasm"><span class="kw">jg</span></code> and <code class="sourceCode nasm"><span class="kw">jle</span></code>. The sign and overflow flags together can be tested with <code class="sourceCode nasm"><span class="kw">jl</span></code> (“jump less”) and <code class="sourceCode nasm"><span class="kw">jge</span></code> (“jump greater or equal”). The instruction <code class="sourceCode nasm"><span class="kw">jl</span></code> is also known as <code class="sourceCode nasm"><span class="kw">jnge</span></code> (“jump not greater or equal”) and <code class="sourceCode nasm"><span class="kw">jge</span></code> is also known as <code class="sourceCode nasm"><span class="kw">jnl</span></code> (“jump not less”).</p>
</section>
<section id="the-overflow-flag-of" class="level3">
<h3>The Overflow flag (OF)</h3>
<p>The overflow flag (OF for short) is set to 1 if the carry into the most significant bit of the result of an operation and the carry out of that bit don’t match. Overflow indicates that the result, interpreted as a signed result, is too large to fit in the destination and is therefore not a valid signed result of the operation. (It may still be a valid unsigned result, however; CF is used to detect too large and too small unsigned results.) In short, OF is set to 1 if the result has overflowed (grown too large for) the destination in terms of signed arithmetic. I know of no use for OF other than in signed arithmetic. The logical operations <code class="sourceCode nasm"><span class="kw">and</span></code>, <code class="sourceCode nasm"><span class="kw">or</span></code>, and <code class="sourceCode nasm"><span class="kw">xor</span></code> always set OF to 0.</p>
<p>OF can be tested in any of several ways. The <code class="sourceCode nasm"><span class="kw">jo</span></code> (“jump overflow”) and <code class="sourceCode nasm"><span class="kw">jno</span></code> (“jump no overflow”) instructions branch or don’t branch depending on the state of OF. As described above, the <code class="sourceCode nasm"><span class="kw">jl</span></code>, <code class="sourceCode nasm"><span class="kw">jnl</span></code>, <code class="sourceCode nasm"><span class="kw">jle</span></code>, <code class="sourceCode nasm"><span class="kw">jnle</span></code>, <code class="sourceCode nasm"><span class="kw">jg</span></code>, <code class="sourceCode nasm"><span class="kw">jng</span></code>, <code class="sourceCode nasm"><span class="kw">jge</span></code>, and <code class="sourceCode nasm"><span class="kw">jnge</span></code> instructions branch or don’t branch depending on the states of OF, SF, and sometimes ZF. Finally, the <code class="sourceCode nasm"><span class="kw">int</span></code> instruction executes an int 4 if and only if OF is set.</p>
</section>
<section id="the-interrupt-flag-if" class="level3">
<h3>The Interrupt flag (IF)</h3>
<p>The interrupt flag (IF for short) enables and disables maskable hardware interrupts. When IF is 1, all hardware interrupts are recognized by the 8088. When IF is 0, maskable interrupts (that is, those interrupts signaled on the INTR pin) are not recognized until such time as IF is set to 1. (Nonmaskable interrupts — interrupts signaled on the NMI pin — are recognized by the 8088 regardless of the setting of IF, as are software interrupts, which are invoked with the <code class="sourceCode nasm"><span class="kw">int</span></code> instruction.) IF is set to 1 (enabling interrupts) with <code class="sourceCode nasm"><span class="kw">sti</span></code> and is set to 0 (disabling interrupts) with <code class="sourceCode nasm"><span class="kw">cli</span></code>. IF is also automatically set to 0 when a hardware interrupt occurs or an <code class="sourceCode nasm"><span class="kw">int</span></code> instruction is executed. In addition, as described in the discussion of the SS register above, interrupts are automatically disabled until the end of the following instruction whenever a segment register is loaded.</p>
<p>The PC is an interrupt-based computer, so interrupts should in general be disabled as infrequently and for as short a time as possible. System resources such as the keyboard and time-of-day clock are interrupt based and won’t function properly if interrupts are off for too long. You really only need to disable interrupts in code that could malfunction if it is interrupted, such as code that services time-sensitive hardware or code that uses multiple prefix bytes per instruction. (The latter, as discussed in Chapter 10, should be avoided whenever possible.)</p>
<p>Leave interrupts enabled at all other times.</p>
</section>
<section id="the-direction-flag-df" class="level3">
<h3>The Direction flag (DF)</h3>
<p>The direction flag (DF for short) controls the direction in which the pointer registers used by the string instructions (SI and DI) count. When DF is 1 (as set with <code class="sourceCode nasm"><span class="kw">std</span></code>), string instruction pointer registers decrement after each memory access; when DF is 0 (as set with <code class="sourceCode nasm"><span class="kw">cld</span></code>), string instruction pointer registers increment. We’ll discuss the direction flag in detail when we cover the string instructions in Chapter 10.</p>
</section>
<section id="the-trap-flag-tf" class="level3">
<h3>The Trap flag (TF)</h3>
<p>The trap flag (TF for short) instructs the 8088 to execute a software interrupt 1 after the next instruction. This is specifically intended to allow debugging software to single-step through code; it has no other known use.</p>
</section>
</section>
<section id="theres-more-to-life-than-registers" class="level2">
<h2>There’s More to Life Than Registers</h2>
<p>The register set is just one aspect of the 8088, albeit an important aspect indeed. The other key features of the 8088 are memory addressing, which expands the 8088’s working data set from the few bytes that can be stored in the registers to the million bytes that can be stored in memory, and the instruction set, which allows manipulation of registers and memory locations and provides program flow control (branching and decision making) as well. We’ll look at memory addressing next, then move on to the limitless possibilities of the instruct instruction set.</p>
</section>
</section>
<section id="chapter-7-memory-addressing" class="level1">
<h1>Chapter 7: Memory Addressing</h1>
<p>The 8088’s registers are very powerful, and critically important to writing high-performance code — but there are scarcely a dozen of them, and they certainly can’t do the job by themselves. We need more than seven — or seventy, or seven hundred or even seven thousand — general-purpose storage locations. We need storage that’s capable of storing characters, numbers, and instruction bytes in great quantities (remember that instruction bytes are just another sort of data) — and, of course, that’s just what we get by way of the 1 megabyte of memory that the 8088 supports.</p>
<p>(The PC has only 640 Kb of system RAM, but nonetheless does support a full megabyte of addressable memory. The memory above the 640 K mark is occupied by display memory and by BIOS code stored in ROM (read-only memory); this memory can always be read from and can in some cases — display memory, for example — be written to as well.)</p>
<p>Not only does the 8088 support 1 Mb of memory, but it also provides many powerful and flexible ways to get at that memory. We’ll skim through the many memory addressing modes and instructions quickly, but we’re not going to spend a great deal of time on their basic operation.</p>
<p>Why not spend more time describing the memory addressing modes and instructions? One reason is that I’ve assumed throughout <em>The Zen of Assembly Language</em> that you’re at least passingly familiar with assembler, thereby avoiding a lot of rehashing and explaining — and memory addressing is fundamental to almost any sort of assembler programming. If you really don’t know the basic memory addressing modes, a refresher on assembler in general might be in order before you continue with <em>The Zen of Assembly Language</em>.</p>
<p>The other reason for not spending much time on the operation of the memory addressing modes is that we have another — and sadly neglected — aspect of memory addressing to discuss: performance.</p>
<p>You see, while the 8088 lets you address a great deal of memory, it isn’t particularly fast at accessing all that memory. This is especially true when dealing with blocks of memory larger than 64 Kb, but is <em>always</em> true to some extent. Memory-accessing instructions are often very long and are always very slow.</p>
<p>Worse, many people don’t seem to understand the sharp distinction between memory and registers. Some “experts” would have you view memory locations as extensions of your register set. With this sort of thinking, the instructions:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">dx</span>,<span class="kw">ax</span></code></pre>
<p>and:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">dx</span>,MemVar</code></pre>
<p>are logically equivalent. Well, the instructions <em>are</em> logically equivalent in the sense that they both move data into DX — but they’re polar opposites when it comes to performance. The register-only <code class="sourceCode nasm"><span class="kw">mov</span></code> is half the length in bytes and anywhere from two to seven times faster than the <code class="sourceCode nasm"><span class="kw">mov</span></code> from memory… and that’s fairly typical of the differences between register-only and memory-addressing instructions.</p>
<p>So you see, saying that memory is logically equivalent to registers is something like saying that a bus is logically equivalent to a 747. Sure, you can buy a ticket to get from one place to another with either mode of transportation… but which would <em>you</em> rather cross the country in?</p>
<p>As we’ll see in this chapter, and indeed throughout the rest of the <em>Zen of Assembly Language</em>, one key to optimizing 8088 code is using the registers heavily while avoiding memory whenever you can. Pick your spots for such optimizations carefully, though. Optimize instructions in tight loops and in time-critical code, but let initialization and set-up code slide; it’s just not worth the time and effort to optimize code that doesn’t much affect overall performance or response time.</p>
<p>Slow and lengthy as memory accessing instructions are, you’re going to end up using them a great deal in your code. (Just try to write a useful program that doesn’t access memory!) In light of that, we’re going to review the memory-addressing architecture and modes of the 8088, then look at the performance implications of accessing memory. We’ll see why memory accesses are slow, and we’ll see that not all memory addressing modes or memory addressing instructions are created equal in terms of size and performance. (In truth, the differences between the various memory-addressing modes and instructions are just about as large as those between register-only and memory-accessing instructions.) Along the way, we’ll come across a number of useful techniques for writing high-performance code for the PC, most notably look-up tables. By the end of this chapter, we’ll be ready to dive into the instruction set in a big way.</p>
<p>We’ve got a lot of ground to cover, so let’s get started.</p>
<section id="definitions" class="level2">
<h2>Definitions</h2>
<p>I’m going to take a moment to define some terms I’ll use in this chapter. These terms will be used to describe operands to various instructions; for example, <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ax</span>,segreg</code> refers to copying the contents of a segment register into AX.</p>
<p><code class="sourceCode nasm">reg</code> refers to any 8-or 16-bit general-purpose register. <code class="sourceCode nasm">reg8</code> refers to any 8-bit (byte-sized) general-purpose register, and <code class="sourceCode nasm">reg16</code> refers to any 16-bit (word-sized) general-purpose register.</p>
<p><code class="sourceCode nasm">segreg</code> refers to any segment register.</p>
<p><code class="sourceCode nasm">mem</code> refers to any 8-, 16-, or 32-bit memory operand. <code class="sourceCode nasm">mem8</code> refers to any byte-sized memory operand, <code class="sourceCode nasm">mem16</code> refers to any word-sized memory operand, and <code class="sourceCode nasm">mem32</code> refers to any doublewordsized memory operand.</p>
<p><code class="sourceCode nasm">reg/mem</code> refers to any 8-or 16-bit register or memory operand. As you’d expect, <code class="sourceCode nasm">reg/mem8</code> refers to any byte-sized register or memory operand, and <code class="sourceCode nasm">reg/mem16</code> refers to any word-sized register or memory operand.</p>
<p><code class="sourceCode nasm">immed</code> refers to any immediate (constant) instruction operand. (Immediate addressing is discussed in detail below.) <code class="sourceCode nasm">immed8</code> refers to any byte-sized immediate operand, and <code class="sourceCode nasm">immed16</code> refers to any word-sized immediate operand.</p>
<section id="square-brackets-mean-memory-addressing" class="level3">
<h3>Square Brackets Mean Memory Addressing</h3>
<p>The use of square brackets is optional when a memory location is being addressed by name. That is, the two following instructions assemble to exactly the same code:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">dx</span>,MemVar
<span class="kw">mov</span>   <span class="kw">dx</span>,[MemVar]</code></pre>
<p>However, addressing memory without square brackets is an extension of the “memory and registers are logically equivalent” mindset. I strongly recommend that you use square brackets on all memory references in order to keep the distinction between memory and registers clear in your mind. This practice also helps distinguish between immediate and memory operands.</p>
</section>
</section>
<section id="the-memory-architecture-of-the-8088" class="level2">
<h2>The Memory Architecture of the 8088</h2>
<p>The ability to address 1 Mb of memory, while unimpressive by today’s standards, was quite remarkable when the PC was first introduced, 64 Kb then being standard for “serious” microcomputers. In fact, an argument could be made that the 8088’s 1 Mb address space is the single factor most responsible for the success of the IBM PC and for the exceptional software that quickly became available for it. Realistically, the letters “IBM” were probably more important, but all that memory didn’t hurt; quantities of memory make new sorts of software possible, and can often compensate for limited processor power in the form of lookup tables, RAM disks, data caching, and in-line code. All in all, the PC’s then-large memory capacity made possible a quantum leap in software quality.</p>
<p>On the other hand, the 8088 actually addresses all that memory in what is perhaps the most awkward manner ever conceived — by way of addressing 64 Kb blocks off each of the four segment registers. This scheme means that programs must perform complex and time-consuming calculations in order to access the full 1 Mb of memory in a general way. One of the ways in which assembler programs can outstrip compiled programs is by cleverly structuring code and data so that sequential memory accesses generally involve only memory within the four segments addressable at any one time, thereby avoiding the considerable overhead associated with calculating full addresses and frequently reloading the segment registers.</p>
<p>In short, the 8088’s memory architecture is the best of worlds and the worst of worlds: the best because a great deal of memory is addressable (at least by 1981 standards), the worst because it’s hard to access all that memory quickly. That said, let’s look at the 8088’s memory architecture in detail. Most likely you know what we’re about to discuss, but bear with me; I want to make sure we’re all speaking the same language before I go on to more advanced subjects.</p>
</section>
<section id="segments-and-offsets" class="level2">
<h2>Segments and Offsets</h2>
<p>20 bits are needed to address 1 Mb of memory, and every one of the one-million-plus memory addresses the 8088 can handle can indeed be expressed as a 20-bit number. However, programs do <em>not</em> address memory with 20-bit addresses. There’s a good reason for that: 20-bit addresses would be most impractical. For one thing, the 8088’s registers are only 16 bits in size, so they couldn’t be used to point to 20-bit addresses. For another, three rather than two bytes would be needed to store each address loaded by a program, making for bloated code. In general, the 8088 just wasn’t designed to handle straight 20-bit addresses.</p>
<p>(You may well ask why the 8088 wasn’t designed better. “Better” is a slippery term, and the 8088 certainly has been successful… nonetheless, that’s a good question, which I’ll answer in Chapter 8. A hint: much of the 8088’s architecture is derived from the 8080, which could only address 64 Kb in all. The 8088 strongly reflects long-ago microcomputer technology, not least in its limitation to 1 Mb in total.)</p>
<p>Well, if the PC doesn’t use straight 20-bit addresses, what does it use? It uses paired segments and offsets, which together form an address denoted as segment:offset. For example, the address 23F0:1512 is the address composed of the segment value 23F0 hex and the offset value 1512 hex. (I’ll always show segment:offset pairs in hexadecimal, which is by far the easiest numbering scheme for memory addressing.) Both segments and offsets are 16-bit values.</p>
<p>Wait one minute! We’re just looking for 20-bit addresses, not 32-bit addresses. Why do we need 16 bits of segment and 16 bits of offset?</p>
<p>Actually, we <em>don’t</em> need 16 bits of segment. We could manage to address 1 Mb perfectly well with a mere 4 bits of segment, but that’s not the way Intel set up the segment:offset addressing scheme. I might add that there’s some justification for using segments and offsets. The segment:offset approach is a reasonable compromise between the needs to use memory efficiently and keep chip costs down that predominated in the late 1970s and the need to use an architecture that could stretch to accommodate the far more sophisticated memory demands of the 8088’s successors. The 80286 uses an extension of the segment:offset approach to address 16 Mb of memory in a fully protected multitasking environment, and the 80386 goes far beyond that, as we’ll see in Chapter 15.</p>
<p>Anyway, although we only need 4 bits of segment, we get 16 bits, and none of them are ignored by the 8088. 20-bit addresses are formed from segment:offset pairs by shifting the segment 4 bits to the left and adding it to the offset, as shown in Figure 7.1.</p>
<figure>
<img src="images/fig7.1RT.png" />
</figure>
<p>I’d like to take a moment to note that for the remainder of this book, I’ll use light lines to signify memory addressing in figures and heavy lines to show data movement, as illustrated by Figure 7.1. In the future, I’ll show segment:offset memory addressing by simply joining the lines from the segment register and any registers and/or displacements (fixed values) used to generate an offset, as in Figure 7.7, avoiding the shift-and-add complications of Figure 7.1(A); the 4-bit left shift of the segment and the addition to the offset to generate a 20-bit memory address, which occurs whenever a segment:offset address is used, is implied. Also, when the segment isn’t germane to the discussion at hand, I may omit it and show only the offset component or components, as in Figure 7.4; although unseen, the segment is implied, since one segment register must participate in forming virtually every 20-bit memory address, as we’ll see shortly.</p>
<p>Figure 7.1 also illustrates another practice I’ll follow in figures that involve memory addressing: the shading of registers and memory locations that change value. This makes it easy to spot the effects of various operations. In Figure 7.1, only the contents of AL are altered; consequently, only AL is shaded.</p>
<p>I’ll generally follow the sequence of Figure 7.1 — memory address, memory access, final state of the PC — in memory addressing figures. While this detailed, step-by-step approach may seem like a bit of overkill right now, it will be most useful for illustrating the 8088’s more complex instructions, particularly the string instructions.</p>
<p>Finally, the numbers in Figure 7.1 — including both addresses and data — are in hexadecimal. Numbers in all figures involving memory addressing will be in hexadecimal unless otherwise noted.</p>
<p>To continue with our discussion of segment:offset addressing, shifting a segment value left 4 bits is equivalent to shifting it left 1 hexadecimal digit — one reason that hexadecimal is a useful notation for memory addresses. Put another way, if the segment is the hexadecimal value <em>ssss</em> and the offset is the hexadecimal value <em>xxxx</em>, then the 20-bit memory address <em>mmmmm</em> is calculated as follows:</p>
<pre><code>    ssss0
+    xxxx
---------
=   mmmmm</code></pre>
<p>For example, the 20-bit memory address corresponding to 23F0:1512 is 25412 (hex) arrived at as follows:</p>
<pre><code>    23F00
+    1512
---------
=   25412</code></pre>
<p>By the way, it happens that the 8088 isn’t particularly fast at calculating 20-bit addresses from segment:offset pairs. Although it only takes the 8088’s Bus Interface Unit 4 cycles to complete a memory access, the fastest memory-accessing instruction the PC has to offer (<code class="sourceCode nasm"><span class="kw">xlat</span></code>) takes 10 cycles to run. Other memory-accessing instructions take longer, some much longer. We’ll delve into the implications of the 8088’s lack of memory-access performance shortly.</p>
<p>Several questions should immediately leap into your mind if you’ve never encountered segments and offsets before. Where do these odd beasts live? What’s to prevent more than one segment:offset pair from pointing to the same 20-bit address? What happens when the sum of the two gets too large to fit in 20 bits?</p>
<p>To answer the first question first, segment values reside in the four segment registers: CS, DS, ES, and SS. One (and only one) of these four registers participates in calculating the address for almost every single memory access the PC makes. (Interrupts are exceptions to this rule, since interrupt vectors are read from fixed locations in the first 1 Kb of memory.) Segments are, practically speaking, part of every memory access your code will ever make.</p>
<p>CS is always used for code addresses, such as addresses involved in instruction fetching and branching. DS is usually used for accessing memory operands; most instructions can use any segment to access memory operands, but DS is generally the most efficient register for data access. SS is used for maintaining the stack, and is used to access data in stack frames. Finally, ES is used to access data anywhere in the 8088’s address space; since it’s not dedicated to any other purpose, it’s useful for pointing to rarely-used segments. ES is particular useful in conjunction with the string instructions, as we’ll see in Chapter 10. In Chapter 6 we discussed exactly what sort of memory accesses operate relative to each segment register by default; we’ll continue that discussion later in this chapter, and look at ways to override the default segment selections in some cases.</p>
<p>Offsets are not so simple as segments. The 8088 can calculate offsets in a number of different ways, depending on the addressing mode being used. Both registers and instructions can contain offsets, and registers and/or constant values can be added together on the fly by the 8088 in order to calculate offsets. In various addressing modes, components of offsets may reside in BX, BP, SI, DI, SP, and AL, and offset components can be built into instructions as well.</p>
<p>We’ll discuss the loading and use of the segment registers and the calculation and use of offsets below. First, though, let’s answer our two remaining questions.</p>
<section id="segmentoffset-pairs-arent-unique" class="level3">
<h3>Segment:Offset Pairs Aren’t Unique</h3>
<p>In answer to question number two, “What’s to prevent more than one segment:offset pair from pointing to the same 20-bit address?” the answer is: nothing. There’s no rule that says two segment:offset pairs can’t point to the same address, and in fact many segment:offset pairs do evaluate to any given address — 4096 segment:offset pairs for every address, to be precise. For example, the following segment:offset pairs all point to the 20-bit address 00410: 0000:0410, 0001:0400, 0002:03F0, 0003:03E0, and so on up to 0041:0000.</p>
<p>You may have noticed that we’ve only accounted for 42h segment:offset pairs, not 4096 of them, and that leads in neatly to the answer to our third and final question. When the sum of a segment shifted left 4 bits and an offset exceeds 20 bits, it wraps back around to address 00000. Basically, any bits that carry out of bit 19 (into what would be bit 20 if the 8088 had 21 addressing bits) are thrown away. The segment:offset pair FFFF:0010 points to the address 00000 as follows:</p>
<pre><code>   FFFF0
+   0010
--------
  100000
  ^
  carry</code></pre>
<p>with the 1 that carries out of bit 19 discarded to leave 00000.</p>
<p>Now we can see what the other 4,000-odd segment:offset pairs that point to address 00410 are. FFFF:0420 points to 00410, as do FFFE:0430, F042:FFF0, and a host of segment:offset pairs in between. I doubt you’ll want to take advantage of that knowledge (in fact, there is a user-selectable trick that can be played on the 80286 and 80386 to disable wrapping at FFFFF, so you shouldn’t count on wrapping if you can help it), but if you <em>do</em> ever happen to address past the end of memory, that’s how it works on the 8088.</p>
</section>
<section id="good-news-and-bad-news" class="level3">
<h3>Good News and Bad News</h3>
<p>Now that we know how segments and offsets work, what are the implications for assembler programs? The obvious implication is that we can address 1 Mb of memory, and that’s good news, since we can use memory in myriad ways to improve performance. For example, we’ll see how look-up tables can turn extra memory into improved performance later in this chapter. Likewise, in Chapter 13 we’ll see how in-line code lets you trade off bytes for performance. Much of top-notch assembler programming involves balancing memory requirements against performance, so the more memory we have available, the merrier.</p>
<p>The bad news is this: while there’s a lot of memory, it’s only available in 64 Kb chunks. The four segment registers can only point to four 64 Kb segments at any one time, as shown in Figure 7.2.</p>
<figure>
<img src="images/fig7.2RT.png" />
</figure>
<p>If you want to access a memory location that’s not in any of the four currently pointed-to segments, there is <em>no way</em> to do that with a single instruction. You must first load a segment register to point to a segment containing the desired memory location, a process which takes a minimum of 1 and often 2 instructions. Only then can you access the desired memory location.</p>
<p>Worse, there are problems dealing with blocks of memory larger than 64 Kb, because there’s no easy way to perform calculations involving full 20-bit addresses, and because 64 Kb is the largest block of memory that can be addressed by way of a single segment register without reloading the segment register. It’s easy enough to access a block up to 64 Kb in size; point a register to the start of the block, and then point wherever you wish. For example, the following bit of code would calculate the 16-bit sum of all the bytes in a 64 Kb array:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">mov</span>   <span class="kw">bx</span>,<span class="kw">seg</span> TestArray
    <span class="kw">mov</span>   <span class="kw">ds</span>,<span class="kw">bx</span>               <span class="co">;point to segment:offset of start of</span>
    <span class="kw">mov</span>   <span class="kw">bx</span>,offset TestArray <span class="co">;array to sum</span>
    <span class="kw">sub</span>   <span class="kw">cx</span>,<span class="kw">cx</span>               <span class="co">;count 64 K bytes</span>
    <span class="kw">mov</span>   <span class="kw">ax</span>,<span class="kw">cx</span>               <span class="co">;set initial sum to 0</span>
    <span class="kw">mov</span>   <span class="kw">dh</span>,<span class="kw">ah</span>               <span class="co">;set DH to 0 for summing later</span>
<span class="fu">SumLoop:</span>
    <span class="kw">mov</span>   <span class="kw">dl</span>,[<span class="kw">bx</span>]             <span class="co">;get the next array element</span>
    <span class="kw">add</span>   <span class="kw">ax</span>,<span class="kw">dx</span>               <span class="co">;add the array element to the sum</span>
    <span class="kw">inc</span>   <span class="kw">bx</span>                  <span class="co">;point to the next array element</span>
    <span class="kw">loop</span>  SumLoop</code></pre>
<p>Easy enough, eh? Ah, but it all falls apart when a block of memory is larger than 64 Kb, or when a block crosses a segment boundary. The problem is that in either of those cases the segment must change as well as the offset, for there’s simply no way for an offset to reach more than 64 K bytes away from any given segment register setting. If a register containing an offset reaches the end of a segment (reaches the value 0FFFFh), then it simply wraps back to zero when it’s incremented. Likewise, the instruction sequence:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">si</span><span class="bn">,0ffffh</span>
<span class="kw">mov</span>   <span class="kw">al</span>,[<span class="kw">si</span><span class="dv">+1</span>]</code></pre>
<p>merely manages to load AL with the contents of offset 0. Basically, whenever an offset exceeds 16 bits in size, the excess bits are ignored, just as the excess bits are ignored when a segment:offset pair adds up to an address past the 1 Mb overall limit on 8088 memory.</p>
<p>So we need to work with the whole segment:offset pair in order to handle blocks larger than 64 Kb. Is that such a problem? Unfortunately, the answer is yes. The 8088 has no particular aptitude for calculations involving more than 16 bits, and is very bad at handling segments. There’s no way to increment a segment:offset pair as a unit, and in fact there’s no way to modify a segment register other than copying it to a general-purpose register, modifying that register, and copying the result back to the segment register. All in all, it’s as difficult to work with blocks of memory larger than 64 Kb as it is easy to work with blocks no larger than 64 Kb.</p>
<p>For example, here’s typical code to calculate the 16-bit sum of a 128 Kb array, of the sort that a high-level language might generate (actually, the following code is a good deal <em>better</em> than most high-level languages would generate, but what the heck, let’s give them the benefit of the doubt!):</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">mov</span>   <span class="kw">bx</span>,<span class="kw">seg</span> TestArray
    <span class="kw">mov</span>   <span class="kw">ds</span>,<span class="kw">bx</span>               <span class="co">;point to segment:offset of start of</span>
    <span class="kw">mov</span>   <span class="kw">bx</span>,offset TestArray <span class="co">;array to sum</span>
    <span class="kw">sub</span>   <span class="kw">cx</span>,<span class="kw">cx</span>               <span class="co">;count 128 K bytes with SI:CX</span>
    <span class="kw">mov</span>   <span class="kw">si</span>,<span class="dv">2</span>
    <span class="kw">mov</span>   <span class="kw">ax</span>,<span class="kw">cx</span>               <span class="co">;set initial sum to 0</span>
    <span class="kw">mov</span>   <span class="kw">dh</span>,<span class="kw">ah</span>               <span class="co">;set DH to 0 for summing later</span>
<span class="fu">SumLoop:</span>
    <span class="kw">mov</span>   <span class="kw">dl</span>,[<span class="kw">bx</span>]             <span class="co">;get the next array element</span>
    <span class="kw">add</span>   <span class="kw">ax</span>,<span class="kw">dx</span>               <span class="co">;add the array element to the sum</span>
    <span class="kw">inc</span>   <span class="kw">bx</span>                  <span class="co">;point to the next array element</span>
    <span class="kw">and</span>   <span class="kw">bx</span><span class="bn">,0fh              </span><span class="co">;time to advance the segment?</span>
    <span class="kw">jnz</span>   SumLoopEnd          <span class="co">;not yet</span>
    <span class="kw">mov</span>   <span class="kw">di</span>,<span class="kw">ds</span>               <span class="co">;advance the segment by 1; since BX has</span>
    <span class="kw">inc</span>   <span class="kw">di</span>                  <span class="co">;just gone from 15 to 0, we&#39;ve advanced</span>
    <span class="kw">mov</span>   <span class="kw">ds</span>,<span class="kw">di</span>               <span class="co">;1 byte in all</span>
<span class="fu">SumLoopEnd:</span>
    <span class="kw">loop</span>  SumLoop             <span class="co">;count down 32-bit counter</span>
    <span class="kw">dec</span>   <span class="kw">si</span>
    <span class="kw">jnz</span>   SumLoop</code></pre>
</section>
<section id="more-good-news" class="level3">
<h3>More Good News</h3>
<p>While the above is undeniably a mess, things are not quite so grim as they might seem. In fact, the news is quite good when it comes to handling multiple segments in assembler. For one thing, assembler is <em>much</em> better than other languages at handling segments efficiently. Only in assembler do you have complete control over all your segments; that means that you can switch the segments as needed in order to make sure that they are pointing to the data you’re currently interested in. What’s more, in assembler you can structure your code and data so that it falls naturally into 64 Kb blocks, allowing most of your accesses at any one time to fall within the currently loaded segments.</p>
<p>In high-level languages you almost always suffer both considerable performance loss and significant increase in code size when you start using multiple code or data segments, but in assembler it’s possible to maintain near-peak performance even with many segments. In fact, segment-handling is one area in which assembler truly distinguishes itself, and we’ll see examples of assembler’s fine touch with segments in this chapter, Chapter 14, and Volume II of <em>The Zen of Assembly Language</em>.</p>
<p>There’s one more reason that handling multiple code or data segments isn’t much of a problem in assembler, and that’s that the assembler programmer knows exactly what his code needs to do and can optimize accordingly. For example, suppose that we know that the array <code class="sourceCode nasm">TestArray</code> in the last example is guaranteed to start at offset 0 in the initial data segment. Given that extra knowledge, we can put together the following version of the above code to sum a 128 Kb array:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">mov</span>   <span class="kw">bx</span>,<span class="kw">seg</span> TestArray
    <span class="kw">mov</span>   <span class="kw">ds</span>,<span class="kw">bx</span>    <span class="co">;point to segment:offset of start of</span>
    <span class="kw">sub</span>   <span class="kw">bx</span>,<span class="kw">bx</span>    <span class="co">;array to sum, which we know starts</span>
                   <span class="co">; at offset 0</span>
    <span class="kw">mov</span>   <span class="kw">cx</span>,<span class="dv">2</span>     <span class="co">;count two 64 Kb blocks</span>
    <span class="kw">sub</span>   <span class="kw">ax</span>,<span class="kw">ax</span>    <span class="co">;set initial sum to 0</span>
    <span class="kw">mov</span>   <span class="kw">dh</span>,<span class="kw">ah</span>    <span class="co">;set DH to 0 for summing later</span>
<span class="fu">SumLoop:</span>
    <span class="kw">mov</span>   <span class="kw">dl</span>,[<span class="kw">bx</span>]  <span class="co">;get the next array element</span>
    <span class="kw">add</span>   <span class="kw">ax</span>,<span class="kw">dx</span>    <span class="co">;add the array element to the sum</span>
    <span class="kw">inc</span>   <span class="kw">bx</span>       <span class="co">;point to the next array element</span>
    <span class="kw">jnz</span>   SumLoop  <span class="co">;until we wrap at the end of a 64 Kb block</span>
    <span class="kw">mov</span>   <span class="kw">si</span>,<span class="kw">ds</span>
    <span class="kw">add</span>   <span class="kw">si</span><span class="bn">,1000h </span><span class="co">;advance the segment by 64 K bytes</span>
    <span class="kw">mov</span>   <span class="kw">ds</span>,<span class="kw">si</span>
    <span class="kw">loop</span>  SumLoop  <span class="co">;count off this 64 Kb block</span></code></pre>
<p>Compare the code within the inner loop above to that in the inner loop of the previous version of this example — the difference is striking. This inner loop is every bit as tight as that of the code for handling blocks 64 Kb-and-less in size; in fact, it’s slightly <em>tighter</em>, as <code class="sourceCode nasm"><span class="kw">jnz</span></code> is faster than <code class="sourceCode nasm"><span class="kw">loop</span></code>. Consequently, there shouldn’t be much difference in performance between the last example and the 64 Kb and less version. Nonetheless, a basic rule of the Zen of assembler is that we should check our assumptions, so let’s toss the three approaches to summing arrays into the Zen timer and see what comes out.</p>
<p><a href="#listing-7-1">Listing 7-1</a> measures the time required to calculate the 16-bit sum of a 64 Kb block without worrying about segments. This code runs in 619 ms, or 9.4 us per byte summed. (Note that <a href="#listing-7-1">Listings 7-1</a> through <a href="#listing-7-3">7-3</a> must be timed with the long-period Zen timer — via LZTIME.BAT — since they take more than 54 ms to run.)</p>
<p><a href="#listing-7-2">Listing 7-2</a> measures the time required to calculate the 16-bit sum of a 128 Kb block. As is always the case with a memory block larger than 64 Kb, segments must be dealt with, and that shows in the performance of <a href="#listing-7-2">Listing 7-2</a>: 2044 ms, or 15.6 us per byte summed. In other words, <a href="#listing-7-1">Listing 7-1</a>, which doesn’t concern itself with segments, sums bytes 66% faster than <a href="#listing-7-2">Listing 7-2</a>.</p>
<p>Finally, <a href="#listing-7-3">Listing 7-3</a> implements 128 Kb-block-handling code that takes advantage of the knowledge that the block of memory being summed starts at offset 0 in the initial data segment. We’ve speculated that <a href="#listing-7-3">Listing 7-3</a> should perform on a par with <a href="#listing-7-3">Listing 7-3</a>, since their inner loops are similar… and the Zen timer bears that out, reporting that <a href="#listing-7-3">Listing 7-3</a> runs in 1239 ms — 9.5 us per byte summed.</p>
<p>Assumptions confirmed.</p>
</section>
<section id="notes-on-optimization" class="level3">
<h3>Notes on Optimization</h3>
<p>There are several points to be made about <a href="#listing-7-1">Listings 7-1</a> through <a href="#listing-7-3">7-3</a>. First, these listings graphically illustrate that you should focus your optimization efforts on inner loops. <a href="#listing-7-3">Listing 7-3</a> is considerably bigger and more complex than <a href="#listing-7-1">Listing 7-1</a>, but by moving the complexity and extra bytes out of the inner loop, we’ve managed to keep performance high in <a href="#listing-7-3">Listing 7-3</a>.</p>
<p>Now, you may well object that in the process of improving the performance of <a href="#listing-7-3">Listing 7-3</a>, we’ve altered the code so that it will only work under certain circumstances, and that’s my second point. Truly general-purpose code runs slowly, no matter whether it’s written in assembler, C, BASIC, or COBOL. Your advantage as a programmer — and your <em>great</em> advantage as an assembler programmer — is that you know exactly what your code needs to do…so why write code that wastes cycles and bytes doing extra work? I stipulated that the start offset was at 0 in the initial data segment, and <a href="#listing-7-3">Listing 7-3</a> is a response to that stipulation. If the conditions to be met had been different, then we would have come up with a different solution.</p>
<p>Do you see what I’m driving at? I hope so, for it’s central to the Zen of assembler. A key to good assembler code is to write lean code. Your code should do everything you need done — and nothing more.</p>
<p>I’ll finish up by pointing out that <a href="#listing-7-1">Listings 7-1</a> through <a href="#listing-7-3">7-3</a> are excellent examples of both the hazards of using memory blocks larger than 64 Kb and of the virtues of using assembler when you must deal with large blocks. It’s rare that you’ll be able to handle larger-than-64 Kb blocks as efficiently as blocks that fit within a single segment; <a href="#listing-7-3">Listing 7-3</a> does take advantage of a very convenient special case. However, it’s equally rare that you won’t be able to handle large blocks much more efficiently in assembler than you ever could in a high-level language.</p>
</section>
<section id="a-final-word-on-segmentoffset-addressing" class="level3">
<h3>A Final Word on Segment:Offset Addressing</h3>
<p>Let’s review what we’ve learned about segment:offset addressing and assembler. The architecture of the 8088 limits us to addressing at most four segments — 64 Kb blocks of memory — at any time, with each segment pointed to by a different segment register. Accessing data in a segment that is not currently pointed to by any segment register is a time-consuming, awkward process, as is handling data that spans multiple blocks. Fortunately, assembler is adept at handling segments, and gives us considerable freedom to structure our programs so that we’re usually working within the currently loaded segments at any one time.</p>
<p>On balance, segment:offset addressing is one of the less attractive features of the 8088. For us, however, it’s actually an advantage, since it allows assembler, with its superb control over the 8088, to far outstrip high-level languages. We won’t deal with segments a great deal in the remainder of this volume, since we’ll be focusing on detailed optimizations, but the topic will come up from time to time. In Volume II, we’ll tackle the subject of segment management in a big way.</p>
<p>The remainder of this chapter will deal only with data addressing — that is, the addressing of instruction operands. Code addressing — in the forms of instruction fetching and branching — is a very real part of PC performance (heck, instruction fetching is perhaps the single most important performance factor of all!), but it’s also very different from the sort of memory addressing we’ll be discussing. We learned as much as we’ll ever need to know (and possibly more) about instruction fetching back in Chapters 4 and 5, so we won’t pursue that aspect of code addressing any further. However, Chapters 12 through 14 discuss code addressing as it relates to branching in considerable detail.</p>
</section>
</section>
<section id="segment-handling" class="level2">
<h2>Segment Handling</h2>
<p>Now that we know what segments are, let’s look at ways to handle the segment registers, in particular how to load them quickly. What we are <em>not</em> going to do is discuss the directives that let you create segments and the storage locations within them.</p>
<p>Why not discuss the segment directives? For one thing, there are enough directives, segment and otherwise, to fill a book by themselves. For another thing, there are already several such books, including both the manuals that come with MASM and TASM and the other books in this series. <em>The Zen of Assembly Language</em> is about writing efficient code, not using MASM, so I’ll assume you already know how to use the <code class="sourceCode nasm"><span class="kw">segment</span></code>, <code class="sourceCode nasm">ends</code>, and <code class="sourceCode nasm">assume</code> directives to define segments and <code class="sourceCode nasm"><span class="dt">db</span></code>, <code class="sourceCode nasm"><span class="dt">dw</span></code>, and the like to create and reserve storage. If that’s not the case, brush up before you continue reading. We’ll use all of the above directives in <em>The Zen of Assembly Language</em>, and we’ll discuss <code class="sourceCode nasm">assume</code> at some length later in this chapter, but we won’t spend time covering the basic functionality of the segment and data directives.</p>
<section id="what-can-you-do-with-segment-registers-not-much" class="level3">
<h3>What Can You Do With Segment Registers? Not Much</h3>
<p>Segment registers are by no means as flexible as general-purpose registers. What can’t you do with segment registers that you can do with general-purpose registers? Let me answer that question by way of a story.</p>
<p>There’s a peculiar sort of “find the mistake” puzzle that’s standard fare in children’s magazines. Such puzzles typically consist of a drawing with a few intentional mistakes (a farmer milking a donkey, for example — a risky proposition at best), captioned, “What’s wrong with this picture?” Invariably, the answer is printed upside down at the bottom of the page.</p>
<p>I dimly recall from my childhood a takeoff that <em>MAD</em> magazine did on those puzzles. <em>MAD</em> showed a picture in which everything — and I do mean <em>everything</em> — was wrong. Just as with the real McCoy, this picture was accompanied by the caption, “What’s wrong with this picture?”, and by the answer at the bottom of the page.</p>
<p>In <em>MAD</em>, the answer was: “Better yet, what’s <em>right</em> with this picture?”</p>
<p>Segment registers are sort of like <em>MAD</em>’s puzzles. What can’t you do with segment registers? Better yet, what <em>can</em> you do with segment registers? Well, you can use them to address memory — and that’s about it.</p>
<p>Any segment register can be copied to a general-purpose register or memory location. Any segment register other than CS can be loaded from a general-purpose register or memory location. Any segment register can be pushed onto the stack, and any segment register but CS can be popped from the stack.</p>
<p>And that’s <em>all</em>.</p>
<p>Segment registers can’t be used for arithmetic. They can’t be operands to logical instructions, and they can’t take part in comparisons. One segment register can’t even be copied directly to another segment register. Basically, segment registers can’t do a blessed thing except get loaded and get copied to a register or memory.</p>
<p>Now, there <em>are</em> reasons why segments are so hard to work with. For one thing, it’s not all that important that segment registers be manipulated quickly. Segment registers aren’t changed as often as general-purpose registers — at least, they shouldn’t be, if you’re interested in decent performance. Segment registers rarely need to be manipulated arithmetically or logically, and when the need does arise, they can always be copied to general-purpose registers and manipulated there. Nonetheless, greater flexibility in handling segment registers would be nice; however, a major expansion of the 8088’s instruction set — requiring additional circuitry inside the 8088 — would have been required in order to allow us to handle segment registers like general-purpose registers, and it seems likely that the 8088’s designers had other, higher-priority uses for their limited chip space.</p>
<p>There’s another reason why segments can only be loaded and copied, nothing else, and it has to do with the protected mode of the 80286 and 80386 processors. Protected mode, which we’ll return to at a bit more length in Chapter 15, is a second mode of the 80286 and 80386 that’s not compatible with either MS-DOS or the 8088, but which makes much more memory available for program use than the familiar 1 Mb of MS-DOS/8088-compatible real mode.</p>
<p>In protected mode, the segment registers don’t contain memory addresses; instead, they contain segment selectors, which the 80286 and 80386 use to look up the actual segment information — location and attributes such as writability — in a table. Not only would it make no sense to perform arithmetic and the like on segment selectors, since selectors don’t correspond directly to memory addresses, but because the segment registers are central to the memory protection scheme of the 80286 and 80386, they simply <em>cannot</em> be loaded arbitrarily — the 80286 and 80386 literally don’t allow that to happen by instantly causing a trap whenever an invalid selector is loaded.</p>
<p>What’s more, it can take quite a while to load a segment register in protected mode. In real mode, moves to and from segment registers are just as fast as transfers involving general-purpose registers, but that’s not the case in protected mode. For example, <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">es</span>,<span class="kw">ax</span></code> takes 2 cycles in real mode and 17 cycles in protected mode.</p>
<p>Given all of the above, all you’d generally want to do in protected mode is load the segment registers with known-good segment selectors provided to you by the operating system. That doesn’t affect real mode, which is all we care about, but since real mode and protected mode share most instructions, the segment-register philosophy of protected mode (which Intel no doubt had as a long-range goal even before they designed the 8088) carries over to real mode.</p>
<p>And now you know why the 8088 offers so little in the way of segment-register manipulation capability.</p>
</section>
<section id="using-segment-registers-for-temporary-storage" class="level3">
<h3>Using Segment Registers for Temporary Storage</h3>
<p>That brings us to another interesting point: the use of segment registers for temporary storage. The 8088 has just 7 available general-purpose registers (remember, we can’t use SP for anything but the stack most of the time), and sometimes it would be awfully handy to have somewhere to store a 16-bit value for a little while. Can we use the segment registers for that purpose?</p>
<p>Some people would answer that “No,” because code that uses segments for temporary storage can’t easily be ported to protected mode. I don’t buy that, for reasons I’ll explain when we get to <code class="sourceCode nasm"><span class="kw">les</span></code>. My answer is “Yes… when they’re available.” Two of the segment registers are never available, one is occasionally available, and one may or may not be readily available, depending on your code.</p>
<p>Some segments are always in use. CS is always busy pointing to the segment of the next instruction to be executed; if you were to load CS with an arbitrary value for even 1 instruction, your program would surely crash. Clearly, it’s not a good idea to use CS for temporary storage. (Actually, this isn’t even a potential problem, as Intel has thoughtfully not implemented the instructions — <code class="sourceCode nasm"><span class="kw">mov</span></code> and <code class="sourceCode nasm"><span class="kw">pop</span></code> — that might load CS directly; MASM will simply generate an error if you try to assemble <code class="sourceCode nasm"><span class="kw">pop</span> <span class="kw">cs</span></code> or <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">cs</span>,[mem16]</code>. CS can only be loaded by far branches: far calls, far returns, far jumps, and interrupts.)</p>
<p>SS isn’t in use during every cycle as CS is, but unless interrupts are off, SS <em>might</em> be used on any cycle. Even if interrupts are off, non-maskable interrupts can occur, and of course your code will often use the stack directly. The risks are too great, the rewards too few. Don’t use SS for temporary storage.</p>
<p>DS can be used for temporary storage whenever it’s free. However, DS is usually used to point to the default data segment. It’s rare that you’ll have a tight loop in which memory isn’t accessed (it’s not worth bothering with such optimizations outside the tightest, most time-critical code), and memory is usually most efficiently accessed via DS. There certainly are loops in which DS is free — loops which use <code class="sourceCode nasm"><span class="kw">scas</span></code> to scan the segment pointed to by ES, for example — but such cases are few and far between. Far more common is the case in which DS is saved and then pointed to another segment, as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">push</span>  <span class="kw">ds</span>                   <span class="co">;preserve normal DS setting</span>
    <span class="kw">mov</span>   <span class="kw">bx</span>,<span class="kw">seg</span> TestArray
    <span class="kw">mov</span>   <span class="kw">ds</span>,<span class="kw">bx</span>                <span class="co">;point DS:BX to array in which</span>
    <span class="kw">mov</span>   <span class="kw">bx</span>,offset TestArray  <span class="co">;to flip all bits</span>
    <span class="kw">mov</span>   <span class="kw">cx</span>,TEST_ARRAY_LENGTH <span class="co">;# of bytes to flip</span>
<span class="fu">FlipLoop:</span>
    <span class="kw">not</span>   <span class="dt">byte</span> <span class="dt">ptr</span> [<span class="kw">bx</span>]        <span class="co">;flip all bits in current byte</span>
    <span class="kw">inc</span>   <span class="kw">bx</span>                   <span class="co">;point to next byte</span>
    <span class="kw">loop</span>  FlipLoop
    <span class="kw">pop</span>   <span class="kw">ds</span>                   <span class="co">;restore normal DS setting</span></code></pre>
<p>This approach allows instructions within the loop to access memory without the segment override prefix required when ES is used. (More on segment override prefixes shortly.)</p>
<p>In short, feel free to use DS for temporary storage if it’s free, but don’t expect that to come up too often.</p>
<p>Which brings us to the use of ES for temporary storage. ES is by far the best segment register to use for temporary storage; not being dedicated to any full-time function, it’s usually free for any sort of use at all, including temporary storage.</p>
<p>Let’s look at an example of code that uses ES for temporary storage to good effect. This sample code sums selected points in a two-dimensional word-sized array. Let’s start by tallying up the registers this code will use. (A bit backwards, true, but we’re focusing on the use of ES for temporary storage at the moment, and this is the best way to go about it.)</p>
<p>In the sample code, the list of subscripts of points to be added in the major dimension will be stored at DI, and the list of subscripts in the minor dimension will stored at BX. CX will contain the number of points to be summed, and BP will contain the final sum. AX and DX will be used for multiplying, and, as usual, SP will be used to point to the stack. Finally, when the code begins, SI will contain the offset of the start of the array.</p>
<p>Let’s see… that covers all eight general-purpose registers. Unfortunately, we need yet another storage location, this one to serve as a working pointer into the array. There are many possible solutions to this problem, including using the <code class="sourceCode nasm"><span class="kw">xchg</span></code> instruction (which we’ll cover in the next chapter), storing values in memory (slow), pushing and popping SI (also slow), or disabling interrupts and using SP (can unduly delay interrupts and carries some risk). Instead, here’s a solution that uses ES for temporary storage; it’s not necessarily the <em>best</em> solution, but it does nicely illustrate the use of ES for temporary storage:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="co">;</span>
<span class="co">; Sums selected points in a two-dimensional array.</span>
<span class="co">;</span>
<span class="co">; Input:</span>
<span class="co">;     BX = list of minor dimension coordinates to sum</span>
<span class="co">;     CX = number of points to sum</span>
<span class="co">;     DS:SI = start address of array</span>
<span class="co">;     DI = list of major dimension coordinates to sum</span>
<span class="co">;</span>
<span class="co">; Output:</span>
<span class="co">;     BP = sum of selected points</span>
<span class="co">;</span>
<span class="co">; Registers altered: AX, BX, CX, DX, SI, DI, BP, ES</span>
<span class="co">;</span>
    <span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">si</span> <span class="co">;set aside the array start offset</span>
    <span class="kw">sub</span>   <span class="kw">bp</span>,<span class="kw">bp</span> <span class="co">;initialize sum to 0</span>
<span class="fu">TwoDimArraySumLoop:</span>
    <span class="kw">mov</span>   <span class="kw">ax</span>,ARRAY_WIDTH <span class="co">;convert the next major dimension</span>
    <span class="kw">mul</span>   <span class="dt">word</span> <span class="dt">ptr</span> [<span class="kw">di</span>]  <span class="co">;coordinate to an offset in the array</span>
                         <span class="co">; (wipes out DX)</span>
    <span class="kw">add</span>   <span class="kw">ax</span>,[<span class="kw">bx</span>]        <span class="co">;add in the minor dimension coordinate</span>
    <span class="kw">shl</span>   <span class="kw">ax</span>,<span class="dv">1</span>           <span class="co">;make it a word-sized lookup</span>
    <span class="kw">mov</span>   <span class="kw">si</span>,<span class="kw">es</span>          <span class="co">;point to the start of the array</span>
    <span class="kw">add</span>   <span class="kw">si</span>,<span class="kw">ax</span>          <span class="co">;point to the desired data point</span>
    <span class="kw">add</span>   <span class="kw">bp</span>,[<span class="kw">si</span>]        <span class="co">;add it to the total</span>
    <span class="kw">inc</span>   <span class="kw">di</span>             <span class="co">;point to the next major dimension coordinate</span>
    <span class="kw">inc</span>   <span class="kw">di</span>
    <span class="kw">inc</span>   <span class="kw">bx</span>             <span class="co">;point to the next minor dimension coordinate</span>
    <span class="kw">inc</span>   <span class="kw">bx</span>
    <span class="kw">loop</span>  TwoDimArraySumLoop</code></pre>
<p>If you find yourself running out of registers in a tight loop and you’re not using the segment pointed to by ES, by all means reload one of your registers from ES if that will help.</p>
</section>
<section id="setting-and-copying-segment-registers" class="level3">
<h3>Setting and Copying Segment Registers</h3>
<p>As I’ve said, loading segment registers is one area in which assembler has a tremendous advantage over high-level languages. High-level languages tend to use DS to point to a default data segment all the time, loading ES every single time any other segment is accessed. In assembler, we can either load a new segment into DS as needed, or we can load ES and leave it loaded for as long as we need to access a given segment.</p>
<p>We’ll see examples of efficient segment use throughout <em>The Zen of Assembly Language</em>, especially when we discuss strings, so I’m not going to go into more detail here. What I am going to do is discuss the <em>process</em> of loading segment registers, because it is by no means obvious what the most efficient segment-loading mechanism is.</p>
<p>For starters, let’s divide segment loading into two categories: setting and copying. Segment setting refers to loading a segment register to point to a certain segment, while segment copying refers to loading a segment register with the contents of another segment register. I’m making this distinction because the instruction sequences used for the two sorts of segment loading differ considerably.</p>
<p>Let’s tackle segment copying first. Segment copying is useful when you want two segment registers to point to the same segment. For example, you’ll want ES to point to the same segment as DS if you’re using <code class="sourceCode nasm">rep <span class="kw">movs</span></code> to copy data within the segment pointed to by DS, because DS and ES are the default source and destination segments, respectively, for <code class="sourceCode nasm"><span class="kw">movs</span></code>. There are two good ways to load ES to point to the same segment as DS, given that we can’t copy one segment register directly to another segment register:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">push</span>  <span class="kw">ds</span>
<span class="kw">pop</span>   <span class="kw">es</span></code></pre>
<p>and:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">ax</span>,<span class="kw">ds</span>
<span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">ax</span></code></pre>
<p>(Any general-purpose register would serve as well as AX.)</p>
<p>Each of the above approaches has its virtues. The <code class="sourceCode nasm"><span class="kw">push</span></code>/<code class="sourceCode nasm"><span class="kw">pop</span></code> approach is extremely compact, at just 2 bytes, and affects no other registers. Unfortunately, it takes a less-than-snappy 27 cycles to run. By contrast, the <code class="sourceCode nasm"><span class="kw">mov</span></code>/<code class="sourceCode nasm"><span class="kw">mov</span></code> approach officially takes just 4 cycles to run; 16 cycles (4 bytes at 4 cycles to fetch each byte) is a more realistic figure, but either way, <code class="sourceCode nasm"><span class="kw">mov</span></code>/<code class="sourceCode nasm"><span class="kw">mov</span></code> is clearly faster than <code class="sourceCode nasm"><span class="kw">push</span></code>/<code class="sourceCode nasm"><span class="kw">pop</span></code>. On the other hand, <code class="sourceCode nasm"><span class="kw">mov</span></code>/<code class="sourceCode nasm"><span class="kw">mov</span></code> takes twice as many bytes as <code class="sourceCode nasm"><span class="kw">push</span></code>/<code class="sourceCode nasm"><span class="kw">pop</span></code>, and destroys the contents of a general-purpose register as well.</p>
<p>There’s no clear winner here. Use the <code class="sourceCode nasm"><span class="kw">mov</span></code>/<code class="sourceCode nasm"><span class="kw">mov</span></code> approach to copy segment registers when you’re interested in speed and can spare a general-purpose register, and use the <code class="sourceCode nasm"><span class="kw">push</span></code>/<code class="sourceCode nasm"><span class="kw">pop</span></code> approach when bytes and/or registers are at a premium. I’ll use both approaches in this book, generally using <code class="sourceCode nasm"><span class="kw">push</span></code>/<code class="sourceCode nasm"><span class="kw">pop</span></code> in non-time-critical code and <code class="sourceCode nasm"><span class="kw">mov</span></code>/<code class="sourceCode nasm"><span class="kw">mov</span></code> when speed really counts. Why waste the bytes when the cycles don’t matter?</p>
<p>That brings us to an important point about assembler programming. There is rarely such a beast as the “best code” in assembler; instead, there’s code that’s good in a given context. In any situation, the choice between fast code, small code, understandable code, portable code, maintainable code, structured code, and whatever other sort of code you can dream up is purely up to you. If you make the right decisions, your code will beat high-level language code hands down, because you know more about your code and can think far more flexibly than any high-level language possibly can.</p>
<p>Now let’s look at ways to set segment registers. Segment registers can’t be loaded directly with a segment value, but they can be loaded either through a general-purpose register or from memory. The two approaches aren’t always interchangeable: one requires that the segment name be available as an immediate operand, while the other requires that a memory variable be set to the desired segment value. Nonetheless, you can generally set things up so that either approach can be used, if you really want to — so which is best?</p>
<p>Well, loading a segment register through a general-purpose register, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">ax</span>,DATA
<span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">ax</span></code></pre>
<p>officially takes 6 cycles. Since the two instructions together are 5 bytes long, however, this approach could take as much a 20 cycles if the prefetch queue is empty. By contrast, loading from memory, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">es</span>,[DataSeg]</code></pre>
<p>officially takes only 18 cycles, is only 4 bytes long, and doesn’t destroy a general-purpose register. (Note that the last approach assumes that the memory variable <code class="sourceCode nasm">DataSeg</code> has previously been set to point to the desired segment.) Loading from memory sounds better, doesn’t it?</p>
<p>It isn’t.</p>
<p>Remember, it’s not just the number of instruction byte fetches that affects performance — <em>it’s the number of memory accesses of all sorts</em>. When a segment register is loaded from memory, 2 memory accesses are performed to read the segment value; together with the 4 instruction bytes, that means that 6 memory accesses in all are performed when a segment register is loaded from memory. What that means is that loading a segment register from memory takes anywhere from 18 to 24 (6 memory accesses at 4 cycles per access) cycles, which stacks up poorly against the 6 to 20 cycles required to load a segment register through a general-purpose register.</p>
<p>In short, it’s clearly fastest to load segment registers through general-purpose registers.</p>
<p>That’s not to say that there aren’t times when you’ll want to load a segment register directly from memory. If you’re <em>really</em> tight on space, you can save a byte every time you load a segment by using the 4-byte load from memory rather than the 5-byte load through a general-purpose register. (This is only worthwhile if there are multiple segment load instructions, since the memory variable containing the segment address takes 2 bytes.) Also, if the segment you want to work with varies as your program runs (for example, if your code can access either display memory or a display buffer in system RAM), then loading the segment register from memory is the way to go. The following code is clearly the best way to load ES to point to a display buffer that may be at any of several segments:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">es</span>,[DisplayBufferSegment]</code></pre>
<p>Here, <code class="sourceCode nasm">DisplayBufferSegment</code> is set externally to point to the segment in which all screen drawing should be performed at any given time.</p>
<p>Finally, segments are often passed as stack frame parameters from high-level languages to assembler subroutines — to point to far data buffers and the like — and in those cases segments can best be loaded directly from stack frames into segment registers. (We’ll discuss stack frames later in this chapter.) It’s easy to forget that segments can be loaded directly from <em>any</em> addressable memory location, as we’ll see in Chapter 16; all too many people load segments from stack frames like this:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">ax</span>,[<span class="kw">bp</span>+BufferSegment]
<span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">ax</span></code></pre>
<p>when the following is shorter, faster, and doesn’t use any general-purpose registers:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">es</span>,[<span class="kw">bp</span>+BufferSegment]</code></pre>
<p>As it happens, though, lone segment values are rarely passed as stack frame parameters. Instead, segment:offset pairs that provide a full 20-bit pointer to a specific data element are usually passed. These can be loaded as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">es</span>,[<span class="kw">bp</span>+BufferSegment]
<span class="kw">mov</span>   <span class="kw">di</span>,[<span class="kw">bp</span>+BufferOffset]</code></pre>
<p>However, the designers of the 8088 anticipated the need for loading 20-bit pointers, and gave us two most useful instructions for just that purpose: <code class="sourceCode nasm"><span class="kw">lds</span></code> and <code class="sourceCode nasm"><span class="kw">les</span></code>.</p>
</section>
<section id="loading-20-bit-pointers-with-lds-and-les" class="level3">
<h3>Loading 20-Bit Pointers With <code>lds</code> and <code>les</code></h3>
<p><code class="sourceCode nasm"><span class="kw">lds</span></code> loads <em>both</em> DS and any one general-purpose register from a doubleword of memory, and <code class="sourceCode nasm"><span class="kw">les</span></code> similarly loads <em>both</em> ES and a general-purpose register, as shown in Figure 7.3.</p>
<figure>
<img src="images/fig7.3RT.png" />
</figure>
<p>While both instructions are useful, <code class="sourceCode nasm"><span class="kw">les</span></code> is by far the more commonly used of the two. Since most programs leave DS pointing to the default data segment whenever possible, it’s rare that we’d want to load DS as part of a segment:offset pointer. True, it does happen, but generally only when we want to point to a block of far memory temporarily for faster processing in a tight loop.</p>
<p>ES, on the other hand, is the segment of choice when a segment:offset pointer is needed, since it’s not generally reserved for any other purpose. Consequently, <code class="sourceCode nasm"><span class="kw">les</span></code> is usually used to load segment:offset pointers.</p>
<p><code class="sourceCode nasm"><span class="kw">lds</span></code> and <code class="sourceCode nasm"><span class="kw">les</span></code> actually don’t come in for all that much use in pure assembler programs. The reason for that is that efficient assembler programs tend to be organized so that segments rarely need to be changed, and so such programs tend to work with 16-bit pointers most of the time. After all, while <code class="sourceCode nasm"><span class="kw">lds</span></code> and <code class="sourceCode nasm"><span class="kw">les</span></code> are efficient considering all they do, they’re still slow, with official execution times of at least 29 cycles. If you need to load segment:offset pointers, use <code class="sourceCode nasm"><span class="kw">lds</span></code> and <code class="sourceCode nasm"><span class="kw">les</span></code>, but try to load just offsets whenever you can.</p>
<p>One place where there’s no way to avoid loading segments is in assembler code that’s called from a high-level language, especially when the large data model (the model that supports more than 64 Kb of data) is used. When a high-level language passes a far pointer as a parameter to an assembler subroutine, the full 20-bit pointer must be loaded from memory before it can be used, and there <code class="sourceCode nasm"><span class="kw">lds</span></code> and <code class="sourceCode nasm"><span class="kw">les</span></code> work beautifully.</p>
<p>Suppose that we have a C statement that calls the assembler subroutine <code class="sourceCode nasm">AddTwoFarInts</code> as follows:</p>
<pre class="sourceCode c"><code class="sourceCode c"><span class="dt">int</span> Sum;
<span class="dt">int</span> far *FarPtr1, far *FarPtr2;
      :
Sum = AddTwoFarInts(FarPtr1, FarPtr2);</code></pre>
<p><code class="sourceCode nasm">AddTwoFarInts</code> could be written without <code class="sourceCode nasm"><span class="kw">les</span></code> as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">Parms <span class="kw">struc</span>
    <span class="dt">dw</span>      ?              <span class="co">;pushed BP</span>
    <span class="dt">dw</span>      ?              <span class="co">;return address</span>
Ptr1Offset  <span class="dt">dw</span> ?
Ptr1Segment <span class="dt">dw</span> ?
Ptr2Offset  <span class="dt">dw</span> ?
Ptr2Segment <span class="dt">dw</span> ?
Parms ends
<span class="co">;</span>
AddTwoFarInts proc near
    <span class="kw">push</span>  <span class="kw">bp</span>               <span class="co">;save caller&#39;s BP</span>
    <span class="kw">mov</span>   <span class="kw">bp</span>,<span class="kw">sp</span>            <span class="co">;point to stack frame</span>
    <span class="kw">mov</span>   <span class="kw">es</span>,[Ptr1Segment] <span class="co">;load segment part of Ptr1</span>
    <span class="kw">mov</span>   <span class="kw">bx</span>,[Ptr1Offset]  <span class="co">;load offset part of Ptr1</span>
    <span class="kw">mov</span>   <span class="kw">ax</span>,<span class="kw">es</span>:[<span class="kw">bx</span>]       <span class="co">;get first int to add</span>
    <span class="kw">mov</span>   <span class="kw">es</span>,[Ptr2Segment] <span class="co">;load segment part of Ptr2</span>
    <span class="kw">mov</span>   <span class="kw">bx</span>,[Ptr2Offset]  <span class="co">;load offset part of Ptr2</span>
    <span class="kw">add</span>   <span class="kw">ax</span>,<span class="kw">es</span>:[<span class="kw">bx</span>]       <span class="co">;add the two ints together</span>
    <span class="kw">pop</span>   <span class="kw">bp</span>               <span class="co">;restore caller&#39;s BP</span>
    <span class="kw">ret</span>
AddTwoFarInts endp</code></pre>
<p>The subroutine is considerably more efficient when <code class="sourceCode nasm"><span class="kw">les</span></code> is used, however:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">Parms <span class="kw">struc</span>
    <span class="dt">dw</span>      ?        <span class="co">;pushed BP</span>
    <span class="dt">dw</span>      ?        <span class="co">;return address</span>
Ptr1   <span class="dt">dd</span> ?
Ptr2   <span class="dt">dd</span> ?
Parms ends
<span class="co">;</span>
AddTwoFarInts proc near
    <span class="kw">push</span>  <span class="kw">bp</span>         <span class="co">;save caller&#39;s BP</span>
    <span class="kw">mov</span>   <span class="kw">bp</span>,<span class="kw">sp</span>      <span class="co">;point to stack frame</span>
    <span class="kw">les</span>   <span class="kw">bx</span>,[Ptr1]  <span class="co">;load both segment and offset of Ptr1</span>
    <span class="kw">mov</span>   <span class="kw">ax</span>,<span class="kw">es</span>:[<span class="kw">bx</span>] <span class="co">;get first int to add</span>
    <span class="kw">les</span>   <span class="kw">bx</span>,[Ptr2]  <span class="co">;load both segment and offset of Ptr2</span>
    <span class="kw">add</span>   <span class="kw">ax</span>,<span class="kw">es</span>:[<span class="kw">bx</span>] <span class="co">;add the two ints together</span>
    <span class="kw">pop</span>   <span class="kw">bp</span>         <span class="co">;restore caller&#39;s BP</span>
    <span class="kw">ret</span>
AddTwoFarInts endp</code></pre>
<p>(We’ll talk about <code class="sourceCode nasm"><span class="kw">struc</span></code>, stack frames, and segment overrides — such as <code class="sourceCode nasm"><span class="kw">es</span>:</code> — later in this chapter.)</p>
<p>High-level languages use <code class="sourceCode nasm"><span class="kw">les</span></code> all the time to point to data that’s not in the default data segment, and that hurts performance significantly. Most high-level languages aren’t very smart about using <code class="sourceCode nasm"><span class="kw">les</span></code>, either. For example, high-level languages tend to load a full 20-bit pointer into ES:BX every time through a loop, even though ES never gets changed from the last pass through the loop. That’s one reason why high-level languages don’t perform very well with more than 64 Kb of data.</p>
<p>You can usually easily avoid <code class="sourceCode nasm"><span class="kw">les</span></code>-related performance problems in assembler. Consider <a href="#listing-7-4">Listing 7-4</a>, which adds one far array to another far array in the same way that most high-level languages would, storing both far pointers in memory variables and loading each pointer with <code class="sourceCode nasm"><span class="kw">les</span></code> every time it’s used. (Actually, <a href="#listing-7-4">Listing 7-4</a> is better than your average high-level language subroutine because it uses <code class="sourceCode nasm"><span class="kw">loop</span></code>, while most high-level languages use less efficient instruction sequences to handle looping.) <a href="#listing-7-4">Listing 7-4</a> runs in 43.42 ms, or 43 us per array element addition.</p>
<p>Now look at <a href="#listing-7-5">Listing 7-5</a>, which does exactly the same thing that <a href="#listing-7-4">Listing 7-4</a> does… except that it loads the far pointers <em>outside</em> the loop and keeps them in the registers for the duration of the loop, using the segment-loading techniques that we learned earlier in this chapter. How much difference does it make to keep the far pointers in registers at all times? <a href="#listing-7-5">Listing 7-5</a> runs in 19.69 ms — <em>more than twice as fast as</em><a href="#listing-7-4">Listing 7-4</a>.</p>
<p>Now you know why I keep saying that assembler can handle segments much better than high-level languages can. <a href="#listing-7-5">Listing 7-5</a> isn’t the ultimate in that regard, however; we can carry that concept a step further still, as shown in <a href="#listing-7-6">Listing 7-6</a>.</p>
<p><a href="#listing-7-6">Listing 7-6</a> brings the full power of assembler to bear on the task of adding two arrays. <a href="#listing-7-6">Listing 7-6</a>sets up the segments so that they never once need to be loaded within the loop. What’s more, <a href="#listing-7-6">Listing 7-6</a> arranges the registers so that the powerful <code class="sourceCode nasm"><span class="kw">lodsb</span></code> string instruction can be used in place of a <code class="sourceCode nasm"><span class="kw">mov</span></code> and an <code class="sourceCode nasm"><span class="kw">inc</span></code>. (We’ll discuss the string instructions in Chapter 10. For now, just take my word that the string instructions are good stuff.) In short, <a href="#listing-7-6">Listing 7-6</a> organizes segment and register usage so that as much work as possible is moved out of the loop, and so that the most efficient instructions can be used.</p>
<p>The results are stunning.</p>
<p><a href="#listing-7-6">Listing 7-6</a> runs in just 13.79 ms, more than three times as fast as <a href="#listing-7-4">Listing 7-4</a>, even though <a href="#listing-7-4">Listing 7-4</a> uses the efficient <code class="sourceCode nasm"><span class="kw">loop</span></code> and <code class="sourceCode nasm"><span class="kw">les</span></code> instructions. This example is a powerful reminder of two important aspects of the Zen of assembler. First, you must strive to play to the strengths of the 8088 (such as the string instructions) while sidestepping its weaknesses (such as the segments and slow memory access speed). Second, <em>you must always concentrate on moving cycles out of loops</em>. The <code class="sourceCode nasm"><span class="kw">lds</span></code> and <code class="sourceCode nasm"><span class="kw">les</span></code> instructions outside the loop in <a href="#listing-7-6">Listing 7-6</a> effectively run 1000 times faster than the <code class="sourceCode nasm"><span class="kw">les</span></code> instructions inside the loop in <a href="#listing-7-4">Listing 7-4</a>, since the latter are executed 1000 times but the former are executed only once.</p>
</section>
<section id="loading-doublewords-with-les" class="level3">
<h3>Loading Doublewords with <code>les</code></h3>
<p>While <code class="sourceCode nasm"><span class="kw">les</span></code> isn’t often used to load segment:offset pointers in pure assembler programs, it has another less obvious use: loading doubleword values into the general-purpose registers.</p>
<p>Normally, a doubleword value is loaded into two general-purpose registers with two instructions. Here’s the standard way to load DX:AX from the doubleword memory variable <code class="sourceCode nasm">DVar</code>:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">ax</span>,<span class="dt">word</span> <span class="dt">ptr</span> [DVar]
<span class="kw">mov</span>   <span class="kw">dx</span>,<span class="dt">word</span> <span class="dt">ptr</span> [DVar<span class="dv">+2</span>]</code></pre>
<p>There’s nothing <em>wrong</em> with this approach, but it does take between 4 and 8 bytes and between 34 and 48 cycles. We can cut the time nearly in half, and can usually reduce the size as well, by using <code class="sourceCode nasm"><span class="kw">les</span></code> in a most unusual way:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">les</span>   <span class="kw">ax</span>,[DVar]
<span class="kw">mov</span>   <span class="kw">dx</span>,<span class="kw">es</span></code></pre>
<p>The only disadvantage of using <code class="sourceCode nasm"><span class="kw">les</span></code> to load doubleword values is that it wipes out the contents of ES; if that isn’t a problem, there’s simply no reason to load doubleword values any other way.</p>
<p>Once again, there are those people who will tell you that it’s a bad idea to load ES with anything but specific segment values, because such code won’t work if you port it to run in protected mode on the 80286 and 80836. While that’s a consideration, it’s not an overwhelming one. For one thing, most code will never be ported to protected mode. For another, protected mode programming, which we’ll touch on in Chapter 15, differs from normal 8088 assembler programming in a number of ways; using <code class="sourceCode nasm"><span class="kw">les</span></code> to load doubleword values is unlikely to be the most difficult part of porting code to protected mode, especially if you have to rewrite the code to run under a new operating system. Still, if protected mode concerns you, use a macro such as:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">LOAD_32_BITS  macro Address
ifdef PROTECTED_MODE
    <span class="kw">mov</span>   <span class="kw">ax</span>,<span class="dt">word</span> <span class="dt">ptr</span> [Address]
    <span class="kw">mov</span>   <span class="kw">dx</span>,<span class="dt">word</span> <span class="dt">ptr</span> [Address<span class="dv">+2</span>]
else
    <span class="kw">les</span>   <span class="kw">ax</span>,<span class="dt">dword</span> <span class="dt">ptr</span> [Address]
    <span class="kw">mov</span>   <span class="kw">dx</span>,<span class="kw">ax</span>
endif
    endm
    :
    LOAD_32_BITS  DwordVar</code></pre>
<p>to load 32-bit values.</p>
<p>The <code class="sourceCode nasm"><span class="kw">les</span></code> approach to loading doubleword values is not only fast but has a unique virtue: it’s indivisible. In other words, there’s no way an interrupt can occur after the lower word of a doubleword is read but before the upper word is read. For example, suppose we want to read the timer count the BIOS maintains at 0000:046C. We <em>could</em> read the count like this:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">sub</span>   <span class="kw">ax</span>,<span class="kw">ax</span>
<span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">ax</span>
<span class="kw">mov</span>   <span class="kw">ax</span>,<span class="kw">es</span>:[46ch]
<span class="kw">mov</span>   <span class="kw">dx</span>,<span class="kw">es</span>:[46eh]</code></pre>
<p>There’s a problem with this code, though. Every 54.9 ms, the timer generates an interrupt which starts the BIOS timer tick handler. The BIOS handler then increments the timer count. If an interrupt occurs right after <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ax</span>,<span class="kw">es</span>:[46ch]</code> in the above code — before <strong>mov dx,es:[46eh]</strong> can execute — we would read half of the value before it’s advanced, and half of the value after it’s advanced. If this happened as an hour or a day turned over, we could conceivably read a count that’s seriously wrong, with potentially disastrous implications for any program that relies on precise time synchronization. Over time, such a misread of the timer is bound to happen if we use the above code.</p>
<p>We could solve the problem by disabling interrupts while we read the count:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">sub</span>   <span class="kw">ax</span>,<span class="kw">ax</span>
<span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">ax</span>
<span class="kw">cli</span>
<span class="kw">mov</span>   <span class="kw">ax</span>,<span class="kw">es</span>:[46ch]
<span class="kw">mov</span>   <span class="kw">dx</span>,<span class="kw">es</span>:[46eh]
<span class="kw">sti</span></code></pre>
<p>but there’s a better solution. There’s no way <code class="sourceCode nasm"><span class="kw">les</span></code> can be interrupted as it reads a doubleword value, so we’ll just load our doubleword thusly:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">sub</span>   <span class="kw">ax</span>,<span class="kw">ax</span>
<span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">ax</span>
<span class="kw">les</span>   <span class="kw">ax</span>,<span class="kw">es</span>:[46ch]
<span class="kw">mov</span>   <span class="kw">dx</span>,<span class="kw">es</span></code></pre>
<p>This last bit of code is shorter, faster, and uninterruptible — in short, it’s perfect for our needs. In fact, we could have put <code class="sourceCode nasm"><span class="kw">les</span></code> to good use reading the BIOS timer count in the long-period Zen timer, way back in <a href="#listing-2-5">Listing 2-5</a>. Why didn’t I use it there? The truth is that I didn’t know about using <code class="sourceCode nasm"><span class="kw">les</span></code> to load doublewords when I wrote the timer (which just goes to show that there’s always more to learn about the 8088). When I did learn about loading doublewords with <code class="sourceCode nasm"><span class="kw">les</span></code>, it didn’t make any sense to tinker with code that worked perfectly well just to save a few bytes and cycles, particularly because the timer count load isn’t time-critical.</p>
<p>Remember, it’s only worth optimizing for speed when the cycles you save make a significant difference… which usually means inside tight loops.</p>
</section>
<section id="segmentoffset-and-byte-ordering-in-memory" class="level3">
<h3>Segment:Offset and Byte Ordering in Memory</h3>
<p>Our discussion of <code class="sourceCode nasm"><span class="kw">les</span></code> brings up the topic of how multi-byte values are stored in memory on the 8088. That’s an interesting topic indeed; on occasion we’ll need to load just the segment part of a 20-bit pointer from memory, or we’ll want to modify only the upper byte of a word variable. The answer to our question is simple but by no means obvious: <em>multi-byte values are always stored with the least-significant byte at the lowest address</em>.</p>
<p>For example, when you execute <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ax</span>,[WordVar]</code>, AL is loaded from address <code class="sourceCode nasm">WordVar</code>, and AH is loaded from address <code class="sourceCode nasm">WordVar<span class="dv">+1</span></code>, as shown in Figure 7.4. Put another way, this:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">ax</span>,[WordVar]</code></pre>
<p>is logically equivalent to this:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">al</span>,<span class="dt">byte</span> <span class="dt">ptr</span> [WordVar]
<span class="kw">mov</span>   <span class="kw">ah</span>,<span class="dt">byte</span> <span class="dt">ptr</span> [WordVar<span class="dv">+1</span>]</code></pre>
<p>although the single-instruction version is much faster and smaller. All word-sized values (including address displacements, which we’ll get to shortly) follow this least-significant-byte-first memory ordering.</p>
<figure>
<img src="images/fig7.4RT.png" />
</figure>
<p>Similarly, segment:offset pointers are stored with the least-significant byte of the offset at the lowest memory address, the most-significant byte of the offset next, the least-significant byte of the segment after that, and the most-significant byte of the segment at the highest memory address, as shown in Figure 7.5. This:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">les</span>   <span class="kw">dx</span>,<span class="dt">dword</span> <span class="dt">ptr</span> [FarPtr]</code></pre>
<p>is logically equivalent to this:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">dx</span>,<span class="dt">word</span> <span class="dt">ptr</span> [FarPtr]
<span class="kw">mov</span>   <span class="kw">es</span>,<span class="dt">word</span> <span class="dt">ptr</span> [FarPtr<span class="dv">+2</span>]</code></pre>
<p>which is in turn logically equivalent to this:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">dl</span>,<span class="dt">byte</span> <span class="dt">ptr</span> [FarPtr]
<span class="kw">mov</span>   <span class="kw">dh</span>,<span class="dt">byte</span> <span class="dt">ptr</span> [FarPtr<span class="dv">+1</span>]
<span class="kw">mov</span>   <span class="kw">al</span>,<span class="dt">byte</span> <span class="dt">ptr</span> [FarPtr<span class="dv">+2</span>]
<span class="kw">mov</span>   <span class="kw">ah</span>,<span class="dt">byte</span> <span class="dt">ptr</span> [FarPtr<span class="dv">+3</span>]
<span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">ax</span></code></pre>
<figure>
<img src="images/fig7.5RT.png" />
</figure>
<p>This organization applies to all segment:offset values stored in memory, including return addresses placed on the stack by far calls, far pointers used by far indirect calls, and interrupt vectors.</p>
<p>There’s nothing sacred about having the least-significant byte at the lowest address; it’s just the approach Intel chose. Other processors store values with most-significant byte at the lowest address, and there’s a sometimes heated debate about which memory organization is better. That debate is of no particular interest to us; we’ll be using an Intel chip, so we’ll always be using Intel’s least-significant-byte-first organization.</p>
<p>So, to load just the segment part of the 20-bit pointer <code class="sourceCode nasm">FarPtr</code>, we’d use:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">es</span>,<span class="dt">word</span> <span class="dt">ptr</span> [FarPtr<span class="dv">+2</span>]</code></pre>
<p>and to increment only the upper byte of the word variable <code class="sourceCode nasm">WordPtr</code>, we’d use:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">inc</span>   <span class="dt">byte</span> <span class="dt">ptr</span> [WordVar<span class="dv">+1</span>]</code></pre>
<p>Remember that the least-significant byte of any value (the byte that’s closest to bit 0 when the value is loaded into a register) is always stored at the lowest memory address, and that offsets are stored at lower memory addresses than segments, and you’ll be set.</p>
</section>
<section id="loading-ss" class="level3">
<h3>Loading SS</h3>
<p>I’d like to take a moment to remind you that SP must be loaded whenever SS is loaded, and that interrupts should be disabled for the duration of the load, as we discussed in the last chapter. It would have been handy if Intel had given us an <code class="sourceCode nasm"><span class="kw">lss</span></code> instruction, but they didn’t. Instead, we’ll load SS and SP with code along the lines of:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">cli</span>
<span class="kw">mov</span>   <span class="kw">ss</span>,[NewSS]
<span class="kw">mov</span>   <span class="kw">sp</span>,[NewSP]
<span class="kw">sti</span></code></pre>
</section>
<section id="extracting-segment-values-with-the-seg-directive" class="level3">
<h3>Extracting Segment Values With the <code>seg</code> Directive</h3>
<p>Next, we’re going to look <em>very</em> quickly at a MASM operator and a MASM directive. As I’ve said, this is not a book about MASM, but these directives are closely related to the efficient use of segments.</p>
<p>The <code class="sourceCode nasm"><span class="kw">seg</span></code> operator returns the segment within which the following symbol (label or variable name) resides. In the following code, <code class="sourceCode nasm"><span class="kw">seg</span> WordVar</code> returns the segment <code class="sourceCode nasm">Data</code>, which is then loaded into ES and used to assume ES to that segment:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">Data  <span class="kw">segment</span>
WordVar   <span class="dt">dw</span>  <span class="dv">0</span>
Data  ends
Code  <span class="kw">segment</span>
      assume  <span class="kw">cs</span>:Code,<span class="kw">es</span>:Nothing
            :
      <span class="kw">mov</span>   <span class="kw">ax</span>,<span class="kw">seg</span>   WordVar
      <span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">ax</span>
      assume  <span class="kw">es</span>:<span class="kw">seg</span> WordVar
:
Code ends</code></pre>
<p>You may well ask why it’s worth bothering with <code class="sourceCode nasm"><span class="kw">seg</span></code>, when we could simply have used the segment name <code class="sourceCode nasm">Data</code> instead. The answer is that you may not know or may not have direct access to the segment name for variables that are declared in other modules. For example, suppose that <code class="sourceCode nasm">WordVar</code> were external in our last example:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">      extrn WordVar:<span class="dt">word</span>
Code  <span class="kw">segment</span>
      assume  <span class="kw">cs</span>:Code, <span class="kw">es</span>:Nothing
      :
      <span class="kw">mov</span>   <span class="kw">ax</span>,<span class="kw">seg</span> WordVar
      <span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">ax</span>
      assume  <span class="kw">es</span>:<span class="kw">seg</span> WordVar
      :
Code ends</code></pre>
<p>This code still returns the segment of <code class="sourceCode nasm">WordVar</code> properly, even though we don’t necessarily have any idea at all as to what the name of that segment might be.</p>
<p>In short, <code class="sourceCode nasm"><span class="kw">seg</span></code> makes it easier to work with multiple segments in multi-module programs.</p>
</section>
<section id="joining-segments" class="level3">
<h3>Joining Segments</h3>
<p>Selected assembler modules can share the same code and/or data segments even when multiple code and data segments are used. In other words, in assembler you can choose to share segments between modules or not as you choose, by contrast with high-level languages, which generally force you to choose between all or no modules sharing segments. (This is not always the case, however, as we’ll see in Chapter 14.)</p>
<p>The mechanism for joining or separating segments is the <code class="sourceCode nasm"><span class="kw">segment</span></code> directive. If each of two modules has a segment of the same name, and if those segments are created as public segments (via the <code class="sourceCode nasm">public</code> option to the <code class="sourceCode nasm"><span class="kw">segment</span></code> directive), then those segments will be joined into a single, shared segment. If the segments are code segments, you can use near calls (faster and smaller than far calls) between the modules. If the segments are data segments, then there’s no need for one module to load segment registers in order to access data in the other module.</p>
<p>All in all, shared segments allow multiple-module programs to produce code that’s as efficient as single-module code, with the segment registers changed as infrequently as possible. In the same program in which multiple modules share a given segment, however, other modules — or even other parts of the same modules — may share segments of different names, or may have segments that are private (unique to that module). As a result, assembler programs can strike an effective balance between performance and available memory: efficient offset-only addressing most of the time, along with access to as many segments and as much memory as the PC can handle on an as-needed basis.</p>
<p>There are many ways to join segments, including grouping them and declaring them common, and there are many options to the <code class="sourceCode nasm"><span class="kw">segment</span></code> directive. We need to get on with our discussion of memory addressing, so we won’t cover MASM’s segment-related directives further, but I strongly suggest that you carefully read the discussion of those directives in your assembler’s manual. In fact, you should make it a point to read your assembler’s manual cover to cover — it may not be the most exciting reading around, but I guarantee that there are tricks and tips in there that you’ll find nowhere else.</p>
<p>While we won’t discuss MASM’s segment-related directives again, we will explore the topic of effective segment use again in Chapter 10 (as it relates to the string instructions), Chapter 14 (as it relates to branching), and in Volume II of <em>The Zen of Assembly Language</em>.</p>
</section>
<section id="segment-override-prefixes" class="level3">
<h3>Segment Override Prefixes</h3>
<p>As we saw in Chapter 6, all memory accesses default to accessing memory relative to one of the four segment registers. Instructions come from CS, stack accesses and memory accesses that use BP as a pointer occur within SS, string instruction accesses via DI are in ES, and everything else is normally in DS. In some — but by no means all — cases, segments other than the default segments can be accessed by way of segment override prefixes, special bytes that can precede — prefix — instructions in order to cause those instructions to use any one of the four segment registers.</p>
<p>Let’s start by listing the types of memory accesses segment override prefixes <em>can’t</em> affect. Instructions are always fetched from CS; there’s no way to alter that. The stack pointer is always used as a pointer into SS, no matter what. ES is always the segment to which string instruction accesses via DI go, regardless of segment override prefixes. Basically, it’s accesses to explicitly named memory operands and string instruction accesses via SI that are affected by segment override prefixes. (The segment accessed by the unusual <code class="sourceCode nasm"><span class="kw">xlat</span></code> instruction, which we’ll encounter later in this chapter, can also be overridden.)</p>
<p>The default segment for a memory operand is overridden by placing the prefix <code class="sourceCode nasm"><span class="kw">CS</span>:</code>, <code class="sourceCode nasm"><span class="kw">DS</span>:</code>, <code class="sourceCode nasm"><span class="kw">ES</span>:</code>, or <code class="sourceCode nasm"><span class="kw">SS</span>:</code> on that memory operand. For example:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">sub</span>   <span class="kw">bx</span>,<span class="kw">bx</span>
<span class="kw">mov</span>   <span class="kw">ax</span>,<span class="kw">es</span>:[<span class="kw">bx</span>]</code></pre>
<p>loads AX with the word at offset 0 in ES, as opposed to:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">sub</span>   <span class="kw">bx</span>,<span class="kw">bx</span>
<span class="kw">mov</span>   <span class="kw">ax</span>,[<span class="kw">bx</span>]</code></pre>
<p>which loads AX with the word at offset 0 in DS.</p>
<p>Segment override prefixes are handy in a number of situations. They’re good for accessing data out of CS when you’re not sure where DS is pointing, or when DS is temporarily pointing to some segment that doesn’t contain the data you want. (CS is the one segment upon whose setting you can absolutely rely at any given time, since you know that if a given instruction is being executed, CS <em>must</em> be pointing to the segment containing that instruction. Consequently, CS is a good place to put jump tables and temporary variables in multi-segment programs, and is a particularly handy segment in which to stash data in interrupt handlers, which start up with only CS among the four segment registers set to a known value.)</p>
<p>In many programs, especially those involving high-level languages, DS and SS normally point to the same segment, since it’s convenient to have both stack frame variables and static/global variables in the same segment. When that’s the case, <code class="sourceCode nasm"><span class="kw">ss</span>:</code> prefixes can be used to point to data in the default data segment when DS is otherwise occupied. Even when SS doesn’t point to the default data segment, segment override prefixes still let you address data on the stack using pointer registers other than BP.</p>
<p>Segment override prefixes are particularly handy when you need to access data in two to four segments at once. Suppose, for example, that we need to add two far word-sized arrays together and store the resulting array in the default data segment. Assuming that SS and DS both point to the default data segment, segment override prefixes let us keep all our pointers and counters in the registers as we add the arrays, as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">push</span>  <span class="kw">ds</span>              <span class="co">;save normal DS</span>
    <span class="kw">les</span>   <span class="kw">di</span>,[FarPtr2]    <span class="co">;point ES:DI to one source array</span>
    <span class="kw">mov</span>   <span class="kw">bx</span>,[DestPtr]    <span class="co">;point SS:BX to the destination array</span>
    <span class="kw">mov</span>   <span class="kw">cx</span>,[AddLength]  <span class="co">;array length</span>
    <span class="kw">lds</span>   <span class="kw">si</span>,[FarPtr1]    <span class="co">;point DS:SI to the other source array</span>
    <span class="kw">cld</span>                   <span class="co">;make LODSW count up</span>
<span class="fu">Add3Loop:</span>
    <span class="kw">lodsw</span>                 <span class="co">;get the next entry from one array</span>
    <span class="kw">add</span>   <span class="kw">ax</span>,<span class="kw">es</span>:[<span class="kw">di</span>]      <span class="co">;add it to the other array</span>
    <span class="kw">mov</span>   <span class="kw">ss</span>:[<span class="kw">bx</span>],<span class="kw">ax</span>      <span class="co">;save the sum in a third array</span>
    <span class="kw">inc</span>   <span class="kw">di</span>              <span class="co">;point to the next entries</span>
    <span class="kw">inc</span>   <span class="kw">di</span>
    <span class="kw">inc</span>   <span class="kw">bx</span>
    <span class="kw">inc</span>   <span class="kw">bx</span>
    <span class="kw">loop</span>  Add3Loop
    <span class="kw">pop</span>   <span class="kw">ds</span>              <span class="co">;restore normal DS</span></code></pre>
<p>Had we needed to, we could also have stored data in CS by using <code class="sourceCode nasm"><span class="kw">cs</span>:</code>.</p>
<p>Handy as segment override prefixes are, you shouldn’t use them too heavily if you can help it. They’re fine for one-shot instructions such as branching through a jump table in CS or retrieving a byte from the BIOS data area by way of ES, but they’re to be avoided whenever possible inside tight loops. The reason: segment override prefixes officially take 2 cycles to execute and, since they’re 1 byte long, they can actually take up to 4 cycles to fetch and execute — and 4 cycles is a significant amount of time inside a tight loop.</p>
<p>Whenever you can, organize your segments outside loops so that segment override prefixes aren’t needed inside loops. For example, consider <a href="#listing-7-7">Listing 7-7</a>, which uses a segment override prefix while stripping the high bit of every byte in an array in the segment addressed via ES. <a href="#listing-7-7">Listing 7-7</a> runs in 2.95 ms.</p>
<p>Now consider <a href="#listing-7-8">Listing 7-8</a>, which does the same thing as <a href="#listing-7-7">Listing 7-7</a>, save that DS is set to match ES outside the loop. Since DS is the default segment for the memory accesses we perform inside the loop, there’s no longer any need for a segment override prefix… and that one change improves performance by nearly 14%, reducing total execution time to 2.59 ms.</p>
<p>The lesson is clear: don’t use segment override prefixes in tight loops unless you have no choice.</p>
</section>
<section id="assume-and-segment-override-prefixes" class="level3">
<h3><code>assume</code> and Segment Override Prefixes</h3>
<p>Segment override prefixes can find their way into your code even if you don’t put them there, courtesy of the assembler and the <code class="sourceCode nasm">assume</code> directive. <code class="sourceCode nasm">assume</code> tells MASM what segments are currently addressable via the segment registers. Whenever MASM doesn’t think the default segment register for a given instruction can reach the desired segment but another segment register can, <em>MASM sticks in a segment override prefix without telling you it’s doing so</em>. As a result, your code can get bigger and slower without you knowing about it.</p>
<p>Take a look at this code:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">Code  <span class="kw">segment</span>
      assume      <span class="kw">cs</span>:code
Start proc  far
    <span class="kw">jmp</span>     Skip
ByteVar     <span class="dt">db</span>    <span class="dv">0</span>
<span class="fu">Skip:</span>
    <span class="kw">push</span>    <span class="kw">cs</span>
    <span class="kw">pop</span>     <span class="kw">ds</span>    <span class="co">;set DS to point to the segment Code</span>
    <span class="kw">inc</span>     [ByteVar]
            :
Code  ends</code></pre>
<p>You know and I know that DS can be used to address <code class="sourceCode nasm">ByteVar</code> in the above code, since the first thing the code does is set DS equal to CS, thereby loading DS to point to the segment <code class="sourceCode nasm">Code</code>. Unfortunately, the assembler does <em>not</em> know that — the <code class="sourceCode nasm">assume</code> directive told it only that CS points to <code class="sourceCode nasm">Code</code>, and <code class="sourceCode nasm">assume</code> is all the assembler has to go by. Given this correct but not complete information, the assembler concludes that <code class="sourceCode nasm">ByteVar</code> must be addressed via CS and inserts a <code class="sourceCode nasm"><span class="kw">cs</span>:</code> segment override prefix, so the <code class="sourceCode nasm"><span class="kw">inc</span></code> instruction assembles as if <code class="sourceCode nasm"><span class="kw">inc</span> <span class="kw">cs</span>:[ByteVar]</code> had been used.</p>
<p>The result is a wasted byte and several wasted cycles. Worse yet, you have no idea that the segment override prefix has been inserted unless you either generate and examine a listing file or view the assembled code as it runs in a debugger. The assembler is just trying to help by taking some of the burden of segment selection away from you, but the outcome is all too often code that’s invisibly bloated with segment override prefixes.</p>
<p>The solution is simple. <em>Keep the assembler’s segment assumptions correct at all times by religiously using the <code class="sourceCode nasm">assume</code> directive every time you load a segment.</em> The above example would have assembled correctly — without a segment override prefix — if only we had inserted the line:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">assume  <span class="kw">ds</span>:Code</code></pre>
<p>before we had attempted to access <code class="sourceCode nasm">ByteVar</code>.</p>
</section>
</section>
<section id="offset-handling" class="level2">
<h2>Offset Handling</h2>
<p>At long last, we’ve completed our discussion of segments. Now it’s time to move on to the other half of the memory-addressing equation: offsets.</p>
<p>Offsets are handled somewhat differently from segments. Segments are simply loaded into the segment registers, which are then used to address memory as half of a segment:offset address. Offsets can also be loaded into registers and used directly as half of a segment:offset address, but just as often offsets are built into instructions, and they can also be calculated on the fly by summing the contents of one or two registers and/or offsets built into instructions.</p>
<p>At any rate, we’ll quickly cover offset loading, and then we’ll look at the many ways to generate offsets for memory addressing. The offset portion of memory addressing is one area in which the 8088 is very flexible, and, as we’ll see, there’s no one best way to address memory.</p>
<section id="loading-offsets" class="level3">
<h3>Loading Offsets</h3>
<p>Offsets are loaded with the <code class="sourceCode nasm">offset</code> operator. <code class="sourceCode nasm">offset</code> is analogous to the <code class="sourceCode nasm"><span class="kw">seg</span></code> operator we encountered earlier; the difference, of course, is that <code class="sourceCode nasm">offset</code> extracts the offset of a label or variable name rather than the segment. For example:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">bx</span>,offset WordVar</code></pre>
<p>loads BX with the offset of the variable <code class="sourceCode nasm">WordVar</code>. If some segment register already points to the segment containing <code class="sourceCode nasm">WordVar</code>, then BX can be used to address memory, as for example in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">bx</span>,<span class="kw">seg</span> WordVar
<span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">bx</span>
<span class="kw">mov</span>   <span class="kw">bx</span>,offset WordVar
<span class="kw">mov</span>   <span class="kw">ax</span>,<span class="kw">es</span>:[<span class="kw">bx</span>]</code></pre>
<p>We’ll discuss the many ways in which offsets can be used to address memory next.</p>
<p>Before we get to using offsets to address memory, there are a couple of points I’d like to make. The first point is that the <code class="sourceCode nasm"><span class="kw">lea</span></code> instruction can also be used to load offsets into registers; however, an understanding of <code class="sourceCode nasm"><span class="kw">lea</span></code> requires an understanding of the 8088’s addressing modes, so we’ll defer the discussion of <code class="sourceCode nasm"><span class="kw">lea</span></code> until later in this chapter.</p>
<p>The second point is a shortcoming of MASM that you must be aware of when you use <code class="sourceCode nasm">offset</code> on variables that reside in segment groups. If you are using the <code class="sourceCode nasm">group</code> directive to make segment groups, you must always specify the group name as well as the variable name when you use the offset operator. For example, if the segment <code class="sourceCode nasm">_DATA</code> is in the group <code class="sourceCode nasm">DGROUP</code>, and <code class="sourceCode nasm">WordVar</code> is in <code class="sourceCode nasm">_DATA</code>, you <em>must</em> load the offset of <code class="sourceCode nasm">WordVar</code> as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">di</span>,offset DGROUP:WordVar</code></pre>
<p>If you don’t specify the group name, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">di</span>,offset WordVar</code></pre>
<p>the offset of <code class="sourceCode nasm">WordVar</code> relative to <code class="sourceCode nasm">_DATA</code> rather than <code class="sourceCode nasm">DGROUP</code> is loaded; given the way segment groups are organized (with all segments in the group addressed in a single combined segment), an offset relative to <code class="sourceCode nasm">_DATA</code> may not work at all.</p>
<p>I realize that the above discussion won’t make much sense if you haven’t encountered the <code class="sourceCode nasm">group</code> directive (lucky you!). I’ve never found segment groups to be necessary in pure assembler code, but they are often needed when sharing segments between high-level language code and assembler. If you do find yourself using segment groups, all you need to remember is this: <em>when loading the offset of a variable that resides within a segment group with the <code class="sourceCode nasm">offset</code> operator, always specify the group name along with the variable name</em>.</p>
</section>
</section>
<section id="mod-reg-rm-addressing" class="level2">
<h2><em>mod-reg-rm</em> Addressing</h2>
<p>There are a number of ways in which the offset of an instruction operand can be specified. Collectively, the ways of specifying operand offsets are known as addressing modes. Most of the 8088’s addressing modes fall into a category known as <em>mod-reg-rm</em> addressing modes. We’re going to discuss <em>mod-reg-rm</em> addressing modes next; later in the chapter we’ll discuss non-<em>mod-reg-rm</em> addressing modes.</p>
<p><em>mod-reg-rm</em> addressing modes are so named because they’re specified by a second instruction byte, known as the <em>mod-reg-rm</em> byte, that follows instruction opcodes in order to specify the memory and/or register operands for many instructions. The <em>mod-reg-rm</em> byte gets its name because the various fields within the byte are used to specify the memory addressing <em>mod</em>e, the <em>reg</em>ister used for one operand, and the <em>r</em>egister or <em>m</em>emory location used for the other operand, as shown in Figure 7.6. (Figure 7.6 should make it clear that at most only one <em>mod-reg-rm</em> operand can be a memory operand; one or both operands must be register operands, for there just aren’t enough bits in a <em>mod-reg-rm</em> byte to specify two memory operands.)</p>
<figure>
<img src="images/fig7.6RT.png" />
</figure>
<p>Simply put, the <em>mod-reg-rm</em> byte tells the 8088 where to find an instruction’s operand or operands. (It’s up to the opcode byte to specify the data size, as well as which operand is the source and which is the destination.) When a memory operand is used, the <em>mod-reg-rm</em> byte tells the 8088 how to add together the contents of registers (BX or BP and/or SI or DI) and/or a fixed value built into the instruction (a displacement) in order to generate the operand’s memory offset. The offset is then combined with the contents of one of the segment registers to make a full 20-bit memory address, as we saw earlier in this chapter, and that 20-bit address serves as the instruction operand. Figure 7.7 illustrates the operation of the complex base+index+displacement addressing mode, in which an offset is generated by adding BX or BP, SI or DI, and a fixed displacement. (Note that displacements are built right into instructions, coming immediately after <em>mod-reg-rm</em> bytes, as illustrated by Figure 7.9.)</p>
<figure>
<img src="images/fig7.7RT.png" />
</figure>
<p>For example, if the opcode for <code class="sourceCode nasm"><span class="kw">mov</span> reg8,[reg/mem8]</code> (8Ah) is followed by the <em>mod-reg-rm</em> byte 17h, that indicates that the register DL is to be loaded from the memory location pointed to by BX, as shown in Figure 7.8. Put the other way around, <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">dl</span>,[<span class="kw">bx</span>]</code> assembles to the two byte sequence 8Ah 17h, where the first byte is the opcode for <code class="sourceCode nasm"><span class="kw">mov</span> reg8,[reg/mem8]</code> and the second byte is the <em>mod-reg-rm</em> byte that selects DL as the destination and the memory location pointed to by BX as the source.</p>
<figure>
<img src="images/fig7.8RT.png" />
</figure>
<p>You may well wonder how the <em>mod-reg-rm</em> byte works with one-operand instructions, such as <code class="sourceCode nasm"><span class="kw">neg</span> <span class="dt">word</span> <span class="dt">ptr</span> <span class="kw">ds</span>:[140h]</code>, or with instructions that have constant data as one operand, such as <code class="sourceCode nasm"><span class="kw">sub</span> [WordVar],<span class="dv">1</span></code>. The answer is that in these cases the <em>reg</em> field isn’t used for source or destination control; instead, it’s used as an extension of the opcode byte. So, for instance, <code class="sourceCode nasm"><span class="kw">neg</span> [reg/mem16]</code> has an opcode byte of 0F7h and always has bits 5-3 of the <em>mod-reg-rm</em> byte set to 011b. Bits 7-6 and 2-0 of the <em>mod-reg-rm</em> byte still select the memory addressing mode for the single operand, but bits 5-3, together with the opcode byte, now simply tell the 8088 that the instruction is <code class="sourceCode nasm"><span class="kw">neg</span> [reg/mem16]</code>, as shown in Figure 7.9. <code class="sourceCode nasm"><span class="kw">not</span> [reg/mem16]</code> also has an opcode byte of 0F7h, but is distinguished from <code class="sourceCode nasm"><span class="kw">neg</span> [reg/mem16]</code> by bits 5-3 of the <em>mod-reg-rm</em> byte, which are 010b for <code class="sourceCode nasm"><span class="kw">not</span></code> and 011b for <code class="sourceCode nasm"><span class="kw">neg</span></code>.</p>
<figure>
<img src="images/fig7.9RT.png" />
</figure>
<p>At any rate, the mechanics of <em>mod-reg-rm</em> addressing aren’t what we need to concern ourselves with; the assembler takes care of such details, thank goodness. We do, however, need to concern ourselves with the <em>implications</em> of <em>mod-reg-rm</em> addressing, particularly size and performance issues.</p>
<section id="whats-mod-reg-rm-addressing-good-for" class="level3">
<h3>What’s <em>mod-reg-rm</em> Addressing Good For?</h3>
<p>The first thing to ask is, “What is <em>mod-reg-rm</em> addressing good for?”What <em>mod-reg-rm</em> addressing does best is address memory in a very flexible way. No other addressing mode approaches <em>mod-reg-rm</em> addressing for sheer number of ways in which memory offsets can be generated.</p>
<p>Look at Figure 7.6, and try to figure out how many source/destination combinations are possible with <em>mod-reg-rm</em> addressing. The answer is simple, since there are 8 bits in a <em>mod-reg-rm</em> byte; 256 possible source/destination combinations are supported. Any general-purpose register can be one operand, and any general-purpose register or memory location can be the other operand.</p>
<p>If we look at memory addressing alone, we see that there are 24 distinct ways to generate a memory offset. (8 of the 32 possible selections that can be made with bits 7-6 and 3-0 of the <em>mod-reg-rm</em> byte select general-purpose registers.) Some of those 24 selections differ only in whether 1 or 2 displacement bytes are present, leaving us with the following 16 completely distinct memory addressing modes:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">[disp16]    [<span class="kw">bp</span>+disp]
[<span class="kw">bx</span>]        [<span class="kw">bx</span>+disp]
[<span class="kw">si</span>]        [<span class="kw">si</span>+disp]
[<span class="kw">di</span>]        [<span class="kw">di</span>+disp]
[<span class="kw">bp</span>+<span class="kw">si</span>]     [<span class="kw">bp</span>+<span class="kw">si</span>+disp]
[<span class="kw">bp</span>+<span class="kw">di</span>]     [<span class="kw">bp</span>+<span class="kw">di</span>+disp]
[<span class="kw">bx</span>+<span class="kw">si</span>]     [<span class="kw">bx</span>+<span class="kw">si</span>+disp]
[<span class="kw">bx</span>+<span class="kw">di</span>]     [<span class="kw">bx</span>+<span class="kw">di</span>+disp]</code></pre>
<p>For two-operand instructions, each of those memory addressing modes can serve as either source or destination, with either a constant value or one of the 8 general-purpose registers as the other operand.</p>
<p>Basically, <em>mod-reg-rm</em> addressing lets you select a memory offset in any of 16 ways (or a general-purpose register, if you prefer), and say, “Use this as an operand.” The other operand can’t involve memory, but it can be any general-purpose register or (usually) a constant value. (There’s no inherent support in <em>mod-reg-rm</em> addressing for constant operands. Special, separate opcodes must used to specify constant operands for instructions that support such operands, and a few <em>mod-reg-rm</em> instructions, such as <code class="sourceCode nasm"><span class="kw">mul</span></code>, don’t accept constant operands at all.)</p>
<p><em>mod-reg-rm</em> addressing is flexible indeed.</p>
</section>
<section id="displacements-and-sign-extension" class="level3">
<h3>Displacements and Sign-Extension</h3>
<p>I’ve said that displacements can be either 1 or 2 bytes in size. The obvious question is: what determines which size is used? That’s an important question, since displacement bytes directly affect program size, which in turn indirectly affects performance via the prefetch queue cycle-eater.</p>
<p>Except in the case of direct addressing, which we’ll discuss shortly, displacements in the range -128 to +127 are stored as one byte, then automatically sign-extended by the 8088 to a word when the instructions containing them are executed. (Expressed in unsigned hexadecimal, -128 to +127 covers two ranges: 0 to 7Fh and 0FF80h to 0FFFFh.) Sign-extension involves copying bit 7 of the byte to bits 15-8, so a byte value of 80h sign-extends to 0FF80h, and a byte value of 7Fh sign-extends to 0007Fh. Basically, sign-extension converts signed byte values to signed word values; since the maximum range of a signed byte is -128 to +127, that’s the maximum range of a 1-byte displacement as well.</p>
<p>The implication of this should be obvious: you should try to use displacements in the range -128 to +127 whenever possible, in order to reduce program size and improve performance. One caution, however: displacements must be either numbers or symbols equated to numbers in order for the assembler to be able to assemble them as single bytes. (Numbers and symbols work equally well. In:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">SAMPLE_DISPLACEMENT   <span class="dt">equ</span>   <span class="dv">1</span>
    :
    <span class="kw">mov</span>   <span class="kw">ax</span>,[<span class="kw">bx</span>+SAMPLE_DISPLACEMENT]
    <span class="kw">mov</span>   <span class="kw">ax</span>,[<span class="kw">bx</span><span class="dv">+9</span>]</code></pre>
<p>both <code class="sourceCode nasm"><span class="kw">mov</span></code> instructions assemble with 1-byte displacements.)</p>
<p>Displacements must be constant values in order to be stored in sign-extended bytes because when a named memory variable is used, the assembler has no way of knowing where in the segment the variable will end up. Other parts of the segment may appear in other parts of the module or may be linked in from other modules, and the linker may also align the segment to various memory boundaries; any of these can have the effect of moving a given variable in the segment to an offset that doesn’t fit in a sign-extended byte. As a result, the following <code class="sourceCode nasm"><span class="kw">mov</span></code> instruction assembles with a 2-byte displacement, even though it appears to be at offset 0 in its segment:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">Data  <span class="kw">segment</span>
MemVar  <span class="dt">db</span>  <span class="dv">10</span> dup (?)
Data  ends
      :
      <span class="kw">mov</span>   <span class="kw">al</span>,[MemVar+<span class="kw">bx</span>]</code></pre>
</section>
<section id="naming-the-mod-reg-rm-addressing-modes" class="level3">
<h3>Naming the <em>mod-reg-rm</em> Addressing Modes</h3>
<p>The 16 distinct memory addressing modes supported by the <em>mod-reg-rm</em> byte are often given a slew of confusing names, such as “implied addressing,” “based relative addressing,” and “direct indexed addressing.” Generally, there’s little need to name addressing modes; you’ll find you use them much more than you talk about them. However, we will need to refer to the modes later in this book, so let me explain my preferred addressing mode naming scheme.</p>
<p>I find it simplest to give a name to each of the three possible components of a memory offset — base for BX or BP, index for SI or DI, displacement for a 1-or 2-byte fixed value — and then just refer to an addressing mode with all the components of that mode. That way, <code class="sourceCode nasm"><span class="kw">mov</span> [<span class="kw">bx</span>],<span class="kw">al</span></code> uses base addressing, <code class="sourceCode nasm"><span class="kw">add</span> <span class="kw">ax</span>,[<span class="kw">si</span><span class="dv">+1</span>]</code> uses index+displacement addressing, and <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">dl</span>,[<span class="kw">bp</span>+<span class="kw">di</span>+1000h]</code> uses base+index+displacement addressing. The names may be long at times, but they’re never ambiguous or hard to remember.</p>
</section>
<section id="direct-addressing" class="level3">
<h3>Direct Addressing</h3>
<p>There is one exception to the above naming scheme, and that’s direct addressing. Direct addressing is used when a memory address is referenced with just a 16-bit displacement, as in <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">bx</span>,[WordVar]</code> or <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">es</span>:[410h],<span class="kw">al</span></code>. You might expect direct addressing to be called displacement addressing, but it’s not, for three reasons. First, the address used in direct addressing is not, properly speaking, a displacement, since it isn’t relative to any register. Second, direct addressing is a time-honored term that came into use long before the 8088 was around, so experienced programmers are more likely to speak of “direct addressing” than “displacement addressing.”</p>
<p>Third, direct addressing is a bit of an anomaly in <em>mod-reg-rm</em> addressing. It’s pretty obvious why we’d <em>want</em> to have direct addressing available; surely you’d rather do this:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">dx</span>,[WordVar]</code></pre>
<p>than this:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">bx</span>,offset WordVar
<span class="kw">mov</span>   <span class="kw">dx</span>,[<span class="kw">bx</span>]</code></pre>
<p>It’s just plain handy to be able to access a memory location directly by name.</p>
<p>Now look at Figure 7.6 again. Direct addressing really doesn’t belong in that figure at all, does it? The <em>mod-reg-rm</em> encoding for direct addressing should by all rights be taken by base addressing using only BP. However, there <em>is</em> no addressing mode that can use only BP — if you assemble the instruction <code class="sourceCode nasm"><span class="kw">mov</span> [<span class="kw">bp</span>],<span class="kw">al</span></code>, you’ll find that it actually assembles as <code class="sourceCode nasm"><span class="kw">mov</span> [<span class="kw">bp</span><span class="dv">+0</span>],<span class="kw">al</span></code>, with a 1-byte displacement.</p>
<p>In other words, the designers of the 8088 rightly considered direct addressing important enough to build it into <em>mod-reg-rm</em> addressing in place of a little-used addressing mode. (BP is designed to point to stack frames, as we’ll see shortly, and there’s rarely any use for BP-only base addressing in stack frames.)</p>
<p>Along the same lines, note that direct addressing always uses a 16-bit displacement. Direct addressing does not use an 8-bit sign-extended displacement even if the address is in the range -128 to +127.</p>
</section>
<section id="miscellaneous-information-about-memory-addressing" class="level3">
<h3>Miscellaneous Information About Memory Addressing</h3>
<p>Be aware that all <em>mod-reg-rm</em> addressing defaults to accessing the segment pointed to by DS — <em>except</em> when BP is used as part of the <em>mod-reg-rm</em> address. Any <em>mod-reg-rm</em> addressing involving BP accesses the segment pointed to by SS by default. (If DS and SS point to the same segment, as they often do, you can use BP-based addressing modes to point to normal data if necessary, and you can use the other <em>mod-reg-rm</em> addressing modes to point to data on the stack.) However, <em>mod-reg-rm</em> addressing can always be forced to use any segment register with a segment override prefix.</p>
<p>There are a few other addressing terms that I should mention now. Indirect addressing is commonly used to refer to any sort of memory addressing that uses a register (BX, BP, SI, or DI, or any of the valid combinations) to point to memory. We’ll also use indirect to refer to branches that branch to destinations specified by memory operands, as in <code class="sourceCode nasm"><span class="kw">jmp</span> <span class="dt">word</span> <span class="dt">ptr</span> [SubroutinePointer]</code>. We’ll discuss indirect branching in detail in Chapter 14.</p>
<p>Immediate addressing is a non-<em>mod-reg-rm</em> form of addressing in which the operand is a constant value that’s built right into the instruction. We’ll cover immediate addressing when we’re done with <em>mod-reg-rm</em> addressing.</p>
<p>Finally, I’d like to make it clear that a displacement is nothing more than a fixed (constant) value that’s added into the memory offset calculated by a <em>mod-reg-rm</em> byte. It’s called a displacement because it specifies the number of bytes by which the addressed offset should be displaced from the offset specified by the registers used to point to memory. In <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">si</span>,[<span class="kw">bx</span><span class="dv">+1</span>]</code>, the displacement is 1; the address from which SI is loaded is displaced 1 byte from the memory location pointed to by BX. In <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ax</span>,[<span class="kw">si</span>+WordVar]</code>, the displacement is the offset of <code class="sourceCode nasm">WordVar</code>. We won’t know exactly what that offset is unless we look at the code with a debugger, but it’s a constant value nonetheless.</p>
<p>Don’t get caught up worrying about the exact meaning of the term displacement, or indeed of any of the memory addressing terms. In a way, the terms are silly; <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ax</span>,[<span class="kw">bx</span>]</code> is base addressing and <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ax</span>,[<span class="kw">si</span>]</code> is index addressing, but both load AX from the address pointed to by a register, both are 2 bytes long, and both take 13 cycles to execute. The difference between the two is purely semantic from a programmer’s perspective.</p>
<p>Notwithstanding, we needed to establish a common terminology for the <em>mod-reg-rm</em> memory addressing modes, and we’ve done so. Now that we understand how <em>mod-reg-rm</em> addressing works and how wonderfully flexible it is, let’s look at its dark side.</p>
</section>
<section id="mod-reg-rm-addressing-the-dark-side" class="level3">
<h3><em>mod-reg-rm</em> Addressing: The Dark Side</h3>
<p>Gee, if <em>mod-reg-rm</em> addressing is so flexible, why don’t we use it for all memory accesses? For that matter, why does the 8088 even <em>have</em> any other addressing modes?</p>
<p>One reason is that <em>mod-reg-rm</em> addressing doesn’t work with all instructions. For example, the string instructions can’t use <em>mod-reg-rm</em> addressing, and neither can <code class="sourceCode nasm"><span class="kw">xlat</span></code>, which we’ll encounter later in this chapter. Nonetheless, most instructions, including <code class="sourceCode nasm"><span class="kw">mov</span></code>, <code class="sourceCode nasm"><span class="kw">add</span></code>, <code class="sourceCode nasm"><span class="kw">adc</span></code>, <code class="sourceCode nasm"><span class="kw">sub</span></code>, <code class="sourceCode nasm"><span class="kw">sbb</span></code>, <code class="sourceCode nasm"><span class="kw">cmp</span></code>, <code class="sourceCode nasm"><span class="kw">and</span></code>, <code class="sourceCode nasm"><span class="kw">or</span></code>, <code class="sourceCode nasm"><span class="kw">xor</span></code>, <code class="sourceCode nasm"><span class="kw">neg</span></code>, <code class="sourceCode nasm"><span class="kw">not</span></code>, <code class="sourceCode nasm"><span class="kw">mul</span></code>, <code class="sourceCode nasm"><span class="kw">div</span></code>, and more, do support <em>mod-reg-rm</em> addressing, so it would seem that there must be some other reason for the existence of other addressing modes.</p>
<p>And indeed there is another reason for the existence of other addressing modes. In fact, there are two reasons: speed and size. <em>mod-reg-rm</em> addressing is more flexible than other addressing modes — and it also produces the largest, slowest code around.</p>
<p>It’s easy to understand why <em>mod-reg-rm</em> addressing produces larger code than other memory addressing modes. The bits needed to encode <em>mod-reg-rm</em> addressing’s many possible source, destination, and addressing mode combinations increase the size of <em>mod-reg-rm</em> instructions, and displacement bytes can make <em>mod-reg-rm</em> instructions larger still. It stands to reason that the string instruction <code class="sourceCode nasm"><span class="kw">lods</span></code>, which always loads AL from the memory location pointed to by DS:SI, should have fewer instruction bytes than the <em>mod-reg-rm</em> instruction <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,[<span class="kw">si</span>]</code>, which selects AL from 8 possible destination registers, and which selects the memory location pointed to by SI from among 32 possible source operands.</p>
<p>It’s less obvious why <em>mod-reg-rm</em> addressing is slower than other memory addressing modes. One major reason falls out from the larger size of <em>mod-reg-rm</em> instructions; we’ve already established that instructions with more instruction bytes tend to run more slowly, simply because it takes time to fetch those extra instruction bytes. That’s not the whole story, however. It takes the 8088 a variable but considerable amount of time — 5 to 12 cycles — to calculate memory addresses from <em>mod-reg-rm</em> bytes. Those lengthy calculations, known as effective address (EA) calculations, are our next topic.</p>
<p>Before we proceed to EA calculations, I’d like to point out that slow and bulky as <em>mod-reg-rm</em> addressing is, it’s still the workhorse memory addressing mode of the 8088. It’s also the addressing mode used by many register-only instructions, such as <code class="sourceCode nasm"><span class="kw">add</span> <span class="kw">dx</span>,<span class="kw">bx</span></code> and <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,<span class="kw">dl</span></code>, with the <em>mod-reg-rm</em> byte selecting register rather than memory operands. My goodness, some instructions don’t even <em>have</em> a non-<em>mod-reg-rm</em> addressing mode. Without a doubt, you’ll be using <em>mod-reg-rm</em> addressing often in your code, so we’ll take the time to learn how to use it well.</p>
<p>Nonetheless, the less-flexible addressing modes are generally shorter and faster than <em>mod-reg-rm</em> addressing. As we’ll see throughout <em>The Zen of Assembly Language</em>, one key to high-performance code is avoiding <em>mod-reg-rm</em> addressing as much as possible.</p>
</section>
<section id="why-memory-accesses-are-slow" class="level3">
<h3>Why Memory Accesses Are Slow</h3>
<p>As I’ve already said, <em>mod-reg-rm</em> memory accesses are slow partly because instructions that use <em>mod-reg-rm</em> addressing tend to have many instruction bytes. The <em>mod-reg-rm</em> byte itself adds 1 byte beyond the opcode byte, and a displacement, if used, will add 1 or 2 more bytes. Remember, 4 cycles are required to fetch each and every one of those instruction bytes.</p>
<p>Taken a step farther, that line of thinking reveals why <em>all</em> instructions that access memory are slow: memory is slow. It takes 4 cycles per byte to access memory in any way. That means that an instruction like <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">bx</span>,[WordVar]</code>, which is 4 bytes long and reads a word-sized memory variable, must perform 6 memory accesses in all; at 4 cycles a pop, that adds up to a minimum execution time of 24 cycles. Even a 2-byte memory-accessing instruction spends a minimum of 12 cycles just accessing memory. By contrast, most register-only operations are 1 to 2 bytes in length and have Execution Unit execution times of 2 to 4 cycles, so the <em>maximum</em> execution times for register-only instructions tend to be 4 to 8 cycles.</p>
<p>I’ve said it before, and I’ll say it again: <em>avoid accessing memory whenever you can</em>. Memory is just plain slow.</p>
<p>In actual use, many memory-accessing instructions turn out to be even slower than memory access times alone would explain. For example, the fastest possible <em>mod-reg-rm</em> memory-accessing instruction, <code class="sourceCode nasm"><span class="kw">mov</span> reg8,[<span class="kw">bx</span>]</code> (BP, SI, or DI would do as well as BX), has an Execution Unit execution time of 13 cycles, although only 3 memory accesses (requiring 12 cycles) are performed. Similarly, string instructions, <code class="sourceCode nasm"><span class="kw">xlat</span></code>, <code class="sourceCode nasm"><span class="kw">push</span></code>, and <code class="sourceCode nasm"><span class="kw">pop</span></code> take more cycles than can be accounted for solely by memory accesses.</p>
<p>The full explanation for the poor performance of the 8088’s memory-accessing instructions lies in the microcode of the 8088 (the built-in bit patterns that sequence the 8088 through the execution of each instruction), which is undeniably slower than it might be. (Check out the execution times of the 8088’s instructions on the 80286 and 80386, and you’ll see that it’s possible to execute the 8088’s instructions in many fewer cycles than the 8088 requires.) That’s not something we can change; about all we can do is choose the fastest available instruction for each task, and we’ll spend much of <em>The Zen of Assembly Language</em> doing just that.</p>
<p>There is one aspect of memory addressing that we <em>can</em> change, however, and that’s EA addressing time — the amount of time it takes the 8088 to calculate memory addresses.</p>
</section>
<section id="some-mod-reg-rm-memory-accesses-are-slower-than-others" class="level3">
<h3>Some <em>mod-reg-rm</em> Memory Accesses Are Slower Than Others</h3>
<p>A given instruction that uses <em>mod-reg-rm</em> addressing doesn’t always execute in the same number of cycles. The Execution Unit execution time of <em>mod-reg-rm</em> instructions comes in two parts: a fixed Execution Unit execution time and an effective address (EA) execution time that varies depending on the <em>mod-reg-rm</em> addressing mode used. The two times added together determine the overall execution time of each <em>mod-reg-rm</em> instruction.</p>
<p>Each <em>mod-reg-rm</em> instruction has its own fixed Execution Unit execution time, which remains the same for all addressing modes. For example, the fixed execution time of <code class="sourceCode nasm"><span class="kw">add</span> <span class="kw">bl</span>,[mem]</code> is 9 cycles, as shown in Appendix A; this value is constant, no matter what <em>mod-reg-rm</em> addressing mode is used.</p>
<p>The EA calculation time, on the other hand, depends not in the least on which instruction is being executed. EA calculation time is determined solely by the <em>mod-reg-rm</em> addressing mode used, and nothing else, as shown in Figure 7.10. As you can see from Figure 7.10, the time it takes the 8088 to calculate an effective address can vary greatly, ranging from a mere 5 cycles if a single register is used to point to memory all the way up to 11 or 12 cycles if the sum of two registers and a displacement is used to point to memory. (Segment override prefixes require an additional 2 cycles each, as we saw earlier.) When I discuss the performance of an instruction that uses <em>mod-reg-rm</em> addressing, I’ll often say that it takes at least a certain number of cycles to execute. What “at least” means is that the instruction will take that many cycles if the fastest <em>mod-reg-rm</em> addressing mode — base-or index-only — is used, and longer if some other <em>mod-reg-rm</em> addressing mode is selected.</p>
<figure>
<img src="images/fig7.10RT.png" />
</figure>
<p>Only <em>mod-reg-rm</em> memory operands require EA calculations. There is no EA calculation time for register operands, or for memory operands accessed with non-<em>mod-reg-rm</em> addressing modes.</p>
<p>In short, EA calculation time means that the choice of <em>mod-reg-rm</em> addressing mode directly affects performance. Let’s look more closely at the performance implications of EA calculations.</p>
</section>
<section id="performance-implications-of-effective-address-calculations" class="level3">
<h3>Performance Implications of Effective Address Calculations</h3>
<p>There are a number of interesting points to be made about EA calculation time. For starters, it should be clear that EA calculation time is a big reason why instructions that use <em>mod-reg-rm</em> addressing are slow. The minimum EA calculation time of 5 cycles, on top of 8 or more cycles of fixed execution time, is no bargain; the maximum EA calculation time of 12 cycles is a grim prospect indeed.</p>
<p>For example, <code class="sourceCode nasm"><span class="kw">add</span> <span class="kw">bl</span>,[<span class="kw">si</span>]</code> takes 13 cycles to execute (8 cycles of fixed execution time and 5 cycles of EA calculation time), which is certainly not terrific by comparison with the 3-cycle execution time of <code class="sourceCode nasm"><span class="kw">add</span> <span class="kw">bl</span>,<span class="kw">dl</span></code>. (Instruction fetching alters the picture somewhat, as we’ll see shortly.) At the other end of the EA calculation spectrum, <code class="sourceCode nasm"><span class="kw">add</span> <span class="kw">bl</span>,[<span class="kw">bx</span>+<span class="kw">di</span>+100h]</code> takes 20 cycles to execute, which is horrendous no matter what you compare it to.</p>
<p>The lesson seems clear: use faster <em>mod-reg-rm</em> addressing modes whenever you can. While that’s true, it’s not necessarily obvious which <em>mod-reg-rm</em> addressing modes are faster. Base-only addressing or index-only addressing are the <em>mod-reg-rm</em> addressing modes of choice, because they add only 5 cycles of EA calculation time and 1 byte, the <em>mod-reg-rm</em> byte. For instance, <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">dl</span>,[<span class="kw">bp</span>]</code> is just 2 bytes long and takes a fairly reasonable 13 cycles to execute.</p>
<p>Direct addressing, which has an EA calculation time of 6 cycles, is only slightly slower than base or index addressing so far as official execution time goes. However, direct addressing requires 2 additional instruction bytes (the 16-bit displacement) beyond the <em>mod-reg-rm</em> byte, so it’s actually a good deal slower than base or index addressing. <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">dl</span>,[ByteVar]</code> officially takes 14 cycles to execute, but given that the instruction is 4 bytes long and performs a memory access, 20 cycles is a more accurate execution time.</p>
<p>Base+index addressing (<code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,[<span class="kw">bp</span>+<span class="kw">di</span>]</code> and the like) takes 1 to 2 cycles more for EA calculation time than does direct addressing, but is nonetheless superior to direct addressing in most cases. The key: base+index addressing requires only the 1 <em>mod-reg-rm</em> byte. Base+index addressing instructions are 2 bytes shorter than equivalent direct addressing instructions, and that translates into a considerable instruction-fetching/performance advantage.</p>
<p>The rule is: <em>use displacement-free </em>mod-reg-rm* addressing modes whenever you can<em>. Instructions that use displacements are always 1 to 2 bytes longer than those that use displacement-free </em>mod-reg-rm* addressing modes, and that means that there’s generally a prefetching penalty for the use of displacements. There’s also a substantial EA calculation time penalty for base+displacement, index+displacement, or base+index+displacement addressing. If you must use displacements, use 1-byte displacements as much as possible; we’ll see an example of this when we get to stack frames later in this chapter.</p>
<p>Now, bear in mind that the choice of <em>mod-reg-rm</em> addressing mode really only matters inside loops, or in time-critical code. If you’re going to load DX from memory just once in a long subroutine, it really doesn’t much matter if you take a few extra cycles to load it with direct addressing rather than base or index addressing. It certainly isn’t worth loading, say, BX to point to memory, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">bx</span>,offset MemVar
<span class="kw">mov</span>   <span class="kw">dx</span>,[<span class="kw">bx</span>]</code></pre>
<p>just to use base or index addressing once — the <code class="sourceCode nasm"><span class="kw">mov</span></code> instruction used to load BX takes 4 cycles and 3 bytes, more than negating any advantage base addressing has over direct addressing.</p>
<p>Inside loops, however, it’s well worth using the most efficient addressing mode available. <a href="#listing-7-9">Listing 7-9</a>, which adds up the elements of a byte-sized array using base+index+displacement addressing every time through the loop, runs in 1.17 ms. <a href="#listing-7-10">Listing 7-10</a>, which changes the addressing mode to base+index by adding the displacement into the base outside the loop, runs in 1.01 ms, nearly 16% faster than <a href="#listing-7-9">Listing 7-9</a>. Finally, <a href="#listing-7-11">Listing 7-11</a>, which performs all the addressing calculations outside the loop and uses plain old base-only addressing, runs in just 0.95 ms, 6% faster still. (The string instruction <code class="sourceCode nasm"><span class="kw">lods</span></code> is even faster than <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,[<span class="kw">bx</span>]</code>, as we’ll see in Chapter 10. Always think of your non-<em>mod-reg-rm</em> alternatives.) Clearly, the choice of addressing mode matters considerably inside tight loops.</p>
<p>We’ve learned two basic rules, then: 1) <em>use displacement-free mod-reg-rm addressing modes whenever you can</em>, and 2) <em>calculate memory addresses outside loops and use base-only or index-only addressing whenever possible</em>. The <code class="sourceCode nasm"><span class="kw">lea</span></code> instruction, which we’ll get to shortly, is most useful for calculating memory addresses outside loops.</p>
</section>
<section id="mod-reg-rm-addressing-slow-but-not-quite-as-slow-as-you-think" class="level3">
<h3><em>mod-reg-rm</em> Addressing: Slow, but Not <em>Quite</em> as Slow as You Think</h3>
<p>There’s no doubt about it: <em>mod-reg-rm</em> addressing is slow. Still, relative to register operands, <em>mod-reg-rm</em> operands might not be quite so slow as you think, for a very strange reason — the prefetch queue. <em>mod-reg-rm</em> addressing executes so slowly that it allows time for quite a few instruction bytes to be prefetched, and that means that instructions that use <em>mod-reg-rm</em> addressing often run at pretty much their official speed.</p>
<p>Consider this. <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,<span class="kw">bl</span></code> is a 2-byte, 2-cycle instruction. String a few such instructions together and the prefetch queue empties, making the actual execution time 8 cycles — the time it takes to fetch the instruction bytes.</p>
<p>By contrast, <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,[<span class="kw">bx</span>]</code> is a 2-byte, 13-cycle instruction. Counting both the memory access needed to read the operand pointed to by BX and the two instruction fetches, only 3 memory accesses are incurred by this instruction. Since 3 memory accesses take only 12 cycles, the 13-cycle official execution time of <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,[<span class="kw">bx</span>]</code> is a fair reflection of the instruction’s true performance.</p>
<p>That doesn’t mean that <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,[<span class="kw">bx</span>]</code> is <em>faster</em> than <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,<span class="kw">bl</span></code>, or that memory-accessing instructions are faster than register-only instructions — they’re not. <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,<span class="kw">bl</span></code> is a minimum of about 50% faster than <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,[<span class="kw">bx</span>]</code> under any circumstances. What it does mean is that memory-accessing instructions tend to suffer less from the prefetch queue cycle-eater than do register-only instructions, because the considerably longer execution times of memory-accessing instructions often allow a good deal of prefetching per instruction byte executed. As a result, the performance difference between the two is often not quite so great as official execution times would indicate.</p>
<p>In short, memory-accessing instructions, especially those that use <em>mod-reg-rm</em> addressing, generally have a better balance between overall memory access time and execution time than register-only instructions, and consequently run closer to their rated speeds. That’s a mixed blessing, since it’s a side effect of the slow speed of memory-accessing instructions, but it does make memory access — which is, after all, a necessary evil — somewhat less unappealing than it might seem.</p>
<p>Let me emphasize that the basic reason that instructions that use <em>mod-reg-rm</em> memory accesses suffer less from the prefetch queue cycle-eater than do equivalent register-only instructions is that both sorts of instructions have <em>mod-reg-rm</em> bytes. True, register-only <em>mod-reg-rm</em> instructions don’t have EA calculation times, but they do have at least 2 bytes, making them as long as the shortest <em>mod-reg-rm</em> memory-accessing instructions. (A number of non-<em>mod-reg-rm</em> instructions are just 1 byte long; we’ll meet them over the next few chapters.) Since register-only instructions are much faster than memory-accessing instructions, it’s just common sense that if they’re the same length in bytes then they can be hit much harder by the prefetch queue cycle-eater.</p>
<p>Still and all, register-only <em>mod-reg-rm</em> instructions are <em>never</em> longer than memory-accessing <em>mod-reg-rm</em> instructions, and are shorter than memory-accessing instructions that use displacements. What’s more, since memory-accessing instructions must by definition access memory at least once apart from fetching instruction bytes, register-only <em>mod-reg-rm</em> instructions must be at least 50% faster than their memory-accessing equivalents — 100% when word-sized operands are used. To sum up, register-only instructions are always much faster and often smaller than equivalent <em>mod-reg-rm</em> memory-accessing instructions. (Register-only instructions are faster than, although not necessarily shorter than or even as short as, non-<em>mod-reg-rm</em> instructions — even the string instructions — as well.)</p>
<p><em>Avoid memory. Use the registers as much as you possibly can.</em></p>
</section>
<section id="the-importance-of-addressing-well" class="level3">
<h3>The Importance of Addressing Well</h3>
<p>When you do use <em>mod-reg-rm</em> addressing, do so efficiently. As we’ve discussed, that means using base-or index-only addressing whenever possible, and avoiding displacements when you can, especially inside loops. If you’re only going to access a memory location once and you don’t have a pointer to that location already loaded into BX, BP, SI, or DI, just use direct addressing; base-and index-only addressing aren’t so much faster than direct addressing that it pays to load a pointer. As we’ve seen, however, don’t use direct addressing inside a loop if you can load a pointer register outside the loop and then use base-or index-only addressing inside the loop.</p>
<p>It’s often surprising how much more efficient than direct addressing base-and index-only addressing are. Consider this simple bit of code:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">dl</span>,[ByteVar]
<span class="kw">and</span>   <span class="kw">dl</span><span class="bn">,0fh</span>
<span class="kw">mov</span>   [ByteVar],<span class="kw">dl</span></code></pre>
<p>You wouldn’t think that code could be improved upon by <em>adding</em> an instruction, but we can cut the code’s size from 10 to 9 bytes by using base-only addressing:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">bx</span>,offset ByteVar
<span class="kw">mov</span>   <span class="kw">dl</span>,[<span class="kw">bx</span>]
<span class="kw">and</span>   <span class="kw">dl</span><span class="bn">,0fh</span>
<span class="kw">mov</span>   [<span class="kw">bx</span>],<span class="kw">dl</span></code></pre>
<p>The cycle count is 2 higher for the latter version, but a 2-byte advantage in instruction fetching could well overcome that.</p>
<p>The point is not that base-only addressing is always the best solution. In fact, the latter example could be made much more efficient simply by anding 0Fh directly with memory, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">and</span>   [ByteVar]<span class="bn">,0fh</span></code></pre>
<p>(Always bear in mind that memory can serve as the destination operand as well as the source operand. When only one modification is involved, it’s always faster to modify a memory location directly, as in the last example, than it is to load a register, modify the register, and store the register back to memory. However, the scales tip when two or more modifications to a memory operand are involved, as we’ll see in Chapter 8.) The special accumulator-specific direct-addressing instructions that we’ll discuss in the next chapter make direct addressing more desirable in certain circumstances as well.</p>
<p>The point is that for repeated accesses to the same memory location, you should arrange your code so that the most efficient possible instruction — base-only, a string instruction, whatever fills the bill — can be used. In the last example, base-only addressing was superior to direct addressing when just two accesses to the same byte were involved. Multiply the number of accesses by ten, or a hundred, or a thousand, as is often the case in a tight loop, and you’ll get a feel for the importance of selecting the correct memory addressing mode in your time-critical code.</p>
</section>
<section id="the-8088-is-faster-at-memory-address-calculations-than-you-are" class="level3">
<h3>The 8088 is Faster at Memory Address Calculations Than You Are</h3>
<p>You may recall that we found earlier that when you must access a word-sized memory operand, it is better to let the 8088 access the second byte than to do it with a separate instruction; the 8088 is simply faster at accessing two adjacent bytes than any two instructions can be. Much the same is true of <em>mod-reg-rm</em> addressing; the 8088 is faster at performing memory address calculations than you are. If you must add registers and/or constant values to address memory, the 8088 can do it faster during EA calculations than you can with separate instructions.</p>
<p>Suppose that we have to initialize a doubleword of memory pointed to by BX to zero. We could do that with:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="dt">word</span> <span class="dt">ptr</span> [<span class="kw">bx</span>],<span class="dv">0</span>
<span class="kw">inc</span>   <span class="kw">bx</span>
<span class="kw">inc</span>   <span class="kw">bx</span>
<span class="kw">mov</span>   <span class="dt">word</span> <span class="dt">ptr</span> [<span class="kw">bx</span>],<span class="dv">0</span></code></pre>
<p>However, it’s better to let the 8088 do the addressing calculations, as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="dt">word</span> <span class="dt">ptr</span> [<span class="kw">bx</span>],<span class="dv">0</span>
<span class="kw">mov</span>   <span class="dt">word</span> <span class="dt">ptr</span> [<span class="kw">bx</span><span class="dv">+2</span>],<span class="dv">0</span></code></pre>
<p>True, the latter version involves a 1-byte displacement, but that displacement is smaller than the 2 bytes required to advance BX in the first version. Since the incremental cost of base+displacement addressing over base-only addressing is 4 cycles, exactly the same number of cycles as two <code class="sourceCode nasm"><span class="kw">inc</span></code> instructions, the code that uses base+displacement addressing is clearly superior.</p>
<p>Similarly, you’re invariably better off letting EA calculations add one register to another than you are using <code class="sourceCode nasm"><span class="kw">add</span></code>. For example, consider two approaches to scanning an array pointed to by BX+SI for the byte in AL:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">mov</span>   <span class="kw">dx</span>,<span class="kw">bx</span>     <span class="co">;set aside the base address</span>
<span class="fu">ScanLoop:</span>
    <span class="kw">mov</span>   <span class="kw">bx</span>,<span class="kw">dx</span>     <span class="co">;get back the base address</span>
    <span class="kw">add</span>   <span class="kw">bx</span>,<span class="kw">si</span>     <span class="co">;add in the index</span>
    <span class="kw">cmp</span>   [<span class="kw">bx</span>],<span class="kw">al</span>   <span class="co">;is this a match?</span>
    <span class="kw">jz</span>    ScanFound <span class="co">;yes, we&#39;re done</span>
    <span class="kw">inc</span>   <span class="kw">si</span>        <span class="co">;advance the index to the next byte</span>
    <span class="kw">jmp</span>   ScanLoop  <span class="co">;scan the next byte</span>
<span class="fu">ScanFound:</span></code></pre>
<p>and:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="fu">ScanLoop:</span>
    <span class="kw">cmp</span>   [<span class="kw">bx</span>+<span class="kw">si</span>],<span class="kw">al</span>  <span class="co">;is this a match?</span>
    <span class="kw">jz</span>    ScanFound   <span class="co">;yes, we&#39;re done</span>
    <span class="kw">inc</span>   <span class="kw">si</span>          <span class="co">;advance the index to the next byte</span>
    <span class="kw">jmp</span>   ScanLoop    <span class="co">;scan the next byte</span>
<span class="fu">ScanFound:</span></code></pre>
<p>It should be pretty clear that the approach that lets the 8088 add the two memory components together is far superior.</p>
<p>While the point is perhaps a little exaggerated — I seriously doubt anyone would use the first approach — it is nonetheless valid. The 8088 can add BX to SI in just 2 extra cycles as part of an EA calculation, and at the cost of no extra bytes at all. What’s more, EA calculations leave all registers unchanged. By contrast, at least one register must be changed to hold the final memory address when you perform memory calculations yourself. That’s what makes the first version above so inefficient; we have to reload BX from DX every time through the loop because it’s altered by the memory-address calculation.</p>
<p>I hope you noticed that neither example above is particularly efficient. We’d be better off simply adding the two memory components <em>outside</em> the loop and using base-or index-only addressing inside the loop. (We’d be even better off using string instructions, but we’ll save that for another chapter.) To wit:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">add</span>   <span class="kw">si</span>,<span class="kw">bx</span>     <span class="co">;add together the memory address components</span>
                    <span class="co">;outside the loop</span>
<span class="fu">ScanLoop:</span>
    <span class="kw">cmp</span>   [<span class="kw">si</span>],<span class="kw">al</span>   <span class="co">;is this a match?</span>
    <span class="kw">jz</span>    ScanFound <span class="co">;yes, we&#39;re done</span>
    <span class="kw">inc</span>   <span class="kw">si</span>        <span class="co">;point to the next byte</span>
    <span class="kw">jmp</span>   ScanLoop  <span class="co">;scan the next byte</span>
<span class="fu">ScanFound:</span></code></pre>
<p>Although EA calculations can add faster than separate instructions can, it’s faster still not to add at all. <em>Whenever you can, perform your calculations outside loops.</em></p>
<p>Which brings us to <code class="sourceCode nasm"><span class="kw">lea</span></code>.</p>
</section>
<section id="calculating-effective-addresses-with-lea" class="level3">
<h3>Calculating Effective Addresses With <code>lea</code></h3>
<p><code class="sourceCode nasm"><span class="kw">lea</span></code> is something of an odd bird, as the only <em>mod-reg-rm</em> memory-addressing instruction that doesn’t access memory. <code class="sourceCode nasm"><span class="kw">lea</span></code> calculates the offset of the memory operand… and then loads that offset into one of the 8 general-purpose registers, without accessing memory at all. Basically, <code class="sourceCode nasm"><span class="kw">lea</span></code> is nothing more than a means by which to load the result of an EA calculation into a register.</p>
<p>For example, <code class="sourceCode nasm"><span class="kw">lea</span> <span class="kw">bx</span>,[MemVar]</code> loads the offset of <code class="sourceCode nasm">MemVar</code> into BX. Now, we wouldn’t generally want to use <code class="sourceCode nasm"><span class="kw">lea</span></code> to load simple offsets, since <code class="sourceCode nasm"><span class="kw">mov</span></code> can do that more efficiently; <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">bx</span>,offset MemVar</code> is 1 byte shorter and 4 cycles faster than <code class="sourceCode nasm"><span class="kw">lea</span> <span class="kw">bx</span>,[MemVar]</code>. (Since <code class="sourceCode nasm"><span class="kw">lea</span></code> involves EA calculation, it’s not particularly fast; however, it’s faster than any <em>mod-reg-rm</em> memory-accessing instruction, taking only 2 cycles plus the EA calculation time.)</p>
<p><code class="sourceCode nasm"><span class="kw">lea</span></code> shines when you need to load a register with a complex memory address, preferably without disturbing any of the registers that make up the memory address. Suppose that we want to push the address of an array element that’s indexed by BP+SI. We could use:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">ax</span>,offset TestArray
<span class="kw">add</span>   <span class="kw">ax</span>,<span class="kw">bp</span>
<span class="kw">add</span>   <span class="kw">ax</span>,<span class="kw">si</span>
<span class="kw">push</span>  <span class="kw">ax</span></code></pre>
<p>which is 8 bytes long. On the other hand, we could simply use:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">lea</span>   <span class="kw">ax</span>,[TestArray+<span class="kw">bp</span>+<span class="kw">si</span>]
<span class="kw">push</span>  <span class="kw">ax</span></code></pre>
<p>which is only 5 bytes long. One of the primary uses of <code class="sourceCode nasm"><span class="kw">lea</span></code> is loading offsets of variables in stack frames, because such variables are addressed with base+displacement addressing.</p>
<p>Refer back to the example we examined in the last section. Suppose that we wanted to scan memory without disturbing either BX or SI. In that case, we could use DI, with an assist from <code class="sourceCode nasm"><span class="kw">lea</span></code>:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">lea</span>   <span class="kw">di</span>,[<span class="kw">bx</span>+<span class="kw">si</span>]  <span class="co">;add together the memory address components</span>
                      <span class="co">; outside the loop</span>
<span class="fu">ScanLoop:</span>
    <span class="kw">cmp</span>   [<span class="kw">di</span>],<span class="kw">al</span>     <span class="co">;is this a match?</span>
    <span class="kw">jz</span>    ScanFound   <span class="co">;yes, we&#39;re done</span>
    <span class="kw">inc</span>   <span class="kw">di</span>          <span class="co">;point to the next byte</span>
    <span class="kw">jmp</span>   ScanLoop    <span class="co">;scan the next byte</span>
<span class="fu">ScanFound:</span></code></pre>
<p><code class="sourceCode nasm"><span class="kw">lea</span></code> is particularly handy in this case because it can add two registers — BX and SI — and place the result in a third register — DI. That enables us to replace the two instructions:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">di</span>,<span class="kw">bx</span>
<span class="kw">add</span>   <span class="kw">di</span>,<span class="kw">si</span></code></pre>
<p>with a single <code class="sourceCode nasm"><span class="kw">lea</span></code>.</p>
<p><code class="sourceCode nasm"><span class="kw">lea</span></code> should make it clear that offsets are just 16-bit numbers. Adding offsets stored in BX and SI together with <code class="sourceCode nasm"><span class="kw">lea</span></code> is no different from adding any two 16-bit numbers together with <code class="sourceCode nasm"><span class="kw">add</span></code>, because offsets are just 16-bit numbers. 0 is a valid offset; if we execute:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">sub</span>   <span class="kw">bx</span>,<span class="kw">bx</span>     <span class="co">;load BX with 0</span>
<span class="kw">mov</span>   <span class="kw">al</span>,[<span class="kw">bx</span>]   <span class="co">;load AL with the byte at offset 0 in DS</span></code></pre>
<p>we’ll read the byte at offset 0 in the segment pointed to by DS. It’s important that you understand that offsets are just numbers, and that you can manipulate offsets every bit as flexibly as any other values.</p>
<p>The flip side is that you could, if you wished, add two registers and/or a constant value together with <code class="sourceCode nasm"><span class="kw">lea</span></code> and place the result in a third register. Of course, the registers would have to be BX or BP and SI or DI, but since offsets and numbers are one and the same, there’s no reason that <code class="sourceCode nasm"><span class="kw">lea</span></code> couldn’t be used for arithmetic under the right circumstances. For example, here’s one way to add two memory variables and 52 together and store the result in DX:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">bx</span>,[MemVar1]
<span class="kw">mov</span>   <span class="kw">si</span>,[MemVar2]
<span class="kw">lea</span>   <span class="kw">dx</span>,[<span class="kw">bx</span>+<span class="kw">si</span><span class="dv">+52</span>]</code></pre>
<p>That’s not to say this is a <em>good</em> way to perform this particular task; the following is faster and uses fewer registers:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">dx</span>,[MemVar1]
<span class="kw">add</span>   <span class="kw">dx</span>,[MemVar2]
<span class="kw">add</span>   <span class="kw">dx</span>,<span class="dv">52</span></code></pre>
<p>Nonetheless, the first approach does serve to illustrate the flexibility of <code class="sourceCode nasm"><span class="kw">lea</span></code>and the equivalence of offsets and numbers.</p>
</section>
<section id="offset-wrapping-at-the-ends-of-segments" class="level3">
<h3>Offset Wrapping at the Ends of Segments</h3>
<p>Before we take our leave of <em>mod-reg-rm</em> addressing, I’d like to repeat a point made earlier that may have slipped past unnoticed. That point is that offsets wrap at the ends of segments. Offsets are 16-bit entities, so they’re limited to the range 0 to 64 K-1. However, it is possible to use two or three <em>mod-reg-rm</em> address components that together add up to a number that’s larger than 64 K. For example, the sum of the memory addressing components in the following code is 18000h:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">bx</span><span class="bn">,4000h</span>
<span class="kw">mov</span>   <span class="kw">di</span><span class="bn">,8000h</span>
<span class="kw">mov</span>   <span class="kw">ax</span>,[<span class="kw">bx</span>+<span class="kw">di</span>+0c000h]</code></pre>
<p>What happens in such a case? We found earlier that segments are limited to 64 Kb in length; is this a clever way to enlarge the effective size of a segment?</p>
<p>Alas, no. If the sum of two offset components won’t fit in 16 bits, bits 16 and above of the sum are simply ignored. In other words, <em>mod-reg-rm</em> address calculations are always performed modulo 64 K (that is, modulo 10000h), as shown in Figure 7.11. As a result, the last example will access not the word at offset 18000h but the word at offset 8000h. Likewise, the following will access the byte at offset 0:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">bx</span><span class="bn">,0ffffh</span>
<span class="kw">mov</span>   <span class="kw">dl</span>,[<span class="kw">bx</span><span class="dv">+1</span>]</code></pre>
<figure>
<img src="images/fig7.11RT.png" />
</figure>
<p>The same rule holds for all memory-accessing instructions, <em>mod-reg-rm</em> or otherwise: <em>offsets are 16-bit values; any additional bits that result from address calculations are ignored</em>. Put another way, memory addresses that reach past the end of a segment’s 64 K limit wrap back to the start of the segment. This allows the use of negative displacements, and is the reason a displacement can always reach anywhere in a segment, including addresses lower than those in the base and/or index registers, as in <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ax</span>,[<span class="kw">bx</span><span class="dv">-1</span>]</code>.</p>
</section>
</section>
<section id="non-mod-reg-rm-memory-addressing" class="level2">
<h2>Non-<em>mod-reg-rm</em> Memory Addressing</h2>
<p><em>mod-reg-rm</em> addressing is the most flexible memory addressing mode of the 8088, and the most widely-used as well, but it’s certainly not the <em>only</em> addressing mode. The 8088 also offers a number of specialized addressing modes, including stack addressing and the string instructions. These addressing modes are supported by fewer instructions than <em>mod-reg-rm</em> instructions, and are considerably more restrictive about the operands they’ll accept — but they’re also more compact and/or faster than the <em>mod-reg-rm</em> instructions.</p>
<p>Why are instructions that use the non-<em>mod-reg-rm</em> addressing modes generally superior to <em>mod-reg-rm</em> instructions? Simply this: being less flexible than <em>mod-reg-rm</em> instructions, they have fewer possible operands to specify, and so fewer instruction bits are needed. Non-<em>mod-reg-rm</em> instructions also don’t require any EA calculation time, because they don’t support the many addressing modes of the <em>mod-reg-rm</em> byte.</p>
<p>We’ll discuss five sorts of non-<em>mod-reg-rm</em> memory-addressing instructions next: special forms of common instructions, string instructions, immediate-addressing instructions, stack-oriented instructions, and <code class="sourceCode nasm"><span class="kw">xlat</span></code>, which is in a category all its own. For all these sorts of instructions, the rule is that if they’re well matched to your application, they’re almost surely worth using in preference to <em>mod-reg-rm</em> addressing. Some of the non-<em>mod-reg-rm</em> instructions, especially the string instructions, are so much faster than <em>mod-reg-rm</em> instructions that they’re worth going out of your way for, as we’ll see throughout <em>The Zen of Assembly Language</em>.</p>
<section id="special-forms-of-common-instructions" class="level3">
<h3>Special Forms of Common Instructions</h3>
<p>The 8088 offers special shorter, faster forms of several commonly used <em>mod-reg-rm</em> instructions, including <code class="sourceCode nasm"><span class="kw">mov</span></code>, <code class="sourceCode nasm"><span class="kw">inc</span></code>, and <code class="sourceCode nasm"><span class="kw">xchg</span></code>. These special forms are both shorter and less flexible than the <em>mod-reg-rm</em> forms. For example, the special form of <code class="sourceCode nasm"><span class="kw">inc</span></code> is just 1 byte long and requires only 2 cycles to execute, but can only work with 16-bit registers. By contrast, the <em>mod-reg-rm</em> form of <code class="sourceCode nasm"><span class="kw">inc</span></code> is at least 2 bytes long and takes at least 3 cycles to execute, but can work with 8-or 16-bit registers or memory locations.</p>
<p>You don’t have to specify that a special form of an instruction is to be used; the assembler automatically selects the shortest possible form of each instruction it assembles. That doesn’t mean that you don’t need to be familiar with the special forms, however. To the contrary, you need to be well aware of the sorts of instructions that have special forms, as well as the circumstances under which those special forms will be assembled. Armed with that knowledge, you can arrange your code so that the special forms will be assembled as often as possible.</p>
<p>We’ll get a solid feel for the various special forms of <em>mod-reg-rm</em> instructions as we discuss them individually in Chapters 8 and 9.</p>
</section>
<section id="the-string-instructions" class="level3">
<h3>The String Instructions</h3>
<p>The string instructions are without question the most powerful instructions of the 8088. String instructions can initialize, copy, scan, and compare arrays of data at speeds far beyond those of mortal <em>mod-reg-rm</em> instructions, and lend themselves well to almost any sort of repetitive processing. In fact, string instructions are so important that they get two full chapters of <em>The Zen of Assembly Language</em> — Chapters 10 and 11 — to themselves. We’ll defer further discussion of these extremely important instructions until then.</p>
</section>
<section id="immediate-addressing" class="level3">
<h3>Immediate Addressing</h3>
<p>Immediate addressing is a form of memory addressing in which the constant value of one operand is built right into the instruction. You should think of immediate operands as being addressed by IP, since they directly follow opcode bytes or <em>mod-reg-rm</em> bytes, as shown in Figure 7.12.</p>
<figure>
<img src="images/fig7.12RT.png" />
</figure>
<p>Instructions that use immediate addressing are clearly faster than instructions that use <em>mod-reg-rm</em> addressing. In fact, according to official execution times, immediate addressing would seem to be <em>much</em> faster than <em>mod-reg-rm</em> addressing. For example, <code class="sourceCode nasm"><span class="kw">add</span> <span class="kw">ax</span>,<span class="dv">1</span></code> is a 4-cycle instruction, while <code class="sourceCode nasm"><span class="kw">add</span> <span class="kw">ax</span>,[<span class="kw">bx</span>]</code> is an 18-cycle instruction. What’s more, <code class="sourceCode nasm"><span class="kw">add</span> reg,immed</code> is just 1 cycle slower than <code class="sourceCode nasm"><span class="kw">add</span> reg,reg</code>, so immediate addressing seems to be nearly as fast as register addressing.</p>
<p>The official cycle counts are misleading, however. While immediate addressing is certainly faster than <em>mod-reg-rm</em> addressing, it is by no means as fast as register-only addressing, and the reason is a familiar one: the prefetch queue cycle-eater. You see, immediate operands are instruction bytes; when we use an immediate operand, we increase the size of that instruction, and that increases the number of cycles needed to fetch the instruction’s bytes.</p>
<p>Looked at another way, immediate operands need to be fetched from the memory location pointed to by IP, so immediate addressing could be considered a memory addressing mode. Granted, immediate addressing is an efficient memory addressing mode, with no EA calculation time or the like — but memory accesses are nonetheless required, at the inescapable 4 cycles per byte.</p>
<p>The upshot is simply that register operands are superior to immediate operands in loops and time-critical code, although immediate operands are still much better than <em>mod-reg-rm</em> memory operands. Back in <a href="#listing-7-11">Listing 7-11</a>, we set DL to 0 outside the loop so that we could use register-register <code class="sourceCode nasm"><span class="kw">adc</span></code> inside the loop. That approach allowed the code to run in 0.95 ms. <a href="#listing-7-12">Listing 7-12</a> is similar to <a href="#listing-7-11">Listing 7-11</a>, but is modified to use an immediate operand of 0 rather than a register operand containing 0. Even though the immediate operand is only byte-sized, <a href="#listing-7-12">Listing 7-12</a> slows down to 1.02 ms. In other words, the need to fetch just 1 immediate operand byte every time through the loop slowed the entire loop by about 7%. What’s more, the performance loss would have been approximately twice as great if we had used a word-sized immediate operand.</p>
<p>On the other hand, immediate operands are certainly preferable to memory operands. <a href="#listing-7-13">Listing 7-13</a>, which adds the constant value 0 from memory, runs in 1.26 ms. (I should hope you’ll never use code as obviously inefficient as <a href="#listing-7-13">Listing 7-13</a>; I’m just presenting it for illustrative purposes.)</p>
<p>To sum up: when speed matters, use register operands rather than immediate operands if you can. If registers are at a premium, however, immediate operands are reasonably fast, and are certainly better than memory operands. If bytes rather than cycles are at a premium, immediate operands are excellent, for it takes fewer bytes to use an immediate operand than it does to load a register with a constant value and then use that register. For example:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="fu">LoopTop:</span>
    <span class="kw">or</span>    <span class="dt">byte</span> <span class="dt">ptr</span> [<span class="kw">bx</span>]<span class="bn">,80h</span>
    <span class="kw">loop</span>  LoopTop</code></pre>
<p>is 1 byte shorter than:</p>
<pre><code>    mov   al,80h
LoopTop:
    or    [bx],al
    loop  LoopTop</code></pre>
<p>However, the latter, register-only version is faster, because it moves 2 bytes out of the loop.</p>
<p>There are many circumstances in which we can substitute register-only instructions for instructions that use immediate operands <em>without</em> adding any extra instructions. The commonest of these cases involve testing for zero. There’s almost never a need to compare a register to zero; instead, we can simply <code class="sourceCode nasm"><span class="kw">and</span></code> or <code class="sourceCode nasm"><span class="kw">or</span></code> the register with itself and check the resulting flags. We’ll discuss ways to handle zero in the next two chapters, and we’ll see similar cases in which immediate operands can be eliminated throughout <em>The Zen of Assembly Language</em>.</p>
<p>By the way, you should be aware that you can use an immediate operand even when the other operand is a memory variable rather than a register. For example, <code class="sourceCode nasm"><span class="kw">add</span> [MemVar],<span class="dv">16</span></code> is a valid instruction, as is <code class="sourceCode nasm"><span class="kw">mov</span> [MemVar],<span class="dv">52</span></code>. As I mentioned earlier, we’re better off performing single operations directly to memory than we are loading from memory into a register, operating on the register, and storing the result back to memory. However, we’re generally better off working with a register when multiple operations are involved.</p>
<p>Ideally, we’d load a memory value into a register, perform multiple operations on it there, store the result back to memory… and then have some additional use for the value left in the register, thereby getting double use out of our memory accesses. For example, suppose that we want to perform the equivalent of the C statement:</p>
<pre class="sourceCode c"><code class="sourceCode c">i = ++j + k;</code></pre>
<p>We could do this as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">inc</span>   [j]
<span class="kw">mov</span>   <span class="kw">ax</span>,[j]
<span class="kw">add</span>   <span class="kw">ax</span>,[k]
<span class="kw">mov</span>   [i],<span class="kw">ax</span></code></pre>
<p>However, we can eliminate a memory access by incrementing <code class="sourceCode nasm">j</code> in a register:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">ax</span>,[j]
<span class="kw">inc</span>   <span class="kw">ax</span>
<span class="kw">mov</span>   [j],<span class="kw">ax</span>
<span class="kw">add</span>   <span class="kw">ax</span>,[k]
<span class="kw">mov</span>   [i],<span class="kw">ax</span></code></pre>
<p>While the latter version is one instruction longer than the original version, it’s actually faster and shorter. One reason for this is that we get double use out of loading <code class="sourceCode nasm">j</code> into AX; we increment <code class="sourceCode nasm">j</code> in AX and store the result to memory, then immediately use the incremented value left in AX as part of the calculation being performed.</p>
<p>The other reason the second example above is superior to the original version is that it used two of the special, more efficient instruction forms: the accumulator-specific direct-addressed form of <code class="sourceCode nasm"><span class="kw">mov</span></code> and the 16-bit register-only form of <code class="sourceCode nasm"><span class="kw">inc</span></code>. We’ll study these instructions in detail in Chapters 8 and 9.</p>
</section>
<section id="sign-extension-of-immediate-operands" class="level3">
<h3>Sign-Extension of Immediate Operands</h3>
<p>I’ve already noted that immediate operands tend to make for compact code. One key to this property is that like displacements in <em>mod-reg-rm</em> addressing, word-sized immediate operands can be stored as a byte and then extended to a word by replicating bit 7 as bits 15-8; that is, word-sized immediate operands can be sign-extended. Almost all instructions that support immediate operands allow word-sized operands in the range -128 to +127 to be stored as single bytes. That means that while <code class="sourceCode nasm"><span class="kw">and</span> <span class="kw">dx</span><span class="bn">,1000h</span></code> is a 4-byte instruction (1 opcode byte, 1 <em>mod-reg-rm</em> byte, and a 2-byte immediate operand), <code class="sourceCode nasm"><span class="kw">and</span> <span class="kw">dx</span><span class="bn">,0fffeh</span></code> is just 3 bytes long; since the signed value of the immediate operand 0FFFEh is -2, 0FFFEh is stored as a single immediate operand byte.</p>
<p>Not all values of the form 000<em>nn</em>h and 0FF<em>nn</em>h (where <em>nn</em> is any two hex digits) can be stored as a single byte and sign-extended. 0007Fh can be stored as a single byte; 00080h cannot. 0FF80h can be stored as a single byte; 0FF7Fh cannot. Watch out for cases where you’re using a word-sized immediate operand that can’t be stored as a byte, when a byte-sized immediate operand would serve as well.</p>
<p>For example, suppose we want to set the lower 8 bits of DX to 0. <code class="sourceCode nasm">{.nasm}<span class="kw">and</span> <span class="kw">dx</span><span class="bn">,0ff00h</span></code> is a 4-byte instruction that accomplishes the desired result. <code class="sourceCode nasm"><span class="kw">and</span> <span class="kw">dl</span><span class="bn">,000h</span></code> produces the same result in just 3 bytes. (Of course, <code class="sourceCode nasm"><span class="kw">sub</span> <span class="kw">dl</span>,<span class="kw">dl</span></code> does the same thing in just 2 bytes — there are <em>many</em> ways to skin a cat in assembler.) Recognizing when a word-sized immediate operand can be handled as a byte-sized operand is still more important when using accumulator-specific immediate-operand instructions, which we’ll explore in the next chapter.</p>
</section>
<section id="mov-doesnt-sign-extend-immediate-operands" class="level3">
<h3><code>mov</code> Doesn’t Sign-Extend Immediate Operands</h3>
<p>Along the same lines, <code class="sourceCode nasm"><span class="kw">or</span> <span class="kw">bh</span><span class="bn">,0ffh</span></code> does the same thing as <code class="sourceCode nasm"><span class="kw">or</span> <span class="kw">bx</span><span class="bn">,0ff00h</span></code> and is shorter, while <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">bh</span><span class="bn">,0ffh</span></code> is also equivalent and is shorter still… and that brings us to the one instruction which cannot sign-extend immediate operands: <code class="sourceCode nasm"><span class="kw">mov</span></code>. Word-sized operands to <code class="sourceCode nasm"><span class="kw">mov</span></code> are always stored as words, no matter what size they may be. However, there’s a compensating factor, and that’s that there’s a special, non-<em>mod-reg-rm</em> form of <code class="sourceCode nasm"><span class="kw">mov</span> reg,immed</code> that’s 1 byte shorter than the <em>mod-reg-rm</em> form.</p>
<p>Let me put it this way. <code class="sourceCode nasm"><span class="kw">and</span> <span class="kw">dx</span><span class="bn">,1000h</span></code> is a 4-byte instruction, with 1 opcode byte, 1 <em>mod-reg-rm</em> byte, and a 2-byte immediate operand. <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">dx</span><span class="bn">,1000h</span></code>, on the other hand, is only 3 bytes long. There’s a special form of the <code class="sourceCode nasm"><span class="kw">mov</span></code> instruction, used only when a register is loaded with an immediate value, that requires just the 1 opcode byte in addition to the immediate value.</p>
<p>There’s also the standard <em>mod-reg-rm</em> form of <code class="sourceCode nasm"><span class="kw">mov</span></code>, which is 4 bytes long for word-sized immediate operands. This form does exactly the same thing as the special form, but is a different instruction, with a different opcode and a <em>mod-reg-rm</em> byte. The 8088 offers a number of duplicate instructions, as we’ll see in the next chapter. Don’t worry about selecting the right form of <code class="sourceCode nasm"><span class="kw">mov</span></code>, however; the assembler does that for you automatically.</p>
<p>In short, you’re no worse off — and often better off — moving immediate values into registers than you are using immediate operands with instructions such as <code class="sourceCode nasm"><span class="kw">add</span></code> and <code class="sourceCode nasm"><span class="kw">xor</span></code>. It takes just 2 or 3 bytes, for byte-or word-sized registers, respectively, to load a register with an immediate operand. <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,<span class="dv">2</span></code> is actually the same size as <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,<span class="kw">bl</span></code> (both are 2 bytes), although the official execution time of the register-only <code class="sourceCode nasm"><span class="kw">mov</span></code> is 2 cycles shorter.</p>
<p>On balance, immediate operands used with <code class="sourceCode nasm"><span class="kw">mov</span> reg,immed</code> perform at nearly the speed of register operands, especially when the register is byte-sized; consequently, there’s less need to avoid immediate operands with <code class="sourceCode nasm"><span class="kw">mov</span></code> than with other instructions. Nonetheless, register-only instructions are never slower, so you won’t go wrong using register rather than immediate operands.</p>
</section>
<section id="dont-mov-immediate-operands-to-memory-if-you-can-help-it" class="level3">
<h3>Don’t <code>mov</code> Immediate Operands to Memory if You Can Help It</h3>
<p>One final note, and then we’re done with immediate addressing. There is <em>no</em> special form of <code class="sourceCode nasm"><span class="kw">mov</span></code> for moving an immediate operand to a memory operand; the special form is limited to register operands only. What’s more, <code class="sourceCode nasm"><span class="kw">mov</span> [mem16],immed16</code> has no sign-extension capability. This double whammy means that storing immediate values to memory is the single least desirable way to use immediate operands. Over the next few chapters, we’ll explore several ways to set memory operands to given values. The one thing that the various approaches have in common is that they all improve performance by avoiding immediate operands to <code class="sourceCode nasm"><span class="kw">mov</span></code>.</p>
<p><em>Don’t move immediate values to memory unless you have no choice.</em></p>
</section>
<section id="stack-addressing" class="level3">
<h3>Stack Addressing</h3>
<p>While SP can’t be used to point to memory by <em>mod-reg-rm</em> instructions, it is nonetheless a memory-addressing register. After all, SP is used to address the top of the stack. Surely you know how the stack works, so I’ll simply note that SP points to the data item most recently pushed onto the top of the stack that has not yet been popped off the stack. Consequently, stack data can only be accessed in Last In, First Out (LIFO) order via SP (that is, the order in which data is popped off the stack is the reverse of the order in which it was pushed on). However, other addressing modes — in particular <em>mod-reg-rm</em> BP-based addressing — can be used to access stack data in non-LIFO order, as we’ll see when we discuss stack frames.</p>
<p>What’s so great about the stack? Simply put, the stack is terrific for temporary storage. Each named memory variable, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">MemVar  <span class="dt">dw</span> <span class="dv">0</span></code></pre>
<p>takes up 1 or more bytes of memory for the duration of the program. That’s not the case with stack data, however; when data is popped from the stack, the space it occupied is freed up for other use. In other words, stack memory is a reusable resource. This makes the stack an excellent place to store temporary data, especially when large data elements such as buffers and structures are involved.</p>
<p>Space allocated on the stack is also unique for each invocation of a given subroutine, which is useful for any subroutine that needs to be capable of being called directly or indirectly from itself. Stack-based storage is how C implements automatic (dynamic) variables, which are unique for each invocation of a given subroutine. In fact, stack-based storage is the heart of the parameter-passing mechanism used by most C implementations, as well as the mechanism used for automatic variables, as we’ll see shortly.</p>
<p>Don’t underestimate the flexibility of the stack. I’ve heard of programs that actually compile code right into a buffer on the stack, then execute that code in place, <em>on the stack</em>. While that’s a strange concept, stack memory is memory like any other, and instruction bytes are data; obviously, those programs needed a temporary place in which to compile code, run it, and discard it, and the stack fits those requirements nicely.</p>
<p>Similarly, suppose that we need to pass a pointer to a variable from an assembler program to a C subroutine… but there’s no variable to point to in the assembler code, because we keep the variable in a register. Suppose also that the C subroutine actually modifies the pointed-to variable, so we need to retrieve the altered value after the call. The stack is admirably suited to the job; at the beginning of the following code, the variable of interest is in DX, and that’s just where the modified result is at the end of the code:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="co">;</span>
<span class="co">; Calls: int CSubroutine(int *Count, char *BufferPointer).</span>
<span class="co">;</span>
<span class="kw">mov</span>   <span class="kw">dx</span>,MAX_COUNT          <span class="co">;store the maximum # of bytes to handle</span>
                            <span class="co">; in the count variable</span>
<span class="kw">push</span>  <span class="kw">dx</span>                    <span class="co">;store the count variable on the stack</span>
                            <span class="co">; for the duration of the call</span>
<span class="kw">mov</span>   <span class="kw">dx</span>,<span class="kw">sp</span>                 <span class="co">;put a pointer to the just-pushed temporary</span>
                            <span class="co">; count variable in DX</span>
<span class="kw">mov</span>   <span class="kw">ax</span>,offset TestBuffer
<span class="kw">push</span>  <span class="kw">ax</span>                    <span class="co">;pass the buffer pointer parameter</span>
<span class="kw">push</span>  <span class="kw">dx</span>                    <span class="co">;pass the count pointer parameter</span>
<span class="kw">call</span>  CSubroutine           <span class="co">;do the count</span>
<span class="kw">add</span>   <span class="kw">sp</span>,<span class="dv">4</span>                  <span class="co">;clear the parameter bytes from the stack</span>
<span class="kw">pop</span>   <span class="kw">dx</span>                    <span class="co">;get the actual count back into DX</span></code></pre>
<p>The important point in the above code is that we created a temporary memory variable on the stack as we needed it; then, when the call was over, we simply popped the variable back into DX, and its space on the stack was freed up for other use. The code is compact, and not a single byte of memory storage had to be reserved permanently.</p>
<p>Compact code without the need for permanent memory space is the hallmark of stack-based code. It’s often possible to write amazingly complex code without using <em>mod-reg-rm</em> addressing or named variables simply by pushing and popping registers. The code tends to be compact because <code class="sourceCode nasm"><span class="kw">push</span> reg16</code> and <code class="sourceCode nasm"><span class="kw">pop</span> reg16</code> are each only 1 byte long. <code class="sourceCode nasm"><span class="kw">push</span> reg16</code> and <code class="sourceCode nasm"><span class="kw">pop</span> reg16</code> are so compact because they don’t need to support the complex memory-addressing options of <em>mod-reg-rm</em> addressing; there are only 8 possible register operands, and each instruction can only address one location, by way of the stack pointer, at any one time. (<code class="sourceCode nasm"><span class="kw">push</span> mem16</code> and <code class="sourceCode nasm"><span class="kw">pop</span> mem16</code> are <em>mod-reg-rm</em> instructions, and so they’re 2-4 bytes long; <code class="sourceCode nasm"><span class="kw">push</span> reg16</code> and <code class="sourceCode nasm"><span class="kw">pop</span> reg16</code>, and <code class="sourceCode nasm"><span class="kw">push</span> segreg</code> and <code class="sourceCode nasm"><span class="kw">pop</span> segreg</code> as well, are special, shorter forms of <code class="sourceCode nasm"><span class="kw">push</span></code> and <code class="sourceCode nasm"><span class="kw">pop</span></code>.)</p>
<p>For once, though, shorter isn’t necessarily better. You see, <code class="sourceCode nasm"><span class="kw">push</span></code> and <code class="sourceCode nasm"><span class="kw">pop</span></code> are memory-accessing instructions, and although they don’t require EA calculation time, they’re still slow -like all instructions that access memory. <code class="sourceCode nasm"><span class="kw">push</span></code> and <code class="sourceCode nasm"><span class="kw">pop</span></code> are fast considering that they are word-sized memory-accessing instructions -<code class="sourceCode nasm"><span class="kw">push</span></code> takes 15 cycles, <code class="sourceCode nasm"><span class="kw">pop</span></code> takes just 12 — and they make for good prefetching, since only 3 memory accesses (including instruction fetches) are performed during an official execution time of 12 to 15 cycles. Nonetheless, they’re clearly slower than register-only instructions. This is basically the same case we studied when we looked into copying segments; it’s faster but takes more bytes and requires a free register to preserve a register by copying it to another register:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">dx</span>,<span class="kw">ax</span>
:
<span class="kw">mov</span>   <span class="kw">ax</span>,<span class="kw">dx</span></code></pre>
<p>than it is to preserve it by pushing and popping it:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">push</span>  <span class="kw">ax</span>
:
<span class="kw">pop</span>   <span class="kw">ax</span></code></pre>
<p>What does all this mean to you? Simply this: use a free register for temporary storage if speed is of the essence, and <code class="sourceCode nasm"><span class="kw">push</span></code> and <code class="sourceCode nasm"><span class="kw">pop</span></code> if code size is your primary concern, if speed is not an issue, or if no registers happen to be free. In any case, it’s faster and far more compact to store register values temporarily by pushing and popping them than it is to store them to memory with <em>mod-reg-rm</em> instructions. So use <code class="sourceCode nasm"><span class="kw">push</span></code> and <code class="sourceCode nasm"><span class="kw">pop</span></code>… but remember that they come with substantial performance overhead relative to register-only instructions.</p>
</section>
<section id="an-example-of-avoiding-push-and-pop" class="level3">
<h3>An Example of Avoiding <code>push</code> and <code>pop</code></h3>
<p>Let’s quickly look at an example of improving performance by using register-only instructions rather than <code class="sourceCode nasm"><span class="kw">push</span></code> and <code class="sourceCode nasm"><span class="kw">pop</span></code>. When copying images into display memory, it’s common to use code like:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="co">;</span>
<span class="co">; Copies an image into display memory.</span>
<span class="co">;</span>
<span class="co">; Input:</span>
<span class="co">;     BX = width of image in bytes</span>
<span class="co">;     DX = height of image in lines</span>
<span class="co">;     BP = number of bytes from the start of one line to the</span>
<span class="co">;          start of the next</span>
<span class="co">;     DS:SI = pointer to image to draw</span>
<span class="co">;     ES:DI = display memory address at which to draw image</span>
<span class="co">;     Direction flag must be cleared on entry</span>
<span class="co">;</span>
<span class="co">; Output:</span>
<span class="co">;     none</span>
<span class="co">;</span>
<span class="fu">DrawLoop:</span>
    <span class="kw">push</span>  <span class="kw">di</span>        <span class="co">;remember where the line starts</span>
    <span class="kw">mov</span>   <span class="kw">cx</span>,<span class="kw">bx</span>     <span class="co">;# of bytes per line</span>
    rep   <span class="kw">movsb</span>     <span class="co">;copy the next line</span>
    <span class="kw">pop</span>   <span class="kw">di</span>        <span class="co">;get back the line start offset</span>
    <span class="kw">add</span>   <span class="kw">di</span>,<span class="kw">bp</span>     <span class="co">;point to the next line in display memory</span>
    <span class="kw">dec</span>   <span class="kw">dx</span>        <span class="co">;repeat if there are any more lines</span>
    <span class="kw">jnz</span>   DrawLoop</code></pre>
<p>That’s fine, but 1 <code class="sourceCode nasm"><span class="kw">push</span></code> and 1 <code class="sourceCode nasm"><span class="kw">pop</span></code> are performed per line, which seems a shame… all the more so given that we can eliminate those pushes and pops altogether, as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="co">;</span>
<span class="co">; Copies an image into display memory.</span>
<span class="co">;</span>
<span class="co">; Input:</span>
<span class="co">;     BX = width of image in bytes</span>
<span class="co">;     DX = height of image in lines</span>
<span class="co">;     BP = number of bytes from the start of one line to the</span>
<span class="co">;          start of the next</span>
<span class="co">;     DS:SI = pointer to image to draw</span>
<span class="co">;     ES:DI = display memory address at which to draw image</span>
<span class="co">;     Direction flag must be cleared on entry</span>
<span class="co">;</span>
<span class="co">; Output:</span>
<span class="co">;     none</span>
<span class="co">;</span>
    <span class="kw">sub</span>   <span class="kw">bp</span>,<span class="kw">bx</span>     <span class="co">;# of bytes from the end of 1 line of the</span>
                    <span class="co">; image in display memory to the start of</span>
                    <span class="co">; the next line of the image</span>
<span class="fu">DrawLoop:</span>
    <span class="kw">mov</span>   <span class="kw">cx</span>,<span class="kw">bx</span>     <span class="co">;# of bytes per line</span>
    rep   <span class="kw">movsb</span>     <span class="co">;copy the next line</span>
    <span class="kw">add</span>   <span class="kw">di</span>,<span class="kw">bp</span>     <span class="co">;point to the next line in display memory</span>
    <span class="kw">dec</span>   <span class="kw">dx</span>        <span class="co">;repeat if there are any more lines</span>
    <span class="kw">jnz</span>   DrawLoop</code></pre>
<p>Do you see what we’ve done? By converting an obvious solution (advancing 1 full line at a time) to a less-obvious but fully equivalent solution (advancing only the remaining portion of the line), we’ve saved about 27 cycles per loop… <em>at no cost</em>. Given inputs like the width of the screen and instructions like <code class="sourceCode nasm"><span class="kw">push</span></code> and <code class="sourceCode nasm"><span class="kw">pop</span></code>, we tend to use them; it’s just human nature to frame solutions in familiar terms. By rethinking the problem just a little, however, we can often find a simpler, better solution.</p>
<p>Saving 27 cycles not by knowing more instructions but by <em>not</em> using two powerful instructions is an excellent example indeed of the Zen of assembler.</p>
</section>
<section id="miscellaneous-notes-about-stack-addressing" class="level3">
<h3>Miscellaneous Notes About Stack Addressing</h3>
<p>Before we proceed to stack frames, I’d like to take a moment to review a few important points about stack addressing.</p>
<p>SP always points to the next item to be popped from the stack. When you push a value onto the stack, SP is first decremented by 2, and then the value is stored at the location pointed to by SP. When you pop a value off of the stack, the value is read from the location pointed to by SP, and then SP is incremented by 2. It’s useful to know this whenever you need to point to data stored on the stack, as we did when we created and pointed to a temporary variable on the stack a few sections back, and as we will need to do when we work with stack frames.</p>
<p><code class="sourceCode nasm"><span class="kw">push</span></code> and <code class="sourceCode nasm"><span class="kw">pop</span></code> can work with <em>mod-reg-rm</em>-addressed memory variables as easily as with registers, albeit more slowly and with more instruction bytes. <code class="sourceCode nasm"><span class="kw">push</span> [WordVar]</code> is perfectly legitimate, as is <code class="sourceCode nasm"><span class="kw">pop</span> <span class="dt">word</span> <span class="dt">ptr</span> [<span class="kw">bx</span>+<span class="kw">si</span>+100h]</code>. Bear in mind, however, that only 16-bit values can be pushed and popped; <code class="sourceCode nasm"><span class="kw">push</span> <span class="kw">bl</span></code> won’t work, and neither will <code class="sourceCode nasm"><span class="kw">pop</span> <span class="dt">byte</span> <span class="dt">ptr</span> [<span class="kw">bx</span>]</code>.</p>
<p>Finally, please remember that once you’ve popped a value from the stack, it’s gone from memory. It’s tempting to look at the way the stack pointer works and think that the data is still in memory at the address just below the new stack pointer, but that’s simply not the case, as shown in Figure 7.13. Sure, <em>sometimes</em> the data is still there — but whenever an interrupt occurs, it uses the top of the stack, wiping out the values that were most recently popped. Interrupts can happen at any time, so unless you’re willing to disable interrupts, accessing popped stack memory is a sure way to get intermittent bugs.</p>
<figure>
<img src="images/fig7.13RT.png" />
</figure>
<p>Even if interrupts are disabled, it’s really not a good idea to access popped stack data. Why bother, when stack frames give you the same sort of access to stack data, but in a straightforward, risk-free way? Not coincidentally, stack frames are our next topic, but first let me emphasize: once you’ve popped data off the stack, it’s gone from memory. Vanished. Kaput. Extinct. For all intents and purposes, that data is nonexistent.</p>
<p><em>Don’t access popped stack memory.</em> Period.</p>
</section>
<section id="stack-frames" class="level3">
<h3>Stack Frames</h3>
<p>Stack frames are transient data structures, usually local to specific subroutines, that are stored on the stack. Two sorts of data are normally stored in stack frames: parameters that are passed from the calling routine by being pushed on the stack, and variables that are local to the subroutine using the stack frame.</p>
<p>Why use stack frames? Well, as we discussed earlier, the stack is an excellent place to store temporary data, a category into which both passed parameters and local storage fall. <code class="sourceCode nasm"><span class="kw">push</span></code> and <code class="sourceCode nasm"><span class="kw">pop</span></code> aren’t good for accessing stack frames, which often contain many variables and which aren’t generally accessed in LIFO order; however, there are several <em>mod-reg-rm</em> addressing modes that are perfect for accessing stack frames — the <em>mod-reg-rm</em> addressing modes involving BP. (We can’t use SP for two reasons: it can’t serve as a memory pointer with <em>mod-reg-rm</em> addressing modes, and it changes constantly during code execution, making offsets from SP hard to calculate.)</p>
<p>If you’ll recall, BP-based addressing modes are the only <em>mod-reg-rm</em> addressing modes that don’t access DS by default. BP-based addressing modes access SS by default, and now we can see why — in order to access stack frames. Typically, BP is set to equal the stack pointer at the start of a subroutine, and is then used to point to data in the stack frame for the remainder of the subroutine, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">push</span>  <span class="kw">bp</span>          <span class="co">;save caller&#39;s BP</span>
<span class="kw">mov</span>   <span class="kw">bp</span>,<span class="kw">sp</span>       <span class="co">;point to stack frame</span>
<span class="kw">mov</span>   <span class="kw">ax</span>,[<span class="kw">bp</span><span class="dv">+4</span>]   <span class="co">;retrieve a parameter</span>
:
<span class="kw">pop</span>   <span class="kw">bp</span>          <span class="co">;restore caller&#39;s BP</span>
<span class="kw">ret</span></code></pre>
<p>If temporary local storage is needed, SP is moved to allocate the necessary room:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">push</span>  <span class="kw">bp</span>          <span class="co">;save caller&#39;s BP</span>
<span class="kw">mov</span>   <span class="kw">bp</span>,<span class="kw">sp</span>       <span class="co">;point to stack frame</span>
<span class="kw">sub</span>   <span class="kw">sp</span>,<span class="dv">10</span>       <span class="co">;allocate 10 bytes of local storage</span>
<span class="kw">mov</span>   <span class="kw">ax</span>,[<span class="kw">bp</span><span class="dv">+4</span>]   <span class="co">;retrieve a parameter</span>
<span class="kw">mov</span>   [<span class="kw">bp</span><span class="dv">-2</span>],<span class="kw">ax</span>   <span class="co">;save it in local storage</span>
:
<span class="kw">mov</span>   <span class="kw">sp</span>,<span class="kw">bp</span>       <span class="co">;dump the temporary storage</span>
<span class="kw">pop</span>   <span class="kw">bp</span>          <span class="co">;restore caller&#39;s BP</span>
<span class="kw">ret</span></code></pre>
<p>I’m not going to spend a great deal of time on stack frames, for one simple reason: they’re not all that terrific in assembler code. Stack frames are ideal for high-level languages, because they allow regular parameter-passing schemes and support dynamically allocated local variables. For assembler code, however, stack frames are quite limiting, in that they require a single consistent parameter-passing convention and the presence of code to create and destroy stack frames at the beginning and end of each subroutine. In particular, the ability of assembler code to pass pointers and variables in registers (which is much more efficient than pushing them on the stack) is constrained by standard stack frames conventions. In addition, the BP register, which is dedicated to pointing to stack frames, normally cannot be used for other purposes when stack frames are used; the loss of one of a mere seven generally-available 16-bit registers is not insignificant.</p>
<p>High-level language stack frame conventions also generally mandate the preservation of several registers — always BP, usually DS, and often SI and DI as well — and that requires time-consuming pushes and pops. Finally, while stack frame addressing is compact (owing to the heavy use of <code class="sourceCode nasm"><span class="kw">bp</span>+disp</code> addressing with 1-byte displacements), it is rather inefficient, even as memory-accessing instructions go; <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ax</span>,[<span class="kw">bp</span>+disp8]</code> is only 3 bytes long, but takes 21 cycles to execute.</p>
<p>In short, stack frames are powerful and useful — but they don’t make for the best possible 8088 code. The best <em>compiled</em> code, yes, but not the best assembler code.</p>
<p>What’s more, compilers handle stack frames very efficiently. If you’re going to work within the constraints of stack frames, you may have a difficult time out-coding compilers, which rarely miss a trick in terms of generating efficient stack frame code. Handling stack frames well is not so simple as it might seem; you have to be sure <em>not</em> to insert unneeded stack-frame-related code, such as code to load BP when there is no stack frame, and you need to be sure that you always preserve the proper registers when they’re altered, but not otherwise. It’s not hard, but it’s tedious, and it’s easy to make mistakes that either waste bytes or lead to bugs as a result of registers that should be preserved but aren’t.</p>
<p>When you work with stack frames, you’re trying to out-compile a compiler while playing by its rules, and that’s hard to do. In pure assembler code, I generally recommend against the use of stack frames, although there are surely exceptions to this rule. Personally, I often use C for the sort of code that requires stack frames, building only the subroutines that do the time-critical work in pure assembler. Why not let a compiler do the dirty work, while you focus your efforts on the code that really makes a difference?</p>
</section>
<section id="when-stack-frames-are-useful" class="level3">
<h3>When Stack Frames Are Useful</h3>
<p>That’s not to say that stack frames aren’t useful in assembler. Stack frames are not only useful but mandatory when assembler subroutines are called from high-level language code, since the stack frame approach is the sole parameter-passing mechanism for most high-level language implementations.</p>
<p>Assembler subroutines for use with high-level languages are most useful; together, assembler subroutines and high-level languages provide relatively good performance and fast development time. The <em>best</em> code is written in assembler, but the best code within a reasonable time frame is often written in a high-level language/assembler hybrid. Then, too, high-level languages are generally better than assembler for managing the complexities of very large applications.</p>
<p>In short, stack frames are generally useful in assembler when assembler is interfaced to a high-level language. High-level language interfacing and stack frame organization varies from one language to another, however, so I’m not going to cover stack frames in detail, although I will offer a few tips about using stack frames in the next section. Before I do that, I’d like to point out an excellent way to mix assembler with high-level language code: in-line assembler. Many compilers offer the option of embedding assembler code directly in high-level language code; in many cases, high-level language and assembler variables and parameters can even be shared. For example, here’s a Turbo C subroutine to set the video mode:</p>
<pre class="sourceCode c"><code class="sourceCode c"><span class="dt">void</span> SetVideoMode(<span class="dt">unsigned</span> <span class="dt">char</span> ModeNumber) {
    asm   mov   ah,<span class="dv">0</span>
    asm   mov   al,byte ptr [ModeNumber]
    asm   <span class="dt">int</span>   10h
}</code></pre>
<p>What makes in-line assembler so terrific is that it lets the compiler handle all the messy details of stack frames while freeing you to use assembler. In the above example, we didn’t have to worry about defining and accessing the stack frame; Turbo C handled all that for us, saving and setting up BP and substituting the appropriate BP+<em>disp</em> value for <code class="sourceCode nasm">ModeNumber</code>. In-line assembler is harder to use for large tasks than is pure assembler, but in most cases where the power of assembler is needed in a high-level language, in-line assembler is a very good compromise.</p>
<p>One warning: many compilers turn off some or all code optimization in subroutines that contain in-line assembler. For that reason, it’s often a good idea <em>not</em> to mix high-level language and in-line assembler statements when performance matters. Write your time-critical code either entirely in in-line assembler or entirely in pure assembler; don’t let the compiler insert code of uncertain quality when every cycle counts.</p>
<p>Still and all, when you need to create the fastest or tightest code, try to avoid stack frames except when you must interface your assembler code to a high-level language. When you must use stack frames, bear in mind that assembler is infinitely flexible; there are more ways to handle stack frames than are dreamt of in high-level languages. In Chapter 16 we’ll see an unusual but remarkably effective way to handle stack frames in a Pascal-callable assembler subroutine.</p>
</section>
<section id="tips-on-stack-frames" class="level3">
<h3>Tips on Stack Frames</h3>
<p>Before we go on to <code class="sourceCode nasm"><span class="kw">xlat</span></code>, I’m going to skim over a few items that you may find useful should you need to use stack frames in assembler code.</p>
<p>MASM provides the <code class="sourceCode nasm"><span class="kw">struc</span></code> directive for defining data structures. Such data structures can be used to access stack frames, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">Parms   <span class="kw">struc</span>
    <span class="dt">dw</span>  ?             <span class="co">;pushed BP</span>
    <span class="dt">dw</span>  ?             <span class="co">;return address</span>
X   <span class="dt">dw</span>  ?             <span class="co">;X coordinate parameter</span>
Y   <span class="dt">dw</span>  ?             <span class="co">;Y coordinate parameter</span>
Parms end
        :
DrawXY  proc  near
    <span class="kw">push</span>  <span class="kw">bp</span>          <span class="co">;save caller&#39;s stack frame pointer</span>
    <span class="kw">mov</span>   <span class="kw">bp</span>,<span class="kw">sp</span>       <span class="co">;point to stack frame</span>
    <span class="kw">mov</span>   <span class="kw">cx</span>,[<span class="kw">bp</span>+X]   <span class="co">;get X coordinate</span>
    <span class="kw">mov</span>   <span class="kw">dx</span>,[<span class="kw">bp</span>+Y]   <span class="co">;get Y coordinate</span>
          :
    <span class="kw">pop</span>   <span class="kw">bp</span>
    <span class="kw">ret</span>
DrawXY    endp</code></pre>
<p>MASM structures have a serious drawback when used with stack frames, however: they don’t allow for negative displacements from BP, which are generally used to access local variables stored on the stack. While it is possible to access local storage by accessing all variables in the stack frames at positive offsets from BP, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">Parms   <span class="kw">struc</span>
Temp    <span class="dt">dw</span>  ?           <span class="co">;temporary storage</span>
OldBP   <span class="dt">dw</span>  ?           <span class="co">;pushed BP</span>
        <span class="dt">dw</span>  ?           <span class="co">;return address</span>
X       <span class="dt">dw</span>  ?           <span class="co">;X coordinate parameter</span>
Y       <span class="dt">dw</span>  ?           <span class="co">;Y coordinate parameter</span>
Parms   end
            :
DrawXY  proc  near
    <span class="kw">push</span>  <span class="kw">bp</span>            <span class="co">;save caller&#39;s stack frame pointer</span>
    <span class="kw">sub</span>   <span class="kw">sp</span>,OldBP      <span class="co">;make room for temp storage</span>
    <span class="kw">mov</span>   <span class="kw">bp</span>,<span class="kw">sp</span>         <span class="co">;point to stack frame</span>
    <span class="kw">mov</span>   <span class="kw">cx</span>,[<span class="kw">bp</span>+X]     <span class="co">;get X coordinate</span>
    <span class="kw">mov</span>   <span class="kw">dx</span>,[<span class="kw">bp</span>+Y]     <span class="co">;get Y coordinate</span>
    <span class="kw">mov</span>   [<span class="kw">bp</span>+Temp],<span class="kw">dx</span>  <span class="co">;set aside Y coordinate</span>
          :
    <span class="kw">add</span>   <span class="kw">sp</span>,OldBP      <span class="co">;dump temp storage space</span>
    <span class="kw">pop</span>   <span class="kw">bp</span>
    <span class="kw">ret</span>
DrawXY  endp</code></pre>
<p>this approach has two disadvantages. First, it prevents us from dumping temporary storage with <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">sp</span>,<span class="kw">bp</span></code>, requiring instead that we use the less efficient <code class="sourceCode nasm"><span class="kw">add</span> <span class="kw">sp</span>,OldBP</code>. Second, and more important, it makes it more likely that parameters will be accessed with a 2-byte displacement.</p>
<p>Why? Remember that a 1-byte displacement can address memory in the range -128 to +127 bytes away from BP. If our entire stack frame is addressed at positive offsets from BP, then we’ve lost the use of a full one-half of the addresses that we can access with 1-byte displacements.</p>
<p>Now, we <em>can</em> use negative stack frame offsets in assembler; it’s just a bit more trouble than we’d like. There are many possible solutions, ranging from a variety of ways to use equated symbols for stack frame variables, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">Temp  <span class="dt">equ</span>   -<span class="dv">2</span>  <span class="co">;temporary storage</span>
X     <span class="dt">equ</span>   <span class="dv">4</span>   <span class="co">;X coordinate parameter</span>
Y     <span class="dt">equ</span>   <span class="dv">6</span>   <span class="co">;Y coordinate parameter</span></code></pre>
<p>and:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">Temp  <span class="dt">equ</span>   -<span class="dv">2</span>  <span class="co">;temporary storage`</span>
X     <span class="dt">equ</span>   <span class="dv">4</span>   <span class="co">;X coordinate parameter`</span>
Y     <span class="dt">equ</span>   X<span class="dv">+2</span> <span class="co">;Y coordinate parameter`</span></code></pre>
<p>up to ways to get the assembler to adjust structure offsets for us. See my “On Graphics” column in the July 1987 issue of <em>Programmer’s Journal</em> (issue 5.4) for an elegant solution, provided by John Navas. (Incidentally, TASM provides special directives — <code class="sourceCode nasm">arg</code> and <code class="sourceCode nasm">local</code> — that handle many of the complications of stack frame addressing and allow negative offsets.)</p>
<p>While we’re discussing stack frame displacements, allow me to emphasize that you should strive to use 1-byte displacements into stack frames as much as possible. If you have so many parameters or local variables that 2-byte displacements must be used, make an effort to put the least frequently used variables at those larger displacements. Alternatively, you may want to put large data elements such as arrays and structures in the stack frame areas that are addressed with 2-byte displacements, since such data elements are often accessed by way of pointer registers such as BX and SI, rather than directly via <code class="sourceCode nasm"><span class="kw">bp</span>+disp</code> addressing. Finally, you should avoid forward references to structures; if you refer to elements of a structure before the structure itself is defined in the code, you’ll always get 2-byte displacements, as we’ll see in Chapter 14.</p>
<p>Whenever you’re uncertain whether 1-or 2-byte displacements are being used, simply generate a listing file, or look at your code with a debugger.</p>
<p>By the way, it’s worth examining the size of your stack frame displacements even in high-level languages. If you can figure out the order in which your compiler organizes data in a stack frame, you can often speed up and shrink your code simply by reorganizing your local variable declarations so that arrays and structures are at 2-byte offsets, allowing most variables to be addressed with 1-byte offsets.</p>
</section>
<section id="stack-frames-are-often-in-ds" class="level3">
<h3>Stack Frames Are Often in DS</h3>
<p>While it’s not always the case, often enough the stack segment pointed to by SS and the default data segment pointed to by DS are one and the same. This is true in most high-level language memory models, and is standard for COM programs.</p>
<p>If DS and SS are the same, the implication is clear: <em>all</em> <em>mod-reg-rm</em> addressing modes can be used to point to stack frames. That’s a real advantage if you need to scan stack frame arrays and the like, because SI or DI can be loaded with the array start address and used to address the array without the need for segment override prefixes. Similarly, BX could be set to point to a stack frame structure, which could then be accessed by way of <code class="sourceCode nasm"><span class="kw">bx</span>+disp</code> addressing without a segment override. In short, be sure to take advantage of the extra stack frame addressing power that you have at your disposal when SS equals DS.</p>
</section>
<section id="use-bp-as-a-normal-register-if-you-must" class="level3">
<h3>Use BP as a Normal Register if You Must</h3>
<p>When stack frame addressing is in use, BP is normally dedicated to addressing the current stack frame. That doesn’t mean you can’t use BP as a normal register in a tight loop, though, and use it as a normal register you should; registers are too scarce to let even one go to waste when performance matters. Just push BP, use it however you wish in the loop, then pop it when you’re done, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">push</span>  <span class="kw">bp</span>            <span class="co">;preserve stack frame pointer</span>
    <span class="kw">mov</span>   <span class="kw">bp</span>,LOOP_COUNT <span class="co">;get # of times to repeat loop</span>
<span class="fu">LoopTop:</span>
          :
    <span class="kw">dec</span>   <span class="kw">bp</span>            <span class="co">;count off loops</span>
    <span class="kw">loop</span>  LoopTop
    <span class="kw">pop</span>   <span class="kw">bp</span>            <span class="co">;restore stack frame pointer</span></code></pre>
<p>Of course, the stack frame can’t be accessed while BP is otherwise occupied, but you don’t want to be accessing memory inside a tight loop anyway if you can help it.</p>
<p>Using BP as a normal register in a tight loop can make the difference between a register-only loop and one that accesses memory operands, and that can translate into quite a performance improvement. Also, don’t forget that BP can be used in <em>mod-reg-rm</em> addressing even when stack frames aren’t involved, so BP can come in handy as a memory-addressing register when BX, SI, and DI are otherwise engaged. In that usage, however, bear in mind that there is no BP-only memory addressing mode; either a 1-or 2-byte displacement or an index register (SI or DI) or both is always involved.</p>
</section>
<section id="the-many-ways-of-specifying-mod-reg-rm-addressing" class="level3">
<h3>The Many Ways of Specifying <em>mod-reg-rm</em> Addressing</h3>
<p>There are, it seems, more ways of specifying an operand addressed with <em>mod-reg-rm</em> addressing than you can shake a stick at. For example, <code class="sourceCode nasm">[<span class="kw">bp</span>+MemVar+<span class="kw">si</span>]</code>, <code class="sourceCode nasm">MemVar[<span class="kw">bp</span>+<span class="kw">si</span>]</code>, <code class="sourceCode nasm">MemVar[<span class="kw">si</span>][<span class="kw">bp</span>]</code>, and <code class="sourceCode nasm">[<span class="kw">bp</span>][MemVar+<span class="kw">si</span>]</code> are all equivalent. Now stack frame addressing introduces us to a new form, involving the dot operator: <code class="sourceCode nasm">[<span class="kw">bp</span>.MemVar+<span class="kw">si</span>]</code>. Or <code class="sourceCode nasm">[<span class="kw">bp</span>.MemVar.<span class="kw">si</span>]</code>. What’s the story with all these <em>mod-reg-rm</em> forms?</p>
<p>It’s actually fairly simple. The dot operator does the same thing as the plus operator: it adds two memory addressing components together. Any memory-addressing component enclosed in brackets is also added into the memory address. The order of the operands doesn’t matter, since everything resolves to a <em>mod-reg-rm</em> byte in the end; <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,[<span class="kw">bx</span>+<span class="kw">si</span>]</code> assembles to exactly the same instruction as <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,[<span class="kw">si</span>+<span class="kw">bx</span>]</code>. All the constant values and symbols (variable names and equated values) in an address are added together into a single displacement, and that’s used with whatever memory addressing registers are present (from among BX, BP, SI, and DI) to form a <em>mod-reg-rm</em> address. (Of course, only valid combinations — the combinations listed in Figure 7.6 — will assemble.) Lastly, if memory addressing registers are present, they must be inside square brackets, but that’s optional for constant values and symbols.</p>
<p>There are a few other rules about constructing memory addressing operands, but I avoid those complications by making it a practice to use a single simple <em>mod-reg-rm</em> memory address notation. As I said at the start of this chapter, I prefer to put square brackets around all memory operands, and I also prefer to use only the plus operator. There are three reasons for this: it’s not complicated, it reminds me that I’m programming in assembler, not in a high-level language where complications such as array element size are automatically taken care of, and it reminds me that I’m accessing a memory operand rather than a register operand, thereby losing performance and gaining bytes.</p>
<p>You can use whatever <em>mod-reg-rm</em> addressing notation you wish. I do suggest, however, that you choose a single notation and stick with it. Why confuse yourself?</p>
</section>
<section id="xlat" class="level3">
<h3><code>xlat</code></h3>
<p>At long last, we come to the final addressing mode of the 8088. This addressing mode is unique to the <code class="sourceCode nasm"><span class="kw">xlat</span></code> instruction, an odd and rather limited instruction that can nonetheless outperform every other 8088 instruction under the proper circumstances.</p>
<p>The operation of <code class="sourceCode nasm"><span class="kw">xlat</span></code> is simple: AL is loaded from the offset addressed by the sum of BX and AL, as shown in Figure 7. 14. DS is the default data segment, but a segment override prefix may be used.</p>
<figure>
<img src="images/fig7.14RT.png" />
</figure>
<p>As you can see, <code class="sourceCode nasm"><span class="kw">xlat</span></code> bears no resemblance to any of the other addressing modes. It’s certainly limited, and it always wipes out one of the two registers it uses to address memory (AL). In fact, the first thought that leaps to mind is: why would we <em>ever</em> want to use <code class="sourceCode nasm"><span class="kw">xlat</span></code>?</p>
<p>If <code class="sourceCode nasm"><span class="kw">xlat</span></code> were slow and large, the answer would be never. However, <code class="sourceCode nasm"><span class="kw">xlat</span></code> is just 1 byte long, and, at 10 cycles, is as fast at accessing a memory operand as any 8088 instruction. As a result, <code class="sourceCode nasm"><span class="kw">xlat</span></code> is excellent for a small but often time-critical category of tasks.</p>
<p><code class="sourceCode nasm"><span class="kw">xlat</span></code> excels when byte values must be translated from one representation to another. The most common example occurs when one character set must be translated to another, as for example when the ASCII character set used by the PC is translated to the EBCDIC character set used by IBM mainframes. In such a case <code class="sourceCode nasm"><span class="kw">xlat</span></code> can form the heart of an extremely efficient loop, along the lines of the following:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="co">;</span>
<span class="co">; Converts the contents of an ASCII buffer to an EBCDIC buffer.</span>
<span class="co">; Stops when a zero byte is encountered, but copies the zero byte.</span>
<span class="co">;</span>
<span class="co">; Input:</span>
<span class="co">;     DS:SI = pointer to ASCII buffer.</span>
<span class="co">;</span>
<span class="co">; Output: none</span>
<span class="co">;</span>
<span class="co">; Registers altered: AL, BX, SI, DI, ES</span>
<span class="co">;</span>
    <span class="kw">mov</span>   <span class="kw">di</span>,<span class="kw">ds</span>
    <span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">di</span>
    <span class="kw">mov</span>   <span class="kw">di</span>,<span class="kw">si</span>       <span class="co">;point ES:DI to the ASCII buffer as well</span>
    <span class="kw">mov</span>   <span class="kw">bx</span>,offset ASCIIToEBCDICTable
                      <span class="co">;point to the table containing the EBCDIC</span>
                      <span class="co">; equivalents of ASCII codes</span>
    <span class="kw">cld</span>
<span class="fu">ASCIIToEBCDICLoop:</span>
    <span class="kw">lodsb</span>             <span class="co">;get the next ASCII character</span>
    <span class="kw">xlat</span>              <span class="co">;convert it to EBCDIC</span>
    <span class="kw">stosb</span>             <span class="co">;put the result back in the buffer</span>
    <span class="kw">and</span>   <span class="kw">al</span>,<span class="kw">al</span>       <span class="co">;zero byte is the last byte</span>
    <span class="kw">jnz</span>   ASCIIToEBCDICLoop</code></pre>
<p>Besides being small and fast, <code class="sourceCode nasm"><span class="kw">xlat</span></code> has an advantage in that byte-sized look-up values don’t need to be converted to words before they can be used to address memory. (Remember, <em>mod-reg-rm</em> addressing modes allow only word-sized registers to be used to address memory.) If we were to implement the look-up in the last example with <em>mod-reg-rm</em> instructions, the code would become a good deal less efficient no matter how efficiently we set up for <em>mod-reg-rm</em> addressing:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">sub</span>   <span class="kw">bh</span>,<span class="kw">bh</span>       <span class="co">;for use in converting a byte in BL</span>
                      <span class="co">;to a word in BX</span>
    <span class="kw">mov</span>   <span class="kw">si</span>,offset ASCIIToEBCDICTable
                      <span class="co">;point to the table containing the EBCDIC</span>
                      <span class="co">;equivalents of ASCII codes</span>
<span class="fu">ASCIIToEBCDICLoop:</span>
    <span class="kw">lodsb</span>             <span class="co">;get the next ASCII character</span>
    <span class="kw">mov</span>   <span class="kw">bl</span>,<span class="kw">al</span>       <span class="co">;get the character into BX, where</span>
                      <span class="co">;we can use it to address memory</span>
    <span class="kw">mov</span>   <span class="kw">al</span>,[<span class="kw">si</span>+<span class="kw">bx</span>]  <span class="co">;convert it to EBCDIC</span>
    <span class="kw">stosb</span>             <span class="co">;put the result back in the buffer</span>
    <span class="kw">and</span>   <span class="kw">al</span>,<span class="kw">al</span>       <span class="co">;zero byte is the last byte</span>
    <span class="kw">jnz</span>   ASCIIToEBCDICLoop</code></pre>
<p>In short, <code class="sourceCode nasm"><span class="kw">xlat</span></code> is clearly superior when a byte-sized look-up is performed, so long as it’s possible to put both the look-up value and the result in AL. Shortly, we’ll see how <code class="sourceCode nasm"><span class="kw">xlat</span></code> can be used to good effect in a case where it certainly isn’t the obvious choice.</p>
</section>
<section id="memory-is-cheap-you-could-look-it-up" class="level3">
<h3>Memory is Cheap: You Could Look It Up</h3>
<p><code class="sourceCode nasm"><span class="kw">xlat</span></code>, simply put, is a table look-up instruction. A table look-up occurs whenever you use an index value to look up a result in an array, or table, of data. A rough analogy might be using the number on a ballplayer’s uniform to look up his name in a program.</p>
<p>Look-up tables are a superb way to improve performance. The basic premise of look-up tables is that it’s faster to precalculate results, either by letting the assembler do the work or by calculating the results yourself and inserting them in the source code, than it is to have the 8088 calculate them at run time. The key factor is this: the 8088 is relatively fast at looking up data in tables and slow at performing almost any kind of calculation. Given that, why not perform your calculations before run time, when speed doesn’t matter, and let the 8088 do what it does best at run time?</p>
<p>Now, look-up tables do have a significant disadvantage — they require extra memory. This is a trade-off we’ll see again and again in <em>The Zen of Assembly Language</em>: cycles for bytes. If you’re willing to expend more memory, you can almost always improve the performance of your code. One trick to generating top-notch code is knowing when that trade-off is worth making.</p>
<p>Let’s look at an example that illustrates the power of look-up tables. In the process, we’ll see an unusual but effective use of <code class="sourceCode nasm"><span class="kw">xlat</span></code>; we’ll also see that there are many ways to approach any programming task, and we’ll get a first-hand look at the cycles-for-bytes tradeoff that arises so often in assembler programming.</p>
</section>
<section id="five-ways-to-double-bits" class="level3">
<h3>Five Ways to Double Bits</h3>
<p>The example we’re about to study is based on the article “Optimizing for Speed,” by Michael Hoyt, which appeared in <em>Programmer’s Journal</em> in March, 1986 (issue 4.2). This is the article I referred to back in Chapter 2 as an example of a programmer operating without full knowledge about code performance on the PC. By no means am I denigrating Mr. Hoyt; his article simply happens to be an excellent starting point for examining both look-up tables and the hazards of the prefetch queue cycle-eater.</p>
<p>The goal of Mr. Hoyt’s article was to expand a byte to a word by doubling each bit, for the purpose of converting display memory pixels to printer pixels in order to perform a screen dump. So, for example, the value 01h (00000001b) would become 0003h (0000000000000011b), the value 02h (00000010b) would become 000Ch (0000000000001100b), and the value 5Ah (01011010b) would become 33CCh (0011001111001100b). Now, in general this isn’t a particularly worthy pursuit, given that the speed of the printer is likely to be the limiting factor; however, speed could matter if the screen dump code is used by a background print spooler. At any rate, bit-doubling is an ideal application for look-up tables, so we’re going to spend some time studying it.</p>
<p>Mr. Hoyt started his article with code that doubled each bit by testing that bit and branching accordingly to set the appropriate doubled bit values. He then optimized the code by eliminating branches entirely, instead using fast shift and rotate instructions, in a manner similar to that used by <a href="#listing-7-14">Listing 7-14</a>.</p>
<p>Eliminating branches isn’t a bad idea in general, since, as we’ll see in Chapter 12, branching is very slow. However, as we’ve already seen in Chapter 4, instruction fetching is also very slow… and the code in <a href="#listing-7-14">Listing 7-14</a> requires a <em>lot</em> of instruction fetching. 70 instruction bytes must be fetched for each byte that’s doubled, meaning that this code can’t possibly run in less than about 280 (70 times 4) cycles per byte doubled, even though its official Execution Unit execution time is scarcely 70 cycles.</p>
<p>The Zen timer confirms our calculations, reporting that <a href="#listing-7-14">Listing 7-14</a> runs in 6.34 ms, or about 300 cycles per byte doubled. (The excess cycles are the result of DRAM refresh.) As a result of this intensive instruction fetching, Mr. Hoyt’s optimized shift-and-rotate code actually ran slower than his original test-and-jump code, as discussed in my article “More Optimizing for Speed,” <em>Programmer’s Journal</em>, <em>July, 1986 (issue 4.4).</em></p>
<p>So far, all we’ve done is confirm that the prefetch queue cycle-eater can cause code to run much more slowly than the official execution times would indicate. This is of course not news to us; in fact, I haven’t even bothered to show the test-and-jump code and contrast it with the shift-and-rotate code, since that would just restate what we already know. What’s interesting is not that Mr. Hoyt’s optimization didn’t make his code faster, but rather that a look-up table approach can make the code <em>much</em> faster. So let’s plunge headlong into look-up tables, and see what we can do with this code.</p>
</section>
<section id="table-look-ups-to-the-rescue" class="level3">
<h3>Table Look-Ups to the Rescue</h3>
<p>Bit-doubling is beautifully suited to an approach based on look-up tables. There are only 256 possible input values, all byte-sized, and only 256 possible output values, all word-sized. Better yet, each input value maps to one and only one output value, and all the input values are consecutive, covering the range 0 to 255, inclusive.</p>
<p>Given those parameters, it should be clear that we can create a table of 256 words, one corresponding to each possible byte to be bit-doubled. We can then use each byte to be doubled as a look-up index into that table, retrieving the appropriate bit-doubled word with just a few instructions. Granted, 512 bytes would be needed to store the table, but the 50 or so instruction bytes we would save would partially compensate for the size of the table. Besides, surely the performance improvement from eliminating all those shifts, rotates, and especially instruction fetches would justify the extra bytes… wouldn’t it?</p>
<p>It would indeed. <a href="#listing-7-15">Listing 7-15</a>, which uses the table look-up approach I’ve just described, runs in just 1.32 ms — <em>more than four times as fast as <a href="#listing-7-14">Listing 7-14</a>!</em> When performance matters, trading less than 500 bytes for a more than four-fold speed increase is quite a deal. <a href="#listing-7-15">Listing 7-15</a> is so fast that it’s faster than <a href="#listing-7-14">Listing 7-14</a> would be even if there were no prefetch queue cycle-eater; in other words, the official execution time of <a href="#listing-7-15">Listing 7-15</a> is faster than that of <a href="#listing-7-14">Listing 7-14</a>. Factor in instruction fetch time, though, and you have a fine example of the massive performance improvement that look-up tables can offer.</p>
<p>The key to <a href="#listing-7-15">Listing 7-15</a>, of course, is that I precalculated all the doubled bit masks when I wrote the program. As a result, the code doesn’t have to perform any calculation more complex than looking up a precalculated bit mask at run time. In a little while, we’ll see how MASM can often perform look-up table calculations at assembly time, relieving us of the drudgery of precalculating results.</p>
</section>
<section id="there-are-many-ways-to-approach-any-task" class="level3">
<h3>There Are Many Ways to Approach Any Task</h3>
<p>Never assume that there’s only one way, or even one “best” way, to approach any programming task. There are always many ways to solve any given programming problem in assembler, and different solutions may well be superior in different situations.</p>
<p>Suppose, for example, that we’re writing bit-doubling code in a situation where size is more important than speed, perhaps because we’re writing a memory-resident program, or perhaps because the code will be used in a very large program that’s squeezed for space. We’d like to improve our speed, if we can — but not at the expense of a single byte. In this case, <a href="#listing-7-14">Listing 7-14</a> is preferable to <a href="#listing-7-15">Listing 7-15</a> — but is <a href="#listing-7-14">Listing 7-14</a> the best we can do?</p>
<p>Not by a long shot.</p>
<p>What we’d like to do is somehow shrink <a href="#listing-7-15">Listing 7-15</a> a good deal. Well, <a href="#listing-7-15">Listing 7-15</a> is so large because it has a 512-byte table that’s used to look up the bit-doubled words that can be selected by the 256 values that can be stored in a byte. We can shrink the table a great deal simply by converting it to a 16-byte table that’s used to look up the bit-doubled <em>bytes</em> that can be selected by the 16 values that can be stored in a <em>nibble</em> (4 bits), and performing two look-ups into that table, one for each half of the byte being doubled.</p>
<p><a href="#listing-7-16">Listing 7-16</a> shows this double table look-up solution in action. This listing requires only 23 bytes of code for each byte doubled, and even if you add the 16-byte size of the table in, the total size of 39 bytes is still considerably smaller than the 70 bytes needed to bit-double each byte in <a href="#listing-7-14">Listing 7-14</a>. What’s more, the table only needs to appear once in any program, so practically speaking <a href="#listing-7-16">Listing 7-16</a> is <em>much</em> more compact than <a href="#listing-7-14">Listing 7-14</a>.</p>
<p><a href="#listing-7-16">Listing 7-16</a> also is more than twice as fast as <a href="#listing-7-14">Listing 7-14</a>, clocking in at 2.52 ms. Of course, <a href="#listing-7-16">Listing 7-16</a> is nearly twice as <em>slow</em> as <a href="#listing-7-15">Listing 7-15</a> — but then, it’s much more compact.</p>
<p>There’s that choice again: cycles or bytes.</p>
<p>In truth, there are both cycles and bytes yet to be saved in <a href="#listing-7-16">Listing 7-16</a>. If we apply our knowledge of <em>mod-reg-rm</em> addressing to <a href="#listing-7-16">Listing 7-16</a>, we’ll realize that it’s a waste to use base+displacement addressing with the same displacement twice in a row; we can save a byte and a few cycles by loading SI with the displacement and using base+index addressing instead. <a href="#listing-7-17">Listing 7-17</a>, which incorporates this optimization, runs in 2.44 ms, a bit faster than <a href="#listing-7-16">Listing 7-16</a>.</p>
<p>There’s yet another optimization to be made, and this one brings us full circle, back to the start of our discussion of look-up tables. Think about it: <a href="#listing-7-17">Listing 7-17</a> basically does nothing more than use two nibble values as look-up indices into a table of byte values. Sound familiar? It should — that’s an awful lot like a description of <code class="sourceCode nasm"><span class="kw">xlat</span></code>. (<code class="sourceCode nasm"><span class="kw">xlat</span></code> can handle byte look-up values, but this task is just a subset of that.)</p>
<p><a href="#listing-7-18">Listing 7-18</a> shows an <code class="sourceCode nasm"><span class="kw">xlat</span></code>-based version of our bit-doubling code. This code runs in just 1.94 ms, still about 50% slower than the single look-up approach, but a good deal faster than anything else we’ve seen. Better yet, this approach takes just 16 instruction bytes per bit-doubled byte (32 if you count the table) — which makes this by far the shortest approach we’ve seen. Comparing <a href="#listing-7-18">Listing 7-18</a> to <a href="#listing-7-14">Listing 7-14</a> reveals that we’ve improved the code to an astonishing degree: <a href="#listing-7-18">Listing 7-18</a> runs more than three times as fast as <a href="#listing-7-14">Listing 7-14</a>, and yet it requires less than one-fourth as many instruction bytes per bit-doubled byte.</p>
<p>There are many lessons here. First, <code class="sourceCode nasm"><span class="kw">xlat</span></code> is extremely efficient at performing the limited category of tasks it can manage; when you need to use a byte index into a byte-sized look-up table, <code class="sourceCode nasm"><span class="kw">xlat</span></code> is often your best bet. Second, the official execution times aren’t a particularly good guide to writing high-performance code. (Of course, you already knew <em>that</em>!) Third, there is no such thing as the best code, because the fastest code is rarely the smallest code, and vice-versa.</p>
<p>Finally, there are an awful lot of solutions to any given programming problem on the 8088. Don’t fall into the trap of thinking that the obvious solution is the best one. In fact, we’ll see yet another solution to the bit-doubling problem in Chapter 9; this solution, based on the <code class="sourceCode nasm"><span class="kw">sar</span></code> instruction, isn’t like <em>any</em> of the solutions we’ve seen so far.</p>
<p>We’ll see look-up tables again in Chapter 14, in the form of jump tables.</p>
</section>
</section>
<section id="initializing-memory" class="level2">
<h2>Initializing Memory</h2>
<p>Assembler offers excellent data-definition capabilities, and look-up tables can benefit greatly from those capabilities. No high-level language even comes close to assembler so far as flexible definition of data is concerned, both in terms of arbitrarily mixing different data types and in terms of letting the assembler perform calculations at assembly time; given that, why not let the assembler generate your look-up tables for you?</p>
<p>For example, consider the multiplication of a word-sized value by 80, a task often performed in order to calculate row offsets in display memory. <a href="#listing-7-19">Listing 7-19</a> does this with the compact but slow <code class="sourceCode nasm"><span class="kw">mul</span></code> instruction, at a pace of 30.17 us per multiply. <a href="#listing-7-20">Listing 7-20</a> improves to 15.08 us per multiply by using a faster shift-and-add approach. However, the performance of the shift-and-add approach is limited by the prefetch queue cycle-eater; <a href="#listing-7-21">Listing 7-21</a>, which looks the multiplication results up in a table, is considerably faster yet, at 12.26 us per multiply. Once again, the look-up approach is faster even than tight register-only code, but that’s not what’s most interesting here.</p>
<p>What’s really interesting about <a href="#listing-7-21">Listing 7-21</a> is that it’s the assembler, not the programmer, that generates the look-up table of multiples of 80. Back in <a href="#listing-7-15">Listing 7-15</a>, I had to calculate and type each entry in the look-up table myself. In <a href="#listing-7-21">Listing 7-21</a>, however, I’ve used the <code class="sourceCode nasm">rept</code> and <code class="sourceCode nasm">=</code> directives to instruct the assembler to build the table automatically. That’s even more convenient than you might think; not only does it save the tedium of a lot of typing, but it avoids the sort of typos that inevitably creep in whenever a lot of typing is involved.</p>
<p>Another area in which assembler’s data-definition capabilities lend themselves to good code is in constructing and using mini-interpreters, which are nothing less than task-specific mini-languages that are easily created and used in assembler. We’ll discuss mini-interpreters at length in Volume II of <em>The Zen of Assembly Language</em>.</p>
<p>You can also take advantage of assembler’s data definition capabilities by assigning initial values to variables when they’re defined, rather than initializing them with code. In other words:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">MemVar  <span class="dt">dw</span> <span class="dv">0</span></code></pre>
<p>takes no time at all at run time; <code class="sourceCode nasm">MemVar</code> simply <em>is</em> 0 when the program starts. By contrast:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">MemVar  <span class="dt">dw</span> ?
:
<span class="kw">mov</span>     [MemVar],<span class="dv">0</span></code></pre>
<p>takes 20 cycles at run time, and adds 6 bytes to the program as well.</p>
<p>In general, the rule is: <em>calculate results and initialize data at or before assembly time if you can, rather than at run time</em>. What makes look-up tables so powerful is simply that they provide an easy way to shift the overhead of calculations from run time to assembly time.</p>
</section>
<section id="a-brief-note-on-io-addressing" class="level2">
<h2>A Brief Note on I/O Addressing</h2>
<p>You may wonder why we’ve spent so much time on memory addressing but none on input/output (I/O) addressing. The answer is simple: I/O addressing is so limited that there’s not much to know about it. There aren’t any profound performance implications or optimizations associated with I/O addressing simply because there are only two ways to perform I/O.</p>
<p><code class="sourceCode nasm"><span class="kw">out</span></code>, which writes data to a port, always uses the accumulator for the source operand: AL when writing to byte-sized ports, AX when writing to word-sized ports. The destination port address may be specified either by a constant value in the range 0-255 (basically direct port addressing with a byte-sized displacement) or by the value in DX (basically indirect port addressing). Here are the two possible ways to send the value 5Ah to port 99:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">al</span><span class="bn">,5ah</span>
<span class="kw">out</span>   <span class="dv">99</span>,<span class="kw">al</span>
<span class="kw">mov</span>   <span class="kw">dx</span>,<span class="dv">99</span>
<span class="kw">out</span>   <span class="kw">dx</span>,<span class="kw">al</span></code></pre>
<p>Likewise, <code class="sourceCode nasm"><span class="kw">in</span></code>, which reads data from a port, always uses AL or AX for the destination operand, and may use either a constant port value between 0 and 255 or the port pointed to by DX as the source operand. Here are the two ways to read a value from port 255 into AL:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">in</span>    <span class="kw">al</span><span class="bn">,0ffh</span>
<span class="kw">mov</span>   <span class="kw">dx</span><span class="bn">,0ffh</span>
<span class="kw">in</span>    <span class="kw">al</span>,<span class="kw">dx</span></code></pre>
<p>And that just about does it for I/O addressing. As you can see, there’s not much flexibility or opportunity for Zen here. All I/O data must pass through the accumulator, and if you want to access a port address greater than 255, you <em>must</em> address the port with DX. What’s more, there are no substitutes for the I/O instructions; when you need to perform I/O, what we’ve just seen is all there is.</p>
<p>While the I/O instructions are a bit awkward, at least they aren’t particularly slow, at 8 (DX-indirect) or 10 (direct-addressed) cycles apiece, with no EA calculation time. Neither are the I/O instructions particularly lengthy; in fact, <code class="sourceCode nasm"><span class="kw">in</span></code> and <code class="sourceCode nasm"><span class="kw">out</span></code> are considerably more compact than the memory-addressing instructions, which shouldn’t be surprising given that the I/O instructions provide such limited functionality. The DX-indirect forms of both <code class="sourceCode nasm"><span class="kw">in</span></code> and <code class="sourceCode nasm"><span class="kw">out</span></code> are just 1 byte long, while the direct-addressed forms are 2 bytes long.</p>
<p>Each I/O access takes over the bus and thereby briefly prevents prefetching, much as each memory access does. However, the ratio of total bus accesses (including instruction byte fetches) to execution time for <code class="sourceCode nasm"><span class="kw">in</span></code> and <code class="sourceCode nasm"><span class="kw">out</span></code> isn’t bad. In fact, byte-sized DX-indirect I/O instructions, which are only 1 byte long and perform only one I/O access, should actually run in close to the advertised 8 cycles per out.</p>
<p>Among our limited repertoire of I/O instructions, which is best? It doesn’t make all <em>that</em> much difference, but given the choice between DX-indirect I/O instructions and direct-addressed I/O instructions for heavy I/O, choose DX-indirect, which is slightly faster and more compact. For one-shot I/O to ports in the 0-255 range, use direct-addressed I/O instructions, since it takes three bytes and 4 cycles to set up DX for a DX-indirect I/O instruction.</p>
<p>On balance, though, don’t worry about I/O — just do it when you must. Rare indeed is the program that spends an appreciable amount of its time performing I/O — and given the paucity of I/O addressing modes, there’s not much to be done about performance in such cases anyway.</p>
<section id="video-programming-and-io" class="level3">
<h3>Video Programming and I/O</h3>
<p>I’d like to make one final point about I/O addressing. This section won’t mean much to you if you haven’t worked with video programming, and I’m not going to explain it further now; we’ll return to the topic when we discuss video programming in Volume II. For those of you who are involved with video programming, however, here goes.</p>
<p>Word-sized <code class="sourceCode nasm"><span class="kw">out</span></code> instructions — <code class="sourceCode nasm"><span class="kw">out</span> <span class="kw">dx</span>,<span class="kw">ax</span></code> — unquestionably provide the fastest way to set the indexed video registers of the CGA, EGA, and VGA. Just put the index of the video register you’re setting in AL and the value you’re setting the register to in AH, and <code class="sourceCode nasm"><span class="kw">out</span> <span class="kw">dx</span>,<span class="kw">ax</span></code> sets both the index and the register in a single instruction. Using byte-sized <code class="sourceCode nasm"><span class="kw">out</span></code> instructions, we’d have to do all this to achieve the same results:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">out</span>   <span class="kw">dx</span>,<span class="kw">al</span>
<span class="kw">inc</span>   <span class="kw">dx</span>
<span class="kw">xchg</span>  <span class="kw">ah</span>,<span class="kw">al</span>
<span class="kw">out</span>   <span class="kw">dx</span>,<span class="kw">al</span>
<span class="kw">dec</span>   <span class="kw">dx</span>
<span class="kw">xchg</span>  <span class="kw">ah</span>,<span class="kw">al</span></code></pre>
<p>(Sometimes you can leave off the final <code class="sourceCode nasm"><span class="kw">dec</span></code> and <code class="sourceCode nasm"><span class="kw">xchg</span></code>, but the word-sized approach is still much more efficient.)</p>
<p>However, there’s a potential pitfall to the use of word-sized <code class="sourceCode nasm"><span class="kw">out</span></code> instructions to set indexed video registers. The 8088 can’t actually perform word-sized I/O accesses, since the bus is only 8 bits wide. Consequently, the 8088 breaks 16-bit I/O accesses into two 8-bit accesses, one sending AL to the addressed port, and a second one sending AH to the addressed port plus one. (If you think about it, you’ll realize that this is exactly how the 8088 handles word-sized memory accesses too.)</p>
<p>All well and good. Unfortunately, on computers built around the 8086, 80286, and the like, the processors do not automatically break up word-sized I/O accesses, since they’re fully capable of outputting 16 bits at once. Consequently, when word-sized accesses are made to 8-bit adapters like the EGA by code running on such computers, it’s the bus, not the processor, that breaks up those accesses. Generally, that works perfectly well — but on certain PC — compatible computers, the bus outputs the byte in AH to the addressed port plus one first, and <em>then</em> sends the byte in AL to the addressed port. The correct values go to the correct ports, but here sequence is critical; <code class="sourceCode nasm"><span class="kw">out</span> <span class="kw">dx</span>,<span class="kw">ax</span></code> to an indexed video register relies on the index in AL being output before the data in AH, and that simply doesn’t happen. As a result, the data goes to the wrong video register, and the video programming works incorrectly — sometimes disastrously so.</p>
<p>You may protest that any computer that gets the sequencing of word-sized <code class="sourceCode nasm"><span class="kw">out</span></code> instructions wrong isn’t truly a PC-compatible, and I suppose that’s so. Nonetheless, if a computer runs <em>everything</em> except your code that uses word-sized <code class="sourceCode nasm"><span class="kw">out</span></code> instructions, you’re going to have a tough time selling that explanation. Consequently, I recommend using byte-sized <code class="sourceCode nasm"><span class="kw">out</span></code> instructions to indexed video registers whenever you can’t be sure of the particular PC-compatible models on which your code will run.</p>
</section>
<section id="avoid-memory" class="level3">
<h3>Avoid Memory!</h3>
<p>We’ve come to the end of our discussion of memory addressing. Memory addressing on the 8088 is no trivial matter, is it? Now that we’ve familiarized ourselves with the registers and memory addressing capabilities of the 8088, we’ll start exploring the instruction set, a journey that will occupy most of the rest of this volume.</p>
<p>Before we leave the realm of memory addressing, let me repeat: <em>avoid memory</em>. Use the registers to the hilt; register-only instructions are shorter and faster. If you must access memory, try not to use <em>mod-reg-rm</em> addressing; the special memory-accessing instructions, such as the string instructions and <code class="sourceCode nasm"><span class="kw">xlat</span></code>, are generally shorter and faster. When you do use <em>mod-reg-rm</em> addressing, try not to use displacements, especially 2-byte displacements.</p>
<p>Last but not least, choose your spots. Don’t waste time optimizing non-critical code; focus on loops and other chunks of code in which every cycle counts. Assembler programming is not some sort of game where the object is to save cycles and bytes blindly. Rather, the goal is a dual one: to produce whole programs that perform well <em>and to produce those programs as quickly as possible</em>. The key to doing that is knowing how to optimize code, and then doing so in time-critical code — and <em>only</em> in time-critical code.</p>
</section>
</section>
</section>
<section id="chapter-8-strange-fruit-of-the-8080" class="level1">
<h1>Chapter 8: Strange Fruit of the 8080</h1>
<blockquote>
<p>For of all sad words of tongue or pen</p>
<p>The saddest are these: “It might have been!”</p>
<p>– John Greenleaf Whittier</p>
</blockquote>
<p>With this chapter we start our exploration of the 8088’s instruction set. What better place to begin than with the roots of that instruction set, which trace all the way back to the dawn of the microcomputer age?</p>
<p>If you’re a veteran programmer, you probably remember the years Before IBM, when state-of-the-art micros were built around the 8-bit 8080 processor and its derivatives. In today’s era of ever-mightier 16-and 32-bit processors, you no doubt think you’ve seen the last of the venerable but not particularly powerful 8080.</p>
<p>Not a chance.</p>
<p>The 8080 lingers on in the instruction set and architecture of the 8088, which was designed with an eye toward making it easy to port 8080 programs to the 8088. While it may seem strange that the design of an advanced processor would be influenced by the architecture of a less-capable processor, that practice is actually quite common and makes excellent market sense. For example, the 80286 and 80386 processors provide complete 8088 compatibility, and would certainly not have been as successful were they not 8088-compatible. In fact, one of the great virtues of the 80386 is its ability to emulate several 8088s at once, and it is well known that the designers of the 80386 went to considerable trouble to maintain that link with the past.</p>
<p>Less well known, perhaps, is the degree to which the designers of the 8088 were guided by the past as well. (Actually, as discussed in Chapter 3, the 8086 was designed first and the 8088 spun off from it, but we’ll refer simply to the 8088 from now on, since that’s our focus and since the two processors share the same instruction set.)</p>
<section id="the-8080-legacy" class="level2">
<h2>The 8080 Legacy</h2>
<p>At the time the 8088 was designed, the Intel 8080, an 8-bit processor, was an industry standard, along with the more powerful but 8080-compatible Zilog Z80 and Intel 8085 chips. The 8080 had spawned CP/M, a widely-used operating system, and with it a variety of useful programs, including word processing, spreadsheet, and database software.</p>
<p>New processors are <em>always</em> — without fail — more powerful than their predecessors. Nonetheless, processors that lack compatibility with any previous generation are generally not widely used for several years — if ever — because software developers don’t come fully up to speed on new processors for several years, and it’s a broad software base that makes a processor useful and therefore popular. In the interim, relatively few programs are available to run on that processor, and sales languish. One solution to this problem is to provide complete compatibility with an earlier standard, as the Z80 and 8085 did. Indeed, today the NEC V20 processor, which is fully 8088 compatible, has the equivalent of an 8080 built in, and can readily switch between 8088-and 8080-compatible modes.</p>
<p>Unfortunately, chip space was at a premium during the 1970s, and presumably Intel couldn’t afford to put both 8088 and 8080 functionality into a single package. What Intel could and did do was design the 8088 so that it would be relatively easy to port 8080 programs — especially assembler programs, since most programs were written in assembler in those days — to run on the 8088, and so that those ported programs would perform reasonably well.</p>
<p>The designers of the 8088 provided such “source-level” compatibility by making the 8088’s register set similar to the 8080’s, by implementing directly analogous — although not identical — 8088 instructions for most 8080 instructions and by providing special speedy, compact forms of key 8080 instructions. As a result, the 8088’s architecture bears a striking similarity to that of the 8080.</p>
<p>For example, the 8088’s 16-bit AX, BX, CX, and DX registers can also be accessed as paired 8-bit registers, thereby making it possible for the 8088 to mimic the seven 8-bit program-accessible registers and the 8-bit FLAGS register of the 8080, as shown in Figure 8.1. In particular, the 8088’s BH and BL registers can be used together as the BX register to address memory, just as the 8080’s HL register pair can.</p>
<figure>
<img src="images/fig8.1RT.png" />
</figure>
<p>The register correspondence between the 8080 and 8088 is not perfect. For one thing, neither CX nor DX can be used to address memory as the 8080’s BC and DE register pairs can; however, the 8088’s <code class="sourceCode nasm"><span class="kw">xchg</span></code> instruction and/or index registers can readily be used to compensate for this. Similarly, the 8080 can push both the flags and the accumulator onto the stack with a single instruction, while the 8088 cannot. As we’ll see later in this chapter, though, the designers of the 8088 provided two instructions — <code class="sourceCode nasm"><span class="kw">lahf</span></code> and <code class="sourceCode nasm"><span class="kw">sahf</span></code> — to take care of that very problem.</p>
<p>All in all, while the 8080 and 8088 certainly aren’t brothers, they’re close relatives indeed.</p>
<section id="more-than-a-passing-resemblance" class="level3">
<h3>More Than a Passing Resemblance</h3>
<p>In general, the 8088’s instruction set reflects the influence of the 8080 fairly strongly. While the 8088’s instruction set is a considerable superset of the 8080’s, there are few 8080 instructions that can’t be emulated by one (or at most two) 8088 instructions, and there are several 8088 instructions that most likely would not exist were it not for the 8080 legacy. Also, although it’s only speculation, it certainly seems possible that the segmented memory architecture of the 8088 is at least partially the result of needing to reconcile the 1 Mb address space of the 8088 with the 8-and 16-bit nature of the registers the 8088 inherited from the 8080. (Segmentation does allow some types of code to be more compact than it would be if the 8088 had an unsegmented address space, so let’s not blame segmentation entirely on the 8080.)</p>
<p>The 8088 is without question a more powerful processor than the 8080, with far more flexible addressing modes and register usage, but it is nonetheless merely a 16-bit extension of the 8080 in many ways, rather than a processor designed from scratch. We can only speculate as to what the capabilities of an 8088 built without regard for the 8080 might have been — but a glance at the 68000’s 16 Mb linear address space and large 32-bit register set gives us a glimpse of that future that never was.</p>
<p>At any rate, the 8088 <em>was</em> designed with the 8080 in mind, and the orientation of the 8088’s instruction set toward porting 8080 programs seems to have served its purpose. Many 8080 programs, including WordStar and VisiCalc, were ported to the 8088, and those ported programs helped generate the critical mass of software that catapulted the 8088 to a position of dominance in the microcomputer world. How much of the early success of the 8088 was due to ported 8080 software and how much resulted from the letters “IBM” on the nameplate of the PC is arguable, but ported 8080 software certainly sold well for some time.</p>
<p>Today the need for 8080 source-level compatibility is long gone, but that 8080-oriented instruction set is with us still, and seems likely to survive well into the 21st century in the silicon of the 80386 and its successors. (Amazingly, every processor shown in Figure 3-5 provides full 8088 compatibility, and it’s a safe bet that future generations will be compatible as well. In fact, although it hasn’t happened as of this writing, it appears that some <em>non-Intel</em> manufacturers may build 8088-compatible subprocessors into their chips!)</p>
<p>The 8080 flavor of the 8088’s instruction set is both a curse and a blessing. It’s a curse because it limits the performance of average 8088 code, and a blessing because it provides great opportunity for assembler code to shine. In particular, the 8080-specific instructions occupy valuable space in the 8088 opcode set — arguably causing native 8088 code (as opposed to ported 8080 code) to be larger and slower than it would otherwise be — and that is, by-and-large, one of the less appealing aspects of the 8088. For the assembler programmer, however, the 8080-specific instructions can be an asset. Since those instructions are faster and more compact than their general-purpose counterparts, they can often be used to create significantly better code. Next, we’ll examine the 8080-specific instructions in detail.</p>
</section>
</section>
<section id="accumulator-specific-instructions" class="level2">
<h2>Accumulator-Specific Instructions</h2>
<p>The accumulator is a rather special register on the 8080. For one thing, the 8080 requires that the accumulator be the destination for most arithmetic and logical operations. For another, the accumulator is the register generally used as source and destination for memory accesses that use direct addressing. (Refer back to Chapter 7 for a discussion of addressing modes.)</p>
<p>Not so with the 8088. In the 8088’s instruction set, the accumulator (AL for 8-bit operations, AX for 16-bit operations) is a special register for some operations, such as multiplication and division, but is by-and-large no different from any other general-purpose register. With the 8088, any of the eight general-purpose registers can be the source or destination for logical operations, addition, subtraction, and memory accesses as readily as the accumulator can.</p>
<p>While the 8088’s instructions are far more flexible than the 8080’s instructions, that flexibility has a price. The price is an extra instruction byte, the <em>mod-reg-rm</em> byte, which encodes the 8088’s many addressing modes and source/destination combinations, as we learned in Chapter 7. Thanks to the <em>mod-reg-rm</em> byte, 8088 instructions are normally 1 byte longer than equivalent 8080 instructions. However, several 8080-inspired 8088 instructions, which require that the accumulator be one of the operands and accept only a few possibilities for the other operand, are the same length as their 8080 counterparts. (Not all the special instructions have exact 8080 counterparts, but that doesn’t make them any less useful.) While these accumulator-specific instructions lack the flexibility of their native 8088 counterparts, they are also smaller and faster, so it’s desirable to use them whenever possible.</p>
<p>The accumulator-specific 8088 instructions fall into two categories: instructions involving direct addressing of memory, and instructions involving immediate arithmetic and logical operands. We’ll look at accumulator-specific memory accesses first.</p>
<section id="accumulator-specific-direct-addressing-instructions" class="level3">
<h3>Accumulator-Specific Direct-Addressing Instructions</h3>
<p>The 8088 lets you address memory operands in a great many different ways — 16 ways, to be precise, as we saw in Chapter 7. This flexibility is one of the strengths of the 8088, and is one way in which the 8088 far exceeds the 8080. There’s a price for that flexibility, though, and that’s the <em>mod-reg-rm</em> byte, which we encountered in Chapter 7. To briefly recap, the <em>mod-reg-rm</em> byte is a second instruction byte, immediately following the opcode byte of most instructions that access memory, which specifies which of 32 possible addressing modes are to be used to select the source and/or destination for the instruction. (8 of the addressing modes are used to select the 8 general-purpose registers as operands, and 8 addressing modes differ only in the size of the displacement field, hence the discrepancy between the 32 addressing modes and the 16 ways to address memory operands.) Together, the <em>mod-reg-rm</em> byte and the 16-bit displacement required for direct addressing mean that any instruction that uses <em>mod-reg-rm</em> direct addressing must be at least 4 bytes long, as shown in Figure 8.2.</p>
<figure>
<img src="images/fig8.2RT.png" />
</figure>
<p>Direct addressing is used whenever you simply want to refer to a memory location by name, with no pointing or indexing. For example, a counter named <code class="sourceCode nasm">Count</code> could be incremented with direct addressing as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">inc</span>   [Count]</code></pre>
<p>Direct addressing is intuitive and convenient, and is one of the most heavily used addressing modes of the 8088.</p>
<p>Since direct addressing is one of the very few addressing modes of the 8080, and since the 8088’s designers needed to make sure that ported 8080 code ran reasonably well on the 8088, there are 8088 instructions that do nothing more than load and store the accumulator from and to memory via direct addressing. These instructions are only 3 bytes long, as shown in Figure 8.3; better yet, they execute in just 10 cycles, rather than the 14 (memory read) or 15 (memory write) cycles required by <em>mod-reg-rm</em> memory accesses that use direct addressing. (Those cycle counts are for byte-sized accesses; add 4 cycles to both forms of <code class="sourceCode nasm"><span class="kw">mov</span></code> for word-sized accesses.)</p>
<figure>
<img src="images/fig8.3RT.png" />
</figure>
</section>
<section id="looks-arent-everything" class="level3">
<h3>Looks Aren’t Everything</h3>
<p>One odd aspect of the accumulator-specific direct-addressing instructions is that in assembler form they don’t <em>look</em> any different from the more general form of the <code class="sourceCode nasm"><span class="kw">mov</span></code> instruction; the difference between the two versions only becomes apparent in machine-language. So, for example, while:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">al</span>,[Count]</code></pre>
<p>and:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">dl</span>,[Count]</code></pre>
<p>look like they refer to the same instruction, the machine code assembled from the two differs greatly, as shown in Figure 8.4; the first instruction is a byte shorter and 4 cycles faster than the second.</p>
<figure>
<img src="images/fig8.4RT.png" />
</figure>
<p>Odder still, there are actually <em>two</em> legitimate machine-language forms of the assembler code for each of the accumulator-specific direct-addressing instructions (and, indeed, for all the accumulator-specific instructions discussed in this chapter), as shown in Figure 8.5. Any 8088 assembler worth its salt automatically assembles the shorter form, of course, so the longer, general-purpose versions of the accumulator-specific instructions aren’t used. Still, the mere existence of two forms of the accumulator-specific instructions points up the special-case nature of these instructions and the general irregularity of the 8088’s instruction set.</p>
</section>
<section id="how-fast-are-they" class="level3">
<h3>How Fast Are They?</h3>
<p>How much difference does the use of the accumulator-specific direct-addressing instructions make? Generally, less difference than the official timings in Appendix A would indicate, but a significant difference</p>
<figure>
<img src="images/fig8.5RT.png" />
</figure>
<p>nonetheless — and you save a byte every time you use an accumulator-specific direct-addressing instruction, as well.</p>
<p>Suppose you want to copy the value of one byte-sized memory variable to another byte-sized memory variable. A common way to perform this simple task is to read the value of the first variable into a register, then write the value from the register to the other variable. <a href="#listing-8-1">Listing 8-1</a> shows a code fragment that performs such a byte copy 1000 times by way of the AH register. Since the accumulator is neither source nor destination in <a href="#listing-8-1">Listing 8-1</a>, the 4-byte <em>mod-reg-rm</em> direct-addressing form of <code class="sourceCode nasm"><span class="kw">mov</span></code> is assembled for each instruction; consequently, 8 bytes of code are assembled in order to copy each byte via AH, as shown in Figure 8.6. (Remember that AH is not considered the accumulator. For 8-bit operations, AL is the accumulator, and for 16-bit operations, AX is the accumulator, but AH by itself is just another general-purpose register.)</p>
<figure>
<img src="images/fig8.6RT.png" />
</figure>
<p>Plugged into the Zen timer test program, <a href="#listing-8-1">Listing 8-1</a> yields an average time per byte copied of 10.06 us, or about 48 cycles per byte copied. That’s considerably longer than the 29 cycles per byte copied you’d expect from adding up the official cycle times given in Appendix A; the difference is the result of the prefetch queue and dynamic RAM refresh cycle-eaters. We can’t cover all the aspects of code performance at once, so for the moment let’s just discuss the implications of the times reported by the Zen timer. Remember, no matter how much theory of code performance you’ve mastered, there’s still only one reliable way to know how fast PC code really is — measure it!</p>
<p><a href="#listing-8-2">Listing 8-2</a> performs the same 1000 byte copies as <a href="#listing-8-1">Listing 8-1</a>, but does so by way of the 8-bit accumulator, AL. In <a href="#listing-8-2">Listing 8-2</a>, 6 bytes of code are assembled in order to copy each byte by way of AL, as shown in Figure 8.7. Each <code class="sourceCode nasm"><span class="kw">mov</span></code> instruction in <a href="#listing-8-2">Listing 8-2</a> is a byte shorter than the corresponding instruction in <a href="#listing-8-1">Listing 8-1</a>, thanks to the 3-byte size of the accumulator-specific direct-addressing <code class="sourceCode nasm"><span class="kw">mov</span></code> instructions. The Zen timer reports that copying by way of the accumulator reduces average time per byte copied to 7.55 microseconds, which works out to about 36 cycles per byte — a 33% improvement in performance over <a href="#listing-8-1">Listing 8-1</a>.</p>
<p>Enough said.</p>
<figure>
<img src="images/fig8.7RT.png" />
</figure>
</section>
<section id="when-should-you-use-them" class="level3">
<h3>When Should You Use Them?</h3>
<p>The implications of accumulator-specific direct addressing are obvious: whenever you need to read or write a direct-addressed memory operand, do so via the accumulator if at all possible. You can take this a step further by running unorthodox applications of accumulator-specific direct addressing through the Zen timer to see whether they’re worth using. For example, one common use of direct addressing is checking whether a flag or count is zero, with an instruction sequence like:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">cmp</span>   [NumberOfShips],<span class="dv">0</span>   <span class="co">;5 bytes/20 cycles</span>
<span class="kw">jz</span>    NoMoreShips         <span class="co">;2 bytes/16 or 4 cycles</span></code></pre>
<p>In this example, <code class="sourceCode nasm">NumberOfShips</code> is accessed with <em>mod-reg-rm</em> direct addressing. We’d like to use accumulator-specific direct addressing, but because this is a <code class="sourceCode nasm"><span class="kw">cmp</span></code> instruction rather than a <code class="sourceCode nasm"><span class="kw">mov</span></code> instruction, it would seem that accumulator-specific direct addressing can’t help us.</p>
<p>Even here, however, accumulator-specific direct addressing can help speed things up a bit. Since we’re only interested in whether <code class="sourceCode nasm">NumberOfShips</code> is zero or not, we can load it into the accumulator and then <code class="sourceCode nasm"><span class="kw">and</span></code> the accumulator with itself to set the zero flag appropriately, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">ax</span>,[NumberOfShips]    <span class="co">;3 bytes/14 cycles</span>
<span class="kw">and</span>   <span class="kw">ax</span>,<span class="kw">ax</span>                 <span class="co">;2 bytes/3 cycles</span>
<span class="kw">jz</span>    NoMoreShips           <span class="co">;2 bytes/16 or 4 cycles</span></code></pre>
<p>While the accumulator-specific version is longer in terms of instructions, what really matters is that both code sequences are 7 bytes long, and that the cycle time for the accumulator-specific code is 3 cycles less according to the timings in Appendix A.</p>
<p>Of course, we only trust what we measure for ourselves, so we’ll run the code in <a href="#listing-8-3">Listings 8-3</a> and <a href="#listing-8-3](#listing-8-3)%20and%20[8-4">8-4</a> through the Zen timer. The Zen timer reports that the accumulator-specific means of testing a memory location and setting the appropriate zero/non-zero status executes in 6.34 us per test, more than 6% faster than the 6.76 us time per test of the standard test-for-zero code. While 6% isn’t a vast improvement, it <em>is</em> an improvement, and that boost in performance comes at no cost in code size. In addition, the accumulator-specific form leaves the variable’s value available in the accumulator after the test is completed, allowing for faster code yet if you need to manipulate or test that value further. The flip side is that the accumulator-specific direct-addressing approach <em>requires</em> that the test value be loaded into the accumulator, so if you’ve got something stored in the accumulator that you don’t want to lose, by all means use the <em>mod-reg-rm</em> <code class="sourceCode nasm"><span class="kw">cmp</span></code> instruction.</p>
<p>Don’t get hung up on using nifty tricks for their own sake. The object is simply to select the best instructions for the task at hand, and it matters not in the least whether those instructions happen to be dazzlingly clever or perfectly straightforward.</p>
<p>Don’t expect that unorthodox uses of accumulator-specific direct addressing will always pay off, but try them out anyway; they <em>might</em> speed up your code, and even if they don’t, your experiments might well lead to something else worth knowing. For instance, based on the official execution times in Appendix A it appears that:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">ax</span>,<span class="dv">1</span>                <span class="co">;3 bytes/4 cycles</span>
<span class="kw">mov</span>   [InitialValue],<span class="kw">ax</span>   <span class="co">;3 bytes/14 cycles</span></code></pre>
<p>should be faster than:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   [InitialValue],<span class="dv">1</span>    <span class="co">;6 bytes/20 cycles</span></code></pre>
<p>running <a href="#listing-8-5">Listings 8-5</a> and <a href="#listing-86">8-6</a> through the Zen timer, however, we find that both versions take exactly 7.54 us per initialization. The execution time in both cases is determined by the number of memory accesses rather than by Execution Unit execution time, and both versions perform 8 memory accesses per initialization (6 instruction byte fetches and 1 word-sized memory operand access).</p>
<p>While that particular trick didn’t work out, it does suggest another possibility. Suppose that we want to initialize the variable <code class="sourceCode nasm">InitialValue</code> to the specific value of zero; now we can modify <a href="#listing-8-5">Listing 8-5</a> to:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">sub</span>   <span class="kw">ax</span>,<span class="kw">ax</span>               <span class="co">;2 bytes/3 cycles`</span>
<span class="kw">mov</span>   [InitialValue],<span class="kw">ax</span>   <span class="co">;3 bytes/14 cycles`</span></code></pre>
<p>which is both 1 byte shorter and 3 cycles faster than the <em>mod-reg-rm</em> instruction:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="dt">word</span> <span class="dt">ptr</span> [InitialValue],<span class="dv">0</span>   <span class="co">;6 bytes/20 cycles</span></code></pre>
<p>Code that’s shorter in both bytes and cycles (remember, we’re talking about official cycles, as listed in Appendix A) almost always provides superior performance, and <a href="#listing-8-7">Listing 8-7</a> does indeed clock the accumulator-specific initialize-to-zero approach at 6.76 us per initialization, more than 11% faster than <a href="#listing-8-6">Listing 8-6</a>.</p>
<p>Actively pursue the possibilities in your assembler code. You never know where they might lead.</p>
</section>
<section id="accumulator-specific-immediate-operand-instructions" class="level3">
<h3>Accumulator-Specific Immediate-Operand Instructions</h3>
<p>The 8088 also offers special accumulator-specific versions of a number of arithmetic and logical instructions — <code class="sourceCode nasm"><span class="kw">adc</span></code>, <code class="sourceCode nasm"><span class="kw">add</span></code>, <code class="sourceCode nasm"><span class="kw">and</span></code>, <code class="sourceCode nasm"><span class="kw">cmp</span></code>, <code class="sourceCode nasm"><span class="kw">or</span></code>, <code class="sourceCode nasm"><span class="kw">sub</span></code>, <code class="sourceCode nasm"><span class="kw">sbb</span></code>, and <code class="sourceCode nasm"><span class="kw">xor</span></code> — when these instructions are used with one register operand and one immediate operand. (Remember that an immediate operand is a constant operand that is built right into an instruction.) The <em>mod-reg-rm</em> immediate-addressing versions of the above instructions, when used with a register as the destination operand, are 3 bytes long for byte comparisons and 4 bytes long for word comparisons, as shown in Figure 8.8. The accumulator-specific immediate-addressing versions, on the other hand, are 2 bytes long for byte comparisons and 3 bytes long for word comparisons, as shown in Figure 8.9. Although the official cycle counts listed in Appendix A for all immediate-addressing forms of these instructions — accumulator-specific or otherwise — are all 4 when used with a register as the destination, shorter is generally faster, thanks to the prefetch queue cycle-eater.</p>
<figure>
<img src="images/fig8.8RT.png" />
</figure>
<p>Let’s see how much faster the accumulator-specific immediate-addressing form of <code class="sourceCode nasm"><span class="kw">cmp</span></code> is than the <em>mod-reg-rm</em> version. (The results will hold true for all 8 accumulator-specific immediate-addressing instructions, since they all have the same sizes and execution times.) The Zen timer reports that each accumulator-specific <code class="sourceCode nasm"><span class="kw">cmp</span></code> in <a href="#listing-8-8">Listing 8-8</a> takes 1.81 us, making it 50% faster than the <em>mod-reg-rm</em> version in <a href="#listing-8-9">Listing 8-9</a>, which clocks in at 2.71 us per comparison. It is not in the least coincidental that the ratio of the execution times, 3:2, is the same as the ratio of instruction lengths in bytes; the performance difference is entirely due to the difference in instruction lengths.</p>
<figure>
<img src="images/fig8.9RT.png" />
</figure>
<p>There are two <em>caveats</em> regarding accumulator-specific immediate-addressing instructions. First, unlike the accumulator-specific form of the direct-addressing <code class="sourceCode nasm"><span class="kw">mov</span></code> instruction, the accumulator-specific immediate-addressing instructions can’t work with memory operands. For instance, <code class="sourceCode nasm"><span class="kw">add</span> <span class="kw">al</span>,[Temp]</code> assembles to a <em>mod-reg-rm</em> instruction, not to an accumulator-specific instruction.</p>
<p>Second, there’s no advantage to using the accumulator-specific immediate-addressing instructions when they’re used with word-sized immediate operands in the range -128 to +127 (inclusive), although there’s no disadvantage, either. This is true because the word-sized <em>mod-reg-rm</em> equivalents of the accumulator-specific instructions can store immediate values in this range as bytes and then sign-extend them to words at execution time, while the accumulator-specific immediate-addressing instructions cannot, as shown in Figure 8.10. Consequently, both forms of these instructions are 3 bytes long when used with immediate operands in the range -128 to +127.</p>
<p>An important note: some 8088 references indicate that while immediate operands to arithmetic instructions can be sign-extended, immediate operands to logical instructions — <code class="sourceCode nasm"><span class="kw">xor</span></code>, <code class="sourceCode nasm"><span class="kw">and</span></code>, and <code class="sourceCode nasm"><span class="kw">or</span></code> — cannot. Not true! Immediate operands to logical instructions <em>can</em> be sign-extended, and MASM does so automatically whenever possible.</p>
<figure>
<img src="images/fig8.10RT.png" />
</figure>
<p>Remember, if you’re not sure exactly what instructions the assembler is generating from your source code, you can always look at the instructions directly with a disassembler. Alternatively, you can look at the assembled hex bytes at the left side of the assembly listing.</p>
</section>
<section id="an-accumulator-specific-example" class="level3">
<h3>An Accumulator-Specific Example</h3>
<p>Let’s look at a real-world example of saving bytes and cycles with accumulator-specific instructions. We’re going to force the adapter-select bits — bits 5 and 4 of the BIOS equipment flag variable at 0000:0410 — to the setting for an 80-column color adapter. This requires first forcing the adapter-select bits to 0, then setting bit 5 to 1 and bit 4 to 0.</p>
<p>The simplest approach to setting the equipment flag to 80-column color text mode is shown in <a href="#listing-8-10">Listing 8-10</a>; this code uses one <em>mod-reg-rm</em> <code>and</code> instruction and one <em>mod-reg-rm</em> <code class="sourceCode nasm"><span class="kw">or</span></code> instruction to set the equipment flag in 18.86 us. By contrast, <a href="#listing-8-11">Listing 8-11</a> uses four accumulator-specific instructions to set the equipment flag. Even though <a href="#listing-8-11">Listing 8-11</a> uses two more instructions than <a href="#listing-8-10">Listing 8-10</a>, it is 12.5% faster, taking only 16.76 us to set the equipment flag.</p>
<figure>
<img src="images/fig8.11RT.png" />
</figure>
</section>
<section id="other-accumulator-specific-instructions" class="level3">
<h3>Other Accumulator-Specific Instructions</h3>
<p>There are two more instructions that have accumulator-specific versions: <code class="sourceCode nasm"><span class="kw">test</span></code> and <code class="sourceCode nasm"><span class="kw">xchg</span></code>. Although these instructions have no direct equivalents in the 8080 instruction set, we’ll cover them now while we’re on the topic of accumulator-specific instructions. (While the 8080 does offer some exchange instructions, the 8088’s accumulator-specific form of <code class="sourceCode nasm"><span class="kw">xchg</span></code> doesn’t correspond directly to any of those 8080 instructions.)</p>
</section>
<section id="the-accumulator-specific-version-of-test" class="level3">
<h3>The Accumulator-Specific Version Of <code>test</code></h3>
<p><code class="sourceCode nasm"><span class="kw">test</span></code> sets the flags as if an <code class="sourceCode nasm"><span class="kw">and</span></code> had taken place, but does not modify the destination. As with <code class="sourceCode nasm"><span class="kw">and</span></code>, there’s an accumulator-specific immediate-addressing version of <code class="sourceCode nasm"><span class="kw">test</span></code> that’s a byte shorter than the <em>mod-reg-rm</em> immediate version. (Unlike <code class="sourceCode nasm"><span class="kw">and</span></code>, the accumulator-specific version of <code class="sourceCode nasm"><span class="kw">test</span></code> is also a cycle faster than the <em>mod-reg-rm</em> version.) So, for example:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">test</span>    <span class="kw">al</span>,<span class="dv">1</span></code></pre>
<p>is a byte shorter and a cycle faster than:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">test</span>    <span class="kw">dh</span>,<span class="dv">1</span></code></pre>
</section>
<section id="the-ax-specific-version-of-xchg" class="level3">
<h3>The Ax-Specific Version of <code>xchg</code></h3>
<p>In its general form, <code class="sourceCode nasm"><span class="kw">xchg</span></code> swaps the values of two registers, or of a register and a memory location. The <em>mod-reg-rm</em> register-register interchange form of <code class="sourceCode nasm"><span class="kw">xchg</span></code> is 2 bytes long and executes in 4 cycles. There is, however, a special form of <code class="sourceCode nasm"><span class="kw">xchg</span></code> specifically for interchanging AX (not AL) with any of the 8 general-purpose registers. This AX-specific form is just 1 byte long and executes in a mere 3 cycles. So, for example:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">xchg</span>    <span class="kw">ax</span>,<span class="kw">bx</span></code></pre>
<p>is 1 byte and 1 cycle shorter than:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">xchg</span>    <span class="kw">al</span>,<span class="kw">bl</span></code></pre>
<p>as shown in Figure 8.11. In fact:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">xchg</span>    <span class="kw">ax</span>,<span class="kw">bx</span></code></pre>
<p>is 1 byte shorter (albeit 1 cycle slower) than:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>     <span class="kw">ax</span>,<span class="kw">bx</span></code></pre>
<p>so the AX-specific form of <code class="sourceCode nasm"><span class="kw">xchg</span></code> can be an attractive alternative to <code class="sourceCode nasm"><span class="kw">mov</span></code> when you don’t require that the copied value remain in the source register after the copy.</p>
<p>When else might the AX-specific version of <code class="sourceCode nasm"><span class="kw">xchg</span></code> be useful? Suppose that we’ve got a loop in which we need to add together elements from two arrays, subtract from that sum a value from a third array, and store the result in a fourth array. Suppose further that we can’t use BP, perhaps because it’s dedicated to maintaining a stack frame. What’s more, the pointers to the arrays are passed in, so we can’t just use one pointer register as an array subscript by way of displacement+base addressing. Now we’ve got a bit of a problem: there are only three registers other than BP capable of addressing memory, but we need pointers to four arrays. We could, of course, load two or more of the pointers from memory each time through the loop, but that would slow processing considerably. We could also store two of the pointers in other registers and copy them into, say, BX as we need them, but that would require us to use three registers to maintain two pointers, and, as it happens, we don’t have a register to spare.</p>
<p>The solution is to keep one pointer in BX and one in AX, and swap them as needed via the AX-specific form of <code class="sourceCode nasm"><span class="kw">xchg</span></code>. (As usual, the assembler automatically uses the most efficient possible form of <code class="sourceCode nasm"><span class="kw">xchg</span></code>; you don’t have to worry about explicitly selecting it.) <a href="#listing-8-12">Listing 8-12</a> show an implementation that uses the AX-specific form of <code class="sourceCode nasm"><span class="kw">xchg</span></code> to handle our four-array case without accessing memory or using BP.</p>
<p><a href="#listing-8-12">Listing 8-12</a> is intentionally constructed to allow us to use the AX-specific form of <code class="sourceCode nasm"><span class="kw">xchg</span></code>. It’s natural to choose AL, not DL, as the register used for adding and moving data, but if we had done that, then the <code class="sourceCode nasm"><span class="kw">xchg</span></code> would have become <code class="sourceCode nasm"><span class="kw">xchg</span> <span class="kw">dx</span>,<span class="kw">bx</span></code>, which is the 2-byte <em>mod-reg-rm</em> version. <a href="#listing-8-13">Listing 8-13</a> shows this less-efficient version of <a href="#listing-8-12">Listing 8-12</a>. Thanks solely to the AX-specific form of <code class="sourceCode nasm"><span class="kw">xchg</span></code>, <a href="#listing-8-12">Listing 8-12</a> executes in 21.12 us per array element, 7% faster than the 22.63 us per array element of <a href="#listing-8-13">Listing 8-13</a>. (By the way, we could revamp <a href="#listing-8-13">Listing 8-13</a> to run considerably faster by using the <code class="sourceCode nasm"><span class="kw">lodsb</span></code> and <code class="sourceCode nasm"><span class="kw">stosb</span></code> string instructions, but for the moment we’re focusing on the AX-specific form of <code class="sourceCode nasm"><span class="kw">xchg</span></code>. Nonetheless, there’s a lesson here: be careful not to become fixated on a particular trick to the point where you miss other and possibly better approaches.)</p>
<p>The important point is that in 8088 assembler it often matters which registers and/or which forms of various instructions you select. Two seemingly similar code sequences, such as <a href="#listing-8-12">Listings 8-12</a> and <a href="#listing-8-13">8-13</a>, can actually have quite different performance characteristics.</p>
<p>Yet another aspect of the Zen of assembler.</p>
</section>
</section>
<section id="pushing-and-popping-the-8080-flags" class="level2">
<h2>Pushing and Popping the 8080 Flags</h2>
<p>Finally, we come to the strangest part of the 8080 legacy, the <code class="sourceCode nasm"><span class="kw">lahf</span></code> and <code class="sourceCode nasm"><span class="kw">sahf</span></code> instructions. <code class="sourceCode nasm"><span class="kw">lahf</span></code> loads AH with the lower byte of the 8088’s FLAGS register, as shown in Figure 8.12. Not coincidentally, the lower byte of the FLAGS register contains the 8088 equivalents of the 8080’s flags, and those flags are located in precisely the same bit positions in the lower byte of the 8088’s FLAGS register as they are in the 8080’s FLAGS register. <code class="sourceCode nasm"><span class="kw">sahf</span></code> reverses the action of <code class="sourceCode nasm"><span class="kw">lahf</span></code>, loading the 8080-compatible flags into the 8088’s FLAGS register by copying AH to the lower byte of the 8088’s FLAGS register, as shown in Figure 8.13.</p>
<figure>
<img src="images/fig8.12RT.png" />
</figure>
<figure>
<img src="images/fig8.13RT.png" />
</figure>
<p>Why do these odd instructions exist? Simply to allow the 8088 to emulate efficiently the 8080’s <code class="sourceCode nasm"><span class="kw">push</span> psw</code> and <code class="sourceCode nasm"><span class="kw">pop</span> psw</code> instructions, which transfer both the 8080’s accumulator and FLAGS register to and from the stack as a single word. The 8088 sequence:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">lahf</span>
<span class="kw">push</span>  <span class="kw">ax</span></code></pre>
<p>is equivalent to the 8080 sequence:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">push</span>  psw</code></pre>
<p>and the 8088 sequence:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">pop</span>   <span class="kw">ax</span>
<span class="kw">sahf</span></code></pre>
<p>is equivalent to the 8080 sequence:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">pop</span>   psw</code></pre>
<p>While it’s a pretty safe bet that nobody is writing code that uses <code class="sourceCode nasm"><span class="kw">lahf</span></code> and <code class="sourceCode nasm"><span class="kw">sahf</span></code> to emulate 8080 instructions anymore, there are nonetheless a few interesting tricks to be played with these instructions. The key is that <code class="sourceCode nasm"><span class="kw">lahf</span></code> and <code class="sourceCode nasm"><span class="kw">sahf</span></code> give us a compact (1 byte) and fast (4 cycles) way to save and load the flags we’re generally most interested in testing without disturbing the direction and interrupt flags. (Note that the overflow flag also is not saved or restored by these instructions.) By contrast, <code class="sourceCode nasm"><span class="kw">pushf</span></code> and <code class="sourceCode nasm"><span class="kw">popf</span></code>, the standard instructions for saving and restoring the flags, take 14 and 12 cycles, respectively, and affect all the flags. What’s more, <code class="sourceCode nasm"><span class="kw">lahf</span></code> and <code class="sourceCode nasm"><span class="kw">sahf</span></code>, unlike <code class="sourceCode nasm"><span class="kw">pushf</span></code> and <code class="sourceCode nasm"><span class="kw">popf</span></code>, avoid the potential complications of accessing the stack.</p>
<p>All in all, <code class="sourceCode nasm"><span class="kw">lahf</span></code> and <code class="sourceCode nasm"><span class="kw">sahf</span></code> run faster and tend to cause fewer complications than <code class="sourceCode nasm"><span class="kw">pushf</span></code> and <code class="sourceCode nasm"><span class="kw">popf</span></code>. This means that these instructions are attractive whenever you generate a status but don’t want to check it right away. This is particularly true if you can’t be sure the stack pointer will point to the same place when you finally do check the status, since <code class="sourceCode nasm"><span class="kw">pushf</span></code> and <code class="sourceCode nasm"><span class="kw">popf</span></code> wouldn’t work in such a case.</p>
<p>By the way, <code class="sourceCode nasm"><span class="kw">sahf</span></code> is also useful for handling certain status flags of the 8087 numeric coprocessor. The 8087’s flags can’t be tested directly; they must be stored to memory by the 8087, then tested by the 8088. One good way to do this for testing certain 8088 statuses, such as greater-than/less-than results from comparisons, is by storing the 8087’s flags to memory, loading AH from the stored flags, and executing <code class="sourceCode nasm"><span class="kw">sahf</span></code> to copy the flags into the 8088’s FLAGS register, where they can be used to control conditional jumps.</p>
<section id="lahf-and-sahf-an-example" class="level3">
<h3><code>lahf</code> and <code>sahf</code>: An Example</h3>
<p>Let’s look at <code class="sourceCode nasm"><span class="kw">lahf</span></code> and <code class="sourceCode nasm"><span class="kw">sahf</span></code> in action. Suppose we have a loop in which a value stored in AL is added to each element of a byte array, with the loop ending only when the result of any addition exceeds 7Fh, causing the Sign flag to be set. Unfortunately, the array pointer must be incremented after the addition, wiping out the Sign flag that we need to test at the bottom of the loop, so we need some way to preserve the Sign flag during execution of the instruction that increments the array pointer.</p>
<p><a href="#listing-8-14">Listing 8-14</a> solves this problem by using <code class="sourceCode nasm"><span class="kw">pushf</span></code> and <code class="sourceCode nasm"><span class="kw">popf</span></code> to preserve the Sign flag. The Zen timer reports that with this approach it takes 16.45 ms to process 1000 array elements, or 16.45 us per element. Astoundingly, <a href="#listing-8-15">Listing 8-15</a>, which is exactly the same as <a href="#listing-8-14">Listing 8-14</a> save that it uses <code class="sourceCode nasm"><span class="kw">lahf</span></code> and <code class="sourceCode nasm"><span class="kw">sahf</span></code> instead of <code class="sourceCode nasm"><span class="kw">pushf</span></code> and <code class="sourceCode nasm"><span class="kw">popf</span></code>, takes only 11.31 ms, or 11.31 us per array element — a performance improvement of 45%! (That’s a 45% improvement in <em>the whole loop</em>; the performance advantage of just <code class="sourceCode nasm"><span class="kw">lahf</span></code> and <code class="sourceCode nasm"><span class="kw">sahf</span></code> versus <code class="sourceCode nasm"><span class="kw">pushf</span></code> and <code class="sourceCode nasm"><span class="kw">popf</span></code> in this loop is far greater, in the neighborhood of 200%.)</p>
</section>
</section>
<section id="a-brief-digression-on-optimization" class="level2">
<h2>A Brief Digression on Optimization</h2>
<p>As is always the case, there are other solutions to the programming task at hand than those shown in <a href="#listing-8-14">Listings 8-14</a> and <a href="#listing-8-15">8-15</a>. For example, the Sign flag could be tested immediately after the addition, as shown in <a href="#listing-8-16">Listing 8-16</a>. The approach of <a href="#listing-8-16">Listing 8-16</a> is exactly equivalent to <a href="#listing-8-14">Listings 8-14</a> and <a href="#listing-8-15">8-15</a>, but eliminates the need to preserve the flags. <a href="#listing-8-16">Listing 8-16</a> executes in 10.78 us per array element, a slight improvement over <a href="#listing-8-15">Listing 8-15</a>.</p>
<p>Let’s look at the code in <a href="#listing-8-16">Listing 8-16</a> for a moment more, since it’s often true that even heavily-optimized code will yield a bit more performance with a bit of effort. What’s looks less-than-optimal about <a href="#listing-8-16">Listing 8-16</a>? <code class="sourceCode nasm"><span class="kw">add</span></code> is pretty clearly indispensible, as is <code class="sourceCode nasm"><span class="kw">inc</span></code>. However, there are two jumps inside the loop; if we could manage with one jump, things should speed up a bit. With a bit of ingenuity, it is indeed possible to get by with one jump, as shown in <a href="#listing-8-17">Listing 8-17</a>.</p>
<p>The key to <a href="#listing-8-17">Listing 8-17</a> is that the <code class="sourceCode nasm"><span class="kw">inc</span></code> instruction that points BX to the next memory location is moved ahead of the addition, allowing us to put the conditional jump at the bottom of the loop without the necessity of preserving the flags for several instructions (as is done in <a href="#listing-8-14">Listings 8-14</a> and <a href="#listing-8-15">8-15</a>). <a href="#listing-8-17">Listing 8-17</a> looks to be much faster than <a href="#listing-8-16">Listing 8-16</a>. After all, it’s a full instruction shorter in the loop than <a href="#listing-8-16">Listing 8-16</a>, and two bytes shorter in the loop as well. Still, we only trust what we measure, so let’s compare actual performance.</p>
<p>Incredibly, the Zen timer reports that <a href="#listing-8-17">Listing 8-17</a> executes in 10.78 us per array element — <em>no faster than</em><a href="#listing-8-16">Listing 8-16</a><em>!</em> Why isn’t <a href="#listing-8-17">Listing 8-17</a> faster? To be honest, I don’t know. <a href="#listing-8-17">Listing 8-17</a> probably wastes some prefetches at the bottom of the loop, where <code class="sourceCode nasm"><span class="kw">add</span> [<span class="kw">bx</span>],<span class="kw">al</span></code>, a slow, short instruction that allows the prefetch queue to fill, is followed by a jump that flushes the queue. There may also be interaction between the memory operand accesses of the <code class="sourceCode nasm"><span class="kw">add</span></code> instruction and prefetching that works to the relative benefit of <a href="#listing-8-16">Listing 8-16</a>. There may be synchronization with DRAM refresh taking place as well.</p>
<p>I could hook up the hardware I used in Chapter 5 to find the answer, but that takes considerable time and money and simply isn’t worth the effort. As we’ve established in past chapters, we’ll never understand the exact operation of 8088 code — that’s why we have to use the Zen timer to monitor performance. The important points of this exercise in optimization are these: we created shorter, faster code by examining a programming problem from a new perspective, and we measured that code and found that it actually ran no faster than the new code.</p>
<p>Bring your knowledge and creativity to bear on improving your code. Then use the Zen timer to make sure you’ve really improved the code!</p>
<p>Interesting optimizations aside, <code class="sourceCode nasm"><span class="kw">lahf</span></code> and <code class="sourceCode nasm"><span class="kw">sahf</span></code> are always preferred to <code class="sourceCode nasm"><span class="kw">pushf</span></code> and <code class="sourceCode nasm"><span class="kw">popf</span></code> whenever you can spare AH and don’t need to save the interrupt, overflow, and direction flags, all the more so when you don’t <em>want</em> to save those flags or don’t want to have to use the stack to store flag states. Who would ever have thought that two warmed-over 8080 instructions could be so useful?</p>
<section id="onward-through-the-instruction-set" class="level3">
<h3>Onward Through the Instruction Set</h3>
<p>Given the extent to which the 8080 influenced the decidedly unusual architecture and instruction set of the 8088, it is interesting (although admittedly pointless) to wonder what might have been had the 8080 been less successful, allowing Intel to make a clean break with the past when the 8088 was designed. Still, the 8088 is what it is — so it’s on to the rest of the instruction set for us.</p>
</section>
</section>
</section>
<section id="chapter-9-around-and-about-the-instruction-set" class="level1">
<h1>Chapter 9: Around and About the Instruction Set</h1>
<p>So far, we’ve covered assembler programming in a fairly linear fashion, with one topic leading neatly to the next and with related topics grouped by chapter. Alas, assembler programming isn’t so easily pigeonholed. For one thing, the relationships between the many facets of assembler programming are complex; consider how often I’ve already mentioned the string instructions, which we have yet to discuss formally. For another, certain aspects of assembler stand alone, and are simply not particularly closely related to any other assembler topic.</p>
<p>Some interesting members of the 8088’s instruction set fall into the category of stand-alone topics, as do unusual applications of a number of instructions. For example, while the knowledge that <code class="sourceCode nasm"><span class="kw">inc</span> <span class="kw">ax</span></code> is a byte shorter than <code class="sourceCode nasm"><span class="kw">inc</span> <span class="kw">al</span></code> doesn’t have any far-reaching implications, that knowledge can save a byte and a few cycles when applied properly. Likewise, the use of <code class="sourceCode nasm"><span class="kw">cbw</span></code> to convert certain unsigned byte values to word values is a self-contained programming technique.</p>
<p>Over the last few chapters, we’ve covered the 8088’s registers, memory addressing, and 8080-influenced instructions. In this chapter, we’ll touch on more 8088 instructions. Not all the instructions, by any means (remember, I’m assuming you already know 8088 assembler) but rather those instructions with subtle, useful idiosyncracies. These instructions fall into the class described above — well worth knowing but unrelated to one another — so this chapter will be a potpourri of assembler topics, leaping from one instruction to another.</p>
<p>In the next chapter we’ll return to a more linear format as we discuss the string instructions. After that we’ll get into branching, look-up tables, and more. For now, though, hold on to your hat as we bound through the instruction set.</p>
<section id="shortcuts-for-handling-zero-and-constants" class="level2">
<h2>Shortcuts for Handling Zero and Constants</h2>
<p>The instruction set of the 8088 can perform any of a number of logical and arithmetic operations on byte-and word-sized, signed and unsigned integer values. What’s more, those values may be stored either in registers or in memory. Much of the complexity of the 8088’s instruction set results from this flexibility — and so does the slow performance of many of the 8088’s instructions. However, some of the 8088’s instructions can be used in a less flexible — but far speedier — fashion. Nowhere is this more apparent than in handling zero.</p>
<p>Zero pops up everywhere in assembler programs. Up counters are initialized to zero. Down counters are counted down to zero. Flag bytes are compared to zero. Parameters of value zero are passed to subroutines. Zero is surely the most commonly-used value in assembler programming — and the easiest value to handle, as well.</p>
<section id="making-zero" class="level3">
<h3>Making Zero</h3>
<p>For starters, there is almost never any reason to assign the immediate value zero to a register. Why assign zero to a register when <code class="sourceCode nasm"><span class="kw">sub</span> reg,reg</code> or <code class="sourceCode nasm"><span class="kw">xor</span> reg,reg</code> always zeros the register in fewer cycles (and also in fewer bytes for 16-bit registers)? The only time you should assign the value zero to a register rather than clearing the register with <code class="sourceCode nasm"><span class="kw">sub</span></code> or <code class="sourceCode nasm"><span class="kw">xor</span></code> is when you need to preserve the flags, since <code class="sourceCode nasm"><span class="kw">mov</span></code> doesn’t affect the flags but <code class="sourceCode nasm"><span class="kw">sub</span></code> and <code class="sourceCode nasm"><span class="kw">xor</span></code> do.</p>
</section>
<section id="initializing-constants-from-the-registers" class="level3">
<h3>Initializing Constants From the Registers</h3>
<p>As we discussed in the last chapter, it pays to clear a direct-addressed memory variable by zeroing AL or AX and storing that register to the memory variable. If you’re setting two or more direct-addressed variables to any specific value (and here we’re talking about <em>any</em> value, not just zero), it’s worth storing that value in the accumulator and then storing the accumulator to the memory variables. (When initializing large blocks of memory, <code class="sourceCode nasm">rep <span class="kw">stos</span></code> works better still, as we’ll see in Chapter 10.) The basic principle is this: <em>avoid extra immediate-operand bytes by storing frequently-used constants in registers and using the registers as operands</em>.</p>
<p><a href="#listing-9-1">Listing 9-1</a> provides an example of initializing multiple memory variables to the same value. This listing, which stores 0FFFFh in AX and then stores AX to three memory variables, executes in 17.60 us per three-word initialization. That’s more than 28% faster than the 22.63 us per initialization of <a href="#listing-9-2">Listing 9-2</a>, which stores the immediate value 0FFFFh to each of the three words. <a href="#listing-9-1">Listing 9-1</a> is that much faster than <a href="#listing-9-2">Listing 9-2</a> <em>even though <a href="#listing-9-1">Listing 9-1</a> is one instruction longer per initialization.</em> The difference? Each of the three <code class="sourceCode nasm"><span class="kw">mov</span></code> instructions in <a href="#listing-9-2">Listing 9-2</a> is 3 bytes longer than the corresponding <code class="sourceCode nasm"><span class="kw">mov</span></code> in <a href="#listing-9-1">Listing 9-1</a>: two bytes are taken up by the immediate value 0FFFFh, and one extra byte is required because the accumulator-specific direct-addressing form of <code class="sourceCode nasm"><span class="kw">mov</span></code> isn’t used. That’s a total of 9 extra bytes for the three <code class="sourceCode nasm"><span class="kw">mov</span></code> instructions of <a href="#listing-9-2">Listing 9-2</a>, more than offsetting the 3 bytes required by the extra instruction <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ax</span><span class="bn">,0ffffh</span></code> of <a href="#listing-9-1">Listing 9-1</a>. (Remember, the 8088 doesn’t sign-extend immediate operands to <code class="sourceCode nasm"><span class="kw">mov</span></code>.) As always, those extra bytes take 4 cycles each to fetch. <em>Shorter is better.</em></p>
<p>If you’re initializing more than one register to zero, you can save 1 cycle per additional register by initializing just one of the registers, then copying it to the other registers, as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">sub</span>   <span class="kw">si</span>,<span class="kw">si</span>   <span class="co">;point to offset 0 in DS</span>
<span class="kw">mov</span>   <span class="kw">di</span>,<span class="kw">si</span>   <span class="co">;point to offset 0 in ES</span>
<span class="kw">mov</span>   <span class="kw">dx</span>,<span class="kw">si</span>   <span class="co">;initialize counter to 0</span></code></pre>
<p>While <code class="sourceCode nasm"><span class="kw">mov</span> reg,reg</code> is 2 bytes long, the same as <code class="sourceCode nasm"><span class="kw">sub</span> reg,reg</code>, according to the official specs <code class="sourceCode nasm"><span class="kw">mov</span></code> is the faster of the two by 1 cycle. Whether this translates into any performance advantage depends on the code mix — if the prefetch queue is empty, code fetching time will dominate and <code class="sourceCode nasm"><span class="kw">mov</span></code> will have no advantage — but it can’t hurt and <em>might</em> help.</p>
<p>Similarly, if you’re initializing multiple 8-bit registers to the same <em>non-zero</em> value, you can save up to 2 cycles per additional register by initializing one of the registers and copying it to the other(s). While <code class="sourceCode nasm"><span class="kw">mov</span> reg,immed8</code> is 2 cycles slower than <code class="sourceCode nasm"><span class="kw">mov</span> reg,reg</code>, both instructions are the same size.</p>
<p>Finally, if you’re initializing multiple 16-bit registers to the same non-zero value, it <em>always</em> pays to initialize one register and copy it to the other(s). The reason: <code class="sourceCode nasm"><span class="kw">mov</span> reg,immed16</code>, at 3 bytes in length, is a byte longer (and 2 cycles slower) than <code class="sourceCode nasm"><span class="kw">mov</span> reg,reg</code>.</p>
</section>
<section id="initializing-two-bytes-with-a-single-mov" class="level3">
<h3>Initializing Two Bytes With a Single <code>mov</code></h3>
<p>While we’re on the topic of initializing registers and variables, let’s take a quick look at initializing paired bytes. Suppose we want to initialize AH to 16h and AL to 1. The obvious solution is to set each register to the desired value:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">ah</span><span class="bn">,16h</span>
<span class="kw">mov</span>   <span class="kw">al</span>,<span class="dv">1</span></code></pre>
<p>However, a better solution is to set the pair of registers with a single <code class="sourceCode nasm"><span class="kw">mov</span></code>:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">ax</span><span class="bn">,1601h</span></code></pre>
<p>The paired-register initialization is a byte shorter and 4 cycles faster… <em>and does exactly the same thing as the separate initializations</em>!</p>
<p>A trick that makes it easier to initialize paired 8-bit registers is to shift the value for the upper register by 8 bits. For example, the last initialization could be performed as:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">ax</span>,(16h <span class="kw">shl</span> <span class="dv">8</span>) + <span class="dv">1</span></code></pre>
<p>This method has two benefits. First, it’s easy to distinguish between the values for the upper and lower registers; 16 and 1 are easy to pick out in the above example. Second, it’s much simpler to handle non-hexadecimal values by shifting and adding. You must admit that:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">dx</span>,(<span class="dv">201</span> <span class="kw">shl</span> <span class="dv">8</span>) + <span class="st">&#39;A&#39;</span></code></pre>
<p>is easier to write and understand than:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">dx</span><span class="bn">,0c941h   </span><span class="co">;DH=201, DL=&#39;A&#39;</span></code></pre>
<p>You need not limit paired-byte initializations to registers. Adjacent byte-sized memory variables can be initialized with a single word access as well. If you do use paired-byte initializations of memory variables, though, be sure to place prominent comments around the memory variables; otherwise, you or someone else might accidentally separate the pair at a later date, ruining the initialization.</p>
</section>
<section id="more-fun-with-zero" class="level3">
<h3>More Fun With Zero</h3>
<p>What else can we do with zero? Well, we can test the zero/non-zero status of a register with either <code class="sourceCode nasm"><span class="kw">and</span> reg,reg</code> or <code class="sourceCode nasm"><span class="kw">or</span> reg,reg</code>. Both of these instructions set the Zero flag just as <code class="sourceCode nasm"><span class="kw">cmp</span> reg,<span class="dv">0</span></code> would… and they execute faster and are anywhere from 0 to 2 bytes shorter than <code class="sourceCode nasm"><span class="kw">cmp</span></code>. (Both <code class="sourceCode nasm"><span class="kw">and</span> reg,reg</code> and <code class="sourceCode nasm"><span class="kw">or</span> reg,reg</code> are guaranteed to be at least 1 byte shorter than <code class="sourceCode nasm"><span class="kw">cmp</span> reg,<span class="dv">0</span></code> except when <code class="sourceCode nasm">reg</code> is AL, in which case all three instructions are the same length.) <a href="#listing-9-3">Listing 9-3</a>, which uses <code class="sourceCode nasm"><span class="kw">and</span> <span class="kw">dx</span>,<span class="kw">dx</span></code> to test for the zero status of DX, clocks in at 3.62 us per test. That’s 25% faster than the 4.53 us per test of <a href="#listing-9-4">Listing 9-4</a>, which uses <code class="sourceCode nasm"><span class="kw">cmp</span> <span class="kw">dx</span>,<span class="dv">0</span></code>.</p>
<p>As described in the last chapter, it is (surprisingly) faster to load the accumulator from a direct-addressed memory variable and <code class="sourceCode nasm"><span class="kw">and</span></code> or <code class="sourceCode nasm"><span class="kw">or</span></code> the accumulator with itself in order to test whether that memory variable is zero than it is to simply compare the memory variable with an immediate operand. For instance:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">al</span>,[ByteFlag]
<span class="kw">and</span>   <span class="kw">al</span>,<span class="kw">al</span>
<span class="kw">jnz</span>   FlagNotZero</code></pre>
<p>is equivalent to and faster than:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">cmp</span>   [ByteFlag],<span class="dv">0</span>
<span class="kw">jnz</span>   FlagNotZero</code></pre>
<p>Finally, there are some cases in which tests that are really not zero/non-zero tests can be converted to tests for zero. For example, consider a test to check whether or not DX is 0FFFFh. We could use <strong>cmp dx,0ffffh</strong>, which is three bytes long and takes 4 cycles to execute. On the other hand, if we don’t need to preserve DX (that is, if we’re performing a one-time-only test) we could simply use <code class="sourceCode nasm"><span class="kw">inc</span> <span class="kw">dx</span></code>, which is only one byte long and takes just 2 cycles to execute, and then test for a zero/non-zero status. So, if we don’t mind altering DX in the course of the test:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">cmp</span>   <span class="kw">dx</span><span class="bn">,0ffffh</span>
<span class="kw">jnz</span>   NotFFFF</code></pre>
<p>and:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">inc</span>   <span class="kw">dx</span>
<span class="kw">jnz</span>   NotFFFF</code></pre>
<p>are functionally the same… save that the latter version is much smaller and faster.</p>
<p>A similar case of turning a test into a zero/non-zero test occurs when testing a value for membership in a short sequence of consecutive numbers — the equivalent of a C switch construct with just a few cases consisting of consecutive values. (Longer and/or non-consecutive sequences should be handled with look-up tables.) For example, suppose that you want to perform one action if CX is 4, another if CX is 3, a third action if CX is 2, and yet another if CX is 1. <a href="#listing-9-5">Listing 9-5</a>, which uses four <code class="sourceCode nasm"><span class="kw">cmp</span></code> instructions to test for the four cases of interest, runs in 17.01 us per switch handled. That’s a good 4.94 us slower per switch than the 12.07 us of <a href="#listing-9-6">Listing 9-6</a>, so <a href="#listing-9-5">Listing 9-5</a> runs at less than 75% of the speed of <a href="#listing-9-6">Listing 9-6</a>. <a href="#listing-9-6">Listing 9-6</a> gets its speed boost by using the 1-byte <code class="sourceCode nasm"><span class="kw">dec</span> <span class="kw">cx</span></code> instruction rather than the 3-byte <code class="sourceCode nasm"><span class="kw">cmp</span> <span class="kw">cx</span>,immed8</code> instruction to test for each of the four cases, thereby turning all the tests into zero/non-zero tests.</p>
<p>Unorthodox, yes — but very effective. The moral is clear: <em>even when the 8088 has an instruction that’s clearly intended to perform a given task (such as <code class="sourceCode nasm"><span class="kw">cmp</span></code> for comparing), don’t assume that instruction is the best way to perform that task under all conditions</em>.</p>
</section>
</section>
<section id="inc-and-dec" class="level2">
<h2><code>inc</code> and <code>dec</code></h2>
<p><code class="sourceCode nasm"><span class="kw">inc</span></code> and <code class="sourceCode nasm"><span class="kw">dec</span></code> are simple, unpretentious instructions — and more powerful than you might imagine. Since <code class="sourceCode nasm"><span class="kw">inc</span></code> and <code class="sourceCode nasm"><span class="kw">dec</span></code> require only one operand (the immediate value 1 that’s added or subtracted is implied by the instruction), they are among the shortest (1 to 4 bytes) and fastest (2 to 3 cycles for a register operand, but up to 35 for a word-sized memory operand — keep your operands in registers!) instructions of the 8088. In particular, when working with 16-bit register operands, <code class="sourceCode nasm"><span class="kw">inc</span></code> and <code class="sourceCode nasm"><span class="kw">dec</span></code> are the fastest arithmetic instructions of the 8088, with an execution time of 2 cycles paired with a length of just 1 byte.</p>
<p>How much difference does it make to use <code class="sourceCode nasm"><span class="kw">inc</span></code> or <code class="sourceCode nasm"><span class="kw">dec</span></code> rather than <code class="sourceCode nasm"><span class="kw">add</span></code> or <code class="sourceCode nasm"><span class="kw">sub</span></code>? When you’re manipulating a register, the answer is: a <em>lot</em>. In fact, it’s actually better to use <em>two</em> <code class="sourceCode nasm"><span class="kw">inc</span></code> instructions to add 2 to a 16-bit register than to add 2 with a single <code class="sourceCode nasm"><span class="kw">add</span></code>, because a single <code class="sourceCode nasm"><span class="kw">add</span></code> with an immediate operand of 2 is 3 bytes long, three times the length of a 16-bit register <code class="sourceCode nasm"><span class="kw">inc</span></code>. (Remember, shorter is better, thanks to the prefetch queue cycle-eater.)</p>
<p>The same is true of <code class="sourceCode nasm"><span class="kw">dec</span></code> versus <code class="sourceCode nasm"><span class="kw">sub</span></code> as of <code class="sourceCode nasm"><span class="kw">inc</span></code> versus <code class="sourceCode nasm"><span class="kw">add</span></code>. For example, the code in <a href="#listing-9-7">Listing 9-7</a>, which uses a 16-bit register <code class="sourceCode nasm"><span class="kw">dec</span></code> instruction, clocks in at 5.03 us per loop, 33% faster than the 6.70 us of the code in <a href="#listing-9-8">Listing 9-8</a>, which uses a <code class="sourceCode nasm"><span class="kw">sub</span></code> instruction to decrement DX.</p>
<p>The difference between the times of <a href="#listing-9-7">Listings 9-7</a> and <a href="#listing-9-8">9-8</a> is primarily attributable to the 8 cycles required to fetch the two extra bytes of the <code class="sourceCode nasm"><span class="kw">sub</span></code> instruction. To illustrate that point, consider <a href="#listing-9-9">Listing 9-9</a>, which decrements DX twice per loop. <a href="#listing-9-9">Listing 9-9</a> executes in 5.80 us per loop, approximately halfway between the times of <a href="#listing-9-7">Listings 9-7</a> and <a href="#listing-9-8">9-8</a>. That’s just what we’d expect, since the loop in <a href="#listing-9-9">Listing 9-9</a> is 1 byte longer than the loop in <a href="#listing-9-7">Listing 9-7</a> and 1 byte shorter than the loop in <a href="#listing-9-8">Listing 9-8</a>.</p>
<p><em>Use <code class="sourceCode nasm"><span class="kw">inc</span></code> or <code class="sourceCode nasm"><span class="kw">dec</span></code> in preference to <code class="sourceCode nasm"><span class="kw">add</span></code> or <code class="sourceCode nasm"><span class="kw">sub</span></code> whenever possible</em>.</p>
<p>(Actually, when SP is involved there’s an exception to the above rule for code that will run on 80286 — or 80386 — based computers. Such code should use <code class="sourceCode nasm"><span class="kw">add</span></code>, <code class="sourceCode nasm"><span class="kw">sub</span></code>, <code class="sourceCode nasm"><span class="kw">push</span></code>, and <code class="sourceCode nasm"><span class="kw">pop</span></code> to alter SP in preference to <code class="sourceCode nasm"><span class="kw">inc</span></code> and <code class="sourceCode nasm"><span class="kw">dec</span></code>, because an odd stack pointer is highly undesirable on 16-and 32-bit processors. I’ll cover this topic in detail in Chapter 15.)</p>
<p>I’d like to pause at this point to emphasize that the 16-bit register versions of <code class="sourceCode nasm"><span class="kw">inc</span></code> and <code class="sourceCode nasm"><span class="kw">dec</span></code> are different beasts from the run-of-the-mill <code class="sourceCode nasm"><span class="kw">inc</span></code> and <code class="sourceCode nasm"><span class="kw">dec</span></code> instructions. As with the 16-bit register <code class="sourceCode nasm"><span class="kw">xchg</span></code>-with-AX instructions we discussed in the last chapter, there are actually two separate <code class="sourceCode nasm"><span class="kw">inc</span></code> instructions on the 8088, one of which is a superset of the other. (The same is true of <code class="sourceCode nasm"><span class="kw">dec</span></code>, but we’ll just discuss <code class="sourceCode nasm"><span class="kw">inc</span></code> for now.)</p>
<p>Figure 9.1 illustrates the two forms of <code class="sourceCode nasm"><span class="kw">inc</span></code>. While the special form is limited to 16-bit register operands, it has the advantage of being a byte shorter and a cycle faster than the <em>mod-reg-rm</em> register form, even when both instructions operate on the same register. As you’d expect, 8088 assemblers automatically use the more efficient special version whenever possible, so you don’t need to select between the two forms explicitly. However, it’s up to you to use 16-bit register <code class="sourceCode nasm"><span class="kw">inc</span></code> (and <code class="sourceCode nasm"><span class="kw">dec</span></code>) instructions whenever you possibly can, since only then can the assembler assemble the more efficient form of those instructions.</p>
<figure>
<img src="images/fig9.1RT.png" />
</figure>
<p>For example, <a href="#listing-9-7">Listing 9-7</a>, which uses the 1-byte-long 16-bit register form of <code class="sourceCode nasm"><span class="kw">dec</span></code> to decrement the 16-bit DX register, executes in 5.03 us per loop, 15% faster than <a href="#listing-9-10">Listing 9-10</a>, which uses the 2-byte-long <em>mod-reg-rm</em> form of <code class="sourceCode nasm"><span class="kw">dec</span></code> to decrement the 8-bit DL register and executes in 5.79 us per loop.</p>
<section id="using-16-bit-inc-and-dec-instructions-for-8-bit-operations" class="level3">
<h3>Using 16-Bit <code>inc</code> and <code>dec</code> Instructions for 8-Bit Operations</h3>
<p>If you’re clever, you can sometimes use the 16-bit form of <code class="sourceCode nasm"><span class="kw">inc</span></code> or <code class="sourceCode nasm"><span class="kw">dec</span></code> even when you only want to affect an 8-bit register. Consider <a href="#listing-9-11">Listing 9-11</a>, which uses AL to count from 0 to 8. Since AL will never pass 0FFh and turn over (the only circumstance in which <code class="sourceCode nasm"><span class="kw">inc</span> <span class="kw">ax</span></code> modifies AH), it’s perfectly safe to use <code class="sourceCode nasm"><span class="kw">inc</span> <span class="kw">ax</span></code> rather than <code class="sourceCode nasm"><span class="kw">inc</span> <span class="kw">al</span></code>. In this case, both instructions always produce the same result; however, <code class="sourceCode nasm"><span class="kw">inc</span> <span class="kw">ax</span></code> produces that result considerably more rapidly than <code class="sourceCode nasm"><span class="kw">inc</span> <span class="kw">al</span></code>. If you do use such a technique, however, remember that the flags are set on the basis of the <em>whole operand</em>. For example, <code class="sourceCode nasm"><span class="kw">dec</span> <span class="kw">ax</span></code> will set the Zero flag only when both AH and AL — not AL alone — go to zero. This seems obvious, but if you’re thinking of AL as the working register, as in <a href="#listing-9-11">Listing 9-11</a>, it’s easy to forget that <code class="sourceCode nasm"><span class="kw">dec</span> <span class="kw">ax</span></code> sets the flags to reflect the status of AX, not AL.</p>
<p>To carry the quest for <code class="sourceCode nasm"><span class="kw">inc</span></code> and <code class="sourceCode nasm"><span class="kw">dec</span></code> efficiency to the limit, suppose we’re constructing code which contains nested countdown loops. Suppose further that all registers but CX are in use, so all we’ve got available for counters are CH and CL. Normally, we would expect to use two 8-bit <code class="sourceCode nasm"><span class="kw">dec</span></code> instructions here. However, we know that the counter for the inner loop is 0 after the loop is completed, so we’ve got an opportunity to perform a 16-bit <code class="sourceCode nasm"><span class="kw">dec</span></code> for the outer loop if we play our cards right.</p>
<p><a href="#listing-9-12">Listing 9-12</a> shows how this trick works. CH is the counter for the inner loop, and we are indeed stuck with an 8-bit <code class="sourceCode nasm"><span class="kw">dec</span></code> for this loop. However, by the time we get around to using CL as a counter, CH is guaranteed to be 0, so we can use a 16-bit <code class="sourceCode nasm"><span class="kw">dec</span> <span class="kw">cx</span></code> for the outer loop. Granted, it would be preferable to place the 16-bit <code class="sourceCode nasm"><span class="kw">dec</span></code> in the time-critical inner loop, and if that loop were long enough, we might well do that by pushing CX for the duration of the inner loop; nonetheless, a 16-bit <code class="sourceCode nasm"><span class="kw">dec</span></code> is preferable in any loop, and in <a href="#listing-9-12">Listing 9-12</a> we get the benefits of a 16-bit <code class="sourceCode nasm"><span class="kw">dec</span></code> at no cost other than a bit of careful register usage.</p>
<p>By the way, you’ve likely noticed that <a href="#listing-9-12">Listing 9-12</a> fairly begs for a <code class="sourceCode nasm"><span class="kw">loop</span></code> instruction at the bottom of the outer loop. That’s certainly the most efficient code in this case; I’ve broken the <code class="sourceCode nasm"><span class="kw">loop</span></code> into a <code class="sourceCode nasm"><span class="kw">dec</span></code> and a <code class="sourceCode nasm"><span class="kw">jnz</span></code> only for illustrative purposes.</p>
</section>
<section id="how-inc-and-add-and-dec-and-sub-differ---and-why" class="level3">
<h3>How <code>inc</code> and <code>add</code> (and <code>dec</code> and <code>sub</code>) Differ - and Why</h3>
<p><code class="sourceCode nasm"><span class="kw">inc</span></code> and <code class="sourceCode nasm"><span class="kw">dec</span></code> are not <em>exactly</em> the same as <code class="sourceCode nasm"><span class="kw">add</span> <span class="dv">1</span></code> and <code class="sourceCode nasm"><span class="kw">sub</span> <span class="dv">1</span></code>. Unlike addition and subtraction, <code class="sourceCode nasm"><span class="kw">inc</span></code> and <code class="sourceCode nasm"><span class="kw">dec</span></code> don’t affect the Carry flag. This can often be a nuisance, but there is a good use for this quirk of <code class="sourceCode nasm"><span class="kw">inc</span></code> and <code class="sourceCode nasm"><span class="kw">dec</span></code>, and that’s in adding or subtracting multi-word memory values.</p>
<p>Multi-word memory values are values longer than 16 bits that are stored in memory. On the 8088 such values can only be added together by a series of 16-and/or 8-bit additions. The first addition — of the least-significant words — must be performed with <code class="sourceCode nasm"><span class="kw">add</span></code>, or with <code class="sourceCode nasm"><span class="kw">adc</span></code> with the Carry flag set to 0. Subsequent additions of successively more-significant words must be performed with <code class="sourceCode nasm"><span class="kw">adc</span></code>, so that the carry-out can be passed from one addition to the next via the Carry flag. The same is true of <code class="sourceCode nasm"><span class="kw">sub</span></code>, <code class="sourceCode nasm"><span class="kw">sbb</span></code>, and borrow for subtraction of multi-word memory variables.</p>
<p>Some way is needed to address each of the words in a multi-word memory value in turn, so that each part of the value may be used as an operand. Consequently, multi-word memory values are often pointed to by registers (BP or BX and/or SI or DI), which can be advanced to point to successively more-significant portions of the values as addition or subtraction proceeds. If, however, there were no way to advance a memory-addressing register without modifying the Carry flag, then <code class="sourceCode nasm"><span class="kw">adc</span></code> and <code class="sourceCode nasm"><span class="kw">sbb</span></code> would only work properly if we preserved the Carry flag around the <code class="sourceCode nasm"><span class="kw">inc</span></code> instructions, with <code class="sourceCode nasm"><span class="kw">pushf</span></code> and <code class="sourceCode nasm"><span class="kw">popf</span></code> or <code class="sourceCode nasm"><span class="kw">lahf</span></code> and <code class="sourceCode nasm"><span class="kw">sahf</span></code>.</p>
<p><code class="sourceCode nasm"><span class="kw">inc</span></code> and <code class="sourceCode nasm"><span class="kw">dec</span></code> don’t affect the Carry flag, however, and that greatly simplifies the process of adding multi-word memory variables. The code in <a href="#listing-9-13">Listing 9-13</a>, which adds together two 64bit memory variables — one pointed to by SI and the other pointed to by DI — only works because the <code class="sourceCode nasm"><span class="kw">inc</span></code> instructions that advance the pointers don’t affect the Carry flag values that join the additions of the various parts of the variables. (It’s equally important that <code class="sourceCode nasm"><span class="kw">loop</span></code> doesn’t affect any flags, as we’ll see in Chapter 14.)</p>
</section>
</section>
<section id="carrying-results-along-in-a-flag" class="level2">
<h2>Carrying Results Along in a Flag</h2>
<p>As mentioned in Chapter 6 and illustrated in the last section, many instructions don’t affect all the flags, and some don’t affect any flags at all. You can take advantage of this by carrying a status along in the FLAGS register for several instructions before testing that status. Of course, if you do choose to carry a status along, all of the instructions executed between setting the status and testing it must leave the status alone.</p>
<p>For example, the following code tests AL for a specific value, then sets AL to 0 even before branching according to the results of the test:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">cmp</span>   <span class="kw">al</span>,RESET_FLAG   <span class="co">;sets Z to reflect test result</span>
<span class="kw">mov</span>   <span class="kw">al</span>,<span class="dv">0</span>            <span class="co">;set AL for the code following the</span>
                      <span class="co">;branch</span>
                      <span class="co">;*** NOTE: THIS INSTRUCTION MUST ***</span>
                      <span class="co">;*** NOT ALTER THE Z FLAG!       ***</span>
<span class="kw">jz</span>    IsReset         <span class="co">;branch according the to Z flag set</span>
                      <span class="co">;by CMP</span></code></pre>
<p>In this example, AL must be set to 0 no matter which way the branch goes. If we were to set AL after the branch rather than before, two <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,<span class="dv">0</span></code> instructions — one for each code sequence that might follow <code class="sourceCode nasm"><span class="kw">jz</span> IsReset</code> — would be needed. If we set AL before the <code class="sourceCode nasm"><span class="kw">cmp</span></code> instruction, the test couldn’t even be performed because the value under test in AL would be lost. In very specific cases such as this, clear advantages result from carrying a status flag along for a few instructions.</p>
<p>One caution when using the above approach: *never set a register to zero via <code class="sourceCode nasm"><span class="kw">sub</span> reg,reg</code> or <code class="sourceCode nasm"><span class="kw">xor</span> reg,reg</code> while carrying a status along. With time, you’ll get in the habit of setting registers to zero with <code class="sourceCode nasm"><span class="kw">sub</span> reg,reg</code> or <code class="sourceCode nasm"><span class="kw">xor</span> reg,reg</code>, either of which is faster (and often smaller) than <code class="sourceCode nasm"><span class="kw">mov</span> reg,<span class="dv">0</span></code>. Unfortunately, <code class="sourceCode nasm"><span class="kw">sub</span></code> and <code class="sourceCode nasm"><span class="kw">xor</span></code>affect the flags, while <code class="sourceCode nasm"><span class="kw">mov</span></code> doesn’t. For example:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">cmp</span>   <span class="kw">al</span>,RESET_FLAG   <span class="co">;sets Z to reflect status under test</span>
<span class="kw">sub</span>   <span class="kw">al</span>,<span class="kw">al</span>           <span class="co">;alters Z, causing the code to</span>
                      <span class="co">; malfunction</span>
<span class="kw">jz</span>    IsReset         <span class="co">;won&#39;t jump properly</span></code></pre>
<p>fails to preserve the Zero flag between the <code class="sourceCode nasm"><span class="kw">cmp</span></code> and the <code class="sourceCode nasm"><span class="kw">jz</span></code>, and wouldn’t work properly. In cases such as this, always be sure to use <code class="sourceCode nasm"><span class="kw">mov</span></code>.</p>
<p>The bugs that can arise from the use of a carried-along status that is accidentally wiped out are often hard to reproduce and difficult to track down, so all possible precautions should be taken whenever this technique is used. No more than a few instructions — and no branches — should occur between the setting and the testing of the status. The use of a carried-along status should always be clearly commented, as in the first example in this section. Careful commenting is particularly important in order to forestall trouble should you (or worse, someone else) alter the code at a later date without noticing that a status is being carried along.</p>
<p>If you do need to carry a status along for more than a few instructions, store the status with either <code class="sourceCode nasm"><span class="kw">pushf</span></code> or <code class="sourceCode nasm"><span class="kw">lahf</span></code>, then restore it later with <code class="sourceCode nasm"><span class="kw">popf</span></code> or <code class="sourceCode nasm"><span class="kw">sahf</span></code>, so there’s no chance of the intervening code accidentally wiping the status out.</p>
</section>
<section id="byte-to-word-and-word-to-doubleword-conversion" class="level2">
<h2>Byte-To-Word and Word-To-Doubleword Conversion</h2>
<p>On the 8088 the need frequently arises to convert byte values to word values. A byte value might be converted to a word in order to add it to a 16-bit value, or in order to use it as a pointer into a table (remember that only 16-bit registers can be used as pointers, with the lone exception of AL in the case of <code class="sourceCode nasm"><span class="kw">xlat</span></code>). Occasionally it’s also necessary to convert word values to doubleword values. One application for word-to-doubleword conversion is the preparation of a 16-bit dividend for 32-bit by 16-bit division.</p>
<p>Unsigned values are converted to a larger data type by simply zeroing the upper portion of the desired data type. For example, an unsigned byte value in DL is converted to an unsigned word value in DX with:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">sub</span>   <span class="kw">dh</span>,<span class="kw">dh</span></code></pre>
<p>Likewise, an unsigned byte value in AL can be converted to a doubleword value in DX:AX with:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">sub</span>   <span class="kw">dx</span>,<span class="kw">dx</span>
<span class="kw">mov</span>   <span class="kw">ah</span>,<span class="kw">dh</span></code></pre>
<p>In principle, conversion of a signed value to a larger data type is more complex, since it requires replication of the high (or sign) bit of the original value throughout the upper portion of the desired data type. Fortunately, the 8088 provides two instructions that handle the complications of signed conversion for us: <code class="sourceCode nasm"><span class="kw">cbw</span></code> and <code class="sourceCode nasm"><span class="kw">cwd</span></code>. <code class="sourceCode nasm"><span class="kw">cbw</span></code> sets all the bits of AH to the value of bit 7 of AL, performing signed byte-to-word conversion. <code class="sourceCode nasm"><span class="kw">cwd</span></code> sets all the bits of DX to the value of bit 15 of AX, performing signed word-to-doubleword conversion.</p>
<p>There’s nothing tricky about <code class="sourceCode nasm"><span class="kw">cbw</span></code> and <code class="sourceCode nasm"><span class="kw">cwd</span></code>, and you’re doubtless familiar with them already. What’s particularly interesting about these instructions is that they’re each only 1 byte long, 1 byte <em>shorter</em> than <code class="sourceCode nasm"><span class="kw">sub</span> reg,reg</code>. What’s more, the official execution time of <code class="sourceCode nasm"><span class="kw">cbw</span></code> is only 2 cycles, so it’s 1 cycle faster than <code class="sourceCode nasm"><span class="kw">sub</span></code> as well. <code class="sourceCode nasm"><span class="kw">cwd</span></code>’s official execution time is 5 cycles, but since it’s shorter than <code class="sourceCode nasm"><span class="kw">sub</span></code>, it will actually often execute more rapidly than <code class="sourceCode nasm"><span class="kw">sub</span></code>, thanks to the prefetch queue cycle-eater.</p>
<p>What all this means is that <code class="sourceCode nasm"><span class="kw">cbw</span></code> and <code class="sourceCode nasm"><span class="kw">cwd</span></code> are the preferred means of converting values to larger data types, and should be used whenever possible. In particular, you should use <code class="sourceCode nasm"><span class="kw">cbw</span></code> to convert unsigned bytes in the range 0-7Fh to unsigned words. While it may seem strange to use a signed type-conversion instruction to convert unsigned values, there’s no distinction between unsigned bytes in the range 0 to 7Fh and signed bytes in the range 0 to +127, since they have the same values and have bit 7 set to 0.</p>
<p><a href="#listing-9-14">Listing 9-14</a> illustrates the use of <code class="sourceCode nasm"><span class="kw">cbw</span></code> to convert an array of unsigned byte values between 0 and 7Fh to an array of word values. Note that values are read from memory and written back to memory and the loop counter is decremented, so this is a realistic usage of <code class="sourceCode nasm"><span class="kw">cbw</span></code> rather than an artificial situation designed to show the instruction in the best possible light. Despite all the other activity occurring in the loop, <a href="#listing-9-14">Listing 9-14</a> executes in 10.06 us per loop, 12% faster than <a href="#listing-9-15">Listing 9-15</a>, which executes in 11.31 us per loop while using <code class="sourceCode nasm"><span class="kw">sub</span> <span class="kw">ah</span>,<span class="kw">ah</span></code> to perform unsigned byte-to-word conversion.</p>
<p><code class="sourceCode nasm"><span class="kw">cwd</span></code> can be used in a similar manner to speed up the conversion of unsigned word values in the range 0-7FFFh to doubleword values. Another clever use of <code class="sourceCode nasm"><span class="kw">cwd</span></code> is as a more efficient way than <code class="sourceCode nasm"><span class="kw">sub</span> reg,reg</code> to set DX to 0 when you’re certain that bit 15 of AX is 0 or as a better way than <code class="sourceCode nasm"><span class="kw">mov</span> reg,0FFFFh</code> to set DX to 0FFFFh when you’re sure that bit 15 of AX is 1. Similarly, <code class="sourceCode nasm"><span class="kw">cbw</span></code> can be used as a faster way to set AH to 0 whenever bit 7 of AL is 0 or to 0FFh when bit 7 of AL is 1.</p>
<p>Viewed objectively, there’s no distinction between using <code class="sourceCode nasm"><span class="kw">cbw</span></code> to convert AL to a signed word, to zero AH when bit 7 of AL is 0, and to set AH to 0FFh when bit 7 of AL is 1. In all three cases each bit of AH is set to the value of bit 7 of AL. Viewed <em>conceptually</em>, however, it can be useful to think of <code class="sourceCode nasm"><span class="kw">cbw</span></code> as capable of performing three distinct functions: converting a signed value in AL to a signed value in AX, setting AH to 0 when bit 7 of AL is 0, and setting AH to 0FFh when bit 7 of AL is 1. After all, an important aspect of the Zen of assembler is the ability to view your resources (such as the instruction set) from the perspective most suited to your current needs. Rather than getting locked in to the limited functionality of the instruction set as it was intended to be used, you must tap into the functionality of the instruction set as it is <em>capable</em> of being used.</p>
<p><a href="#listing-9-14">Listing 9-14</a> is an excellent example of how focusing too closely on a particular sort of optimization or getting too locked into a particular meaning for an instruction can obscure a better approach. In <a href="#listing-9-14">Listing 9-14</a>, aware that the values in the array are less than 80h, we cleverly use <code class="sourceCode nasm"><span class="kw">cbw</span></code> to set AH to 0. This means that AH is set to zero every time through the loop — even though AH never changes from one pass through the loop to the next! This makes sense only if you view each byte-to-word conversion in isolation. <a href="#listing-9-16">Listing 9-16</a> shows a more sensible approach, in which AH is set to 0 just once, outside the loop. In <a href="#listing-9-16">Listing 9-16</a>, each byte value is automatically converted to a word value in AX simply by being loaded into AL.</p>
<p>In the particular case of <a href="#listing-9-16">Listing 9-16</a>, it happens that moving the setting of AH to 0 outside the loop doesn’t improve performance; <a href="#listing-9-16">Listing 9-16</a> runs at exactly the same speed as <a href="#listing-9-14">Listing 9-14</a>, no doubt thanks to the prefetch queue and DRAM refresh cycle-eaters. That’s just a fluke, though — on average, an optimization such as the one in <a href="#listing-9-16">Listing 9-16</a> will save about 4 cycles. Don’t let the quirks of the 8088 deter you from the pursuit of saving bytes and cycles — but do remember to always time your code to make sure you’ve improved it!</p>
<p>If for any reason AH <em>did</em> change each time through the loop, we could no longer use the method of <a href="#listing-9-16">Listing 9-16</a>, and <a href="#listing-9-14">Listing 9-14</a> would be a good alternative. That’s why there are no hard-and-fast rules that produce the best assembler code. Instead, you must respond flexibly to the virtually infinite variety of assembler coding situations that arise. The bigger your bag of tricks, the better off you’ll be.</p>
</section>
<section id="xchg-is-handy-when-registers-are-tight" class="level2">
<h2><code>xchg</code> is Handy When Registers Are Tight</h2>
<p>One key to good assembler code is avoiding memory and using the registers as much as possible. When you start juggling registers in order to get the maximum mileage from them, you’ll find that <code class="sourceCode nasm"><span class="kw">xchg</span></code> is a good friend.</p>
<p>Why? Because the 8088’s general-purpose registers are actually fairly special-purpose. BX is used to point to memory, CX is used to count, SI is used with <code class="sourceCode nasm"><span class="kw">lods</span></code>, and so on. As a result, you may want to use a specific register for two different purposes in a tight loop. <code class="sourceCode nasm"><span class="kw">xchg</span></code> makes that possible.</p>
<p>Consider the case where you need to handle both a loop count and a shift count. Ideally, you would want to use CX to store the loop count and CL to store the shift count. <a href="#listing-9-17">Listing 9-17</a> uses CX for both purposes by pushing and popping the loop count around the use of the shift count. However, this solution is less than ideal because <code class="sourceCode nasm"><span class="kw">push</span></code> and <code class="sourceCode nasm"><span class="kw">pop</span></code> are relatively slow instructions. Instead, we can use <code class="sourceCode nasm"><span class="kw">xchg</span></code> to swap the lower byte of the loop count with the shift count, giving each a turn in CL, as shown in <a href="#listing-9-18">Listing 9-18</a>. <a href="#listing-9-18">Listing 9-18</a> runs in 15.08 us per byte processed, versus the 20.11 us time of <a href="#listing-9-17">Listing 9-17</a>. <em>That’s a 33% improvement from a seemingly minor change!</em> The secret is that <code class="sourceCode nasm"><span class="kw">push</span></code> and <code class="sourceCode nasm"><span class="kw">pop</span></code> together take 27 cycles, while a register-register <code class="sourceCode nasm"><span class="kw">xchg</span></code> takes no more than 4 cycles to execute once fetched and only 8 cycles even when the prefetch queue is empty.</p>
<p>Neither <a href="#listing-9-17">Listing 9-17</a> or <a href="#listing-9-18">Listing 9-18</a> is the most practical solution to this particular problem. A better solution would be to simply store the loop count in a register other than CX and use <code class="sourceCode nasm"><span class="kw">dec</span></code>/<code class="sourceCode nasm"><span class="kw">jnz</span></code> rather than <code class="sourceCode nasm"><span class="kw">loop</span></code>. The object of this exercise wasn’t to produce ideal code, but rather to illustrate that <code class="sourceCode nasm"><span class="kw">xchg</span></code> gives you both speed and flexibility when you need to use a single register for more than one purpose.</p>
<p><code class="sourceCode nasm"><span class="kw">xchg</span></code> is also useful when you need more memory pointers in a loop than there are registers that can point to memory. See Chapter 8 for an example of the use of <code class="sourceCode nasm"><span class="kw">xchg</span></code> to allow BX to point to two arrays. As the example in Chapter 8 also points out, the form of <code class="sourceCode nasm"><span class="kw">xchg</span></code> used to swap AX with another general-purpose register is 1 byte shorter than the standard form of <code class="sourceCode nasm"><span class="kw">xchg</span></code>.</p>
<p>Finally, <code class="sourceCode nasm"><span class="kw">xchg</span></code> is useful for getting and setting a memory variable at the same time. For example, suppose that we’re maintaining a flag that’s used by an interrupt handler. One way to get the current flag setting and force the flag to zero is:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">cli</span>               <span class="co">;turn interrupts off</span>
<span class="kw">mov</span>   <span class="kw">al</span>,[Flag]   <span class="co">;get the current flag value</span>
<span class="kw">mov</span>   [Flag],<span class="dv">0</span>    <span class="co">;set the flag to 0</span>
<span class="kw">sti</span>               <span class="co">;turn interrupts on</span></code></pre>
<p>(It’s necessary to disable interrupts to ensure that the interrupt handler doesn’t change <code class="sourceCode nasm">Flag</code> between the instruction that reads the flag and the instruction that resets it.)</p>
<p>With <code class="sourceCode nasm"><span class="kw">xchg</span></code>, however, we can do the same thing with just two instructions:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">sub</span>   <span class="kw">al</span>,<span class="kw">al</span>       <span class="co">;set AL to 0</span>
<span class="kw">xchg</span>  [Flag],<span class="kw">al</span>   <span class="co">;get the current flag value and</span>
                  <span class="co">; set the flag to 0</span></code></pre>
<p>Best of all, we don’t need to disable interrupts in the <code class="sourceCode nasm"><span class="kw">xchg</span></code>-based code, since interrupts can only occur between instructions, not during them! (Interrupts <em>can</em> occur between repetitions of a repeated string instruction, but that’s because a single string instruction is actually executed multiple times when it’s repeated. We’ll discuss repeated string instructions at length in Chapters 10 and 11.)</p>
</section>
<section id="destination-register" class="level2">
<h2>Destination: Register</h2>
<p>Many arithmetic and logical operations can be performed with a register as one operand and a memory location as the other, with either one being the source and the other serving as the destination. For example, both of the following forms of <code class="sourceCode nasm"><span class="kw">sub</span></code> are valid:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">sub</span>   [<span class="kw">bx</span>],<span class="kw">al</span>
<span class="kw">sub</span>   <span class="kw">al</span>,[<span class="kw">bx</span>]</code></pre>
<p>The two instructions are not the same, of course. Memory is the destination in the first case, while AL is the destination in the second case. That’s not the only distinction between the two instructions, however. There’s also a major difference in the area of performance.</p>
<p>Consider this. Any instruction, such as <code class="sourceCode nasm"><span class="kw">sub</span></code>, that has a register source operand and a memory destination operand must access memory twice: once to fetch the destination operand prior to performing an operation, and once to store the result of the operation to the destination operand. By contrast, the same instruction with a memory source operand and a register destination operand must access memory just once, in order to fetch the source value from memory. Consequently, having a memory operand as the destination imposes an immediate penalty of at least 4 cycles per instruction, since each memory access takes a minimum of 4 cycles.</p>
<p>As it turns out, however, the extra time required to access destination memory operands with such instructions — which include <code class="sourceCode nasm"><span class="kw">adc</span></code>, <code class="sourceCode nasm"><span class="kw">add</span></code>, <code class="sourceCode nasm"><span class="kw">and</span></code>, <code class="sourceCode nasm"><span class="kw">or</span></code>, <code class="sourceCode nasm"><span class="kw">sbb</span></code>, <code class="sourceCode nasm"><span class="kw">sub</span></code>, and <code class="sourceCode nasm"><span class="kw">xor</span></code> — is not 4 but 7 cycles, according to the official specs in Appendix A. We can measure the actual difference by timing the code in <a href="#listing-9-19">Listings 9-19</a> and <a href="#listing-9-20">9-20</a>. As it turns out, the code with AL as the destination takes just 5.03 us per instruction. That’s 1.00 us (4.77 cycles) or nearly 20% faster than the code with memory as the destination operand, which takes 6.03 us per instruction.</p>
<p>The moral of the story? Simply to keep those operands which tend to be destination operands most frequently — counters, pointers, and the like — in registers whenever possible. The ideal situation is one in which both destination and source operands are in registers.</p>
<p>By the way, remember that an instruction with a word-sized memory operand requires an additional 4 cycles per memory access to access the second byte of the word. Consequently:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">add</span>   [<span class="kw">si</span>],<span class="kw">dx</span>   <span class="co">;performs 2 word-sized accesses</span>
                <span class="co">; (= 4 byte-sized accesses)</span></code></pre>
<p>takes 8 cycles longer than:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">add</span>   [<span class="kw">si</span>],<span class="kw">dl</span>   <span class="co">;performs 2 byte-sized accesses</span></code></pre>
<p>However:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">add</span>   <span class="kw">dx</span>,[<span class="kw">si</span>]   <span class="co">;performs 1 word-sized access</span>
                <span class="co">; (= 2 byte-sized accesses)</span></code></pre>
<p>takes only 4 cycles longer than:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">add</span>   <span class="kw">dl</span>,[<span class="kw">si</span>]   <span class="co">;performs 1 byte-sized access</span></code></pre>
<p>since only one memory access is performed by each.</p>
<p>A final note: at least one 8088 reference lists <code class="sourceCode nasm"><span class="kw">cmp</span></code> as requiring the same 7 additional cycles as <code class="sourceCode nasm"><span class="kw">sub</span></code> when used with a memory operand that is the destination rather than the source. Not so — <code class="sourceCode nasm"><span class="kw">cmp</span></code> requires the same time no matter which operand is a memory operand. That makes sense, since <code class="sourceCode nasm"><span class="kw">cmp</span></code> doesn’t actually modify the destination operand and so has no reason to perform a second memory access. The same is true for <code class="sourceCode nasm"><span class="kw">test</span></code>, which doesn’t modify the destination operand.</p>
</section>
<section id="neg-and-not" class="level2">
<h2><code>neg</code> and <code>not</code></h2>
<p><code class="sourceCode nasm"><span class="kw">neg</span></code> and <code class="sourceCode nasm"><span class="kw">not</span></code> are short, fast instructions that are sometimes undeservedly overlooked. Each instruction is 2 bytes long and executes in just 3 cycles when used with a register operand, and each instruction can often replace a longer instruction or several instructions.</p>
<p><code class="sourceCode nasm"><span class="kw">not</span> mem/reg</code> is similar to <code class="sourceCode nasm"><span class="kw">xor</span> mem/reg<span class="bn">,0ffffh</span></code> (or <code class="sourceCode nasm"><span class="kw">xor</span> mem/reg<span class="bn">,0ffh</span></code> for 8-bit operands), but is usually 1 byte shorter and 1 cycle faster. (If <em>mem/reg</em> is AL, <code class="sourceCode nasm"><span class="kw">not</span></code> and <code class="sourceCode nasm"><span class="kw">xor</span></code> are the same length, but <code class="sourceCode nasm"><span class="kw">not</span></code> is still 1 cycle faster.) Another difference between the two instructions is that unlike <code class="sourceCode nasm"><span class="kw">xor</span></code>, <code class="sourceCode nasm"><span class="kw">not</span></code> doesn’t affect any of the status flags. This can be useful for, say, toggling the state of a flag byte without disturbing the statuses that an earlier operation left in the FLAGS register.</p>
<p><code class="sourceCode nasm"><span class="kw">neg</span></code> negates a signed value in a register or memory variable. You can think of <code class="sourceCode nasm"><span class="kw">neg</span></code> as subtracting the operand from 0 and storing the result back in the operand. The flags are set to reflect this subtraction from 0, so <code class="sourceCode nasm"><span class="kw">neg</span> <span class="kw">ax</span></code> sets the flags as if:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">dx</span>,<span class="kw">ax</span>
<span class="kw">mov</span>   <span class="kw">ax</span>,<span class="dv">0</span>
<span class="kw">sub</span>   <span class="kw">ax</span>,<span class="kw">dx</span></code></pre>
<p>had been performed.</p>
<p>One interesting consequence of the way in which <code class="sourceCode nasm"><span class="kw">neg</span></code> sets the flags is that the Carry flag is set in every case except when the operand was originally 0. (That’s because in every other case a value larger than 0 is being subtracted from 0, resulting in a borrow.) This is very handy for negating 32-bit operands quickly. In the following example, DX:AX contains a 32-bit operand to be negated:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">neg</span>   <span class="kw">dx</span>
<span class="kw">neg</span>   <span class="kw">ax</span>
<span class="kw">sbb</span>   <span class="kw">dx</span>,<span class="dv">0</span></code></pre>
<p>Although it’s not obvious, the above code does indeed negate DX:AX, and does so very quickly indeed. (You might well think that there couldn’t possibly be a faster way to negate a 32-bit value, but in Chapter 13 we’ll see a decidedly unusual approach that’s faster still. Be wary of thinking you’ve found the fastest possible code for any task!)</p>
<p>How does the above negation code work? Well, normally we would want to perform a two’s complement negation by flipping all bits of the operand and then adding 1 to it, as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">not</span>   <span class="kw">dx</span>    <span class="co">;flip all bits...</span>
<span class="kw">not</span>   <span class="kw">ax</span>    <span class="co">;...of the operand</span>
<span class="kw">add</span>   <span class="kw">ax</span>,<span class="dv">1</span>  <span class="co">;remember, INC doesn&#39;t set the Carry flag!</span>
<span class="kw">adc</span>   <span class="kw">dx</span>,<span class="dv">0</span>  <span class="co">;then add 1 to finish the two&#39;s complement</span></code></pre>
<p>However, this code is 10 bytes long, a full 3 bytes longer than our optimized negation code. In the optimized code, the first negation word flips all bits of DX and adds 1 to that result, and the second negation flips all bits of AX and adds 1 to that result. At this point, we’ve got a perfect two’s complement result, except that 1 has been added to DX. That’s incorrect — unless AX was originally 0.</p>
<p>Aha! Thanks to the way <code class="sourceCode nasm"><span class="kw">neg</span></code> sets the flags, the Carry flag is always set <em>except when the operand was originally 0</em>. Consequently, we need only to subtract from DX the carry-out from <code class="sourceCode nasm"><span class="kw">neg</span> <span class="kw">ax</span></code> and we’ve got a 32-bit two’s-complement negation — in just 7 bytes!</p>
<p>By the way, 32-bit negation can also be performed with the three instruction, 7-cycle sequence:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">not</span>   <span class="kw">dx</span>
<span class="kw">neg</span>   <span class="kw">ax</span>
<span class="kw">sbb</span>   <span class="kw">dx</span>,-<span class="dv">1</span></code></pre>
<p>If you can understand why this sequence works, you’ve got a good handle on <code class="sourceCode nasm"><span class="kw">neg</span></code>, <code class="sourceCode nasm"><span class="kw">not</span></code>, and two’s complement arithmetic. (Hint: the underlying principle in the last sequence is exactly the same as with the <code class="sourceCode nasm"><span class="kw">neg</span></code>/<code class="sourceCode nasm"><span class="kw">neg</span></code>/<code class="sourceCode nasm"><span class="kw">sbb</span></code> approach we just discussed.) If not, wait until Chapter 13, in which we’ll explore the workings of 32-bit negation in considerable detail.</p>
<p><code class="sourceCode nasm"><span class="kw">neg</span></code> is also handy for generating differences without using <code class="sourceCode nasm"><span class="kw">sub</span></code> and without using other registers. For example, suppose that we’re scanning a list for a match with AL. <code class="sourceCode nasm">repnz <span class="kw">scasb</span></code> (which we’ll discuss further in Chapter 10) is ideal for such an application. However, after <code class="sourceCode nasm">repnz <span class="kw">scasb</span></code> has found a match, CX contains the number of entries in the list that weren’t scanned, not the number that <em>were</em> scanned, and it’s the latter number that we want in CX. Fortunately, we can use <code class="sourceCode nasm"><span class="kw">neg</span></code> to convert the entries-remaining count in CX into an entries-scanned count, as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="co">; The value to search for is already in AL, and ES:DI</span>
<span class="co">; already points to the list to scan.</span>
<span class="kw">mov</span>     <span class="kw">cx</span>,[NumberOfEntries]  <span class="co">;# of entries to scan</span>
<span class="kw">cld</span>                           <span class="co">;make SCASB count up</span>
repnz   <span class="kw">scasb</span>                 <span class="co">;look for the value</span>
<span class="kw">jnz</span>     ValueNotFound         <span class="co">;the value is not in the list</span>
<span class="kw">neg</span>     <span class="kw">cx</span>                    <span class="co">;the # of entries not scanned</span>
                              <span class="co">; times -1</span>
<span class="kw">add</span>     <span class="kw">cx</span>,[NumberOfEntries]  <span class="co">;total # of entries -# of</span>
                              <span class="co">; entries not scanned = # of</span>
                              <span class="co">; entries scanned</span></code></pre>
<p>Thanks to <code class="sourceCode nasm"><span class="kw">neg</span></code>, this replaces the longer code sequence:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="co">; The value to search for is already in AL, and ES:DI</span>
<span class="co">; already points to the list to scan.</span>
<span class="kw">mov</span>     <span class="kw">cx</span>,[NumberOfEntries]  <span class="co">;# of entries to scan</span>
<span class="kw">cld</span>                           <span class="co">;make SCASB count up</span>
repnz   <span class="kw">scasb</span>                 <span class="co">;look for the value</span>
<span class="kw">jnz</span>     ValueNotFound         <span class="co">;the value is not in the list</span>
<span class="kw">mov</span>     <span class="kw">ax</span>,[NumberOfEntries]  <span class="co">;total # of entries</span>
<span class="kw">sub</span>     <span class="kw">ax</span>,<span class="kw">cx</span>                 <span class="co">;total # of entries -# of</span>
                              <span class="co">; entries not scanned = # of</span>
                              <span class="co">; entries scanned</span>
<span class="kw">mov</span>     <span class="kw">cx</span>,<span class="kw">ax</span>                 <span class="co">;put the result back in CX</span></code></pre>
<p>Another advantage of <code class="sourceCode nasm"><span class="kw">neg</span></code> in the above example is that it lets us generate the entries-remaining count without using another register. By contrast, the alternative approach requires the use of a 16-bit register for temporary storage. When registers are in short supply — as is usually the case — the register-conserving nature of <code class="sourceCode nasm"><span class="kw">neg</span></code> can be most useful.</p>
</section>
<section id="rotates-and-shifts" class="level2">
<h2>Rotates and Shifts</h2>
<p>Next, we’re going to spend some time going over interesting aspects of the various shift and rotate instructions. To my mind, the single most fascinating thing about these instructions concerns their ability to shift or rotate by either 1 bit or the number of bits specified by CL; in particular, it’s most informative to examine the relative performance of the two approaches for multi-bit operations.</p>
<p>It’s much more desirable than you might think to perform multi-bit shifts and rotates by repeating the shift or rotate CL times, as opposed to using multiple 1-bit shift or rotate instructions. As is so often the case, the cycle counts in Appendix A are misleading in this regard. As it turns out, shifting or rotating multiple bits by repeating an instruction CL times, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">cl</span>,<span class="dv">4</span>
<span class="kw">shr</span>   <span class="kw">ax</span>,<span class="kw">cl</span></code></pre>
<p>is almost always faster than shifting by 1 bit repeatedly, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">shr</span>   <span class="kw">ax</span>,<span class="dv">1</span>
<span class="kw">shr</span>   <span class="kw">ax</span>,<span class="dv">1</span>
<span class="kw">shr</span>   <span class="kw">ax</span>,<span class="dv">1</span>
<span class="kw">shr</span>   <span class="kw">ax</span>,<span class="dv">1</span></code></pre>
<p><em>This is true even though the official specs in Appendix A indicate that the latter approach is more than twice as fast.</em></p>
<p>Shifting or rotating by CL also requires fewer instruction bytes for shifts of more than 2 bits. In fact, that reduced instruction byte count is precisely the reason the shift/rotate by CL approach is faster. As we saw in Chapter 4, fetching the instruction bytes of <code class="sourceCode nasm"><span class="kw">shr</span> <span class="kw">ax</span>,<span class="dv">1</span></code> takes up to four cycles per byte; each shift or rotate instruction is 2 bytes long, so <code class="sourceCode nasm"><span class="kw">shr</span> <span class="kw">ax</span>,<span class="dv">1</span></code> can take as much as 8 cycles per bit shifted. By contrast, only 4 instruction bytes in total need to be fetched in order to load CL and execute <code class="sourceCode nasm"><span class="kw">shr</span> <span class="kw">ax</span>,<span class="kw">cl</span></code>. Once those bytes are fetched, <code class="sourceCode nasm"><span class="kw">shr</span> <span class="kw">ax</span>,<span class="kw">cl</span></code> runs at its Execution Unit speed of 4 cycles per bit shifted, since no additional instruction fetching is needed. Better yet, the <em>next</em> instruction’s bytes can be prefetched while a shift or rotate by CL executes.</p>
<p>The point is not that shifts and rotates by CL are faster than you’d expect, but rather that 1-bit shifts and rotates are <em>slower</em> than you’d expect, courtesy of the prefetch queue cycle-eater. The question is, of course, at what point does it become faster to shift or rotate by CL instead of using multiple 1-bit shift or rotate instructions?</p>
<p>To answer that, I’ve timed the two approaches, shown in <a href="#listing-9-21">Listings 9-21</a> and <a href="#listing-9-22">9-22</a>, for shifts ranging from 1 to 7 bits, by altering the equated value of BITS_TO_SHIFT accordingly. The results are as follows:</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Bits shifted (BITS_TO_SHIFT)</th>
<th style="text-align: left;">Time taken to shift by CL (<a href="#listing-9-21">Listing 9-21</a>)</th>
<th style="text-align: left;">Time taken to shift 1 bit at a time (<a href="#listing-9-22">Listing 9-22</a>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">3.6 us</td>
<td style="text-align: left;">1.8 us</td>
</tr>
<tr class="even">
<td style="text-align: left;">2</td>
<td style="text-align: left;">4.2 us</td>
<td style="text-align: left;">3.6 us</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3</td>
<td style="text-align: left;">5.0 us</td>
<td style="text-align: left;">5.4 us</td>
</tr>
<tr class="even">
<td style="text-align: left;">4</td>
<td style="text-align: left;">5.9 us</td>
<td style="text-align: left;">7.2 us</td>
</tr>
<tr class="odd">
<td style="text-align: left;">5</td>
<td style="text-align: left;">6.7 us</td>
<td style="text-align: left;">9.1 us</td>
</tr>
<tr class="even">
<td style="text-align: left;">6</td>
<td style="text-align: left;">7.5 us</td>
<td style="text-align: left;">10.9 us</td>
</tr>
<tr class="odd">
<td style="text-align: left;">7</td>
<td style="text-align: left;">8.4 us</td>
<td style="text-align: left;">12.7 us</td>
</tr>
</tbody>
</table>
<p>Astonishingly, it hardly <em>ever</em> pays to shift or rotate by multiple bit places with separate 1-bit instructions. The prefetch queue cycle-eater exacts such a price on 1-bit shifts and rotates that it pays to shift or rotate by CL for shifts of 3 or more bits. Actually, the choice is not entirely clear-cut for 3-to 5-bit shifts/rotates, since the 1-bit-at-a-time approach can become relatively somewhat faster if the prefetch queue is full when the shift/rotate sequence begins. Still, there’s no question but what shifting or rotating by CL is as good as or superior to using multiple 1-bit shifts for most multi-bit shifts.</p>
<p>By the way, you should be aware that the contents of CL are not changed when CL is used to supply the count for a shift or rotate instruction. This allows you to load CL once and then use it to control multiple shift and/or rotate instructions.</p>
<section id="shifting-and-rotating-memory" class="level3">
<h3>Shifting and Rotating Memory</h3>
<p>One feature of the 8088 that for some reason is often overlooked is the ability to shift or rotate a memory variable. True, the 8088 doesn’t shift or rotate memory variables very <em>rapidly</em>, but the capability is there should you need it. If you should find the need to perform a multi-bit shift or rotate on a memory variable, for goodness sakes use a CL shift! Every 1-bit memory shift/rotate takes a <em>minimum</em> of 20 cycles. By contrast, a shift-by-CL memory shift/rotate takes a minimum of 25 cycles, but only 4 additional cycles per bit shifted. It doesn’t take a genius to see that for, say, a 4-bit rotate, the 41 cycles taken by the CL shift would beat the stuffing out of the 80 cycles taken by the four 1-bit shifts.</p>
</section>
<section id="rotates" class="level3">
<h3>Rotates</h3>
<p>You should be well aware that there are two sorts of rotates. One category, made up of <code class="sourceCode nasm"><span class="kw">rol</span></code> and <code class="sourceCode nasm"><span class="kw">ror</span></code>, consists of rotates that simply rotate the bits in the operand, as shown in Figure 9.2.</p>
<figure>
<img src="images/fig9.2RT.png" />
</figure>
<p>These instructions are useful for adjusting masks, swapping nibbles, and the like. For example:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">cl</span>,<span class="dv">4</span>
<span class="kw">ror</span>   <span class="kw">al</span>,<span class="kw">cl</span></code></pre>
<p>swaps the high and low nibbles of AL. Note that these instructions don’t rotate through the Carry flag. However, they <em>do</em> copy the bit wrapped around to the other end of the operand to the Carry flag as well.</p>
<p>The other rotate category, made up of <code class="sourceCode nasm"><span class="kw">rcl</span></code> and <code class="sourceCode nasm"><span class="kw">rcr</span></code>, consists of rotates that rotate the operand <em>through</em> the Carry flag, as shown in Figure 9.3. These instructions are useful for multi-word shifts and rotates.</p>
<figure>
<img src="images/fig9.3RT.png" />
</figure>
<p>For example:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">shr</span>   <span class="kw">dx</span>,<span class="dv">1</span>
<span class="kw">rcr</span>   <span class="kw">cx</span>,<span class="dv">1</span>
<span class="kw">rcr</span>   <span class="kw">bx</span>,<span class="dv">1</span>
<span class="kw">rcr</span>   <span class="kw">ax</span>,<span class="dv">1</span></code></pre>
<p>shifts the 64-bit value in DX:CX:BX:AX right one bit.</p>
<p>The rotate instructions affect fewer flags than you might think, befitting their role as bit-manipulation rather than arithmetic instructions. None of the rotate instructions affect the Sign, Zero, Auxiliary Carry, or Parity flags. On 1-bit left rotates the Overflow flag is set to the exclusive-or of the value of the resulting Carry flag and the most-significant bit of the result. On 1-bit right rotates the Overflow flag is set to the exclusive-or of the two most-significant bits of the result. (These Overflow flag settings indicate whether the rotate has changed the sign of the operand.) On rotates by CL the setting of the Overflow flag is undefined.</p>
</section>
<section id="shifts" class="level3">
<h3>Shifts</h3>
<p>Similarly, there are two sorts of shift instructions. One category, made up of <code class="sourceCode nasm"><span class="kw">shl</span></code> (also known as <code class="sourceCode nasm"><span class="kw">sal</span></code>) and <code class="sourceCode nasm"><span class="kw">shr</span></code>, consists of shifts that shift out to the Carry flag, shifting a 0 into the vacated bit of the operand, as shown in Figure 9.4.</p>
<figure>
<img src="images/fig9.4RT.png" />
</figure>
<p>These instructions are used for moving masks and bits about and for performing fast unsigned division and multiplication by powers of 2. For example:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">shl</span>   <span class="kw">ax</span>,<span class="dv">1</span></code></pre>
<p>multiplies AX, viewed as an unsigned value, by 2.</p>
<p>The other shift category contains only <code class="sourceCode nasm"><span class="kw">sar</span></code>. <code class="sourceCode nasm"><span class="kw">sar</span></code> performs the same shift right as does <code class="sourceCode nasm"><span class="kw">shr</span></code>, save that the most significant bit of the operand is preserved rather than zeroed after the shift, as shown in Figure 9.5.</p>
<figure>
<img src="images/fig9.5RT.png" />
</figure>
<p>This preserves the sign of the operand, and is useful for performing fast signed division by powers of 2. For example:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">sar</span>   <span class="kw">ax</span>,<span class="dv">1</span></code></pre>
<p>divides AX, viewed as a signed value, by 2.</p>
<p>The shift instructions affect the arithmetic-oriented flags that the rotate instructions leave alone, which makes sense since the shift instructions can perform certain types of multiplication and division. Unlike the rotate instructions, the shift instructions modify the Sign, Zero, and Parity flags in the expected ways. The setting of the Auxiliary Carry flag is undefined. The setting of the Overflow flag by the shift instructions is identical to the Overflow settings of the rotate instructions. On 1-bit left shifts the Overflow flag is set to the exclusive-or of the resulting Carry flag and the most-significant bit of the result. On 1-bit right shifts the Overflow flag is set to the exclusive-or of the two most-significant bits of the result.</p>
<p>Basically, any given shift will set the Overflow flag to 1 if the sign of the result differs from the sign of the original operand, thereby signalling that the shift has not produced a valid signed multiplication or division result. <code class="sourceCode nasm"><span class="kw">sar</span></code> always sets the Overflow flag to 0, since <code class="sourceCode nasm"><span class="kw">sar</span></code> can never change the sign of an operand. <code class="sourceCode nasm"><span class="kw">shr</span></code> always sets the Overflow flag to the high-order bit of the original value, since the sign of the result is always positive. On shifts by CL the setting of the Overflow flag is undefined.</p>
</section>
<section id="signed-division-with-sar" class="level3">
<h3>Signed Division With <code>sar</code></h3>
<p>One tip if you do use <code class="sourceCode nasm"><span class="kw">sar</span></code> to divide signed values: for negative dividends, <code class="sourceCode nasm"><span class="kw">sar</span></code> rounds to the integer result of the next <em>largest</em> absolute value. This can be confusing, since for positive values <code class="sourceCode nasm"><span class="kw">sar</span></code> rounds to the integer result of the next <em>smallest</em> absolute value, just as <code class="sourceCode nasm"><span class="kw">shr</span></code> does. That is:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">ax</span>,<span class="dv">1</span>
<span class="kw">sar</span>   <span class="kw">ax</span>,<span class="dv">1</span></code></pre>
<p>returns 1/2=0, while:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">ax</span>,-<span class="dv">1</span>
<span class="kw">sar</span>   <span class="kw">ax</span>,<span class="dv">1</span></code></pre>
<p>doesn’t return -1/2=0, but rather -1/2=-1. Similarly, <code class="sourceCode nasm"><span class="kw">sar</span></code> insists that -5/4=-2, not -1. This is actually a tendency to round to the next integer value less than the actual result in all cases, which is exactly what <code class="sourceCode nasm"><span class="kw">shr</span></code> also does. While that may be consistent, it’s nonetheless generally a nuisance, since we tend to expect that, say, -1/2*-1 should equal 1/2*1, but with <code class="sourceCode nasm"><span class="kw">sar</span></code> we actually get 1 for the former and 0 for the latter.</p>
<p>The solution? For a signed division by <em>n</em> of a negative number with <code class="sourceCode nasm"><span class="kw">sar</span></code>, simply add <em>n</em>-1 to the dividend before shifting. This compensates exactly for the rounding <code class="sourceCode nasm"><span class="kw">sar</span></code> performs. For example:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">mov</span>   <span class="kw">ax</span>,-<span class="dv">1</span>   <span class="co">;sample dividend</span>
    <span class="kw">and</span>   <span class="kw">ax</span>,<span class="kw">ax</span>   <span class="co">;is the dividend negative?</span>
    <span class="kw">jns</span>   DoDiv   <span class="co">;it&#39;s positive, so we&#39;re ready to divide</span>
    <span class="kw">add</span>   <span class="kw">ax</span>,<span class="dv">2-1</span>  <span class="co">;it&#39;s negative, so we need to compensate.</span>
                  <span class="co">; This is division by 2, so we&#39;ll</span>
                  <span class="co">; add n-1 = 2-1</span>
<span class="fu">DoDiv:</span>
    <span class="kw">sar</span>   <span class="kw">ax</span>,<span class="dv">1</span>    <span class="co">;signed divide by 2</span></code></pre>
<p>returns 0, just what we’d expect from -1/2.</p>
<p>That’s a quick look at what the shift and rotate instructions were designed to do. Now let’s bring a little Zen of assembler to bear in cooking up a use for <code class="sourceCode nasm"><span class="kw">sar</span></code> that you can be fairly sure was never planned by the architects of the 8088.</p>
</section>
<section id="bit-doubling-made-easy" class="level3">
<h3>Bit-Doubling Made Easy</h3>
<p>Think back to the bit-doubling example of Chapter 7, where we found that a bit-doubling routine based on register-register instructions didn’t run nearly as fast as it should have, thanks to the prefetch queue. We boosted the performance of the routine by performing a table look-up, and that’s the best solution that I know of. There is, however, yet <em>another</em> bit-doubling technique (conceived by my friend Dan Illowsky) that’s faster than the original shift-based approach. Interestingly enough, this new technique uses <code class="sourceCode nasm"><span class="kw">sar</span></code>.</p>
<p>Let’s consider <code class="sourceCode nasm"><span class="kw">sar</span></code> as a bit-manipulation instruction rather than as a signed arithmetic instruction. What does <code class="sourceCode nasm"><span class="kw">sar</span></code> really do? Well, it shifts all the bits of the operand 1 bit to the right, and it shifts bit 0 of the operand into the Carry flag. The most significant bit of the operand is left unchanged — <em>and it is also shifted 1 bit to the right</em>.</p>
<p>In other words, the most significant bit is doubled!</p>
<p>Once we’ve made the conceptual leap from <code class="sourceCode nasm"><span class="kw">sar</span></code> as arithmetic instruction to <code class="sourceCode nasm"><span class="kw">sar</span></code> as “bit-twiddler,” we’ve got an excellent tool for bit-doubling. The code in <a href="#listing-7-14">Listing 7-14</a> placed the byte containing the bits to be doubled in two registers (BL and BH) and then doubled the bits with 4 instructions:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">shr</span>   <span class="kw">bl</span>,<span class="dv">1</span>
<span class="kw">rcr</span>   <span class="kw">ax</span>,<span class="dv">1</span>
<span class="kw">shr</span>   <span class="kw">bh</span>,<span class="dv">1</span>
<span class="kw">rcr</span>   <span class="kw">ax</span>,<span class="dv">1</span></code></pre>
<p>By contrast, the <code class="sourceCode nasm"><span class="kw">sar</span></code> approach, illustrated in <a href="#listing-9-23">Listing 9-23</a>, requires only one source register and doubles the bits with just 3 instructions:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">shr</span>   <span class="kw">bl</span>,<span class="dv">1</span>
<span class="kw">rcr</span>   <span class="kw">ax</span>,<span class="dv">1</span>
<span class="kw">sar</span>   <span class="kw">ax</span>,<span class="dv">1</span></code></pre>
<p>The <code class="sourceCode nasm"><span class="kw">sar</span></code> approach requires only 75% as many code bytes as the approach in <a href="#listing-7-14">Listing 7-14</a>. Since instruction fetching dominates the execution time of <a href="#listing-7-14">Listing 7-14</a>, the shorter <code class="sourceCode nasm"><span class="kw">sar</span></code>-based code should be considerably faster, and indeed it is. <a href="#listing-9-23">Listing 9-23</a> doubles bits in 47.07 us per byte doubled, more than 34% faster than the 63.36 us of <a href="#listing-7-14">Listing 7-14</a>. (Note that the ratio of the execution times is almost exactly 3-to-4…which is the ratio of the code sizes of the two approaches. <em>Keep your code short!</em>)</p>
<p>Mind you, the <code class="sourceCode nasm"><span class="kw">sar</span></code> approach of <a href="#listing-9-23">Listing 9-23</a> is still <em>much</em> slower than the look-up approach of <a href="#listing-7-15">Listing 7-15</a>. What’s more, the code in <a href="#listing-9-23">Listing 9-23</a> is both slower and larger than the <code class="sourceCode nasm"><span class="kw">xlat</span></code>-based nibble look-up approach shown in <a href="#listing-7-18">Listing 7-18</a>, so <code class="sourceCode nasm"><span class="kw">sar</span></code> really isn’t a preferred technique for doubling bits. The point to our discussion of bit-doubling with <code class="sourceCode nasm"><span class="kw">sar</span></code> is actually this: <em>all sorts of interesting possibilities open up once you start to view instructions in terms of what they do, rather than what they were designed to do.</em></p>
</section>
</section>
<section id="ascii-and-decimal-adjust" class="level2">
<h2>ASCII and Decimal Adjust</h2>
<p>Now we come to the ASCII and decimal-adjust instructions: <code class="sourceCode nasm"><span class="kw">daa</span></code>, <code class="sourceCode nasm"><span class="kw">das</span></code>, <code class="sourceCode nasm"><span class="kw">aaa</span></code>, <code class="sourceCode nasm"><span class="kw">aas</span></code>, <code class="sourceCode nasm"><span class="kw">aam</span></code>, and <code class="sourceCode nasm"><span class="kw">aad</span></code>. To be honest, I’m covering these instructions only because many people have asked me what they are used for. In truth, they aren’t useful very often, and there aren’t any particularly nifty or non-obvious uses for them that I’m aware of, so I’m not going to cover them at great length, and you shouldn’t spend too much time trying to understand them unless they fill a specific need of yours. Still, the ASCII and decimal-adjust instructions do have their purposes, so here goes.</p>
<section id="daa-das-and-packed-bcd-arithmetic" class="level3">
<h3><code>daa</code>, <code>das</code>, and Packed BCD Arithmetic</h3>
<p><code class="sourceCode nasm"><span class="kw">daa</span></code> (“decimal adjust AL after addition”) and <code class="sourceCode nasm"><span class="kw">das</span></code> (“decimal adjust AL after subtraction”) adjust AL to the correct value after addition of two packed BCD (binary coded decimal) operands. Packed BCD is a number-storage format whereby a digit between 0 and 9 is stored in each nibble, so the hex value 1000h interpreted in BCD is 1000 decimal, not 4096 decimal. (Unpacked BCD is similar to packed BCD, save that only one digit rather than two is stored in each byte.)</p>
<p>Naturally, the addition of two BCD values with the <code class="sourceCode nasm"><span class="kw">add</span></code> instruction doesn’t produce the right result. The contents of AL after <code class="sourceCode nasm"><span class="kw">add</span> <span class="kw">al</span>,<span class="kw">bl</span></code> is performed with 09h (9 decimal in BCD) in AL and 01h (1 decimal in BCD) in BL is 0Ah, which isn’t even a BCD digit. What <code class="sourceCode nasm"><span class="kw">daa</span></code> does is take the binary result of the addition of a packed BCD byte (two digits) in AL and adjust it to the correct sum. If, in the last example, <code class="sourceCode nasm"><span class="kw">daa</span></code> had been performed after <code class="sourceCode nasm"><span class="kw">add</span> <span class="kw">al</span>,<span class="kw">bl</span></code>, AL would have contained 10h, which is 10 in packed BCD — the correct answer.</p>
<p><code class="sourceCode nasm"><span class="kw">das</span></code> performs a similar adjustment after subtraction of packed BCD numbers. The mechanics of <code class="sourceCode nasm"><span class="kw">daa</span></code> and <code class="sourceCode nasm"><span class="kw">das</span></code> are a bit complex, and I won’t go into them here, since I know of no use for the instructions save to adjust packed BCD results. Yes, I <em>do</em> remember that I told you to look at instructions for what they can do, not what they were designed to do. As far as I know, though, the two are one and the same for <code class="sourceCode nasm"><span class="kw">daa</span></code> and <code class="sourceCode nasm"><span class="kw">das</span></code>. I’ll tell you what: look up the detailed operation of these instructions, find an unintended use for them, and let me know what it is. I’ll be delighted to hear! One possible hint: these instructions are among the very few that pay attention to the Auxiliary Carry flag.</p>
<p>I’m not going to spend any more time on <code class="sourceCode nasm"><span class="kw">daa</span></code> and <code class="sourceCode nasm"><span class="kw">das</span></code>, because they’re just not used that often. BCD arithmetic is used primarily for working with on values to an exact number of decimal digits. (By contrast, normal binary arithmetic stores values to an exact number of <em>binary</em> digits, which can cause rounding problems with decimal calculations.) Consequently, BCD arithmetic is useful for accounting purposes, but not much else. Moreover, BCD arithmetic is decidedly slow. If you’re one of the few who need BCD arithmetic, the BCD-oriented instructions are there, and BCD arithmetic is well-discussed in the literature — it’s been around for decades, and many IBM mainframes use it — so go to it. For the rest of you, don’t worry that you’re missing out on powerful and mysterious instructions — the BCD instructions are deservedly obscure.</p>
</section>
<section id="aam-aad-and-unpacked-bcd-arithmetic" class="level3">
<h3><code>aam</code>, <code>aad</code>, and Unpacked BCD Arithmetic</h3>
<p><code class="sourceCode nasm"><span class="kw">aam</span></code> and <code class="sourceCode nasm"><span class="kw">aad</span></code> are BCD instructions of a slightly different flavor and a bit more utility. <code class="sourceCode nasm"><span class="kw">aam</span></code> (“ASCII adjust AX after multiply”) adjusts the result in AL of the multiplication of two single-digit unpacked BCD values to a valid two-digit unpacked BCD value in AX. This is accomplished by dividing AL by 10 and storing the quotient in AH and the remainder in AL. (By contrast, <code class="sourceCode nasm"><span class="kw">div</span></code> stores the quotient in AL and the remainder in AH.)</p>
<p><code class="sourceCode nasm"><span class="kw">aad</span></code> (“ASCII adjust AL <em>before</em> division”) converts a two-digit unpacked BCD value in AX into the binary equivalent in AX. This is performed by multiplying AH by 10, adding it to AL, and zeroing AH. The binary result of <code class="sourceCode nasm"><span class="kw">aad</span></code> can then be divided by a single-digit BCD value to generate a single-digit BCD result.</p>
<p>By the way, “ASCII adjust” really means unpacked BCD for these instructions, since ASCII digits with the upper nibble zeroed are unpacked BCD digits. <code class="sourceCode nasm"><span class="kw">aaa</span></code> and <code class="sourceCode nasm"><span class="kw">aas</span></code>, which we’ll discuss shortly, explicitly convert ASCII digits into unpacked BCD, but <code class="sourceCode nasm"><span class="kw">aam</span></code> and <code class="sourceCode nasm"><span class="kw">aad</span></code> require that you use <code class="sourceCode nasm"><span class="kw">and</span></code> to zero the upper nibble of ASCII digits before performing multiplication and division.</p>
<p><code class="sourceCode nasm"><span class="kw">aam</span></code> can be used to implement multiplication of arbitrarily long unpacked BCD operands <em>one digit at a time</em>. That is, with <code class="sourceCode nasm"><span class="kw">aam</span></code> you can multiply decimal numbers just the way we do it with a pencil and paper, multiplying one digit of each product together at a time and carrying the results along. Presumably, <code class="sourceCode nasm"><span class="kw">aad</span></code> can be used similarly in the division of two BCD operands, although I’ve never found an example of the use of <code class="sourceCode nasm"><span class="kw">aad</span></code>.</p>
<p>At any rate, the two instructions do have some small use apart from unpacked BCD arithmetic. They can save a bit of code space if you need to perform exactly the specified division by 10 of <code class="sourceCode nasm"><span class="kw">aam</span></code> or multiplication by 10 and addition of <code class="sourceCode nasm"><span class="kw">aad</span></code>, although you must be sure that the result can fit in a single byte. In particular, <code class="sourceCode nasm"><span class="kw">aam</span></code> has an advantage over <code class="sourceCode nasm"><span class="kw">div</span></code> in that a <code class="sourceCode nasm"><span class="kw">div</span></code> by an 8-bit divisor requires a 16-bit dividend in AX, while <code class="sourceCode nasm"><span class="kw">aam</span></code> uses only an 8-bit dividend in AL. <code class="sourceCode nasm"><span class="kw">aam</span></code> has another advantage in that unlike <code class="sourceCode nasm"><span class="kw">div</span></code>, it doesn’t require a register to store the divisor.</p>
<p>For example, <a href="#listing-9-24">Listing 9-24</a> shows code that converts a byte value to a three-digit ASCII string by way of <code class="sourceCode nasm"><span class="kw">aam</span></code>. <a href="#listing-9-25">Listing 9-25</a>, by contrast, converts a byte value to an ASCII string by using explicit division by 10 via <code class="sourceCode nasm"><span class="kw">div</span></code>. <a href="#listing-9-24">Listing 9-24</a> is only 28 bytes long per byte converted, 2 bytes shorter than <a href="#listing-9-25">Listing 9-25</a>. <a href="#listing-9-24">Listing 9-24</a> also executes in 54.97 us per conversion, 2.65 us faster than the 57.62 us of <a href="#listing-9-25">Listing 9-25</a>. Normally, an improvement of 2.65 us would have us jumping up and down, but the lengthy execution times of both conversion routines mean that the speed advantage of <a href="#listing-9-24">Listing 9-24</a> is only about 5%. That’s certainly an improvement — but painfully slow nonetheless.</p>
<p><code class="sourceCode nasm"><span class="kw">aam</span></code> and <code class="sourceCode nasm"><span class="kw">aad</span></code> would be more interesting if they provided significantly faster ways than <code class="sourceCode nasm"><span class="kw">div</span></code> and <code class="sourceCode nasm"><span class="kw">mul</span></code> to divide and multiply by 10. Unfortunately, that’s not the case, as the above results illustrate. <code class="sourceCode nasm"><span class="kw">aad</span></code> and <code class="sourceCode nasm"><span class="kw">aam</span></code> must use the 8088’s general-purpose multiplication and division capabilities, for they are just about as slow as <code class="sourceCode nasm"><span class="kw">mul</span></code> and <code class="sourceCode nasm"><span class="kw">div</span></code>. <code class="sourceCode nasm"><span class="kw">aad</span></code> is the speedster of the two at 60 cycles per execution, while <code class="sourceCode nasm"><span class="kw">aam</span></code> executes in 83 cycles.</p>
</section>
<section id="notes-on-mul-and-div" class="level3">
<h3>Notes on <code>mul</code> and <code>div</code></h3>
<p>I’d like to take a moment to note some occasionally annoying characteristics of <code class="sourceCode nasm"><span class="kw">mul</span></code> and <code class="sourceCode nasm"><span class="kw">div</span></code>. <code class="sourceCode nasm"><span class="kw">mul</span></code> (and <code class="sourceCode nasm"><span class="kw">imul</span></code>, but I’ll refer only to <code class="sourceCode nasm"><span class="kw">mul</span></code> from now on for brevity) has a tendency to surprise you by wiping out a register that you’d intuitively think it wouldn’t, because the product is stored in twice as many bits as either factor. For example, <code class="sourceCode nasm"><span class="kw">mul</span> <span class="kw">bl</span></code> stores the result in AX, not AL, and <code class="sourceCode nasm"><span class="kw">mul</span> <span class="kw">cx</span></code> stores the result in DX:AX, not AX. While this sounds simple enough, it’s easy to forget in the heat of coding.</p>
<p>Similarly, it’s easy to forget that <code class="sourceCode nasm"><span class="kw">div</span></code> requires that the dividend be twice as large as the divisor and quotient. (The following discussion applies to <code class="sourceCode nasm"><span class="kw">idiv</span></code> as well; again, I’ll refer only to <code class="sourceCode nasm"><span class="kw">div</span></code> for brevity.) In order to divide one 16-bit value by another, it’s essential that the 16-bit dividend be extended to a 32-bit value, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">bx</span>,[Divisor]
<span class="kw">mov</span>   <span class="kw">ax</span>,[Dividend]
<span class="kw">sub</span>   <span class="kw">dx</span>,<span class="kw">dx</span>         <span class="co">;extend Dividend to an unsigned 32-bit value</span>
<span class="kw">div</span>   <span class="kw">bx</span></code></pre>
<p>(<code class="sourceCode nasm"><span class="kw">cwd</span></code> can be used for sign-extension to a 32-bit value.) What’s particularly tricky about 32-bit-by-16-bit division is that it leaves the remainder in DX. That means that if you perform multiple 16-bit-by-16-bit divisions in a loop, <em>you must zero DX every time through the loop</em>. For example, the following code to convert a binary number to five ASCII digits wouldn’t work properly, because the dividend wouldn’t be properly extended to 32 bits after the first division, which would leave the remainder in DL:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">mov</span>   <span class="kw">ax</span>,[Count]            <span class="co">;value to convert to ASCII</span>
    <span class="kw">sub</span>   <span class="kw">dx</span>,<span class="kw">dx</span>                 <span class="co">;extend Count to an unsigned 32-bit value</span>
    <span class="kw">mov</span>   <span class="kw">bx</span>,<span class="dv">10</span>                 <span class="co">;divide by 10 to convert to decimal</span>
    <span class="kw">mov</span>   <span class="kw">si</span>,offset CountEnd<span class="dv">-1</span>  <span class="co">;ASCII count goes here</span>
    <span class="kw">mov</span>   <span class="kw">cx</span>,<span class="dv">5</span>                  <span class="co">;we want 5 ASCII digits</span>
<span class="fu">DivLoop:</span>
    <span class="kw">div</span>   <span class="kw">bx</span>                    <span class="co">;divide by 10</span>
    <span class="kw">add</span>   <span class="kw">dl</span>,<span class="st">&#39;0&#39;</span>                <span class="co">;convert this digit to ASCII</span>
    <span class="kw">mov</span>   [<span class="kw">si</span>],<span class="kw">dl</span>               <span class="co">;store the ASCII digit</span>
    <span class="kw">dec</span>   <span class="kw">si</span>                    <span class="co">;point to the next most significant digit</span>
    <span class="kw">loop</span>  DivLoop</code></pre>
<p>On the other hand, the following code would work perfectly well, because it extends the dividend to 32 bits every time through the loop:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">mov</span>   <span class="kw">ax</span>,[Count]            <span class="co">;value to convert to ASCII</span>
    <span class="kw">mov</span>   <span class="kw">bx</span>,<span class="dv">10</span>                 <span class="co">;extend Count to an unsigned 32-bit value</span>
    <span class="kw">mov</span>   <span class="kw">si</span>,offset CountEnd<span class="dv">-1</span>  <span class="co">;ASCII count goes here</span>
    <span class="kw">mov</span>   <span class="kw">cx</span>,<span class="dv">5</span>                  <span class="co">;we want 5 ASCII digits</span>
<span class="fu">DivLoop:</span>
    <span class="kw">sub</span>   <span class="kw">dx</span>,<span class="kw">dx</span>                 <span class="co">;extend the dividend to an unsigned 32-bit value</span>
    <span class="kw">div</span>   <span class="kw">bx</span>                    <span class="co">;divide by 10</span>
    <span class="kw">add</span>   <span class="kw">dl</span>,<span class="st">&#39;0&#39;</span>                <span class="co">;convert this digit to ASCII</span>
    <span class="kw">mov</span>   [<span class="kw">si</span>],<span class="kw">dl</span>               <span class="co">;store the ASCII digit</span>
    <span class="kw">dec</span>   <span class="kw">si</span>                    <span class="co">;point to the next most significant digit</span>
    <span class="kw">loop</span>  DivLoop</code></pre>
<p>All of the above goes for 8-bit-by-8-bit division as well, except that in that case it’s the 8-bit dividend in AL that you must extend to a word in AX before each division.</p>
<p>There’s another tricky point to <code class="sourceCode nasm"><span class="kw">div</span></code>: <code class="sourceCode nasm"><span class="kw">div</span></code> can crash a program by generating a divide-by-zero interrupt (interrupt 0) under certain circumstances. Obviously, this can happen if you divide by zero, but that’s not the only way <code class="sourceCode nasm"><span class="kw">div</span></code> can generate a divide-by-zero interrupt. If a division is attempted for which the quotient doesn’t fit into the destination register (AX for 32-bit-by-16-bit divides, AL for 16-bit-by-8-bit divides), a divide-by-zero interrupt occurs. So, for example:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">ax</span><span class="bn">,0ffffh</span>
<span class="kw">mov</span>   <span class="kw">dl</span>,<span class="dv">1</span>
<span class="kw">div</span>   <span class="kw">dl</span></code></pre>
<p>results in a divide-by-zero interrupt.</p>
<p>Often, you know exactly what the dividend and divisor will be for a particular division, or at least what range they’ll be in, and in those cases you don’t have to worry about <code class="sourceCode nasm"><span class="kw">div</span></code> causing a divide-by-zero interrupt. If you’re not sure that the dividend and divisor are safe, however, you <em>must</em> guard against potential problems. One way to do this is by intercepting interrupt 0 and handling divide-by-zero interrupts. The alternative is to check the dividend and divisor before each division to make sure both that the divisor is non-zero and that the dividend isn’t so much larger than the divisor that the result won’t fit in 8 or 16 bits, whichever size the division happens to be.</p>
<p>This division-by-zero business is undeniably a nuisance to have to deal with — but it’s absolutely necessary if you’re going to perform division without knowing that the inputs can safely be used.</p>
</section>
<section id="aaa-aas-and-decimal-ascii-arithmetic" class="level3">
<h3><code>aaa</code>, <code>aas</code>, and Decimal ASCII Arithmetic</h3>
<p>Finally, we come to <code class="sourceCode nasm"><span class="kw">aaa</span></code> and <code class="sourceCode nasm"><span class="kw">aas</span></code>, which support addition and subtraction of decimal ASCII digits. Actually, <code class="sourceCode nasm"><span class="kw">aaa</span></code> and <code class="sourceCode nasm"><span class="kw">aas</span></code> support addition and subtraction of any two unpacked BCD digits, or indeed of any two bytes at all the lower nibbles of which contain digits in the range 0-9.</p>
<p><code class="sourceCode nasm"><span class="kw">aaa</span></code> (“ASCII adjust after addition”) adjusts AL to the correct decimal (unpacked BCD) result of the addition of two nibbles. Consider this: if you add two digits in the range 0-9, one of three things can happen. The result can be in the range 0-9, in which case no adjustment is needed and no decimal carry has occurred. Alternatively, the result can be in the range 0Ah-0Fh, in which case the result can be corrected by adding 6 to the result, taking the result modulo 16 (decimal), and setting carry-out. Finally, the result can be in the range 10h-12h, in which case the result can be corrected in exactly the same way as for results in the range 0Ah-0Fh.</p>
<p><code class="sourceCode nasm"><span class="kw">aaa</span></code> handles all three cases with a single 1-byte instruction. <code class="sourceCode nasm"><span class="kw">aaa</span></code> assumes that an <code class="sourceCode nasm"><span class="kw">add</span></code> or <code class="sourceCode nasm"><span class="kw">adc</span></code> instruction has just executed, with the Auxiliary Carry flag set appropriately. If the Auxiliary Carry flag is set (indicating a result in the range 10h-12h) or if the lower nibble of AL is in the range 0Ah-0Fh, then 6 is added to AL, the Auxiliary Carry and Carry flags are set to 1, and AH is incremented. Finally, the upper nibble of AL is set to 0 in all cases.</p>
<p>What does all this mean? Obviously, it means that it’s easy to add together unpacked BCD numbers. More important, though, is that <code class="sourceCode nasm"><span class="kw">aaa</span></code> makes it fast (4 cycles per <code class="sourceCode nasm"><span class="kw">aaa</span></code>) and easy to add together ASCII representations of decimal numbers. That’s genuinely useful because it takes a slew of cycles to convert a binary number to an ASCII representation; after all, a division by 10 is required for each digit to be converted. ASCII numbers are necessary for all sorts of data displays for which speed is important, ranging from game scores to instrumentation readouts. <code class="sourceCode nasm"><span class="kw">aaa</span></code> makes possible the attractive alternative of keeping the numbers in displayable ASCII forms at all times, thereby avoiding the need for any sort of conversion at all.</p>
<p><a href="#listing-9-26">Listing 9-26</a> shows the use of <code class="sourceCode nasm"><span class="kw">aaa</span></code> in adding the value 1 - stored as the ASCII decimal string “00001” — to an ASCII decimal count. Granted, it takes much longer to perform the ASCII decimal increment shown in <a href="#listing-9-26">Listing 9-26</a> than it does to execute an <code class="sourceCode nasm"><span class="kw">inc</span></code> instruction — more than 100 times as long, in fact, at 93.00 us per ASCII decimal increment versus a maximum of 0.809 us per <code class="sourceCode nasm"><span class="kw">inc</span></code>. However, <a href="#listing-9-26">Listing 9-26</a> maintains the count in instantly-displayable ASCII form, and for frequently-displayed but rarely-changed numbers, a ready-to-display format can more than compensate for lengthier calculations.</p>
<p>If you do use <code class="sourceCode nasm"><span class="kw">aaa</span></code>, remember that you have not one but two ways to use the carry-out that indicates that a decimal digit has counted from 9 back around to 0. The Carry flag is set on carry-out; that’s what we use as the carry-out status in <a href="#listing-9-26">Listing 9-26</a>. In addition, though, AH is incremented by <code class="sourceCode nasm"><span class="kw">aaa</span></code> whenever decimal carry-out occurs. It’s certainly possible to get some extra mileage by putting the next-most-significant digit in AH before performing <code class="sourceCode nasm"><span class="kw">aaa</span></code> so that the carry-out is automatically carried. It’s also conceivable that you could use <code class="sourceCode nasm"><span class="kw">aaa</span></code> specifically to increment AH depending on either the value in AL or on the setting of the Auxiliary Carry flag, although I’ve never seen such an application. Since the Auxiliary Carry flag isn’t testable by any conditional jump (or indeed by any instructions other than <code class="sourceCode nasm"><span class="kw">daa</span></code>, <code class="sourceCode nasm"><span class="kw">das</span></code>, <code class="sourceCode nasm"><span class="kw">aaa</span></code>, and <code class="sourceCode nasm"><span class="kw">aas</span></code>), <code class="sourceCode nasm"><span class="kw">aaa</span></code> is perhaps the best hope for getting extra utility from that obscure flag.</p>
<p><code class="sourceCode nasm"><span class="kw">aas</span></code> (“ASCII adjust after subtraction”) is well and truly the mirror image of <code class="sourceCode nasm"><span class="kw">aaa</span></code>. <code class="sourceCode nasm"><span class="kw">aas</span></code> is designed to be used after a <code class="sourceCode nasm"><span class="kw">sub</span></code> or <code class="sourceCode nasm"><span class="kw">sbb</span></code>, subtracting 6 from the result, decrementing AH, and setting the Carry flag if the result in AL is not in the range 0-9, and zeroing the high nibble of AL in any case. You’ll find that wherever <code class="sourceCode nasm"><span class="kw">aaa</span></code> is useful, so too will be <code class="sourceCode nasm"><span class="kw">aas</span></code>.</p>
</section>
</section>
<section id="mnemonics-that-cover-multiple-instructions" class="level2">
<h2>Mnemonics That Cover Multiple Instructions</h2>
<p>As we’ve seen several times in this chapter and the last, 8088 assembler often uses a single mnemonic, such as <code class="sourceCode nasm"><span class="kw">mov</span></code>, to name two or more instructions that perform the same operations but are quite different in size and execution speed. When the assembler encounters such a mnemonic in assembler source code, it automatically chooses the most efficient instruction that fills the bill.</p>
<p>For example, earlier in this chapter we learned that there’s a special 16-bit register-only version of <code class="sourceCode nasm"><span class="kw">inc</span></code> that’s shorter and faster than the standard <em>mod-reg-rm</em> version of <code class="sourceCode nasm"><span class="kw">inc</span></code>. Whenever you use a 16-bit register <code class="sourceCode nasm"><span class="kw">inc</span></code> in source code — for example, <code class="sourceCode nasm"><span class="kw">inc</span> <span class="kw">ax</span></code> — the assembler uses the more efficient 16-bit register-only <code class="sourceCode nasm"><span class="kw">inc</span></code>; otherwise, the assembler uses the standard version.</p>
<p>Naturally, you’d prefer to use the most efficient version of a given mnemonic whenever possible. The only way to do that is to know the various instructions described by each mnemonic and to strive to use the forms of the mnemonic that assemble to the most efficient instruction. For instance, consider the choice between <code class="sourceCode nasm"><span class="kw">inc</span> <span class="kw">ax</span></code> and <code class="sourceCode nasm"><span class="kw">inc</span> <span class="kw">al</span></code>. Without inside knowledge, there’s nothing to choose from between these two assembler lines. In fact, there might be a temptation to choose the 8-bit form on the premise that an 8-bit operation can’t <em>possibly</em> be slower than a 16-bit one. Actually, of course, it <em>can</em>… but you’ll only know that the 16-bit <code class="sourceCode nasm"><span class="kw">inc</span></code> is the one to pick if you’re aware of the two instructions <code class="sourceCode nasm"><span class="kw">inc</span></code> describes.</p>
<p>This section is a summary of mnemonics that cover multiple instructions, many of which we’ve covered in detail elsewhere in this book. The mnemonics that describe multiple instructions are:</p>
<ul>
<li><code class="sourceCode nasm"><span class="kw">inc</span></code>, which has a <em>mod-reg-rm</em> version and a 16-bit register-only version, as described earlier in this chapter (the same applies to <code class="sourceCode nasm"><span class="kw">dec</span></code>).</li>
<li><code class="sourceCode nasm"><span class="kw">xchg</span></code>, which has a <em>mod-reg-rm</em> version and a 16-bit exchange-with-AX-only version, as described in Chapter 8.</li>
<li><code class="sourceCode nasm"><span class="kw">add</span></code>, which has two <em>mod-reg-rm</em> versions (one for adding a register and a memory variable or a second register together, and another for adding immediate data to a register or memory variable) and an accumulator-specific immediate-addressing version, as described in Chapter 8 (the same applies to <code class="sourceCode nasm"><span class="kw">adc</span></code>, <code class="sourceCode nasm"><span class="kw">and</span></code>, <code class="sourceCode nasm"><span class="kw">cmp</span></code>, <code class="sourceCode nasm"><span class="kw">or</span></code>, <code class="sourceCode nasm"><span class="kw">sbb</span></code>, <code class="sourceCode nasm"><span class="kw">sub</span></code>, <code class="sourceCode nasm"><span class="kw">test</span></code> and <code class="sourceCode nasm"><span class="kw">xor</span></code>, also as described in Chapter 8).</li>
<li><code class="sourceCode nasm"><span class="kw">mov</span></code>, which requires further explanation.</li>
</ul>
<p><code class="sourceCode nasm"><span class="kw">mov</span></code> covers several instructions, and it’s worth understanding each one. The basic form of <code class="sourceCode nasm"><span class="kw">mov</span></code> is a <em>mod-reg-rm</em> form that copies one register or memory variable to another register or memory variable. (Memory-to-memory moves are not permitted, however.) There’s also a <em>mod-reg-rm</em> form of <code class="sourceCode nasm"><span class="kw">mov</span></code> that allows the copying of a segment register to a general-purpose register or a memory variable, and vice-versa. Last among the <em>mod-reg-rm</em> versions of <code class="sourceCode nasm"><span class="kw">mov</span></code>, there’s a form of <code class="sourceCode nasm"><span class="kw">mov</span></code> that supports the setting of a register or a memory variable to an immediate value.</p>
<p>There are two more versions of <code class="sourceCode nasm"><span class="kw">mov</span></code>, both of which are non-<em>mod-reg-rm</em> forms of the instruction. There’s an accumulator-specific version that allows the transfer of values between direct-addressed memory variables and the accumulator (AL or AX) faster and in fewer bytes than the <em>mod-reg-rm</em> instruction, as discussed in Chapter 8. There’s also a register-specific form of <code class="sourceCode nasm"><span class="kw">mov</span></code>, as we discussed in Chapter 7; I’d like to discuss that version of <code class="sourceCode nasm"><span class="kw">mov</span></code> further, for it’s an important instruction indeed.</p>
<p>Every <em>mod-reg-rm</em> instruction requires at least 2 bytes, one for the instruction opcode and one for the <em>mod-reg-rm</em> byte. Consequently, the <em>mod-reg-rm</em> version of <code class="sourceCode nasm"><span class="kw">mov</span> mem/reg,immed8</code> is 3 bytes long, since the immediate value takes another byte. However, there’s a register-specific immediate-addressing form of <code class="sourceCode nasm"><span class="kw">mov</span></code> that doesn’t have a <em>mod-reg-rm</em> byte. Instead, the register selection is built right into the opcode, so only 1 byte is needed to both describe the instruction and select the destination. The result: the register-specific immediate-addressing form of <code class="sourceCode nasm"><span class="kw">mov</span></code> allows <code class="sourceCode nasm"><span class="kw">mov</span> reg,immed8</code> to assemble to just 2 bytes, and <code class="sourceCode nasm"><span class="kw">mov</span> reg,immed16</code> to assemble to just 3 bytes.</p>
<p>The presence of the register-specific immediate-addressing version of <code class="sourceCode nasm"><span class="kw">mov</span></code> makes loading immediate values into registers quite reasonable in terms of code size and performance. For example, <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,<span class="dv">0</span></code> assembles to a 2-byte instruction, exactly the same length as <code class="sourceCode nasm"><span class="kw">sub</span> <span class="kw">al</span>,<span class="kw">al</span></code>. Granted, <code class="sourceCode nasm"><span class="kw">sub</span> <span class="kw">al</span>,<span class="kw">al</span></code> is 1 cycle faster than <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,<span class="dv">0</span></code>, and <code class="sourceCode nasm"><span class="kw">sub</span> <span class="kw">ax</span>,<span class="kw">ax</span></code> is both 1 cycle faster and 1 byte shorter than <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ax</span>,<span class="dv">0</span></code>, but nonetheless the upshot is that registers can be loaded with immediate values fairly efficiently.</p>
<p>Be aware, however, that the same is <em>not</em> generally true of <code class="sourceCode nasm"><span class="kw">add</span></code>, <code class="sourceCode nasm"><span class="kw">sub</span></code>, or any of the logical or arithmetic instructions — the <em>mod-reg-rm</em> immediate-addressing forms of these instructions take a minimum of 3 bytes. As mentioned above, though, the accumulator-specific immediate-addressing forms of these instructions <em>are</em> fast and compact at 2 or 3 bytes in length.</p>
<p>While there is a special form of <code class="sourceCode nasm"><span class="kw">mov</span></code> for loading registers with immediate data, there is no such form for loading memory variables. The shortest possible instruction for loading memory with an immediate value is 3 bytes long, and such instructions can range all the way up to 6 bytes in length. In fact, thanks to the 8088’s accumulator — and register-specific <code class="sourceCode nasm"><span class="kw">mov</span></code> instructions:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">al</span>,<span class="dv">0</span>
<span class="kw">mov</span>   [MemVar],<span class="kw">al</span></code></pre>
<p>is not only the same length as:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   [MemVar],<span class="dv">0</span></code></pre>
<p><em>but is also 2 cycles faster</em>!</p>
<p>Learn well those special cases where a single mnemonic covers multiple instructions — and <em>use</em> them! They’re one of the secrets of good 8088 assembler code.</p>
<section id="on-to-the-string-instructions" class="level3">
<h3>On to the String Instructions</h3>
<p>We’ve cut a wide swath through the 8088’s instruction set in this chapter, but we have yet to touch on one important set of instructions — the string instructions. These instructions, which are perhaps the most important instructions the 8088 has to offer when it comes to high-performance programming, are coming up next. Stay tuned.</p>
</section>
</section>
</section>
<section id="chapter-10-string-instructions-the-magic-elixir" class="level1">
<h1>Chapter 10: String Instructions: The Magic Elixir</h1>
<p>The 8088’s instruction set is flexible, full-featured, and a lot of fun to work with. On the whole, there’s just one thing that seriously ails the 8088’s instruction set, and that’s lousy performance. Branches are slow, memory accesses are slow, and even register-only instructions are slowed by the prefetch queue cycle-eater. Let’s face it: most 8088 code just doesn’t run very fast.</p>
<p>Don’t despair, though. There’s a sure cure for the 8088 performance blues: the magic elixir of the string instructions. The string instructions are like nothing else in the 8088’s instruction set. They’re compact — 1 byte apiece — so they’re not much affected by the prefetch queue cycle-eater. A single string instruction can be repeated up to 65,535 times, avoiding both branching and instruction fetching. String instructions access memory faster than most 8088 instructions, and can advance pointers and decrement counters into the bargain. In short, string instructions can do more with fewer cycles than other 8088 instructions.</p>
<p>Of course, nothing is perfect in this imperfect world, and the string instructions are no exception. The major drawback to the string instructions is that there are just so darn <em>few</em> of them — five, to be exact. The only tasks that can be performed with string instructions are reading from memory, writing to memory, copying from memory to memory, comparing a byte or word to a block of memory, and comparing two blocks of memory. That may sound like a lot, but in truth it isn’t. The many varieties of normal (non-string) instructions can add constants to memory, shift memory, perform logical operations with memory operands, and much more, far exceeding the limited capabilities of the five string instructions. What’s more, the normal instructions can work with a variety of registers and can address memory in all sorts of ways, while string instructions are very restrictive in terms of register usage and memory addressing modes.</p>
<p>That doesn’t mean that the string instructions are of limited value — far from it, in fact. What it does mean is that your programs must be built around the capabilities of the string instructions if they are to run as fast as possible. As you learn to bring string instructions to bear on your programming tasks, you’ll find that the performance of your code improves considerably.</p>
<p>In other words, use string instructions whenever you possibly can, and try to think of ways to use them even when it seems you can’t.</p>
<section id="a-quick-tour-of-the-string-instructions" class="level2">
<h2>A Quick Tour of the String Instructions</h2>
<p>Odds are good that you’re already at least somewhat conversant with the string instructions, so I’m not going to spend much time going over their basic functionality. I am going to summarize them briefly, however; I want to make sure that we’re speaking the same language, and I also want you to be as knowledgeable as possible about these key instructions.</p>
<p>After we’ve discussed the individual string instructions, we’ll cover a variety of important and often non-obvious facts, tips, and potential problems associated with the string instructions. Finally, in the next chapter we’ll look at some powerful applications of the string instructions.</p>
<p>This chapter is a tour of the string instructions, not a tutorial. We’ll be moving fast — while we’ll hit the important points about the string instructions, we won’t linger. At times I’ll refer to some material that’s not covered until later in this chapter or the next. Alas, that sort of forward reference is unavoidable with a topic as complex as the string instructions. Bear with me, though — by the end of the next chapter, I promise that everything will come together.</p>
<section id="reading-memory-lods" class="level3">
<h3>Reading Memory: <code>lods</code></h3>
<p><code class="sourceCode nasm"><span class="kw">lodsb</span></code> (“load string byte”) reads the byte addressed by DS:SI (the source operand) into AL and then either increments or decrements SI, depending on the setting of the direction flag, as shown in Figure 10.1.</p>
<figure>
<img src="images/fig10.1RT.png" />
</figure>
<p><code class="sourceCode nasm"><span class="kw">lodsw</span></code> (“load string word”) reads the word addressed by DS:SI into AX and then adds or subtracts 2 to or from SI, again depending on the state of the direction flag. In either case, the use of DS as the segment can be overridden, as we’ll see later.</p>
<p>We’ll discuss the direction flag in detail later on. For now, let’s just refer to string instructions as “advancing” their pointers, with the understanding that advancing means either adding or subtracting 1 or 2, depending on the direction flag and the data size.</p>
<p><code class="sourceCode nasm"><span class="kw">lods</span></code> is particularly useful for reading the elements of an array or string sequentially, since SI is automatically advanced each time <code class="sourceCode nasm"><span class="kw">lods</span></code> is executed.</p>
<p><code class="sourceCode nasm"><span class="kw">lods</span></code> is considerably more limited than, say, <code class="sourceCode nasm"><span class="kw">mov</span> reg8,[mem8]</code>. For instance, <code class="sourceCode nasm"><span class="kw">lodsb</span></code> requires that AL be the destination and that SI point to the source operand, while the <code class="sourceCode nasm"><span class="kw">mov</span></code> instruction allows any of the 8 general-purpose registers to be the destination and allows the use of any of the 16 addressing modes to address the source.</p>
<p>On the other hand, <code class="sourceCode nasm"><span class="kw">lodsb</span></code> is shorter and a good deal faster than <code class="sourceCode nasm"><span class="kw">mov</span></code>. <code class="sourceCode nasm"><span class="kw">mov</span> reg8,[mem8]</code> is between 2 and 4 bytes in length, while <code class="sourceCode nasm"><span class="kw">lodsb</span></code> is exactly 1 byte long. <code class="sourceCode nasm"><span class="kw">lodsb</span></code> also advances SI, an action which requires a second instruction (albeit a fast one), <code class="sourceCode nasm"><span class="kw">inc</span> <span class="kw">si</span></code>, when <code class="sourceCode nasm"><span class="kw">mov</span></code> is used.</p>
<p>Let’s compare <code class="sourceCode nasm"><span class="kw">lodsb</span></code> and <code class="sourceCode nasm"><span class="kw">mov</span></code> in action. <a href="#listing-10-1">Listing 10-1</a>, which loads AL and advances SI 1000 times with <code class="sourceCode nasm"><span class="kw">mov</span></code> and <code class="sourceCode nasm"><span class="kw">inc</span></code>, executes in 3.77 ms. <a href="#listing-10-2">Listing 10-2</a>, which uses <code class="sourceCode nasm"><span class="kw">lodsb</span></code> to both load and advance in a single instruction, is 33% faster at 2.83 ms. When two code sequences perform the same task and one of them is 33% faster and one-third the length, there can’t be much doubt about which is better.</p>
<p><code class="sourceCode nasm"><span class="kw">lodsb</span></code> is even superior to <code class="sourceCode nasm"><span class="kw">mov</span></code> when the time required to advance SI is ignored. Suppose, for example, that you were to load SI with a pointer into a look-up table. Would you be better off using <code class="sourceCode nasm"><span class="kw">lods</span></code> or <code class="sourceCode nasm"><span class="kw">mov</span></code> to perform the look-up, given that it doesn’t matter in this case whether SI advances or not?</p>
<p>Use <code class="sourceCode nasm"><span class="kw">lods</span></code>. <a href="#listing-10-3">Listing 10-3</a>, which is <a href="#listing-10-1">Listing 10-1</a> modified to remove the <code class="sourceCode nasm"><span class="kw">inc</span></code> instructions, executes in 3.11 ms. <a href="#listing-10-2">Listing 10-2</a>, which uses <code class="sourceCode nasm"><span class="kw">lodsb</span></code>, is one-half the length of <a href="#listing-10-3">Listing 10-3</a> and 10% faster, even though <a href="#listing-10-3">Listing 10-3</a> uses the shortest and fastest memory-accessing form of the <code class="sourceCode nasm"><span class="kw">mov</span></code> instruction and doesn’t advance SI.</p>
<p>Of course, if you specifically didn’t <em>want</em> SI to advance, you’d be better off with <code class="sourceCode nasm"><span class="kw">mov</span></code>, since there’s no way to stop <code class="sourceCode nasm"><span class="kw">lods</span></code> from advancing SI. (In fact, all the string instructions always advance their pointer registers, whether you want them to or not.)</p>
<p>I’m not going to contrast the other string instructions with their non-string equivalents in the next few sections; we’ll get plenty of that later in the chapter. The rule we just established applies to the other string instructions as well, though: it’s often better to use a string instruction than <code class="sourceCode nasm"><span class="kw">mov</span></code> even when you don’t need all the power of the string instruction. While it can be a nuisance to set up the registers for the string instructions, it’s still usually worth using the string instructions whenever you can do so without going through too many contortions. In general, the string instructions simply make for shorter, faster code than their <code class="sourceCode nasm"><span class="kw">mov</span></code>-based equivalents.</p>
<p>Never assume, though: string instructions aren’t superior in <em>all</em> cases. Always time your code!</p>
</section>
<section id="writing-memory-stos" class="level3">
<h3>Writing Memory: <code>stos</code></h3>
<p><code class="sourceCode nasm"><span class="kw">stosb</span></code> (“store string byte”) writes the value in AL to the byte addressed by ES:DI (the destination operand) and then either increments or decrements DI, depending on the setting of the direction flag. <code class="sourceCode nasm"><span class="kw">stosw</span></code> (“store string word”) writes the value in AX to the word addressed by ES:DI and then adds or subtracts 2 to or from DI, again depending on the direction flag, as shown in Figure 10.2. The use of ES as the destination segment cannot be overridden.</p>
<figure>
<img src="images/fig10.2RT.png" />
</figure>
<p><code class="sourceCode nasm"><span class="kw">stos</span></code> is the preferred way to initialize arrays, strings, and other blocks of memory, especially when used with the <code class="sourceCode nasm">rep</code> prefix, which we’ll discuss shortly. <code class="sourceCode nasm"><span class="kw">stos</span></code> also works well with <code class="sourceCode nasm"><span class="kw">lods</span></code> for tasks that require performing some sort of translation while copying arrays or strings, such as conversion of a text string to uppercase. In this use, <code class="sourceCode nasm"><span class="kw">lods</span></code> loads an array element into AL, the element is translated in AL, and <code class="sourceCode nasm"><span class="kw">stos</span></code> stores the element to the new array. Put a loop around all that and you’ve got a compact, fast translation routine. We’ll discuss this further in the next chapter.</p>
</section>
<section id="moving-memory-movs" class="level3">
<h3>Moving Memory: movs</h3>
<p><code class="sourceCode nasm"><span class="kw">movsb</span></code> (“move string byte”) copies the value stored at the byte addressed by DS:SI (the source operand) to the byte addressed by ES:DI (the destination operand) and then either increments or decrements SI and DI, depending on the setting of the direction flag, as shown in Figure 10.3.</p>
<figure>
<img src="images/fig10.3RT.png" />
</figure>
<p><code class="sourceCode nasm"><span class="kw">movsw</span></code> (“move string word”) copies the value stored at the word addressed by DS:SI to the word addressed by ES:DI and then adds or subtracts 2 to or from SI or DI, again depending on the direction flag. The use of DS as the source segment can be overridden, but the use of ES as the destination segment cannot.</p>
<p>Note that the accumulator is not affected by <code class="sourceCode nasm"><span class="kw">movs</span></code>; the data is copied directly from memory to memory, not by way of AL or AX.</p>
<p><code class="sourceCode nasm"><span class="kw">movs</span></code> is by far the 8088’s best instruction for copying arrays, strings, and other blocks of data from one memory location to another.</p>
</section>
<section id="scanning-memory-scas" class="level3">
<h3>Scanning Memory: scas</h3>
<p><code class="sourceCode nasm"><span class="kw">scasb</span></code> (“scan string byte”) compares AL to the byte addressed by ES:DI (the source operand) and then either increments or decrements DI, depending on the setting of the direction flag, as shown in Figure 10.4.</p>
<figure>
<img src="images/fig10.4aRT.png" />
</figure>
<figure>
<img src="images/fig10.4bRT.png" />
</figure>
<p><code class="sourceCode nasm"><span class="kw">scasw</span></code> (“scan string word”) compares the value in AX to the word addressed by ES:DI and then adds or subtracts 2 to or from DI, again depending on the direction flag. The use of ES as the source segment cannot be overridden.</p>
<p><code class="sourceCode nasm"><span class="kw">scas</span></code> performs its comparison exactly as <code class="sourceCode nasm"><span class="kw">cmp</span></code> does, by performing a trial subtraction of the memory location addressed by ES:DI from the accumulator without actually changing either the accumulator or the memory location. All the arithmetic flags — Overflow, Sign, Zero, Auxiliary Carry, Parity, and Carry — are affected by <code class="sourceCode nasm"><span class="kw">scas</span></code>. That’s easy to forget when you use <code class="sourceCode nasm">repz <span class="kw">scas</span></code> or <code class="sourceCode nasm">repnz <span class="kw">scas</span></code>, which can only terminate according to the status of the Zero flag. (We’ll cover all the repeated string instruction below.)</p>
<p><code class="sourceCode nasm"><span class="kw">scas</span></code> is the preferred instruction for searching strings and arrays for specific values, and is especially good for looking up values in tables. Many programmers get so used to using <code class="sourceCode nasm">repz <span class="kw">scas</span></code> and <code class="sourceCode nasm">repnz <span class="kw">scas</span></code> that they forget that non-repeated <code class="sourceCode nasm"><span class="kw">scas</span></code> instructions are more flexible than their repeated counterparts and can often be used when the repeated versions of <code class="sourceCode nasm"><span class="kw">scas</span></code> can’t. For example, suppose that we wanted to search a word-sized array for the first element greater than 10,000. <a href="#listing-10-4">Listing 10-4</a> shows code for doing this with non-string instructions. The code in <a href="#listing-10-4">Listing 10-4</a> runs in 10.07 ms.</p>
<p>Note that in <a href="#listing-10-4">Listing 10-4</a> the value 10,000 is placed in a register outside the loop in order to make the <code class="sourceCode nasm"><span class="kw">cmp</span></code> instruction inside the loop faster and 2 bytes shorter. Also note that the code is arranged so that DI can be incremented <em>before</em> each comparison inside the loop, allowing us to get by with just one jump instruction. The alternative would be:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="fu">SearchLoop:</span>
    <span class="kw">cmp</span>   <span class="kw">ax</span>,[<span class="kw">di</span>]
    <span class="kw">jb</span>    SearchDone
    <span class="kw">inc</span>   <span class="kw">di</span>
    <span class="kw">inc</span>   <span class="kw">di</span>
    <span class="kw">jmp</span>   SearchLoop
<span class="fu">SearchDone:</span></code></pre>
<p>While this works perfectly well, it has not only the 4 instructions of the loop in <a href="#listing-10-4">Listing 10-4</a> but also an additional jump instruction, and so it’s bound to be slower.</p>
<p><a href="#listing-10-5">Listing 10-5</a> is functionally equivalent to <a href="#listing-10-4">Listing 10-4</a>, but uses <code class="sourceCode nasm"><span class="kw">scasw</span></code> rather than <code class="sourceCode nasm"><span class="kw">cmp</span></code> and <code class="sourceCode nasm"><span class="kw">inc</span></code>. That slight difference allows <a href="#listing-10-5">Listing 10-5</a> to run in 8.25 ms, 22% faster than <a href="#listing-10-4">Listing 10-4</a>. While <code class="sourceCode nasm"><span class="kw">scasw</span></code> works beautifully in this application, <code class="sourceCode nasm">rep <span class="kw">scasw</span></code> would not have worked at all, since <code class="sourceCode nasm">rep <span class="kw">scasw</span></code> can only handle equality/non-equality comparisons, not greater-than or less-than. If we had been thinking in terms of <code class="sourceCode nasm">rep <span class="kw">scasw</span></code>, we might well have missed the superior <code class="sourceCode nasm"><span class="kw">scasw</span></code> implementation. The moral: although repeated string instructions are the most powerful instructions of the 8088, don’t forget that non-repeated string instructions are nearly as powerful and generally more flexible.</p>
<p>As another example, <a href="#listing-10-6">Listing 10-6</a> shows a <code class="sourceCode nasm"><span class="kw">lodsw</span></code>-based version of <a href="#listing-10-4">Listing 10-4</a>. While this straightforward approach is faster than <a href="#listing-10-4">Listing 10-4</a> (it executes in 9.07 ms), it is clearly inferior to the <code class="sourceCode nasm"><span class="kw">scasw</span></code>-based implementation of <a href="#listing-10-5">Listing 10-5</a>. When you set out to tackle a programming problem, always think of the string instructions first… and think of <em>all</em> the string instructions. The obvious solution is not necessarily the best.</p>
</section>
<section id="notes-on-loading-segments-for-string-instructions" class="level3">
<h3>Notes on Loading Segments for String Instructions</h3>
<p>You may have noticed that in <a href="#listing-10-5">Listing 10-5</a> I chose to use DI to load ES with the target segment. This is a useful practice to follow when setting up pointers in ES:DI for string instructions; since you know you’re going to load DI with the target offset next, you can be sure that you won’t accidentally wipe out any important data in that register. It’s more common to use AX to load segment registers, since AX is the most general-purpose of registers, but why use AX — which <em>might</em> contain something useful — when DI is guaranteed to be free?</p>
<p>Similarly, I make a practice of using SI to load DS for string instructions, loading the offset into SI immediately after setting DS.</p>
<p>Along the same lines, I load the segment into DI in <a href="#listing-10-5">Listing 10-5</a> with the <code class="sourceCode nasm"><span class="kw">seg</span></code> operator. You may prefer to load the name of the segment instead (for example, <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">di</span>,DataSeg</code>). That’s okay too, but consider this: you can’t go wrong with the <code class="sourceCode nasm"><span class="kw">seg</span></code> operator when you’re loading a segment in order to access a specific named variable. Even if you change the name of the segment containing the array in <a href="#listing-10-5">Listing 10-5</a>, the code will still assemble properly. The same cannot be said for loading DI with the name of the segment. The choice is yours, but personally I prefer to make my code as immune as possible to errors induced by later changes.</p>
<p>It may have occurred to you that in <a href="#listing-10-5">Listing 10-5</a> it would be faster to load DI with the target segment from DS rather than with a constant. That is:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">di</span>,<span class="kw">ds</span>
<span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">di</span></code></pre>
<p>is shorter and faster than:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">di</span>,<span class="kw">seg</span> WordArray
<span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">di</span></code></pre>
<p>True enough, and you should use the first approach whenever you can. I’ve chosen to use the latter approach in the listings in this chapter in order to make the operation of the string instructions clear, and to illustrate the most general case. After all, in many cases the destination segment for a string instruction won’t be DS.</p>
</section>
<section id="comparing-memory-cmps" class="level3">
<h3>Comparing Memory: <code>cmps</code></h3>
<p><code class="sourceCode nasm"><span class="kw">cmpsb</span></code> (“compare string byte”) compares the byte addressed by DS:SI (the destination operand) to the byte addressed by ES:DI (the source operand) and then either increments or decrements SI and DI, depending on the setting of the direction flag. <code class="sourceCode nasm"><span class="kw">cmpsw</span></code> (“compare string word”) compares the value stored at the word addressed by DS:SI to the word addressed by ES:DI and then adds or subtracts 2 to or from SI and DI, again depending on the direction flag, as shown in Figure 10.5.</p>
<figure>
<img src="images/fig10.5aRT.png" />
</figure>
<figure>
<img src="images/fig10.5bRT.png" />
</figure>
<p>The use of DS as the destination segment can be overridden, but the use of ES as the source segment cannot.</p>
<p><code class="sourceCode nasm"><span class="kw">cmps</span></code> performs its comparison as <code class="sourceCode nasm"><span class="kw">cmp</span></code> does, by performing a trial subtraction of the memory location addressed by ES:DI from the memory location addressed by DS:SI without actually changing either location. As with <code class="sourceCode nasm"><span class="kw">scas</span></code>, all six arithmetic flags are affected by <code class="sourceCode nasm"><span class="kw">cmps</span></code>. The key difference between <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code> is that <code class="sourceCode nasm"><span class="kw">scas</span></code> compares the accumulator to memory, while <code class="sourceCode nasm"><span class="kw">cmps</span></code> compares two memory locations directly. The accumulator is not affected by <code class="sourceCode nasm"><span class="kw">cmps</span></code> in any way; data is compared directly from one memory operand to the other, not by way of AL or AX. <code class="sourceCode nasm"><span class="kw">cmps</span></code> is in a class by itself for comparing arrays, strings, and other blocks of memory data.</p>
</section>
</section>
<section id="hither-and-yon-with-the-string-instructions" class="level2">
<h2>Hither and Yon With the String Instructions</h2>
<p>That does it for our quick tour of the individual string instructions. Now it’s on to a variety of useful items about string instructions in general.</p>
<section id="data-size-advancing-pointers-and-the-direction-flag" class="level3">
<h3>Data Size, Advancing Pointers, and the Direction Flag</h3>
<p>Each string instruction advances its associated pointer register (or registers) by one memory location each time it executes. <code class="sourceCode nasm"><span class="kw">lods</span></code> advances SI, <code class="sourceCode nasm"><span class="kw">stos</span></code> and <code class="sourceCode nasm"><span class="kw">scas</span></code> advance DI, and <code class="sourceCode nasm"><span class="kw">movs</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code> advance both SI and DI. As we’ve seen, that’s a very handy bonus of using the string instructions — not only do they access memory rapidly, they also advance pointers in that same short time. String instructions advance their pointer registers just once per execution. However, any string instruction prefixed with <code class="sourceCode nasm">rep</code> can execute — and consequently advance its pointer or pointers — thousands of times.</p>
<p>All that seems straightforward enough. There are complications, though: both the definition of “one memory location” and the direction in which the pointer or pointers advance can vary.</p>
<p>String instructions can operate on either byte-or word-sized data. We’ve already seen one way to choose data size: by putting the suffix “b” or “w” on the end of a string instruction’s mnemonic. For example, <code class="sourceCode nasm"><span class="kw">lodsb</span></code> loads a byte, and <code class="sourceCode nasm"><span class="kw">cmpsw</span></code> compares two words. Later in the chapter we’ll see another way to specify data size, along with ways to specify segment overrides for string instructions that access memory via SI.</p>
<p>When working with byte-sized data, string instructions advance their pointers by 1 byte per memory access, and when working with word-sized data, they advance their pointers by one word per memory access. So “one memory location” means whichever of 1 byte or 1 word is the data size of the instruction. That makes perfect sense given that the idea of using string instructions is to advance sequentially through the elements of a byte-or word-sized array.</p>
<p>Ah, but what exactly does “advance” mean? Do the pointer registers used by string instructions move to the next location higher in memory or to the next location lower in memory?</p>
<p>Both, actually. Or, rather, either one, depending on the setting of the Direction flag in the FLAGS register. If the Direction flag is set, string instructions move their pointers down in memory, subtracting either 1 or 2 — whichever is the data size — from the pointer registers. If the Direction flag is reset, string instructions move their pointers up in memory by adding either 1 or 2.</p>
<p>The Direction flag can be explicitly set with the <code class="sourceCode nasm"><span class="kw">std</span></code> (“set Direction flag”) instruction and reset with the <code class="sourceCode nasm"><span class="kw">cld</span></code> (“clear Direction flag”) instruction. Other instructions that load the FLAGS register, such as <code class="sourceCode nasm"><span class="kw">popf</span></code> and <code class="sourceCode nasm"><span class="kw">iret</span></code>, can alter the Direction flag as well. Be aware, however, that <code class="sourceCode nasm"><span class="kw">sahf</span></code> does not affect the Direction flag, since it loads only the lower byte of the FLAGS register from AH. A glance at Figure 6-2 shows that the Direction flag resides in the upper byte of the FLAGS register.</p>
<p>The Direction flag doesn’t seem like a big deal, but in fact it can be responsible for some particularly nasty bugs. The problem with the Direction flag is that it allows a given string instruction to produce two completely different results under what look to be the same circumstances — the same register settings, memory contents, and so on. In other words, the Direction flag makes string instructions modal, and the instruction that controls that mode at any given time — the <code class="sourceCode nasm"><span class="kw">cld</span></code> or <code class="sourceCode nasm"><span class="kw">std</span></code> that selected the string direction — may have occurred long ago, in a subroutine far, far away. A string instruction that runs perfectly most of the time can mysteriously crash the system every so often because a different Direction flag state was selected by seemingly unrelated code that ran thousands of cycles earlier.</p>
<p>What’s the solution? Well, usually you’ll want your string instructions to move their pointers up in memory, since that’s the way arrays and strings are stored. (It’s also the way people tend to think about memory, with storage running from low to high addresses.) There are good uses for counting down, such as copying overlapping source and destination blocks and searching for the last element in an array, but those are not the primary applications for string instructions. Given that, it makes sense to leave the Direction flag cleared at all times except when you explicitly need to move pointers down rather than up in memory. That way you can always count on your string instructions to move their pointers up unless you specify otherwise.</p>
<p>Unfortunately, that solution can only be used when you’ve written all the code in a program yourself, and done so in pure assembler. Since you have no control over the code generated by compilers or the code in third-party libraries, you can’t rely on such code to leave the Direction flag cleared. I know of one language in which library functions do indeed leave the Direction flag set occasionally, and I’ve no doubt that there are others. What to do here?</p>
<p>The solution is obvious, though a bit painful: whenever you can’t be sure of the state of the Direction flag, you absolutely <em>must</em> put it in a known state before using any of the string instructions. This causes your code to be sprinkled with <code class="sourceCode nasm"><span class="kw">cld</span></code> and <code class="sourceCode nasm"><span class="kw">std</span></code> instructions, and that makes your programs a bit bigger and slower. Fortunately, though, <code class="sourceCode nasm"><span class="kw">cld</span></code> and <code class="sourceCode nasm"><span class="kw">std</span></code> are 1-byte, 2-cycle instructions, so they have a minimal impact on size and performance. As with so much else about the 8088, it would have been nice if Intel had chosen to build direction into the opcode bytes of the string instruction, as they did with data size. Alas, Intel chose not to do so -so be sure the Direction flag is in the proper state each and every time you use a string instruction.</p>
<p>That doesn’t mean you have to put a <code class="sourceCode nasm"><span class="kw">cld</span></code> or <code class="sourceCode nasm"><span class="kw">std</span></code> before <em>every</em> string instruction. Just be sure you know the state of the Direction flag when each string instruction is executed. For example, in <a href="#listing-10%20-%205">Listing 10 - 5</a> <code class="sourceCode nasm"><span class="kw">cld</span></code> is performed just once, outside the loop. Since nothing inside the loop changes the Direction flag, there’s no need to set the flag again.</p>
<p>An important tip: <em>always</em> put the Direction flag in a known state in interrupt — handling code. Interrupts can occur at any time, while any code is executing -including BIOS and DOS code, over which you have no control. Consequently, the Direction flag may be in any state when an interrupt handler is invoked, even if your program always keeps the Direction flag cleared.</p>
</section>
<section id="the-rep-prefix" class="level3">
<h3>The <code>rep</code> Prefix</h3>
<p>Taken by themselves, the string instructions are superior instructions: they’re shorter and faster than the average memory-accessing instruction, and advance pointer registers too. It’s in conjunction with the <code class="sourceCode nasm">rep</code> prefix that string instructions really shine, though.</p>
<p>As you may recall from Chapter 7, a prefix is an instruction byte that modifies the operation of the following instruction. For example, segment override prefixes can cause many instructions to access memory in segments other than their default segments.</p>
<p><code class="sourceCode nasm">rep</code> is a prefix that modifies the operation of the string instructions (and only the string instructions). <code class="sourceCode nasm">rep</code> is exactly 1 byte long, so it effectively doubles the 1-byte length of the string instruction it prefixes. Put another way, <code class="sourceCode nasm"><span class="kw">movsb</span></code> is a 1-byte instruction, while <code class="sourceCode nasm">rep <span class="kw">movsb</span></code> is effectively a 2-byte instruction, although it actually consists of a 1-byte prefix and a 1-byte instruction. What <code class="sourceCode nasm">rep</code> does to justify the expenditure of an extra byte is simple enough: it instructs the following string instruction to execute the number of times specified by CX.</p>
<p>Sounds familiar, doesn’t it? It should — it’s a lot like the “repeat CL times” capability of the shift and rotate instructions that we discussed in the last chapter. There is a difference, however. Because <code class="sourceCode nasm">rep</code> causes instructions to be repeated CX times, any string instruction can be repeated up to 65,535 times, rather than the paltry 255 times a shift or rotate can be repeated. Of course, there’s really no reason to want to repeat a shift or rotate more than 16 times, but there’s plenty of reason to want to do so with the string instructions. By repeating a single string instruction CX times, that instruction can, if necessary, access every word in an entire segment. That’s one — count it, <em>one</em> — string instruction!</p>
<p>The above description makes it sound as if string instruction repetitions are free. They aren’t. A string instruction repeated <em>n</em> times takes about <em>n</em> times longer to execute than a single non-repeated instance of that instruction, as measured in Execution Unit cycles. There’s some start-up time for repeated string instructions, and some of the string instructions take a cycle more or less per execution when repeated than when run singly. Nonetheless, the execution time of repeated string instructions is generally proportional to the number of repetitions.</p>
<p>That’s okay, though, because repeated string instructions do the next best thing to running in no time at all: <em>they beat the prefetch queue cycle-eater.</em> How? By performing multiple repetitions of an instruction with just one instruction fetch. When you repeat a string instruction, you’re basically executing multiple instances of that instruction without having to fetch the extra instruction bytes. For instance, as shown in Figure 10.6, the <code class="sourceCode nasm">rep</code> prefix lets this:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">sub</span>   <span class="kw">di</span>,<span class="kw">di</span>
<span class="kw">mov</span>   <span class="kw">ax</span><span class="bn">,0a000h</span>
<span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">ax</span>
<span class="kw">sub</span>   <span class="kw">ax</span>,<span class="kw">ax</span>
<span class="kw">mov</span>   <span class="kw">cx</span>,<span class="dv">10</span>
<span class="kw">cld</span>
rep   <span class="kw">stosw</span></code></pre>
<p>replace this:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">sub</span>    <span class="kw">di</span>,<span class="kw">di</span>
<span class="kw">mov</span>    <span class="kw">ax</span><span class="bn">,0a000h</span>
<span class="kw">mov</span>    <span class="kw">es</span>,<span class="kw">ax</span>
<span class="kw">sub</span>    <span class="kw">ax</span>,<span class="kw">ax</span>
<span class="kw">cld</span>
<span class="kw">stosw</span>
<span class="kw">stosw</span>
<span class="kw">stosw</span>
<span class="kw">stosw</span>
<span class="kw">stosw</span>
<span class="kw">stosw</span>
<span class="kw">stosw</span>
<span class="kw">stosw</span>
<span class="kw">stosw</span>
<span class="kw">stosw</span></code></pre>
<figure>
<img src="images/fig10.6RT.png" />
</figure>
<p>The <code class="sourceCode nasm">rep</code>-based version takes a bit more set-up, but it’s worth it. Because <code class="sourceCode nasm">rep <span class="kw">stosw</span></code> (requiring one 2-byte instruction fetch) replaces ten <code class="sourceCode nasm"><span class="kw">stosw</span></code> instructions (requiring ten 1-byte instruction fetches), we can replace 20 instruction bytes with 15 instruction bytes. The instruction fetching benefits should be obvious.</p>
<p>No doubt you’ll look at the last example and think that it would be easy to reduce the number of instruction bytes by using a loop, such as:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">sub</span>   <span class="kw">di</span>,<span class="kw">di</span>
    <span class="kw">mov</span>   <span class="kw">ax</span><span class="bn">,0a000h</span>
    <span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">ax</span>
    <span class="kw">sub</span>   <span class="kw">ax</span>,<span class="kw">ax</span>
    <span class="kw">cld</span>
    <span class="kw">mov</span>   <span class="kw">cx</span>,<span class="dv">10</span>
<span class="fu">ClearLoop:</span>
    <span class="kw">stosw</span>
    <span class="kw">loop</span>  ClearLoop</code></pre>
<p>True enough, that would reduce the count of instruction bytes to 16 — but it wouldn’t reduce the overhead of instruction fetching in the least. In fact, it would <em>increase</em> the instruction fetch overhead, since a total of 43 bytes — including 3 bytes each of the 10 times through the loop — would have to be fetched.</p>
<p>There’s another reason that the <code class="sourceCode nasm">rep <span class="kw">stosw</span></code> version of the last example is by far the preferred version, and that’s branching (or the lack thereof). To see why this is, lets look at another example which contrasts <code class="sourceCode nasm">rep <span class="kw">stosw</span></code> with a non-string loop.</p>
</section>
<section id="rep-no-instruction-fetching-no-branching" class="level3">
<h3>rep = No Instruction Fetching + No Branching</h3>
<p>Suppose we want to set not 10 but 1000 words of memory to zero. <a href="#listing-10-7">Listing 10-7</a> shows code which uses <code class="sourceCode nasm"><span class="kw">mov</span></code>, <code class="sourceCode nasm"><span class="kw">inc</span></code>, and <code class="sourceCode nasm"><span class="kw">loop</span></code> to do this in a respectable 10.06 ms.</p>
<p>By contrast, <a href="#listing-10-8">Listing 10-8</a> initializes the same 1000 words to zero with one repeated <code class="sourceCode nasm"><span class="kw">stosw</span></code> instruction — <em>and no branches</em>. The result: the 1000 words are set to zero in just 3.03 ms. <a href="#listing-10-8">Listing 10-8</a> is over <em>three times</em> as fast as <a href="#listing-10-7">Listing 10-7</a>, a staggeringly large difference between two well-written assembler routines.</p>
<p>Now you know why it’s worth going out of your way to use string instructions.</p>
<p>Why is there so large a difference in performance between <a href="#listing-10-7">Listings 10-7</a> and <a href="#listing-10-8">10-8</a>? It’s not because of instruction execution speed. Sure, <code class="sourceCode nasm"><span class="kw">stos</span></code> is faster than <code class="sourceCode nasm"><span class="kw">mov</span></code>, but a repeated <code class="sourceCode nasm"><span class="kw">stosw</span></code> takes 14 cycles to write each word, while <code class="sourceCode nasm"><span class="kw">mov</span> [<span class="kw">di</span>],<span class="kw">ax</span></code> takes 18 cycles, hardly a three-times difference.</p>
<p>The real difference lies in instruction fetching and branching. When <a href="#listing-10-7">Listing 10-7</a> runs, the 8088 must fetch 6 instruction bytes and write 2 data bytes per loop, which means that each loop takes at least 32 cycles — 4 cycles per memory byte accessed times 8 bytes — no matter what.</p>
<p>By contrast, because the 8088 simply holds a repeated string instruction inside the chip while executing it over and over, the loop-equivalent code in <a href="#listing-10-8">Listing 10-8</a> requires no instruction fetching at all after the 2 bytes of <code class="sourceCode nasm">rep <span class="kw">stosw</span></code> are fetched. What’s more, since the 8 cycles required to write the 2 data bytes fit neatly within the 14-cycle official execution time of a repeated <code class="sourceCode nasm"><span class="kw">stosw</span></code>, that 14-cycle official execution time should be close to the actual execution time, apart from any effects DRAM refresh may have. Indeed, dividing 3.03 ms by 1000 repetitions reveals that each <code class="sourceCode nasm"><span class="kw">stosw</span></code> takes 14.5 cycles — 3.03 us — to execute, which works out nicely as 14 cycles plus about 4% DRAM refresh overhead.</p>
<p>Let’s look at this from a different perspective. The 8088 must fetch 6000 instruction bytes (6 bytes per loop times 1000 loops, as shown in Figure 10.7) when the loop in <a href="#listing-10-7">Listing 10-7</a> executes.</p>
<figure>
<img src="images/fig10.7RT.png" />
</figure>
<p>The <code class="sourceCode nasm">rep <span class="kw">stosw</span></code> instruction in <a href="#listing-10-8">Listing 10-8</a>, on the other hand, requires the fetching of exactly 2 instruction bytes <em>in total</em>, as shown in Figure 10.8 — quite a difference!</p>
<figure>
<img src="images/fig10.8RT.png" />
</figure>
<p>Better still, the prefetch queue can fill completely whenever a string instruction is repeated a few times. Fast as string instructions are, they don’t keep the bus busy all the time. Since repetitions of string instructions require no additional instruction fetching, there’s plenty of time for the instruction bytes of the following instructions to be fetched while string instructions repeat. On balance, then, repeated string instructions not only require very little fetching for a great many executions, but also allow the prefetch queue to fill with the bytes of the following instructions.</p>
<p>There’s more to the difference between <a href="#listing-10-7">Listings 10-7</a> and <a href="#listing-10-8">10-8</a> than just prefetching, however. The 8088 must not only fetch the bytes of the instructions in the loop in <a href="#listing-10-7">Listing 10-7</a> over and over, but must also perform one <code class="sourceCode nasm"><span class="kw">loop</span></code> instruction per word written to memory, and that’s costly indeed. Although <code class="sourceCode nasm"><span class="kw">loop</span></code> is the 8088’s most efficient instruction for repeating code by branching, it’s slow nonetheless, as we’ll see in Chapter 12. Each <code class="sourceCode nasm"><span class="kw">loop</span></code> instruction in <a href="#listing-10-7">Listing 10-7</a> takes at least 17 cycles to execute. That means that the code in <a href="#listing-10-7">Listing 10-7</a> spends more time looping than the code in <a href="#listing-10-8">Listing 10-8</a> spends <em>in total</em> to initialize each word!</p>
<p>Used properly, repeated string instructions are truly the magic elixir of the PC. Alone among the 8088’s instructions, they can cure the most serious performance ills of the PC, the prefetch queue cycle-eater and slow branching. The flip side is that repeated string instructions are much less flexible than normal instructions. For example, while you can do whatever you want inside a loop terminated with <code class="sourceCode nasm"><span class="kw">loop</span></code>, all you can do during a repeated string instruction is the single action of which that instruction is capable. Even so, the performance advantages of repeated string instructions are so great that you should try to use them at every opportunity.</p>
</section>
<section id="repz-and-repnz" class="level3">
<h3><code>repz</code> and <code>repnz</code></h3>
<p>There are two special forms of <code class="sourceCode nasm">rep</code> — <code class="sourceCode nasm">repz</code> and <code class="sourceCode nasm">repnz</code> — designed specifically for use with <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code>. The notion behind these prefixes is that when you repeat one of the comparison string instructions, you want the repeated comparison to end either the first time a specified match does occur or the first time that match <em>doesn’t</em> occur.</p>
<p><code class="sourceCode nasm">repnz</code> (“repeat while not Zero flag”) causes the following <code class="sourceCode nasm"><span class="kw">scas</span></code> or <code class="sourceCode nasm"><span class="kw">cmps</span></code> to repeat until either the string instruction sets the Zero flag (indicating a match) or CX counts down to zero. For instance, the following compares <code class="sourceCode nasm">ByteArray1</code> to <code class="sourceCode nasm">ByteArray2</code> until either a position at which the two arrays differ is found or 100 bytes have been checked:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">si</span>,<span class="kw">seg</span> ByteArray1
<span class="kw">mov</span>   <span class="kw">ds</span>,<span class="kw">si</span>
<span class="kw">mov</span>   <span class="kw">si</span>,offset ByteArray1
<span class="kw">mov</span>   <span class="kw">di</span>,<span class="kw">seg</span> ByteArray2
<span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">di</span>
<span class="kw">mov</span>   <span class="kw">di</span>,offset ByteArray2
<span class="kw">mov</span>   <span class="kw">cx</span>,<span class="dv">100</span>
<span class="kw">cld</span>
repnz <span class="kw">cmpsb</span></code></pre>
<p><code class="sourceCode nasm">repnz</code> also goes by the name of <code class="sourceCode nasm">repne</code>; the two are interchangeable.</p>
<p><code class="sourceCode nasm">repz</code> (“repeat while Zero flag”) causes the following <code class="sourceCode nasm"><span class="kw">scas</span></code> or <code class="sourceCode nasm"><span class="kw">cmps</span></code> to repeat until either the string instruction resets the Zero flag (indicating a non-match) or CX counts down to zero. For instance, the following scans <code class="sourceCode nasm">WordArray</code> until either a non-zero word is found or 1000 words have been checked:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">di</span>,<span class="kw">seg</span> WordArray
<span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">di</span>
<span class="kw">mov</span>   <span class="kw">di</span>,offset WordArray
<span class="kw">sub</span>   <span class="kw">ax</span>,<span class="kw">ax</span>
<span class="kw">mov</span>   <span class="kw">cx</span>,<span class="dv">1000</span>
<span class="kw">cld</span>
repz  <span class="kw">scasw</span></code></pre>
<p><code class="sourceCode nasm">repz</code> is also known as <code class="sourceCode nasm">repe</code>.</p>
<p>How do you know whether a repeated <code class="sourceCode nasm"><span class="kw">scas</span></code> or <code class="sourceCode nasm"><span class="kw">cmps</span></code> has found its termination condition — match or non-match — or simply run out of repetitions? By way of the Zero flag, of course. If — and only if — the Zero flag is set after a <code class="sourceCode nasm">repnz <span class="kw">scas</span></code> or <code class="sourceCode nasm">repnz <span class="kw">cmps</span></code>, then the desired match was found. Likewise, if and only if the Zero flag is reset after a <code class="sourceCode nasm">repz <span class="kw">scas</span></code> or <code class="sourceCode nasm">repz <span class="kw">cmps</span></code> was the desired non-match found.</p>
<p>As I pointed out earlier, repeated <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code> instructions are not as flexible as their non-repeated counterparts. When used singly, <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code> set all the arithmetic flags, which can be tested with the appropriate conditional jumps. Although these instructions still set all the arithmetic flags when repeated, they can terminate only according to the state of the Zero flag.</p>
<p>Beware of accidentally using just plain <code class="sourceCode nasm">rep</code> with <code class="sourceCode nasm"><span class="kw">scas</span></code> or <code class="sourceCode nasm"><span class="kw">cmps</span></code>. MASM will accept a dubious construct such as <code class="sourceCode nasm">rep <span class="kw">scasw</span></code> without complaint and dutifully generate a <code class="sourceCode nasm">rep</code> prefix byte. Unfortunately, the same byte that MASM generates for <code class="sourceCode nasm">rep</code> with <code class="sourceCode nasm"><span class="kw">movs</span></code>, <code class="sourceCode nasm"><span class="kw">lods</span></code>, and <code class="sourceCode nasm"><span class="kw">stos</span></code> means <code class="sourceCode nasm">repz</code> when used with <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code>. Of course, <code class="sourceCode nasm">repz</code> may not have been at all what you had in mind, and because <code class="sourceCode nasm">rep <span class="kw">scas</span></code> and <code class="sourceCode nasm">rep <span class="kw">cmps</span></code> <em>look</em> all right and assemble without warning, this can lead to some difficult debugging. It’s unfortunate that MASM doesn’t at least generate a warning when it encounters <code class="sourceCode nasm">rep <span class="kw">scas</span></code> or <code class="sourceCode nasm">rep <span class="kw">cmps</span></code>, but it doesn’t, so you’ll just have to watch out for such cases yourself.</p>
<p>(Don’t expect too much from MASM, which not only accepts a number of dubious assembler constructs — as we’ll see again later in this chapter — but also has some out-and-out bugs. If something just doesn’t seem to assemble properly, no matter what you do, then the problem is most likely a bug in MASM. This can often be confirmed by running the malfunctioning code through TASM, which generally has far fewer bugs than MASM — and my experience is that the bugs it does have are present for MASM compatibility!)</p>
<p><code class="sourceCode nasm">repnz</code> is ideal for all sort of searches and look-ups, as we’ll see at the end of the chapter. <code class="sourceCode nasm">repz</code> is less generally useful, but can serve to find the first location at which a sequence of repeated values ends. For example, suppose you wanted to find the last non-blank character in a buffer padded to the end with blanks. You could set the Direction flag, point DI to the last byte of the buffer, set CX to the length of the buffer, and load AL with a space character. A fairly elaborate set-up sequence, true — but then a single <code class="sourceCode nasm">rep <span class="kw">scasb</span></code> would then find the last non-blank character for you. We’ll look at this application in more detail in the next chapter.</p>
</section>
<section id="rep-is-a-prefix-not-an-instruction" class="level3">
<h3><code>rep</code> is a Prefix, Not an Instruction</h3>
<p>I’d like to take a moment to point out that <code class="sourceCode nasm">rep</code>, <code class="sourceCode nasm">repz</code>, and <code class="sourceCode nasm">repnz</code> are prefixes, not instructions. When you see code like:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">cld</span>
rep   <span class="kw">stosw</span>
<span class="kw">jmp</span>   <span class="kw">Test</span></code></pre>
<p>you may well get the impression that <code class="sourceCode nasm">rep</code> is an instruction and that <code class="sourceCode nasm"><span class="kw">stosw</span></code> is some sort of operand. Not so — <code class="sourceCode nasm">rep</code> is a prefix, and <code class="sourceCode nasm"><span class="kw">stosw</span></code> is an instruction. A more appropriate way to show a repeated <code class="sourceCode nasm"><span class="kw">stosw</span></code> might be:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">      <span class="kw">cld</span>
rep   <span class="kw">stosw</span>
      <span class="kw">jmp</span>   <span class="kw">Test</span></code></pre>
<p>which makes it clear that <code class="sourceCode nasm">rep</code> is a prefix by putting it to the left of the instruction field. However, MASM considers both forms to be the same, and since it has become the convention in the PC world to put <code class="sourceCode nasm">rep</code> in the mnemonic column, I’ll do the same in <em>The Zen of Assembly Language</em>. Bear in mind, though, that <code class="sourceCode nasm">rep</code> is not an instruction.</p>
<p>Also remember that <code class="sourceCode nasm">rep</code> only works with string instructions. Lines like:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">rep   <span class="kw">mov</span>   [<span class="kw">di</span>],<span class="kw">al</span></code></pre>
<p>don’t do anything out of the ordinary. If you think about it, you’ll realize that that’s no great loss; there really isn’t any reason to want to repeat a non-string instruction. Without the automatically-advanced pointers that only the string instructions offer, the action of a repeated non-string instruction would simply be repeated over and over, to no useful end. At any rate, like it or not, if you try to repeat a non-string instruction the repeat prefix is ignored.</p>
</section>
<section id="of-counters-and-flags" class="level3">
<h3>Of Counters and Flags</h3>
<p>When you use CL as a count for a shift or rotate instruction, CL is left unchanged by the instruction. Not so with CX and <code class="sourceCode nasm">rep</code>. Repeated string instructions decrement CX once for each repetition. CX always contains zero after repeated <code class="sourceCode nasm"><span class="kw">lods</span></code>, <code class="sourceCode nasm"><span class="kw">stos</span></code>, and <code class="sourceCode nasm"><span class="kw">movs</span></code> instructions finish, because those instructions simply execute until CX counts down to zero.</p>
<p>The situation is a bit more complex with <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code> instructions. These repeated instructions can terminate either when CX counts down to zero or when a match or non-match, as selected with <code class="sourceCode nasm">repz</code> or <code class="sourceCode nasm">repnz</code>, becomes true. As a result, <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code> instructions can leave CX with any value between 0 and <em>n</em>-1, where <em>n</em> is the value loaded into CX when the repeated instruction began. The value <em>n</em>-1 is left in CX if the termination condition for the repeated <code class="sourceCode nasm"><span class="kw">scas</span></code> or <code class="sourceCode nasm"><span class="kw">cmps</span></code> occurred on the first byte or word. CX counts down by 1 for each additional byte or word checked, ending up at 0 if the instruction was repeated the full number of times initially specified by CX.</p>
<p>Point number 1, then: CX is always altered by repeated string instructions.</p>
<p>By the way, while both repeated and non-repeated string instructions alter pointer registers, it’s only <em>repeated</em> string instructions that alter CX. For example, after the following code is executed:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">di</span><span class="bn">,0b800h</span>
<span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">di</span>
<span class="kw">mov</span>   <span class="kw">di</span><span class="bn">,1000h</span>
<span class="kw">mov</span>   <span class="kw">cx</span>,<span class="dv">1</span>
<span class="kw">sub</span>   <span class="kw">al</span>,<span class="kw">al</span>
<span class="kw">cld</span>
<span class="kw">stosb</span></code></pre>
<p>DI will contain 1001h but CX will still contain 1. However, after the same code using a <code class="sourceCode nasm">rep</code> prefix is executed:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">di</span><span class="bn">,0b800h</span>
<span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">di</span>
<span class="kw">mov</span>   <span class="kw">di</span><span class="bn">,1000h</span>
<span class="kw">mov</span>   <span class="kw">cx</span>,<span class="dv">1</span>
<span class="kw">sub</span>   <span class="kw">al</span>,<span class="kw">al</span>
<span class="kw">cld</span>
rep   <span class="kw">stosb</span></code></pre>
<p>DI will contain 1001h and CX will contain 0.</p>
<p>As we saw earlier, repeated <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code> instructions count CX down to zero if they complete without encountering the terminating match or non-match condition. As a result, you may be tempted to test whether CX is zero — perhaps with the compact <code class="sourceCode nasm"><span class="kw">jcxz</span></code> instruction — to see whether a repeated <code class="sourceCode nasm"><span class="kw">scas</span></code> or <code class="sourceCode nasm"><span class="kw">cmps</span></code> instruction found its match or non-match condition. <em>Don’t do it!</em></p>
<p>It’s true that repeated <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code> instructions count CX down to zero if the termination condition isn’t found — but this is a case of “if but <em>not</em> only if.” These instructions also count CX down to zero if the termination condition is found on the last possible execution. That is, if CX was initially set to 10 and a <code class="sourceCode nasm">repz <span class="kw">scasb</span></code> instruction is about to repeat for the tenth time, CX will be equal to 1. The next repetition will be performed, decrementing CX, regardless of whether the next byte scanned matches AL or not, so CX will surely be zero when the <code class="sourceCode nasm">repz <span class="kw">scasb</span></code> ends, no matter what the outcome.</p>
<p>In short, always use the Zero flag, <em>not</em> CX, to determine whether a <code class="sourceCode nasm"><span class="kw">scas</span></code> or <code class="sourceCode nasm"><span class="kw">cmps</span></code> instruction found its termination condition.</p>
<p>There’s another point to be made here. We’ve established that the flags set by a repeated <code class="sourceCode nasm"><span class="kw">scas</span></code> or <code class="sourceCode nasm"><span class="kw">cmps</span></code> instruction reflect the result of the last repetition of <code class="sourceCode nasm"><span class="kw">scas</span></code> or <code class="sourceCode nasm"><span class="kw">cmps</span></code>. Given that, it would seem that the flags can’t very well reflect the result of decrementing CX too. (After all, there’s only one set of flags, and it’s already spoken for.) That is indeed the case: the changes made to CX during a repeated string instruction never affect the flags. In fact, <code class="sourceCode nasm"><span class="kw">movs</span></code>, <code class="sourceCode nasm"><span class="kw">lods</span></code>, and <code class="sourceCode nasm"><span class="kw">stos</span></code>, whether repeated or not, never affect the flags at all, while <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code> only affect the flags according to the comparison performed.</p>
<p>There’s a certain logic to this. The <code class="sourceCode nasm"><span class="kw">loop</span></code> instruction, which <code class="sourceCode nasm">rep</code> resembles, doesn’t affect any flags, even though it decrements CX and may branch on the result. You can view both <code class="sourceCode nasm"><span class="kw">loop</span></code> and <code class="sourceCode nasm">rep</code> as program flow control instructions rather than counting instructions; as such, there’s really no reason for them to set the flags. You set CX for a certain number of repetitions, and those repetitions occur in due course; where’s the need for a status? Anyway, whether you agree with the philosophy or not, that’s the way both <code class="sourceCode nasm">rep</code> and <code class="sourceCode nasm"><span class="kw">loop</span></code> work.</p>
</section>
<section id="of-data-size-and-counters" class="level3">
<h3>Of Data Size and Counters</h3>
<p>We said earlier that CX specifies the number of times that a string instruction preceded by a <code class="sourceCode nasm">rep</code> prefix should be repeated. Be aware that CX literally controls the number of repeated executions of a string instruction, not the number of memory accesses. While that seems easy enough to remember, consider the case where you want to set every element of an array containing 1000 8-bit values to 1. The obvious approach to setting the array is shown in <a href="#listing-10-9">Listing 10-9</a>, which sets the array in 2.17 ms.</p>
<p>While <a href="#listing-10-9">Listing 10-9</a> is certainly fast, it is not the ideal way to initialize this array. It would be far better to repeat <code class="sourceCode nasm"><span class="kw">stos</span></code> half as many times, writing 2 bytes at a time with <code class="sourceCode nasm"><span class="kw">stosw</span></code> rather than 1 byte at a time with <code class="sourceCode nasm"><span class="kw">stosb</span></code>. Why? Well, recall that way back in Chapter 4 we found that the 8088 handles the second byte of a word-sized memory access in just 4 cycles. That’s faster than any normal instruction can handle that second byte, and, as it turns out, it’s faster than <code class="sourceCode nasm">rep <span class="kw">stosb</span></code> can handle a second byte as well. While <code class="sourceCode nasm">rep <span class="kw">stosw</span></code> can write the second byte of a word access in just 4 cycles, for a total time per word written of 14 cycles, <code class="sourceCode nasm">rep <span class="kw">stosb</span></code> requires 10 cycles for each byte, for a total time per word of 20 cycles. The same holds true across the board: you should use string instructions with word-sized data whenever possible.</p>
<p><a href="#listing-10-10">Listing 10-10</a> illustrates the use of word-sized data in initializing the same array to the same values as in Listing 109. As expected, <a href="#listing-10-10">Listing 10-10</a> is considerably faster than <a href="#listing-10-9">Listing 10-9</a>, finishing in just 1.52 ms. In fact, the ratio of the execution time of <a href="#listing-10-9">Listing 10-9</a> to that of <a href="#listing-10-10">Listing 10-10</a> is 1.43, which happens to be a ratio of 10/7, or 20/14. That should ring a bell, since it’s the ratio of the execution time of two <code class="sourceCode nasm">rep <span class="kw">stosb</span></code> instructions to one <code class="sourceCode nasm">rep <span class="kw">stosw</span></code> instruction.</p>
<p>All well and good, but we didn’t set out to compare the performance of word-and byte-sized string instructions. The important point in <a href="#listing-10-10">Listing 10-10</a> is that since we’re using <code class="sourceCode nasm">rep <span class="kw">stosw</span></code>, CX is loaded with <code class="sourceCode nasm">ARRAY_LENGTH/<span class="dv">2</span></code>, the array length in words, rather than <code class="sourceCode nasm">ARRAY_LENGTH</code>, the array length in bytes. Of course, it is <code class="sourceCode nasm">ARRAY_LENGTH</code>, not <code class="sourceCode nasm">ARRAY_LENGTH/<span class="dv">2</span></code>, that’s the actual length of the array as measured in byte-sized array elements. When you’re thinking of a <code class="sourceCode nasm">rep <span class="kw">stosw</span></code> instruction as clearing a byte array of length <code class="sourceCode nasm">ARRAY_LENGTH</code>, as we are in <a href="#listing-10-10">Listing 10-10</a>, it’s <em>very</em> easy to slip and load CX with <code class="sourceCode nasm">ARRAY_LENGTH</code> rather than <code class="sourceCode nasm">ARRAY_LENGTH/<span class="dv">2</span></code>. The end result is unpredictable but almost surely unpleasant, as you’ll wipe out the contents of the <code class="sourceCode nasm">ARRAY_LENGTH</code> bytes immediately following the array.</p>
<p>The lesson is simple: whenever you use a repeated word-sized string instruction, make sure that the count you load into CX is a count in words, not in bytes.</p>
</section>
<section id="pointing-back-to-the-last-element" class="level3">
<h3>Pointing Back to the Last Element</h3>
<p>Sometimes it’s a little tricky figuring out where your pointers are after a string instruction finishes. That’s because each string instruction advances its pointer or pointers only <em>after</em> performing its primary function, so pointers are always one location past the last byte or word processed, as shown in Figures 10.9 and 10.10. This is definitely a convenience with <code class="sourceCode nasm"><span class="kw">lods</span></code>, <code class="sourceCode nasm"><span class="kw">stos</span></code>, and <code class="sourceCode nasm"><span class="kw">movs</span></code>, since it always leaves the pointers ready for the next operation. However, it can be a nuisance with <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code>, because it complicates the process of calculating exactly where a match or non-match occurred.</p>
<figure>
<img src="images/fig10.9RT.png" />
</figure>
<figure>
<img src="images/fig10.10RT.png" />
</figure>
<p>Along the same lines, CX counts down one time more than you might expect when repeated <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code> instructions find their termination conditions. Suppose, for instance, that a <code class="sourceCode nasm">repnz <span class="kw">scasb</span></code> instruction is started with CX equal to 100 and DI equal to 0. If the very first byte, byte 0, is a match, the <code class="sourceCode nasm">repnz <span class="kw">scasb</span></code> instruction will terminate. However, CX will contain 99, not 100, and DI will contain 1, not 0.</p>
<p>We’ll return to this topic in the next chapter. For now, just remember that string instructions never leave their pointers pointing at the last byte or word processed, and repeated <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code> instructions count down CX one more time than you’d expect.</p>
</section>
<section id="handling-very-small-and-very-large-blocks" class="level3">
<h3>Handling Very Small and Very Large Blocks</h3>
<p>The repeated string instructions have some interesting boundary conditions. One of those boundary conditions occurs when a repeated string instruction is executed with CX equal to zero.</p>
<p>When CX is zero, the analogy of <code class="sourceCode nasm">rep</code> to <code class="sourceCode nasm"><span class="kw">loop</span></code> breaks down. A <code class="sourceCode nasm"><span class="kw">loop</span></code>-based loop entered with CX equal to zero will execute 64 K times, as CX decrements from 0 to 0FFFFh and then all the way back down to 0. However, a repeated instruction executed with CX equal to zero won’t even execute once! That actually can be a useful feature, since it saves you from having to guard against a zero repeat count, as you do with <code class="sourceCode nasm"><span class="kw">loop</span></code>.</p>
<p>(Be aware that if you repeat <code class="sourceCode nasm"><span class="kw">scas</span></code> or <code class="sourceCode nasm"><span class="kw">cmps</span></code> with CX equal to 0, no comparisons will be performed <em>and no flags will be changed</em>. This means that when CX could possibly be set to 0, you must actively check for that case and skip the comparison if CX is indeed 0, as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">jcxz</span>  NothingToTest
    repnz <span class="kw">scasb</span>
    <span class="kw">jnz</span>   NoMatch
    <span class="co">; A match occurred.</span>
          :
    <span class="co">; No match occurred.</span>
<span class="fu">NoMatch:</span>
          :
    <span class="co">; There was nothing to scan, which is usually handled either</span>
    <span class="co">; as a non-match or as an error.</span>
<span class="fu">NothingToTest:</span></code></pre>
<p>Otherwise, you might unwittingly end up acting on flags set by some earlier instruction, since either <code class="sourceCode nasm"><span class="kw">scas</span></code> or <code class="sourceCode nasm"><span class="kw">cmps</span></code> repeated zero times will leave those flags unchanged.)</p>
<p>However, as Robert Heinlein was fond of saying, there ain’t no such things as a free lunch. What <code class="sourceCode nasm">rep</code> giveth with small (zero-length) blocks it taketh away with large (64 Kb) blocks. Since a zero count causes nothing to happen, the largest number of times a string instruction can be repeated is 0FFFFh, which is not 64 K but 64 K-1. That means that a byte-sized repeated string instruction can’t <em>quite</em> cover a full segment. That can certainly be a bother, since it’s certainly possible that you’ll want to use repeated string instructions to initialize or copy arrays and strings of any length between 0 and 64 K bytes — inclusive. What to do?</p>
<p>First of all, let me point out that there’s never a problem in covering large blocks with <em>word-sized</em> repeated string instructions. A mere 8000h repetitions of any word-sized string instruction will suffice to cover an entire segment. Additional repetitions are useless — which brings us to another interesting point about string instructions. String instructions can handle a maximum of 64 K bytes, and then only <em>within a single segment</em>.</p>
<p>You’ll surely recall that string instructions advance pointer registers. Those pointer registers are SI, DI or both SI and DI. Notice that we didn’t mention anything about advancing DS, ES, or any other segment register. That’s because the string instructions don’t affect the segment registers. The implication should be pretty obvious: like all the memory addressing instructions of the 8088, the string instructions can only access those bytes that lie within the 64 Kb ranges of their associated segment registers, as shown in Figure 10.11. (We’ll discuss the relationships between the segment registers and the string instructions in detail shortly.)</p>
<figure>
<img src="images/fig10.11RT.png" />
</figure>
<p>Granted, <code class="sourceCode nasm"><span class="kw">movs</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code> can access source bytes in one 64 Kb block and destination bytes in another 64 Kb block, but each pointer register has a maximum range of 64 K, and that’s that.</p>
<p>While the string instructions are limited to operating within 64 Kb blocks, that doesn’t mean that they stop advancing their pointers when they hit one end or the other of one of those 64 Kb blocks — quite the contrary, in fact. Upon hitting one end of a 64 Kb block, the string instructions keep right on going at the <em>other</em> end of the block. This somewhat odd phenomenon springs directly from the nature of the pointer registers used by the string instructions, as follows.</p>
<p>The largest value a 16-bit register can contain is 0FFFFh. Consequently, SI and DI turn over from 0FFFFh to 0 as they are incremented by a string instruction (or from 0 to 0FFFFh as they’re decremented.) This effectively causes each string instruction pointer to wrap when it reaches the end of the segment it’s operating within, as shown in Figure 10.12.</p>
<figure>
<img src="images/fig10.12aRT.png" />
</figure>
<figure>
<img src="images/fig10.12bRT.png" />
</figure>
<p>This means that a string instruction can’t access part or all of just <em>any</em> 64 Kb block starting at a given segment:offset address, but only the 64 Kb block starting at the address <em>segment</em>:0, where <em>segment</em> is whichever of CS, DS, ES, or SS the string instruction is using. For instance:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">di</span><span class="bn">,0a000h</span>
<span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">di</span>
<span class="kw">mov</span>   <span class="kw">di</span><span class="bn">,8000h</span>
<span class="kw">mov</span>   <span class="kw">cx</span><span class="bn">,8000h</span>
<span class="kw">sub</span>   <span class="kw">ax</span>,<span class="kw">ax</span>
<span class="kw">cld</span>
rep   <span class="kw">stosw</span></code></pre>
<p>won’t clear the 32 K words starting at A000:8000, but rather the 32 K words starting at A000:0000. The words will be cleared in the following order: the words from A000:8000 to A000:FFFE will be cleared first, followed by the words from A000:0000 to A000:7FFE, as shown in Figure 10.13.</p>
<figure>
<img src="images/fig10.13RT.png" />
</figure>
<p>Now you can see why it’s pointless to repeat a word-sized string instruction more than 8000h times. Repetitions after 8000h simply access the same addresses as the first 8000h repetitions, as shown in Figure 10.14.</p>
<figure>
<img src="images/fig10.14aRT.png" />
</figure>
<figure>
<img src="images/fig10.14bRT.png" />
</figure>
<p>That brings us back to the original problem of handling both zero-length and 64 Kb blocks that consist of byte-sized elements. It should be clear that there’s no way that a single block of code can handle both zero-length and 64 Kb blocks unless the block length is stored in something larger than a 16-bit register. Handling both the zero-length and 64 Kb cases and everything in-between takes 64 K+1 counter values, one more than the 64 K values that can be stored in 16 bits. Simply put, if CX is zero, that can mean “handle zero bytes” or “handle 64 K bytes,”but it can’t mean both.</p>
<p>If you want to take CX equal to zero to mean “handle zero bytes,” you’re all set — that’s exactly how repeated string instructions work, as described above. For example, the subroutine <code class="sourceCode nasm">BlockClear</code> in <a href="#listing-10-11">Listing 10-11</a> clears a block of memory between zero and 64 K-1 bytes in length; as called in <a href="#listing-10-11">Listing 10-11</a>, <code class="sourceCode nasm">BlockClear</code> clears a 1000-byte block in 2.18 ms. If you want to take CX equal to zero to mean “handle 64 K bytes,” however, you have to do a bit of work — but there’s an opportunity for higher performance there as well.</p>
<p>The obvious way to handle 64 K bytes with a single repeated string instruction is to simply perform 32 K word-sized operations. Now, that’s fine for blocks that are exactly 64 K bytes long, but what about blocks between 1 and 64 K-1 bytes long? Such blocks may be an odd number of bytes in length, so we can’t just divide the count by two and perform a word-sized repeated string instruction.</p>
<p>What we can do, however, is divide the byte count by two, perform a word-sized repeated string instruction, and then make up the odd byte (if there is one) with a byte-sized non-repeated string instruction. The subroutine <code class="sourceCode nasm">BlockClear64</code> in <a href="#listing-10-12">Listing 10-12</a> does exactly that. <a href="#listing-10-12">Listing 10-12</a> divides the count by two with a <code class="sourceCode nasm"><span class="kw">rcr</span></code> instruction, converting zero counts into 32 K-word counts in the process. Next, <code class="sourceCode nasm">BlockClear64</code> clears memory in word-sized chunks with <code class="sourceCode nasm">rep <span class="kw">stosw</span></code>. Finally, one extra <code class="sourceCode nasm"><span class="kw">stosb</span></code> is performed if there was a carry from the <code class="sourceCode nasm"><span class="kw">rcr</span></code> — that is, if the array is an odd number of bytes in length — in order to clear the last byte of the array.</p>
<p><a href="#listing-10-12">Listing 10-12</a>, unlike <a href="#listing-10-11">Listing 10-11</a>, is capable of handling blocks between 1 and 64 K bytes in length. The more interesting thing about <a href="#listing-10-12">Listing 10-12</a>, however, is that it’s <em>fast</em>, clocking in at 1.55 ms, about 41% faster than <a href="#listing-10-11">Listing 10-11</a>. Why? Well, as we found earlier, we’re always better off using word-sized rather than byte-sized string instructions. A side-effect of <a href="#listing-10-12">Listing 10-12</a> is that initialization of byte-sized data is performed almost entirely with word-sized string instructions, and that pays off handsomely.</p>
<p>You need not be copying full 64 Kb blocks in order to use the approach of <a href="#listing-10-12">Listing 10-12</a>. It’s worth converting any byte-sized string instruction that’s repeated more than a few times to use a word-sized string instruction followed by a final conditional byte-sized instruction. For instance, <a href="#listing-10-13">Listing 10-13</a> is functionally identical to <a href="#listing-10-11">Listing 10-11</a>, but is 5 bytes longer and executes in just 1.54 ms, thanks to the use of a word-sized <code class="sourceCode nasm">rep <span class="kw">stos</span></code>. That’s the same 41% improvement that we got in <a href="#listing-10-12">Listing 10-12</a>, which isn’t surprising considering that <a href="#listing-10-12">Listings 10-12</a> and <a href="#listing-10-13">10-13</a> both spend virtually all of their time performing repeated <code class="sourceCode nasm"><span class="kw">stosw</span></code> instructions. I’m sure you’ll agree that a 41% speed-up is quite a return for the expenditure of 5 bytes.</p>
<p>Once again: <em>use word-rather than byte-sized string instructions whenever you can.</em></p>
</section>
<section id="words-of-caution" class="level3">
<h3>Words of Caution</h3>
<p>Before we take our leave of the issue of byte-versus word-sized string instructions, I’d like to give you a couple of warnings about the use of word-sized string instructions.</p>
<p>You must exercise additional caution when using word-sized string instructions on the 8086, 80286, and 80386 processors. The 8086 and 80286 processors access word-sized data that starts at an even address (word-aligned data) twice as fast as word-sized data that starts at an odd address. This means that code such as that in <a href="#listing-10-13">Listing 10-13</a> would run at only half speed on an 8086 or 80286 if the start of the array happened to be at an odd address. This can be solved by altering the code to detect whether arrays start at odd or even addresses and then performing byte moves as needed to ensure that the bulk of the operation — performed with a repeated word-sized instruction — is word-aligned.</p>
<p>The 80386 has similar constraints involving doubleword alignment. We’ll discuss the issue of word and doubleword alignment in detail in Chapter 15. For now just be aware that while the word-sized string instruction rule for the 8088 is simple — use word-sized string instructions whenever possible — there are additional considerations, involving alignment, for the other members of the 8086 family.</p>
<p>The second warning concerns the use of word-sized string instructions to access EGA and VGA display memory in modes 0Dh, 0Eh, 0Fh, 10h, and 12h. In each these modes it’s possible to copy 4 bytes of video data -1 byte from each of the four planes at once by loading the 4 bytes into four special latches in the adapter with a single read and then storing all 4 latches back to display memory with a single write, as shown in Figure 10.15.</p>
<figure>
<img src="images/fig10.15RT.png" />
</figure>
<p>Use of the latches can greatly speed graphics code; for example, copying via the latches can improve the performance of tasks that require block copies from one part of display memory to another, such as scrolling, by a factor of four over normal byte-at-a-time copying techniques.</p>
<p>Unfortunately, because each latch can store only 1 byte, the latches only work properly with byte-sized string instructions. Word-sized string instructions cause the latches to be loaded twice per word-sized read from display memory: once for the lower byte of each word, then again for the upper byte, wiping out the data read from the lower byte. Consequently, only half of each word is really transferred. The end result is that half the data you’d expect to copy is missing, and the other half is copied twice.</p>
<p>The EGA/VGA latches are complex, and now is not the time to describe them in detail. We’ll return to the latches in Volume II of <em>The Zen of Assembly Language</em>. For now, remember this: don’t use word-sized string instructions to copy data from one area to another of EGA/VGA display memory via the latches.</p>
</section>
<section id="segment-overrides-sometimes-you-can-sometimes-you-cant" class="level3">
<h3>Segment Overrides: Sometimes You Can, Sometimes You Can’t</h3>
<p>We’ve said that string instructions advance only their pointers, not their segments, so they can only access memory within the 64 Kb block after a given segment. That raises the question of which segments the string instructions access by default, and when the default segment selections can be overridden.</p>
<p>The rules for default segments are simple. String instructions that use DI as a pointer register (<code class="sourceCode nasm"><span class="kw">stos</span></code> and <code class="sourceCode nasm"><span class="kw">movs</span></code> for the destination operand, and <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code> for the source operand) use DI as an offset in the ES segment. String instructions that use SI as a pointer register (<code class="sourceCode nasm"><span class="kw">lods</span></code> and <code class="sourceCode nasm"><span class="kw">movs</span></code> for the source operand, and <code class="sourceCode nasm"><span class="kw">cmps</span></code> for the destination operand) use SI as an offset in the DS segment.</p>
<p>The rule for segment overrides is equally simple. Accesses via DI must go to the ES segment; that cannot be overridden. Accesses via SI default to the DS segment, but that default can be overridden. In other words, the source segment for <code class="sourceCode nasm"><span class="kw">lods</span></code> and <code class="sourceCode nasm"><span class="kw">movs</span></code> and the destination segment for <code class="sourceCode nasm"><span class="kw">cmps</span></code> can be any of the four segments, but the destination segment for <code class="sourceCode nasm"><span class="kw">stos</span></code> and <code class="sourceCode nasm"><span class="kw">movs</span></code> and the source segment for <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code> must be ES.</p>
<p>How do we tell MASM to override the segment for those string instructions that allow segment overrides? While we’re at it, how do we specify the size — word or byte — of a string instruction’s data? Both answers lie in the slightly unusual way in which string instructions are coded in 8088 assembler.</p>
<p>String instructions are odd in that operands are optional. <code class="sourceCode nasm"><span class="kw">stosb</span></code> with no operands means “perform a byte-sized <code class="sourceCode nasm"><span class="kw">stos</span></code>,” and <code class="sourceCode nasm"><span class="kw">cmpsw</span></code> with no operands means “perform a word-sized <code class="sourceCode nasm"><span class="kw">cmps</span></code>.” There really isn’t any need for explicit operands to string instructions, since the memory operands are fully implied by the contents of the SI, DI, and segment registers.</p>
<p>However, MASM is a strongly-typed assembler, meaning that MASM considers named memory operands to have inherent types — byte, word, and so on. Consequently, MASM lets you provide operands to string instructions, <em>even though those operands have no effect on the memory location actually accessed</em>! MASM uses operands to string instructions to check segment accessibility (by way of the <code class="sourceCode nasm">assume</code> directive, which is a bit of a kludge — but that’s another story), to decide whether to assemble byte-or word-sized string instructions, and to decide whether to perform segment overrides — and that’s all.</p>
<p>For example, the following is a valid <code class="sourceCode nasm"><span class="kw">movs</span></code> instruction that copies <code class="sourceCode nasm">SourceWord</code> to <code class="sourceCode nasm">DestWord</code>:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">SourceWord  <span class="dt">dw</span>   <span class="dv">1</span>
DestWord    <span class="dt">dw</span>   ?
    :
    <span class="kw">mov</span>   <span class="kw">si</span>,<span class="kw">seg</span> SourceWord
    <span class="kw">mov</span>   <span class="kw">ds</span>,<span class="kw">si</span>
    <span class="kw">mov</span>   <span class="kw">si</span>,offset SourceWord
    <span class="kw">mov</span>   <span class="kw">di</span>,<span class="kw">seg</span> DestWord
    <span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">di</span>
    <span class="kw">mov</span>   <span class="kw">di</span>,offset DestWord
    <span class="kw">movs</span>  <span class="kw">es</span>:[DestWord],[SourceWord]</code></pre>
<p>There’s something strange here, though, and that’s that the operands to <code class="sourceCode nasm"><span class="kw">movs</span></code> have <em>nothing</em> to do with the source and destination addresses.</p>
<p>Why? String instructions don’t contain any addresses at all; they’re only 1 byte long, so there isn’t even room for a <em>mod-reg-rm</em> byte. Instead, string instructions use whatever addresses are already in DS:SI and ES:DI. By providing operands to <code class="sourceCode nasm"><span class="kw">movs</span></code> in the last example, you’ve simply told the assembler to <em>assume</em> that DS:SI points to <code class="sourceCode nasm">SourceWord</code> and ES:DI points to <code class="sourceCode nasm">DestWord</code>. The assembler uses that information only to decide to assemble a <code class="sourceCode nasm"><span class="kw">movsw</span></code> rather than a <code class="sourceCode nasm"><span class="kw">movsb</span></code>, since the operands are word-sized. If you had set up SI or DI to point to a different variable, the assembler would never have known, and the <code class="sourceCode nasm"><span class="kw">movs</span></code> operands would only have served to confuse you when you tried to debug the program. For example:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">SourceWord  <span class="dt">dw</span>  <span class="dv">1</span>
DestWord    <span class="dt">dw</span>  ?
    :
    <span class="kw">mov</span>   <span class="kw">di</span>,<span class="kw">seg</span> SourceWord
    <span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">di</span>
    <span class="kw">mov</span>   <span class="kw">di</span>,offset SourceWord
    <span class="kw">mov</span>   <span class="kw">si</span>,<span class="kw">seg</span> DestWord
    <span class="kw">mov</span>   <span class="kw">ds</span>,<span class="kw">si</span>
    <span class="kw">mov</span>   <span class="kw">si</span>,offset DestWord
    <span class="kw">movs</span>  <span class="kw">es</span>:[DestWord],[SourceWord]</code></pre>
<p>actually copies <code class="sourceCode nasm">DestWord</code> to <code class="sourceCode nasm">SourceWord</code>, despite the operands to <code class="sourceCode nasm"><span class="kw">movs</span></code>. Seems pretty silly, doesn’t it? That’s MASM, though.</p>
<p>(Actually, that’s not the worst of it. Try assembling:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">movs</span>  <span class="dt">byte</span> <span class="dt">ptr</span> <span class="kw">es</span>:[<span class="kw">bx</span>],<span class="dt">byte</span> <span class="dt">ptr</span> [<span class="kw">di</span>]</code></pre>
<p>which features not one but <em>two</em> memory addressing modes that can’t be used by <code class="sourceCode nasm"><span class="kw">movs</span></code>. MASM cheerfully assembles this line without complaint; it already knows the addressing modes used by <code class="sourceCode nasm"><span class="kw">movs</span></code>, so it pays little attention to the modes you specify.)</p>
<p>In short, operands to string instructions can be misleading and don’t really provide any data-type information that the simple suffixes “b”and “w” on string instructions don’t. Consequently, I prefer to steer clear of string instruction operands in favor of stand-alone string instructions such as <code class="sourceCode nasm"><span class="kw">scasb</span></code> and <code class="sourceCode nasm"><span class="kw">lodsw</span></code>. However, there’s one case where operands are quite useful, and that’s when you want to force a segment override.</p>
<p>Recall from Chapter 7 that a prefix like <code class="sourceCode nasm"><span class="kw">DS</span>:</code> can be placed on a memory operand in order to force a segment override on that memory access. Segment overrides work in just the same way with string instructions. For instance, we can modify our ongoing example to copy <code class="sourceCode nasm">SourceWord</code> to <code class="sourceCode nasm">DestWord</code>, with both operands accessed in ES, as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">SourceWord  <span class="dt">dw</span>  <span class="dv">1</span>
DestWord    <span class="dt">dw</span>  ?
    :
    <span class="kw">mov</span>   <span class="kw">si</span>,<span class="kw">seg</span> SourceWord
    <span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">si</span>
    <span class="kw">mov</span>   <span class="kw">si</span>,offset SourceWord
    <span class="kw">mov</span>   <span class="kw">di</span>,offset DestWord
    <span class="kw">movs</span>  <span class="kw">es</span>:[DestWord],<span class="kw">es</span>:[SourceWord]</code></pre>
<p>The segment override on <code class="sourceCode nasm">SourceWord</code> forces the 8088 to access the source operand at ES:SI rather than the default of DS:SI.</p>
<p>This is a less-than-ideal approach, however. For one thing, I’m still not fond of using meaningless and potentially misleading memory operands with string instructions. For another, there are many cases where SI and/or DI are passed to a subroutine that uses a string instruction, or where SI and/or DI can be set to point to any one of a number of memory locations before a string instruction is executed. In these cases, there simply isn’t any single memory variable name that can legitimately be assigned to an operand.</p>
<p>Fortunately, there’s an easy solution: specify the memory operands to string instructions as consisting of only the pointer registers in the form <code class="sourceCode nasm">[<span class="kw">SI</span>]</code> and <code class="sourceCode nasm">[<span class="kw">DI</span>]</code>. Here’s our ongoing example with the pointer-register approach:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">SourceWord  <span class="dt">dw</span>  <span class="dv">1</span>
DestWord    <span class="dt">dw</span>  ?
    :
    <span class="kw">mov</span>   <span class="kw">si</span>,<span class="kw">seg</span> SourceWord
    <span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">si</span>
    <span class="kw">mov</span>   <span class="kw">si</span>,offset SourceWord
    <span class="kw">mov</span>   <span class="kw">di</span>,offset DestWord
    <span class="kw">movs</span>  <span class="dt">word</span> <span class="dt">ptr</span> <span class="kw">es</span>:[<span class="kw">di</span>],<span class="dt">word</span> <span class="dt">ptr</span> <span class="kw">es</span>:[<span class="kw">si</span>]</code></pre>
<p>This code is acceptable, since the operands to <code class="sourceCode nasm"><span class="kw">movs</span></code> merely confirm what we already know, that <code class="sourceCode nasm"><span class="kw">movs</span></code> copies the data pointed to by SI to the location pointed to by DI. Note that the operator <code class="sourceCode nasm"><span class="dt">word</span> <span class="dt">ptr</span></code> is required because the <code class="sourceCode nasm"><span class="kw">movsw</span></code> form of <code class="sourceCode nasm"><span class="kw">movs</span></code> doesn’t accept operands (yet another quirk of MASM).</p>
<p>Now that we have a decent solution to the problem of generating segment overrides to string instructions, let’s review what we’ve learned. The entire point of our discussion of operands to string instructions is simply that such operands make it possible to perform segment overrides with string instructions. If you don’t need to perform segment overrides, I strongly suggest that you skip the operands altogether. Here’s my preferred version of the first example in this section:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">SourceWord  <span class="dt">dw</span>  <span class="dv">1</span>
DestWord    <span class="dt">dw</span>  ?
    :
    <span class="kw">mov</span>   <span class="kw">si</span>,<span class="kw">seg</span> SourceWord
    <span class="kw">mov</span>   <span class="kw">ds</span>,<span class="kw">si</span>
    <span class="kw">mov</span>   <span class="kw">si</span>,offset SourceWord
    <span class="kw">mov</span>   <span class="kw">di</span>,<span class="kw">seg</span> DestWord
    <span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">di</span>
    <span class="kw">mov</span>   <span class="kw">di</span>,offset DestWord
    <span class="kw">movsw</span></code></pre>
<p>A final note. You may be tempted to try something like:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">movs</span>  <span class="dt">byte</span> <span class="dt">ptr</span> <span class="kw">ds</span>:[<span class="kw">di</span>],<span class="dt">byte</span> <span class="dt">ptr</span> [<span class="kw">si</span>]</code></pre>
<p>After all, it would be awfully convenient if string instruction accesses via DI didn’t always have to be in ES. Go right ahead and try it, if you wish — but it won’t work. It won’t even assemble. (The same goes for trying to use registers or addressing modes other than those I’ve shown as operands to string instructions; MASM either ignores the operands or spits them out with an error message.)</p>
<p>Segment overrides on string instruction accesses via DI don’t assemble because the ES segment must <em>always</em> be used when string instructions access operands addressed by DI. Why? There is no particular “why”: for whatever reason, that’s just the way the 8088 works. The 8088 doesn’t have to make sense — inside the universe of PC programming, the quirks of the 8088 become laws of nature. Understanding those laws and making the best possible use of them is what the Zen of assembler is all about.</p>
<p>Then, too, if you had to choose one segment to be stuck with, it would certainly be ES. CS and SS can’t be changed freely, and DS is often dedicated to maintaining a near data segment, but ES is usually free to point anywhere in memory. Remember also that the segments of all SI operands to string instructions can be overridden, so string instructions can access <em>any</em> operand — source, destination, or both — via the ES segment if that becomes necessary.</p>
</section>
<section id="the-good-and-the-bad-of-segment-overrides" class="level3">
<h3>The Good and the Bad of Segment Overrides</h3>
<p>Should you use segment overrides with string instructions? That depends on the situation. Segment override prefixes take up 1 byte and take 2 cycles to execute, so you’re better off without them if that’s possible. When you use a string instruction repeatedly within a loop, you should generally set up the segment registers outside the loop in such a way that the string instruction can use its default segment or segments. If, on the other hand, you’re using a string instruction to perform a single memory access, a segment override prefix is preferable to all the code required to set up the default segment registers for that instruction.</p>
<p>For example, suppose that we’re calculating the 8-bit checksum of a 1000-byte array residing in a far segment. <a href="#listing-10-14">Listing 10-14</a>, which reads the 1000 elements via a <code class="sourceCode nasm"><span class="kw">lods</span></code> with an <code class="sourceCode nasm"><span class="kw">ES</span>:</code> prefix, runs in 9.06 ms. In contrast, <a href="#listing-10-15">Listing 10-15</a>, which juggles the registers so that DS points to the array’s segment for the duration of the loop, runs in just 7.56 ms.</p>
<p>Now suppose that we’re reading a single memory location — also located in a far segment — with <code class="sourceCode nasm"><span class="kw">lods</span></code>. <a href="#listing-10-16">Listing 10-16</a>, which does this by loading ES and using an <code class="sourceCode nasm"><span class="kw">ES</span>:</code> override, runs in 10.35 us per byte read. <a href="#listing-10-17">Listing 10-17</a>, which first preserves DS, then loads DS and reads the memory location via DS, the default segment for <code class="sourceCode nasm"><span class="kw">lods</span></code>, and finally pops DS, runs in a considerably more leisurely 15.06 us per byte read. In this situation it pays to use the segment override.</p>
<p>By the way, there’s an opportunity for tremendous performance improvement in <a href="#listing-10-16">Listing 10-16</a>. The trick: just leave ES set for as long as necessary. <a href="#listing-10-18">Listing 10-18</a> performs exactly the same task as <a href="#listing-10-16">Listing 10-16</a>, save that ES is loaded only once, at the start of the program. The result: an execution time of just 5.87 ms per byte read, a 76% improvement over <a href="#listing-10-16">Listing 10-16</a>. What that means is that you should…</p>
</section>
<section id="leave-es-andor-ds-set-for-as-long-as-possible" class="level3">
<h3>…Leave ES and/or DS Set for as Long as Possible</h3>
<p><em>When you’re accessing far data, leave ES and/or DS (whichever you’re using) set for as long as possible.</em> This rule may seem impractical, since it prevents the use of those registers to point to any other area of memory, but properly applied it has tremendous benefits.</p>
<p>For example, you can leave DS set for the duration of a loop that scans a far data array, as we did in <a href="#listing-10-15">Listing 10-15</a>. This is one of the areas in which you can outshine any compiler. Typically, compilers reload both the segment and offset portions of far pointers on every use, even inside a loop. <a href="#listing-10-19">Listing 10-19</a>, which is the sort of code a high-level language compiler would generate for the task of <a href="#listing-10-15">Listing 10-15</a>, takes 25.14 ms to execute. <a href="#listing-10-15">Listing 10-15</a> is <em>232%</em> faster than <a href="#listing-10-19">Listing 10-19</a>, and the difference is entirely due to the superior ability of the assembler programmer to deal with string instructions and segments. (Actually, <a href="#listing-10-19">Listing 10-19</a> is <em>more</em> efficient than the code generated by most high-level language compilers would be, since it keeps the checksum in a byte-sized register rather than in a memory variable and uses a <code class="sourceCode nasm"><span class="kw">loop</span></code> instruction rather than decrementing a counter stored in memory.)</p>
<p>As an example of leaving ES set for as long as possible, I once wrote and sold a game in which ES contained the display memory segment — 0B800h — for the entire duration of the game. My program spent so much of its time drawing that it was worth dedicating ES to a single area of memory in order to save the cycles that would otherwise have been expended on preserving and reloading ES during each call to the video driver. I’m not saying this is generally a good idea (in fact, it’s not, because it sharply restricts the use of the most flexible segment register), but rather that this is the sort of unusual approach that’s worth considering when you’re looking to turbocharge your code.</p>
</section>
<section id="rep-and-segment-prefixes-dont-mix" class="level3">
<h3><code>rep</code> and Segment Prefixes Don’t Mix</h3>
<p>One case in which you should exercise extreme caution when using segment overrides is in conjunction with repeated string instructions. The reason: the 8088 has the annoying habit of remembering a maximum of one prefix byte when a string instruction is interrupted by a hardware interrupt and then continues after an <code class="sourceCode nasm"><span class="kw">iret</span></code>. <code class="sourceCode nasm">rep</code> is a prefix byte, and segment overrides are prefix bytes, which means that a repeated string instruction with a segment override has two prefix bytes — and that’s one too many. You’re pretty much guaranteed to have erratic and unreproducible bugs in any code that uses instructions like:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">rep   <span class="kw">movs</span>  <span class="dt">byte</span> <span class="dt">ptr</span> <span class="kw">es</span>:[<span class="kw">di</span>],<span class="dt">byte</span> <span class="dt">ptr</span> <span class="kw">es</span>:[<span class="kw">si</span>]</code></pre>
<p>If you have some time-critical task that absolutely requires the use of a repeated string instruction with a segment override, you must turn off interrupts before executing the instruction. With interrupts disabled, there’s no chance that the repeated string instruction will be confused by an interrupt and subsequent <code class="sourceCode nasm"><span class="kw">iret</span></code>. However, this technique should be used only as a last resort, because it involves disabling interrupts for the potentially lengthy duration of a repeated string instruction. If interrupts are kept disabled for too long, then keystrokes, mouse actions, and serial data can be lost or corrupted. The preferred solution is to reduce the two prefix bytes to just one — the <code class="sourceCode nasm">rep</code> prefix — by juggling the segments so that the repeated string instruction can use its default segments.</p>
</section>
<section id="on-to-string-instruction-applications" class="level3">
<h3>On to String Instruction Applications</h3>
<p>We haven’t covered <em>everything</em> there is to know about the string instructions, but we have touched on the important points. Now we’re ready to see the string instructions in action. To an assembler programmer, that’s a pleasant sight indeed.</p>
</section>
</section>
</section>
<section id="chapter-11-string-instruction-applications" class="level1">
<h1>Chapter 11: String Instruction Applications</h1>
<p>Now that we’ve got a solid understanding of what the string instructions do, let’s look at a few applications to get a sense of what they’re particularly good for. The applications we’ll look at include copying arrays, searching strings for characters, looking up entries in tables, comparing strings, and animation.</p>
<p>There’s a lot of meat in this chapter, and a lot of useful code. The code isn’t fully fleshed out, since I’m trying to illustrate basic principles rather than providing you with a library from A to Z, but that’s actually all to the good. You can build on this code to meet your specific needs or write your own code from scratch once you understand the ins and outs of the string instructions. In either case, you’ll be better off with code customized to suit your purposes than you would be using any one-size-fits-all code I could provide.</p>
<p>I’ll frequently contrast the string instruction-based implementations with versions built around non-string instructions. This should give you a greater appreciation for the string instructions, and may shed new light on the non-string instructions as well. I’ll tell you ahead of time how the comparisons will turn out: in almost every case the string instructions will prove to be vastly superior. The lesson we learned in the last chapter holds true: <em>use the string instructions to the hilt!</em> There’s nothing like them under the (8088) sun.</p>
<p>Contrasting string and non-string implementations also reinforces an important point. There are many, many ways to accomplish any given task on the 8088. It’s knowing which approach to choose that separates the journeyman programmer from the guru.</p>
<section id="string-handling-with-lods-and-stos" class="level2">
<h2>String Handling With <code>lods</code> and <code>stos</code></h2>
<p><code class="sourceCode nasm"><span class="kw">lods</span></code> is an odd bird among string instructions, being the only string instruction that doesn’t benefit in the least from <code class="sourceCode nasm">rep</code>. While <code class="sourceCode nasm">rep</code> does work with <code class="sourceCode nasm"><span class="kw">lods</span></code>, in that it causes <code class="sourceCode nasm"><span class="kw">lods</span></code> to repeat multiple times, the combination of the two is nonetheless totally impractical: what good could it possibly do to load AL twice (to say nothing of 64 K times)? Without <code class="sourceCode nasm">rep</code>, <code class="sourceCode nasm"><span class="kw">lods</span></code> is still better than <code class="sourceCode nasm"><span class="kw">mov</span></code>, but not <em>that</em> much better; <code class="sourceCode nasm"><span class="kw">lods</span></code> certainly doesn’t generate the quantum jump in performance that <code class="sourceCode nasm">rep <span class="kw">stos</span></code> and <code class="sourceCode nasm">rep <span class="kw">movs</span></code> do. So — when <em>does</em> <code class="sourceCode nasm"><span class="kw">lods</span></code> really shine?</p>
<p>It turns out that <code class="sourceCode nasm"><span class="kw">lods</span></code> is what might be called a “synergistic”instruction, at its best when used with <code class="sourceCode nasm"><span class="kw">stos</span></code> (or sometimes <code class="sourceCode nasm"><span class="kw">scas</span></code>, or even non-string instructions) in a loop. Together, <code class="sourceCode nasm"><span class="kw">lods</span></code> and <code class="sourceCode nasm"><span class="kw">stos</span></code> let you load an array or string element into AL, test and/or modify it, and then write the element back to either the original array or a new array, as shown in Figure 11.1.</p>
<figure>
<img src="images/fig11.1aRT.png" />
</figure>
<figure>
<img src="images/fig11.1bRT.png" />
</figure>
<p>You might think of the <code class="sourceCode nasm"><span class="kw">lods</span></code>-process-<code class="sourceCode nasm"><span class="kw">stos</span></code> combination as being a sort of “meta-<code class="sourceCode nasm"><span class="kw">movs</span></code>,” whereby you can whip up customized memory-to-memory moves as needed. Of course, <code class="sourceCode nasm"><span class="kw">lods</span></code>/<code class="sourceCode nasm"><span class="kw">stos</span></code> is slower than <code class="sourceCode nasm"><span class="kw">movs</span></code> (especially <code class="sourceCode nasm">rep <span class="kw">movs</span></code>), but by the same token <code class="sourceCode nasm"><span class="kw">lods</span></code>/<code class="sourceCode nasm"><span class="kw">stos</span></code> is far more flexible. Besides, <code class="sourceCode nasm"><span class="kw">lods</span></code>/<code class="sourceCode nasm"><span class="kw">stos</span></code> isn’t <em>that</em> slow — <em>all</em> of the 8088’s memory-accessing instructions suffer by comparison with <code class="sourceCode nasm"><span class="kw">movs</span></code>. Placed inside a loop, the <code class="sourceCode nasm"><span class="kw">lods</span></code>/<code class="sourceCode nasm"><span class="kw">stos</span></code> combination makes for fairly speedy array and string processing.</p>
<p>For example, <a href="#listing-11-1">Listing 11-1</a> copies a string to a new location, converting all characters to uppercase in the process, by using a loop containing <code class="sourceCode nasm"><span class="kw">lods</span></code> and <code class="sourceCode nasm"><span class="kw">stos</span></code>. <a href="#listing-11-1">Listing 11-1</a> takes just 773 us to copy and convert. By contrast, <a href="#listing-11-2">Listing 11-2</a>, which uses non-string instructions to perform the same task, takes 921 us to perform the copy and conversion.</p>
<p>By the way, <a href="#listing-11-1">Listing 11-1</a> could just as easily have converted <code class="sourceCode nasm">SourceString</code> to uppercase in place, rather than copying the converted text to <code class="sourceCode nasm">DestString</code>. This would be accomplished simply by loading both DS:SI and ES:DI to point to <code class="sourceCode nasm">SourceString</code>, as shown in <a href="#listing-11-3">Listing 11-3</a>, which changes nothing else from <a href="#listing-11-1">Listing 11-1</a>.</p>
<p>Why is this interesting? It’s interesting because two pointers — DS:SI and ES:DI — are used to point to a single array. It’s often faster to maintain two pointers and use <code class="sourceCode nasm"><span class="kw">lods</span></code> and <code class="sourceCode nasm"><span class="kw">stos</span></code> than it is to use a single pointer with non-string instructions, as in <a href="#listing-11-4">Listing 11-4</a>. <a href="#listing-11-3">Listing 11-3</a> runs in 771 us, about the same as <a href="#listing-11-1">Listing 11-1</a> (after all, they’re virtually identical). However, <a href="#listing-11-4">Listing 11-4</a> takes 838 us, even though it uses only one pointer to point to the array being converted to uppercase.</p>
<p>The <code class="sourceCode nasm"><span class="kw">lods</span></code>/<code class="sourceCode nasm"><span class="kw">stos</span></code> pair lies somewhere between the repeated string instructions and the non-string instructions in terms of performance and flexibility. <code class="sourceCode nasm"><span class="kw">lods</span></code>/<code class="sourceCode nasm"><span class="kw">stos</span></code> isn’t as fast as any of the repeated string instructions, both because two instructions are involved and because it can’t be used with a <code class="sourceCode nasm">rep</code> prefix but must instead be placed in a loop. However, <code class="sourceCode nasm"><span class="kw">lods</span></code>/<code class="sourceCode nasm"><span class="kw">stos</span></code> is a good deal more flexible than any repeated string instruction, since once a memory operand is loaded into AL or AX it can be tested and manipulated easily (and often quickly as well, thanks to the accumulator-specific instructions).</p>
<p>On the other hand, the <code class="sourceCode nasm"><span class="kw">lods</span></code>/<code class="sourceCode nasm"><span class="kw">stos</span></code> pair is certainly faster than non-string instructions, as <a href="#listing-11-1">Listings 11-1</a> through <a href="#listing-11-4">11-4</a> illustrate. However, <code class="sourceCode nasm"><span class="kw">lods</span></code>/<code class="sourceCode nasm"><span class="kw">stos</span></code> is not as flexible as the non-string instructions, since DS:SI and ES:DI must be used as pointer registers and only the accumulator can be loaded from and stored to memory.</p>
<p>On balance, the <code class="sourceCode nasm"><span class="kw">lods</span></code>/<code class="sourceCode nasm"><span class="kw">stos</span></code> pair overcomes some but not all of the limitations of repeated string instructions, and does so at a substantial performance cost <em>vis-a-vis</em> the repeated string instructions. One thing that <code class="sourceCode nasm"><span class="kw">lods</span></code>/<code class="sourceCode nasm"><span class="kw">stos</span></code> doesn’t do particularly well is modify memory directly. For example, suppose that we want to set the high bit of every byte in a 1000-byte array. We could of course do this with <code class="sourceCode nasm"><span class="kw">lodsb</span></code> and <code class="sourceCode nasm"><span class="kw">stosb</span></code>, setting the high bit of each word while it’s loaded into AL. <a href="#listing-11-5">Listing 11-5</a>, which does exactly that, takes 10.07 us per word.</p>
<p>However, we could also use a plain old <code class="sourceCode nasm"><span class="kw">or</span></code> instruction working directly with a memory operand to do the same thing, as shown in <a href="#listing-11-6">Listing 11-6</a>. <a href="#listing-11-6">Listing 11-6</a> is just as fast as <a href="#listing-11-5">Listing 11-5</a> at 10.06 us per word, and it’s also considerably shorter at 13 rather than 21 bytes, with 1 less byte inside the loop. <code class="sourceCode nasm"><span class="kw">lods</span></code>/<code class="sourceCode nasm"><span class="kw">stos</span></code> isn’t <em>disastrously</em> worse in this case, but it certainly isn’t the preferred solution — and there are plenty of other situations in which <code class="sourceCode nasm"><span class="kw">lods</span></code>/<code class="sourceCode nasm"><span class="kw">stos</span></code> is less than ideal.</p>
<p>For instance, when registers are tight, the extra pointer register <code class="sourceCode nasm"><span class="kw">lods</span></code>/<code class="sourceCode nasm"><span class="kw">stos</span></code> takes can be sorely missed. If the accumulator is reserved for some specific purpose and can’t be modified, <code class="sourceCode nasm"><span class="kw">lods</span></code>/<code class="sourceCode nasm"><span class="kw">stos</span></code> can’t very well be used. If a pointer to far data is needed by other instructions in the same routine, the limitation of <code class="sourceCode nasm"><span class="kw">stos</span></code> to operating in the ES segment would become a burden. In other words, while the <code class="sourceCode nasm"><span class="kw">lods</span></code>/<code class="sourceCode nasm"><span class="kw">stos</span></code> pair is more flexible than the repeated string instructions, its limitations are significant nonetheless.</p>
<p>The point is not simply that the <code class="sourceCode nasm"><span class="kw">lods</span></code>/<code class="sourceCode nasm"><span class="kw">stos</span></code> pair is not as flexible as the non-string instructions. The real point is that you shouldn’t assume you’ve come up with the best solution just because you’ve used string instructions. Yes, I know that I’ve been touting string instructions as the greatest thing since sliced bread, and by and large that’s true. However, because the string instructions have a sharply limited repertoire and often require a good deal of preliminary set-up, you must consider your alternatives before concluding that a string instruction-based implementation is best.</p>
</section>
<section id="block-handling-with-movs" class="level2">
<h2>Block Handling With <code>movs</code></h2>
<p>Simply put, <code class="sourceCode nasm"><span class="kw">movs</span></code> is the king of the block copy. There’s no other 8088 instruction that can hold a candle to <code class="sourceCode nasm"><span class="kw">movs</span></code>when it comes to copying blocks of data from one area of memory to another. It does take several instructions to set up for <code class="sourceCode nasm"><span class="kw">movs</span></code>, so if you’re only moving a few bytes and DS:SI and ES:DI don’t happen to be pointing to your source and destination, you might want to use a regular <code class="sourceCode nasm"><span class="kw">mov</span></code>. Whenever you want to move more than a few bytes, though, <code class="sourceCode nasm"><span class="kw">movs</span></code> — or better yet <code class="sourceCode nasm">rep <span class="kw">movs</span></code> — is the ticket.</p>
<p>Let’s look at the archetypal application for <code class="sourceCode nasm"><span class="kw">movs</span></code>, a subroutine which copies a block of memory from one memory area to another. What’s special about the subroutine we’ll look at is that it handles copying a block when the destination of the copy overlaps the source. This is a bit tricky because the direction in which the copy must proceed — from the start of the block toward the end, or vice-versa — depends on the direction of overlap.</p>
<p>If the destination block overlaps the source block and starts at a lower memory address than the source block, then the copy can proceed in the normal direction, from lower to higher addresses, as shown in Figure 11.2.</p>
<figure>
<img src="images/fig11.2RT.png" />
</figure>
<p>If the destination block overlaps the source block and starts at a <em>higher</em> address, however, the block must be copied starting at its highest address and proceeding toward the low end, as shown in Figure 11.3.</p>
<figure>
<img src="images/fig11.3RT.png" />
</figure>
<p>Otherwise, the first data copied to the destination block would wipe out source data that had yet to be copied, resulting in a corrupted copy, as shown in Figure 11.4.</p>
<figure>
<img src="images/fig11.4aRT.png" />
</figure>
<figure>
<img src="images/fig11.4bRT.png" />
</figure>
<p>Finally, if the blocks don’t overlap, the copy can proceed in either direction, since the two blocks can’t conflict.</p>
<p>The block-copy subroutine <code class="sourceCode nasm">BlockCopyWithOverlap</code> shown in <a href="#listing-11-7">Listing 11-7</a> handles potential overlap problems exactly as described above. In cases where the destination block starts at a higher address than the source block, <code class="sourceCode nasm">BlockCopyWithOverlap</code> performs an <code class="sourceCode nasm"><span class="kw">std</span></code> and uses <code class="sourceCode nasm"><span class="kw">movs</span></code> to copy the source block starting at the high end and proceeding to the low end. Otherwise, the source block is copied from the low end to the high end with <code class="sourceCode nasm"><span class="kw">cld</span></code>/<code class="sourceCode nasm"><span class="kw">movs</span></code>. <code class="sourceCode nasm">BlockCopyWithOverlap</code> is both remarkably compact and very fast, clocking in at 5.57 ms for the cases tested in <a href="#listing-11-7">Listing 11-7</a>. The subroutine could actually be more compact still, but I’ve chosen to improve performance at the expense of a few bytes by copying as much of the block as possible a word rather than a byte at a time.</p>
<p>There are two points of particular interest in <a href="#listing-11-7">Listing 11-7</a>. First, <code class="sourceCode nasm">BlockCopyWithOverlap</code> only handles blocks that reside in the same segment, and then only if neither block wraps around the end of the segment. While it would certainly be possible to write a version of the subroutine that properly handled both potentially overlapping copies between different segments and segment wrapping, neither of those features is usually necessary, and the additional code would reduce overall performance. If you need such a routine, write it, but as a general practice don’t write extra, slower code just to handle cases that you can readily avoid.</p>
<p>Second, <code class="sourceCode nasm">BlockCopyWithOverlap</code> nicely illustrates a nasty aspect of the use of word-sized string instructions when the Direction flag is set to 1. The basic problem is this: if you point to the last byte of a block of memory and perform a word-sized operation, the byte <em>after</em> the end of the memory block will be accessed along with the last byte of the block, rather than the last <em>two</em> bytes of the block, as shown in Figure 11.5.</p>
<figure>
<img src="images/fig11.5RT.png" />
</figure>
<p>This problem of accessing the byte after the end of a memory block can occur with all word-sized instructions, not just string instructions. However, it’s especially liable to happen with a word-sized string instruction that’s moving its pointer or pointers backward (with the Direction flag equal to 1) because the temptation is to point to the end of the block, set the Direction flag, and let the string instruction do its stuff in repeated word-sized chunks for maximum performance. To avoid this problem, you must always be sure to point to the last <em>word</em> rather than byte when you point to the last element in a memory block and then access memory with a word-sized instruction.</p>
<p>Matters get even more dicey when byte-and word-sized string instructions are mixed when the Direction flag is set to 1. This is done in <a href="#listing-11-7">Listing 11-7</a> in order to use <code class="sourceCode nasm">rep <span class="kw">movsw</span></code> to move the largest possible portion of odd-length memory blocks. The problem here is that when a string instruction moves its pointer or pointers from high addresses to low, the address of the next byte that we want to access (with <code class="sourceCode nasm"><span class="kw">lodsb</span></code>, for example) and the address of the next word that we want to access (with <code class="sourceCode nasm"><span class="kw">lodsw</span></code>, for example) differ, as shown in Figure 11.6.</p>
<figure>
<img src="images/fig11.6RT.png" />
</figure>
<p>For a byte-sized string instruction such as <code class="sourceCode nasm"><span class="kw">lodsb</span></code>, we <em>do</em> want to point to the end of the array. After that <code class="sourceCode nasm"><span class="kw">lodsb</span></code> has executed with the Direction flag equal to 1, though, where do the pointers point? To the address 1 byte — not 1 word — lower in memory. Then what happens when <code class="sourceCode nasm"><span class="kw">lodsw</span></code> is executed as the next instruction, with the intent of accessing the word just above the last byte of the array? Why, the last byte of the array is incorrectly accessed again, as shown in Figure 11.7.</p>
<figure>
<img src="images/fig11.7aRT.png" />
</figure>
<figure>
<img src="images/fig11.7bRT.png" />
</figure>
<p>The solution, as shown in <a href="#listing-11-7">Listing 11-7</a>, is fairly simple. We must perform the initial <code class="sourceCode nasm"><span class="kw">movsb</span></code> and then adjust the pointers to point 1 byte lower in memory — to the start of the next <em>word</em>. Only then can we go ahead with a <code class="sourceCode nasm"><span class="kw">movsw</span></code>, as shown in Figure 11.8.</p>
<figure>
<img src="images/fig11.8aRT.png" />
</figure>
<figure>
<img src="images/fig11.8bRT.png" />
</figure>
<p>Mind you, all this <em>only</em> applies when the Direction Flag is 1. When the Direction flag is 0, <code class="sourceCode nasm"><span class="kw">movsb</span></code> and <code class="sourceCode nasm"><span class="kw">movsw</span></code> can be mixed freely, since the address of the next byte is the same as the address of the next word when we’re counting from low addresses to high, as shown in Figure 11.9.</p>
<figure>
<img src="images/fig11.9RT.png" />
</figure>
<p><a href="#listing-11-7">Listing 11-7</a> reflects this, since the pointer adjustments are only made when the Direction flag is 1.</p>
<p><a href="#listing-11-8">Listing 11-8</a> contains a version of <code class="sourceCode nasm">BlockCopyWithOverlap</code> that does exactly what the version in <a href="#listing-11-7">Listing 11-7</a> does, but does so without string instructions. While <a href="#listing-11-8">Listing 11-8</a> doesn’t <em>look</em> all that much different from <a href="#listing-11-7">Listing 11-7</a>, it takes a full 15.16 ms to run -quite change from the time of 5.57 ms we measured for <a href="#listing-11-7">Listing 11-7</a>. Think about it: <a href="#listing-11-7">Listing 11-7</a> is nearly <em>three times</em> as fast as <a href="#listing-11-8">Listing 11-8</a>, thanks to <code class="sourceCode nasm"><span class="kw">movs</span></code> — and it’s shorter too.</p>
<p>Enough said.</p>
</section>
<section id="searching-with-scas" class="level2">
<h2>Searching With <code>scas</code></h2>
<p><code class="sourceCode nasm"><span class="kw">scas</span></code> is often (but not always, as we shall see) the preferred way to search for either a given value or the absence of a given value in any array. When <code class="sourceCode nasm"><span class="kw">scas</span></code> is well-matched to the task at hand, it is the best choice by a wide margin. For example, suppose that we want to count the number of times the letter ‘A’ appears in a text array. <a href="#listing-11-9">Listing 11-9</a>, which uses non-string instructions, counts the number of occurrences of ‘A’ in the sample array in 475 us. <a href="#listing-11-10">Listing 11-10</a>, which does exactly the same thing with <code class="sourceCode nasm">repnz <span class="kw">scasb</span></code>, finishes in just 203 us. That, my friends, is an improvement of 134%. What’s more, <a href="#listing-11-10">Listing 11-10</a> is shorter than <a href="#listing-11-9">Listing 11-9</a>.</p>
<p>Incidentally, <a href="#listing-11-10">Listing 11-10</a> illustrates the subtlety of the pitfalls associated with forgetting that <code class="sourceCode nasm"><span class="kw">scas</span></code> repeated zero times (with CX equal to zero) doesn’t alter the flags. If the <code class="sourceCode nasm"><span class="kw">jcxz</span></code> instruction in <a href="#listing-11-10">Listing 11-10</a> were to be removed, the code would still work perfectly — except when the array being scanned was exactly 64 K bytes long and <em>every</em> byte in the array matched the byte being searched for. In that one case, CX would be zero when <code class="sourceCode nasm">repnz <span class="kw">scasb</span></code> was restarted after the last match, causing <code class="sourceCode nasm">repnz <span class="kw">scasb</span></code> to drop through without altering the flags. The Zero flag would be 0 as a result of DX previously incrementing from 0FFFFh to 0, and so the <code class="sourceCode nasm"><span class="kw">jnz</span></code> branch would not be taken. Instead, DX would be incremented again, causing a non-existent match to be counted. The result would be that 1 rather than 64 K matches would be returned as the match count, an error of considerable magnitude.</p>
<p>If you could be sure that no array longer than 64 K-1 bytes would ever be passed to <code class="sourceCode nasm">ByteCount</code>, you <em>could</em> eliminate the <code class="sourceCode nasm"><span class="kw">jcxz</span></code> and speed the code considerably. Trimming the fat from your code until it’s matched exactly to an application’s needs is one key to performance.</p>
<section id="scas-and-zero-terminated-strings" class="level3">
<h3><code>scas</code> and Zero-Terminated Strings</h3>
<p>Clearly, then, when you want to find a given byte or word value in a buffer, table, or array of a known fixed length, it’s often best to load up the registers and let a repeated <code class="sourceCode nasm"><span class="kw">scas</span></code> do its stuff. However, the same is not always true of searching tasks that require multiple comparisons for each byte or word, such as a loop that ends when either the letter ‘A’ <em>or</em> a zero byte is found. Alas, <code class="sourceCode nasm"><span class="kw">scas</span></code> can perform just one comparison per memory location, and <code class="sourceCode nasm">repz</code> or <code class="sourceCode nasm">repnz</code> can only terminate on the basis of the Zero flag setting after that one comparison. This is unfortunate because multiple comparisons are exactly what we need to handle C-style strings, which are of no fixed length and are terminated with zeros. <code class="sourceCode nasm">rep <span class="kw">scas</span></code> can still be used in such situations, but its sheer power is diluted by the workarounds needed to allow it to function more flexibly than it is normally capable of doing. The choice between repeated <code class="sourceCode nasm"><span class="kw">scas</span></code> instructions and other approaches then must be made on a case-by-by case basis, according to the balance between the extra overhead needed to coax <code class="sourceCode nasm"><span class="kw">scas</span></code> into doing what is needed and the inherent speed of the instruction.</p>
<p>For example, suppose we need a subroutine that returns either the offset in a string of the first instance of a selected byte value or the value zero if a zero byte (marking the end of the string) is encountered before the desired byte is found. There’s no simple way to do this with <code class="sourceCode nasm"><span class="kw">scasb</span></code>, for in this application we have to compare each memory location first to the desired byte value and then to zero. <code class="sourceCode nasm"><span class="kw">scasb</span></code> can perform one comparison or the other, but not both.</p>
<p>Now, we <em>could</em> use <code class="sourceCode nasm">rep <span class="kw">scasb</span></code> to find the zero byte at the end of the string, so we’d know how long the string was, and then use <code class="sourceCode nasm">rep <span class="kw">scasb</span></code> again with CX set to the length of the string to search for the selected byte value. Unfortunately, that involves processing <em>every</em> byte in the string once before even beginning the search. On average, this double-search approach would read every element of the string being searched once and would then read one-half of the elements again, as shown in Figure 11.10. By contrast, an approach that reads each byte and immediately compares it to both the desired value <em>and</em> zero would read only one-half of the elements in the string, as shown in Figure 11.11. Powerful as repeated <code class="sourceCode nasm"><span class="kw">scasb</span></code> is, could it</p>
<figure>
<img src="images/fig11.10aRT.png" />
</figure>
<figure>
<img src="images/fig11.10bRT.png" />
</figure>
<p>possibly run fast enough to allow the double-search approach to outperform an approach that accesses memory only one-third as many times?</p>
<p>The answer is yes… conditionally. The double-search approach actually <em>is</em> slightly faster than a <code class="sourceCode nasm"><span class="kw">lodsb</span></code>-based single-search string-searching approach for the average case. The double-search approach performs relatively more poorly if matches tend to occur most frequently in the first half of the strings being searched, and relatively better if matches tend to occur in the second half of the strings. Also, the more flexible <code class="sourceCode nasm"><span class="kw">lodsb</span></code>-based approach rapidly becomes the solution of choice as the termination condition becomes more complex, as when a case-insensitive search is desired. The same is true when modification as well as searching of the string is desired, as when the string is converted to uppercase.</p>
<p><a href="#listing-11-11">Listing 11-11</a> shows <code class="sourceCode nasm"><span class="kw">lodsb</span></code>-based code that searches a zero-terminated string for the character ‘z’. For the sample string, which has the first match right in the middle of the string, <a href="#listing-11-11">Listing 11-11</a> takes 375 us to find the match. <a href="#listing-11-12">Listing 11-12</a> shows <code class="sourceCode nasm">repnz <span class="kw">scasb</span></code>-based code that uses the double-search approach. For the same sample string as <a href="#listing-11-11">Listing 11-11</a>, <a href="#listing-11-12">Listing 11-12</a> takes just 340 us to find the match, despite having to perform about three times as many memory accesses as <a href="#listing-11-11">Listing 11-11</a> — a tribute to the raw</p>
<figure>
<img src="images/fig11.11RT.png" />
</figure>
<p>power of repeated <code class="sourceCode nasm"><span class="kw">scas</span></code>. Finally, <a href="#listing-11-13">Listing 11-13</a>, which performs the same search using non-string instructions, takes 419 us to find the match.</p>
<p>It is apparent from <a href="#listing-11-11">Listings 11-11</a> and <a href="#listing-11-12">11-12</a> that the performance margin between <code class="sourceCode nasm"><span class="kw">scas</span></code>-based string searching and other approaches is considerably narrower than it was for array searching, due to the more complex termination conditions. Given a still more complex termination condition, <code class="sourceCode nasm"><span class="kw">lods</span></code> would likely become the preferred solution due to its greater flexibility. In fact, if we’re willing to expend a few bytes, the greater flexibility of <code class="sourceCode nasm"><span class="kw">lods</span></code> can be translated into higher performance for <a href="#listing-11-11">Listings 11-11</a>, as follows.</p>
<p><a href="#listing-11-14">Listing 11-14</a> shows an interesting variation on <a href="#listing-11-11">Listings 11-11</a>. Here <code class="sourceCode nasm"><span class="kw">lodsw</span></code> rather than <code class="sourceCode nasm"><span class="kw">lodsb</span></code> is used, and AL and AH, respectively, are checked for the termination conditions. This technique uses a bit more code, but the replacement of two <code class="sourceCode nasm"><span class="kw">lodsb</span></code> instructions with a single <code class="sourceCode nasm"><span class="kw">lodsw</span></code> and the elimination of every other branch pays off handsomely, as <a href="#listing-11-14">Listing 11-14</a> runs in just 325 us, 15% faster than <a href="#listing-11-11">Listings 11-11</a> and 5% faster than <a href="#listing-11-12">Listing 11-12</a>. The key here is that <code class="sourceCode nasm"><span class="kw">lods</span></code> allows us leeway in designing code to work around the slow memory access and slow branching of the 8088, while <code class="sourceCode nasm"><span class="kw">scas</span></code> does not. In truth, the flexibility of <code class="sourceCode nasm"><span class="kw">lods</span></code> can make for better performance still through in-line code… but that’s a story for the next few chapters.</p>
</section>
<section id="more-on-scas-and-zero-terminated-strings" class="level3">
<h3>More on <code>scas</code> and Zero-Terminated Strings</h3>
<p>While repeated <code class="sourceCode nasm"><span class="kw">scas</span></code> instructions aren’t ideally suited to string searches involving complex conditions, they <em>do</em> work nicely with strings whenever brute force scanning comes into play. One such application is finding the offset of the <em>last</em> element of some sort in a string. For example, <a href="#listing-11-15">Listing 11-15</a>, which finds the last non-blank element of a string by using <code class="sourceCode nasm"><span class="kw">lodsw</span></code> and remembering the offset of the most recent non-blank character encountered, takes 907 us to find the last non-blank character of the sample string, which has the last non-blank character in the middle of the string. <a href="#listing-11-16">Listing 11-16</a>, which does the same thing by using <code class="sourceCode nasm">repnz <span class="kw">scasb</span></code> to find the end of the string and then <code class="sourceCode nasm">repz <span class="kw">scasw</span></code> with the Direction flag set to 1 to find the first non-blank character scanning backward from the end of the string, runs in just 386 us.</p>
<p>That’s an <em>amazing</em> improvement given our earlier results involving the relative speeds of <code class="sourceCode nasm"><span class="kw">lodsw</span></code> and repeated <code class="sourceCode nasm"><span class="kw">scas</span></code> in string applications. The reason that repeated <code class="sourceCode nasm"><span class="kw">scas</span></code> outperforms <code class="sourceCode nasm"><span class="kw">lodsw</span></code> by a tremendous amount in this case but underperformed it earlier is simple. The <code class="sourceCode nasm"><span class="kw">lodsw</span></code>-based code always has to check every character in the string — right up to the terminating zero — when searching for the last non-blank character, as shown in Figure 11.12.</p>
<p>While the <code class="sourceCode nasm"><span class="kw">scasb</span></code>-base code also has to access every character in the string, and then some, as shown in Figure 11.13, the worst case is that</p>
<figure>
<img src="images/fig11.12RT.png" />
</figure>
<p><a href="#listing-11-16">Listing 11-16</a> accesses string elements no more than twice as many times as <a href="#listing-11-15">Listing 11-15</a>. In our earlier example, the <em>best</em> case was a two-to-one ratio. The timing results for <a href="#listing-11-15">Listings 11-15</a> and <a href="#listing-11-16">11-16</a> show that the superior speed, lack of prefetching, and lack of branching associated with repeated <code class="sourceCode nasm"><span class="kw">scas</span></code> far outweigh any performance loss resulting from a memory-access ratio of less than two-to-one.</p>
<p>By the way, <a href="#listing-11-16">Listing 11-16</a> is an excellent example of the need to correct for pointer overrun when using the string instructions. No matter which direction we scan in, it’s necessary to undo the last advance of DI performed by <code class="sourceCode nasm"><span class="kw">scas</span></code> in order to point to the byte on which the comparison ended.</p>
<figure>
<img src="images/fig11.13aRT.png" />
</figure>
<figure>
<img src="images/fig11.13bRT.png" />
</figure>
<p><a href="#listing-11-16">Listing 11-16</a> also shows the use of <code class="sourceCode nasm"><span class="kw">jcxz</span></code> to guard against the case where CX is zero. As you’ll recall from the last chapter, repeated <code class="sourceCode nasm"><span class="kw">scas</span></code> doesn’t alter the flags when started with CX equal to zero. Consequently, we must test for the case of CX equal to zero before performing <code class="sourceCode nasm">repz <span class="kw">scasw</span></code>, and we must treat that case if we had never found the terminating condition (a non-blank character). Otherwise, the leftover flags from an earlier instruction might give us a false result following a <code class="sourceCode nasm">repz <span class="kw">scasw</span></code> which doesn’t change the flags because it is repeated zero times. In <a href="#listing-11-21">Listing 11-21</a> we’ll see that we need to do the same with repeated <code class="sourceCode nasm"><span class="kw">cmps</span></code> as well.</p>
<p>Bear in mind, however, that there are several ways to solve any problem in assembler. For example, in <a href="#listing-11-16">Listing 11-16</a> I’ve chosen to use <code class="sourceCode nasm"><span class="kw">jcxz</span></code> to guard against the case where CX is zero, thereby compensating for the fact that <code class="sourceCode nasm"><span class="kw">scas</span></code> repeated zero times doesn’t change the flags. Rather than thinking defensively, however, we could actually take advantage of that particular property of repeated <code class="sourceCode nasm"><span class="kw">scas</span></code>. How? We could set the Zero flag to 1 (the “match” state) by placing <code class="sourceCode nasm"><span class="kw">sub</span> <span class="kw">dx</span>,<span class="kw">dx</span></code> before <code class="sourceCode nasm">repz <span class="kw">scasw</span></code>. Then if <code class="sourceCode nasm">repz <span class="kw">scasw</span></code> is repeated zero times because CX is zero the following conditional jump will reach the proper conclusion, that the desired non-match (a non-blank character) wasn’t found.</p>
<p>As it happens, <code class="sourceCode nasm"><span class="kw">sub</span> <span class="kw">dx</span>,<span class="kw">dx</span></code> isn’t particularly faster than <code class="sourceCode nasm"><span class="kw">jcxz</span></code>, and so there’s not much to choose from between the two solutions. With <code class="sourceCode nasm"><span class="kw">sub</span> <span class="kw">dx</span>,<span class="kw">dx</span></code> the code is 3 cycles faster when CX isn’t zero but is the same number of bytes in length, and is considerably slower when CX is zero. (There’s really no reason to worry about performance here when CX is zero, however, since that’s a rare case that’s always handled relatively quickly. Rather, our focus should be on losing as little performance as possible to the test for CX being zero in the more common case — when CX <em>isn’t</em> zero.) In another application, though, the desired Zero flag setting might fall out of the code preceding the repeated <code class="sourceCode nasm"><span class="kw">cmps</span></code>, and no extra code at all would be required for the test for CX equal to zero. <a href="#listing-11-24">Listing 11-24</a>, which we’ll come to shortly, is such a case.</p>
<p>What’s interesting here is that it’s instinctive to use <code class="sourceCode nasm"><span class="kw">jcxz</span></code>, which is after all a specialized and fast instruction that is clearly present in the 8088’s instruction set for just such a purpose as protecting against repeating a string comparison zero times. The idea of presetting a flag and letting the comparison drop through without changing the flag, on the other hand, is anything but intuitive — but is just about as effective as <code class="sourceCode nasm"><span class="kw">jcxz</span></code>, more so under certain circumstances.</p>
<p>Don’t let your mind be constrained by intentions of the designers of the 8088. Think in terms of what instructions <em>do</em> rather than what they were <em>intended</em> to do.</p>
</section>
<section id="using-repeated-scasw-on-byte-sized-data" class="level3">
<h3>Using Repeated <code>scasw</code> on Byte-Sized Data</h3>
<p><a href="#listing-11-16">Listing 11-16</a> is also a fine example of how to use repeated <code class="sourceCode nasm"><span class="kw">scasw</span></code> on byte-sized data. You’ll recall that one of the rules of repeated string instruction usage is that word-sized string instructions should be used wherever possible, due to their faster overall speed. It turns out, however, that it’s rather tricky to apply this rule to <code class="sourceCode nasm"><span class="kw">scas</span></code>.</p>
<p>For starters, there’s hardly ever any use for <code class="sourceCode nasm">repnz <span class="kw">scasw</span></code> when searching for a specific byte value in memory. Why? Well, while we could load up both AH and AL with the byte we’re looking for and then use <code class="sourceCode nasm">repnz <span class="kw">scasw</span></code>, we’d only find cases where the desired byte occurs at least twice in a row, and then we’d only find such 2-byte cases that didn’t span word boundaries. Unfortunately, there’s no way to use <code class="sourceCode nasm">repnz <span class="kw">scasw</span></code> to check whether either AH or AL — but not necessarily both — matched their respective bytes. With <code class="sourceCode nasm">repnz <span class="kw">scasw</span></code>, if AX doesn’t match all 16 bits of memory, the search will continue, and individual byte matches will be missed.</p>
<p>On the other hand, we <em>can</em> use <code class="sourceCode nasm">repz <span class="kw">scasw</span></code> to search for the first <em>non-match</em>, as in <a href="#listing-11-16">Listing 11-16</a>. Why is it all right to search a word at a time for non-matches but not matches? Because if <em>either</em> byte of each word compared with <code class="sourceCode nasm">repz <span class="kw">scasw</span></code> doesn’t match the byte of interest (which is stored in both AH and AL), then <code class="sourceCode nasm">repz <span class="kw">scasw</span></code> will stop, which is what we want. Of course, there’s a bit of cleaning up to do in order to figure out which of the 2 bytes was the first non-match, as illustrated by <a href="#listing-11-16">Listing 11-16</a>. Yes, it is a bit complex and does add a few bytes, but it also speeds things up, and that’s what we’re after.</p>
<p>In short, <code class="sourceCode nasm">repz <span class="kw">scasw</span></code> can be used to boost performance when scanning for non-matching byte-sized data. However, <code class="sourceCode nasm">repnz <span class="kw">scasw</span></code> is generally useless when scanning for matching byte-sized data.</p>
</section>
<section id="scas-and-look-up-tables" class="level3">
<h3><code>scas</code> and Look-Up Tables</h3>
<p>One common application for table searching is to get an element number or an offset into a table that can be used to look up related data or a jump address in another table. We saw look-up tables in Chapter 7, and we’ll see them again, for they’re a potent performance tool.</p>
<p><code class="sourceCode nasm"><span class="kw">scas</span></code> is often excellent for look-up code, but the pointer and counter overrun characteristic of all string instructions make it a bit of a nuisance to calculate offsets and/or element numbers after repeated <code class="sourceCode nasm"><span class="kw">scas</span></code> instructions. <a href="#listing-11-17">Listing 11-17</a> shows a subroutine that calculates the offset of a match in a word-sized table in the process of jumping to the associated routine from a jump table. Notice that it’s necessary to subtract the 2-byte overrun from the difference between the final value of DI and the start of the table. The calculation would be the same for a byte-sized table scanned with <code class="sourceCode nasm"><span class="kw">scasb</span></code>, save that <code class="sourceCode nasm"><span class="kw">scasb</span></code> has only a 1-byte overrun and so only 1 would be subtracted from the difference between DI and the start of the table.</p>
<p>Finding the element number is a slightly different matter. After a repeated <code class="sourceCode nasm"><span class="kw">scas</span></code>, CX contains the number of elements that weren’t scanned. Since CX counts down just once each time <code class="sourceCode nasm"><span class="kw">scas</span></code> is repeated, there’s no difference between <code class="sourceCode nasm"><span class="kw">scasw</span></code> and <code class="sourceCode nasm"><span class="kw">scasb</span></code> in this respect.</p>
<p>Well, if CX contains the number of elements that weren’t scanned, then subtracting CX from the table length in elements must yield the number of elements that <em>were</em> scanned. Subtracting 1 from that value gives us the number of the last element scanned. (The first element is element number 0, the second element is element number 1, and so on.) <a href="#listing-11-18">Listing 11-18</a> illustrates the calculation of the element number found in a look-up table as a step in the process of jumping to the associated routine from a jump table, much as in <a href="#listing-11-17">Listing 11-17</a>.</p>
</section>
<section id="consider-your-options" class="level3">
<h3>Consider Your Options</h3>
<p>Don’t assume that <code class="sourceCode nasm"><span class="kw">scas</span></code> is the ideal choice even for all memory-searching tasks in which the search length is known. Suppose that we simply want to know if a given character is any of, say, four characters: ‘A’, ‘Z’, ‘3’, or ‘!’. We could do this with <code class="sourceCode nasm">repnz <span class="kw">scasb</span></code>, as shown in <a href="#listing-11-19">Listing 11-19</a>. Alternatively, however, we could simply do it with four comparisons and conditional jumps, as shown in <a href="#listing-11-20">Listing 11-20</a>. Even with the prefetch queue cycle-eater doing its worst, each compare and conditional jump pair takes no more than 16 cycles when the jump isn’t taken (the jump is taken at most once, on a match), which stacks up pretty well against the 15 cycle per comparison and 9 cycle set-up time of <code class="sourceCode nasm">repnz <span class="kw">scasb</span></code>. What’s more, the compare-and-jump approach requires no set-up instructions. In other words, the less sophisticated approach might well be better in this case.</p>
<p>The Zen timer bears this out. <a href="#listing-11-19">Listing 11-19</a>, which uses <code class="sourceCode nasm">repnz <span class="kw">scasb</span></code>, takes 183 us to perform five checks, while <a href="#listing-11-20">Listing 11-20</a>, which uses the compare-and-jump approach, takes just 119 us to perform the same five checks. <a href="#listing-11-20">Listing 11-20</a> is not only 54% faster than <a href="#listing-11-19">Listing 11-19</a> but is also 1 byte shorter. (Don’t forget to count the look-up table bytes in <a href="#listing-11-19">Listing 11-19</a>.)</p>
<p>Of course, the compare-and-jump approach is less flexible than the look-up approach, since the table length and contents can’t be passed as parameters or changed as the program runs. The compare-and-jump approach also becomes unwieldy when more entries need to be checked, since 4 bytes are needed for each additional compare-and-jump entry where the <code class="sourceCode nasm">repnz <span class="kw">scasb</span></code> approach needs just 1. The compare-and-jump approach finally falls apart when it’s no longer possible to short-jump out of the comparison/jump code and so jumps around jumps must be used, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">cmp</span>   <span class="kw">al</span>,<span class="st">&#39;Z&#39;</span>
<span class="kw">jnz</span>   <span class="dv">$</span>+<span class="dv">5</span>
<span class="kw">jmp</span>   CharacterFound
<span class="kw">cmp</span>   <span class="kw">al</span>,<span class="st">&#39;3&#39;</span></code></pre>
<p>When jumps around jumps are used, the comparison time per character goes from 16 to 24 cycles, and <code class="sourceCode nasm">rep <span class="kw">scasb</span></code> emerges as the clear favorite.</p>
<p>Nonetheless, <a href="#listing-11-19">Listings 11-19</a> and <a href="#listing-11-20">11-20</a> illustrate two important points. Point number 1: the repeated string instructions tend to have a greater advantage when they’re repeated many times, allowing their speed and compact size to offset the overhead in set-up time and code they require. Point number 2: specialized as the string instructions are, there are ways to program the 8088 that are more specialized still. In certain cases, those specialized approaches can even outperform the string instructions. Sure, the specialized approaches, such as the compare-and-jump approach we just saw, are limited and inflexible — but when you don’t need the flexibility, why pay for it in lost performance?</p>
</section>
</section>
<section id="comparing-memory-to-memory-with-cmps" class="level2">
<h2>Comparing Memory to Memory With <code>cmps</code></h2>
<p>When <code class="sourceCode nasm"><span class="kw">cmps</span></code> does exactly what you need done it can’t be beat, although to an even greater extent than with <code class="sourceCode nasm"><span class="kw">scas</span></code> the cases in which that is true are relatively few. <code class="sourceCode nasm"><span class="kw">cmps</span></code> is used for applications in which byte-for-byte or word-for-word comparisons between two memory blocks of a known length are performed, most notably array comparisons and substring searching. Like <code class="sourceCode nasm"><span class="kw">scas</span></code>, <code class="sourceCode nasm"><span class="kw">cmps</span></code> is not flexible enough to work at full power on other comparison tasks, such as case-insensitive substring searching or the comparison of zero-terminated strings, although with a bit of thought <code class="sourceCode nasm"><span class="kw">cmps</span></code> can be made to serve adequately in some such applications.</p>
<p><code class="sourceCode nasm"><span class="kw">cmps</span></code> does just one thing, but it does far better than any other 8088 instruction or combination of instructions. The one transcendent ability of <code class="sourceCode nasm"><span class="kw">cmps</span></code> is the direct comparison of two fixed-length blocks of memory. The obvious use of <code class="sourceCode nasm"><span class="kw">cmps</span></code> is in determining whether two memory arrays or blocks of memory are the same, and if not, where they differ. <a href="#listing-11-21">Listing 11-21</a>, which runs in 685 us, illustrates <code class="sourceCode nasm">repz <span class="kw">cmpsw</span></code> in action. <a href="#listing-11-22">Listing 11-22</a>, which performs exactly the same task as <a href="#listing-11-21">Listing 11-21</a> but uses <code class="sourceCode nasm"><span class="kw">lodsw</span></code> and <code class="sourceCode nasm"><span class="kw">scasw</span></code> instead of <code class="sourceCode nasm"><span class="kw">cmpsw</span></code>, runs in 1298 us. Finally, <a href="#listing-11-23">Listing 11-23</a>, which uses non-string instructions, takes a leisurely 1798 us to complete the task. As you can see, <code class="sourceCode nasm"><span class="kw">cmps</span></code> blows away not only non-string instructions but also other string instructions under the right circumstances. (As I’ve said before, there are many, many different sequences of assembler code that will work for any given task. It’s the choice of implementation that makes the difference between adequate code and great code.)</p>
<p>By the way, in <a href="#listing-11-21">Listings 11-21</a> though <a href="#listing-11-23">11-23</a> I’ve used <code class="sourceCode nasm"><span class="kw">jcxz</span></code> to make sure the correct result is returned if zero-length arrays are compared. If you use this routine in your code and you can be sure that zero-length arrays will never be passed as parameters, however, you can save a few bytes and cycles by eliminating the <code class="sourceCode nasm"><span class="kw">jcxz</span></code> check. After all, what sense does it make to compare zero-length arrays… and what sense does it make to waste precious bytes and cycles guarding against a contingency that can never arise?</p>
<p>Make the comparison a bit more complex, however, and <code class="sourceCode nasm"><span class="kw">cmps</span></code> comes back to the pack. Consider the comparison of two zero-terminated strings, rather than two fixed-length arrays. As with <code class="sourceCode nasm"><span class="kw">scas</span></code> in the last section, <code class="sourceCode nasm"><span class="kw">cmps</span></code> can be made to work in this application by first performing a <code class="sourceCode nasm"><span class="kw">scasb</span></code> pass to determine one string length and then comparing the strings with <code class="sourceCode nasm"><span class="kw">cmpsw</span></code>, but the double pass negates much of the superior performance of <code class="sourceCode nasm"><span class="kw">cmps</span></code>. <a href="#listing-11-24">Listing 11-24</a> shows an implementation of this approach, which runs in 364 us for the test strings.</p>
<p>We found earlier that <code class="sourceCode nasm"><span class="kw">lods</span></code> works well for string searching when multiple termination conditions must be dealt with. That is true of string comparison as well, particularly since there we can benefit from the combination of <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">lods</span></code>. The <code class="sourceCode nasm"><span class="kw">lodsw</span></code>/<code class="sourceCode nasm"><span class="kw">scasw</span></code> approach, shown in <a href="#listing-11-25">Listing 11-25</a>, runs in just 306 us — 19% faster than the <code class="sourceCode nasm">rep <span class="kw">scasb</span></code>/<code class="sourceCode nasm">repz <span class="kw">cmpsw</span></code>-based <a href="#listing-11-24">Listing 11-24</a>. For once, I won’t bother with a non-string instruction-based implementation, since it’s perfectly obvious that replacing <code class="sourceCode nasm"><span class="kw">lodsw</span></code> and <code class="sourceCode nasm"><span class="kw">scasw</span></code> with non-string sequences such as:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">ax</span>,[<span class="kw">si</span>]
<span class="kw">inc</span>   <span class="kw">si</span>
<span class="kw">inc</span>   <span class="kw">si</span></code></pre>
<p>and:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">cmp</span>   [<span class="kw">di</span>],<span class="kw">ax</span>
      :
<span class="kw">inc</span>   <span class="kw">di</span>
<span class="kw">inc</span>   <span class="kw">di</span></code></pre>
<p>can only reduce performance.</p>
<p><code class="sourceCode nasm"><span class="kw">cmps</span></code> and even <code class="sourceCode nasm"><span class="kw">scas</span></code> become still less suitable if a highly complex operation such as case-insensitive string comparison is required. Since both source and destination must be converted to the same case before being compared, both must be loaded into the registers for manipulation, and only <code class="sourceCode nasm"><span class="kw">lods</span></code> among the string instructions will do us any good at all. <a href="#listing-11-26">Listing 11-26</a> shows code that performs case-insensitive string comparison. <a href="#listing-11-26">Listing 11-26</a> takes 869 us to run, which is not very fast by comparison with <a href="#listing-11-21">Listings 11-21</a> through <a href="#listing-11-25">11-25</a>. That’s to be expected, though, given the flexibility required for this comparison. The more flexibility required for a given task, the less likely we are to be able to bring the full power of the highly-specialized string instructions to bear on that task. That doesn’t mean that we shouldn’t try to do so, just that we won’t always succeed.</p>
<p>If we’re willing to expend 200 extra bytes or so, we can speed <a href="#listing-11-26">Listing 11-26</a> up considerably with a clever trick. Making sure a character is uppercase takes a considerable amount of time even when all calculations are done in the registers, as is the case in <a href="#listing-11-26">Listing 11-26</a>. Fast as the instructions in the macro <code class="sourceCode nasm">TO_UPPER</code> in <a href="#listing-11-26">Listing 11-26</a> are, two to five of them are executed every time a byte is made uppercase, and a time-consuming conditional jump may also be performed.</p>
<p>So what’s better than two to five register-only instructions with at most one jump? A look-up table, that’s what. <a href="#listing-11-27">Listing 11-27</a> is a modification of <a href="#listing-11-26">Listing 11-26</a> that looks up the uppercase version of each character in <code class="sourceCode nasm">ToUpperTable</code> with a single instruction — and the extremely fast and compact <code class="sourceCode nasm"><span class="kw">xlat</span></code> instruction, at that. (It’s possible that <code class="sourceCode nasm"><span class="kw">mov</span></code> could be used instead of <code class="sourceCode nasm"><span class="kw">xlat</span></code> to make an even faster version of <a href="#listing-11-27">Listing 11-27</a>, since <code class="sourceCode nasm"><span class="kw">mov</span></code> can reference any general-purpose register while <code class="sourceCode nasm"><span class="kw">xlat</span></code> can only load AL. As I’ve said, there are many ways to do anything in assembler.) For most characters there is no uppercase version, and the same character that we started with is looked up in <code class="sourceCode nasm">ToUpperTable</code>. For the 26 lowercase characters, however, the character looked up is the uppercase equivalent.</p>
<p>You may well be thinking that it doesn’t make much sense to try to speed up code by <em>adding</em> a memory access, and normally you’d be right. However, <code class="sourceCode nasm"><span class="kw">xlat</span></code> is very fast — it’s a 1-byte instruction that executes in 10 cycles — and it saves us the trouble of fetching the many instruction bytes of <code class="sourceCode nasm">TO_UPPER</code>. (Remember, instruction fetches are memory accesses too.) What’s more, <code class="sourceCode nasm"><span class="kw">xlat</span></code> eliminates the need for conditional jumps in the uppercase-conversion process.</p>
<p>Sounds good in theory, doesn’t it? It works just as well in the real world, too. <a href="#listing-11-27">Listing 11-27</a> runs in just 638 us, a 36% improvement over <a href="#listing-11-26">Listing 11-26</a>. Of course, <a href="#listing-11-27">Listing 11-27</a> is also a good deal larger than <a href="#listing-11-26">Listing 11-26</a>, owing to the look-up table, and that’s a dilemma the assembler programmer faces frequently on the PC: the choice between speed and size. More memory, in the form of look-up tables and in-line code, often means better performance. It’s actually relatively easy to speed up most code by throwing memory at it. The hard part is knowing where to strike the balance between performance and size.</p>
<p>Although both look-up tables and in-line code are discussed elsewhere in this volume, a broad discussion of the issue of memory versus performance will have to wait until Volume II of <em>The Zen of Assembly Language</em>. The mechanics of translating memory into performance — the knowledge aspect, if you will — is quite simple, but understanding when that tradeoff can and should be made is more complex and properly belongs in the discussion of the flexible mind.</p>
<section id="string-searching" class="level3">
<h3>String Searching</h3>
<p>Perhaps the single finest application of <code class="sourceCode nasm"><span class="kw">cmps</span></code> is in searching for a sequence of bytes within a data buffer. In particular, <code class="sourceCode nasm"><span class="kw">cmps</span></code> is excellent for finding a particular text sequence in a buffer full of text, as is the case when implementing a find-string capability in a text editor.</p>
<p>One way to implement such a searching capability is by simply starting <code class="sourceCode nasm">repz <span class="kw">cmps</span></code> at each byte of the buffer until either a match is found or the end of the buffer is reached, as shown in Figure 11.14.</p>
<figure>
<img src="images/fig11.14aRT.png" />
</figure>
<figure>
<img src="images/fig11.14bRT.png" />
</figure>
<p><a href="#listing-11-28">Listing 11-28</a>, which employs this approach, runs in 2995 us for the sample search sequence and buffer.</p>
<p>That’s not bad, but there’s a better way to go. Suppose we load the first byte of the search string into AL and use <code class="sourceCode nasm">repnz <span class="kw">scasb</span></code> to find the next candidate for the full <code class="sourceCode nasm">repz <span class="kw">cmps</span></code> comparison, as shown in Figure 11.15.</p>
<figure>
<img src="images/fig11.15aRT.png" />
</figure>
<figure>
<img src="images/fig11.15bRT.png" />
</figure>
<p>By so doing we could use a fast repeated string instruction to disqualify most of the potential strings, rather than having to loop and start up <code class="sourceCode nasm">repz <span class="kw">cmps</span></code> at each and every byte in the buffer. Would that make a difference?</p>
<p>It would indeed! <a href="#listing-11-29">Listing 11-29</a>, which uses the hybrid <code class="sourceCode nasm">repnz <span class="kw">scasb</span></code>/<code class="sourceCode nasm">repz <span class="kw">cmps</span></code> technique, runs in just 719 us for the same search sequence and buffer as <a href="#listing-11-28">Listing 11-28</a>. Now, the margin between the two techniques could vary considerably, depending on the contents of the buffer and the search sequence. Nonetheless, we’ve just seen an improvement of more than 300% over already-fast string instruction-based code! That improvement is primarily due to the use of <code class="sourceCode nasm">repnz <span class="kw">scasb</span></code> to eliminate most of the instruction fetches and branches of <a href="#listing-11-28">Listing 11-28</a>.</p>
<p>Even when you’re using string instructions, stretch your mind to think of still-better approaches…</p>
<p>As for non-string implementations, <a href="#listing-11-30">Listing 11-30</a>, which performs the same task as do <a href="#listing-11-28">Listings 11-28</a> and <a href="#listing-11-29">11-29</a> but does so with non-string instructions, takes a full 3812 us to run. It should be very clear that non-string instructions should be used in searching applications only when their greater flexibility is absolutely required.</p>
<p>Make no mistake, there’s more to searching performance than simply using the right combination of string instructions. The right choice of algorithm is critical. For a list of several thousand sorted items, a poorly-coded binary search might well beat the pants off a slick <code class="sourceCode nasm">repnz <span class="kw">scasb</span></code>/<code class="sourceCode nasm">repz <span class="kw">cmps</span></code> implementation. On the other hand, the <code class="sourceCode nasm">repnz <span class="kw">scasb</span></code>/<code class="sourceCode nasm">repz <span class="kw">cmps</span></code> approach is excellent for searching free-form data of the sort that’s found in text buffers.</p>
<p>The key to searching performance lies in choosing a good algorithm for your application <em>and</em> implementing it with the best possible code. Either the searching algorithm or the implementation may be the factor that limits performance. Ideally, a searching algorithm would be chosen with an eye toward using the strengths of the 8088 — and that usually means the string instructions.</p>
</section>
<section id="cmps-without-rep" class="level3">
<h3><code>cmps</code> Without <code>rep</code></h3>
<p>In the last chapter I pointed out that <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code> are slower but more flexible when they’re not repeated. Although <code class="sourceCode nasm">repz</code> and <code class="sourceCode nasm">repnz</code> only allow termination according to the state of the Zero flag, <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code> actually set all the status flags, and we can take advantage of that when <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code> aren’t repeated. Of course, we should use <code class="sourceCode nasm">repz</code> or <code class="sourceCode nasm">repnz</code> whenever we can, but non-repeated <code class="sourceCode nasm"><span class="kw">scas</span></code> and <code class="sourceCode nasm"><span class="kw">cmps</span></code> let us tap the power of string instructions when <code class="sourceCode nasm">repz</code> and <code class="sourceCode nasm">repnz</code> simply won’t do.</p>
<p>For instance, suppose that we’re comparing two arrays that contain signed 16-bit values representing signal measurements. Suppose further that we want to find the first point at which the waves represented by the arrays cross. That is, if wave A starts out above wave B, we want to know when wave A becomes less than or equal to wave B, as shown in Figure 11.16.</p>
<figure>
<img src="images/fig11.17RT.png" />
</figure>
<p>If wave B starts out above wave A, then we want to know when wave B becomes less than or equal to wave A.</p>
<p>There’s no way to perform this comparison with repeated <code class="sourceCode nasm"><span class="kw">cmps</span></code>, since greater-than/less-than comparisons aren’t in the limited repertoire of the <code class="sourceCode nasm">rep</code> prefix. However, plain old non-repeated <code class="sourceCode nasm"><span class="kw">cmpsw</span></code> is up to the task, as shown in <a href="#listing-11-31">Listing 11-31</a>, which runs in 1232 us. As shown in <a href="#listing-11-31">Listing 11-31</a>, we must initially determine which array starts out on top, in order to set SI to point to the initially-greater array and DI to point to the other array. Once that’s done, all we need do is perform a <code class="sourceCode nasm"><span class="kw">cmpsw</span></code> on each data point and check whether that point is still greater with <code class="sourceCode nasm"><span class="kw">jg</span></code>. <code class="sourceCode nasm"><span class="kw">loop</span></code> repeats the comparison for however many data points there are — and that’s the whole routine in a very compact package! The 3-instruction, 5-byte loop of <a href="#listing-11-31">Listing 11-31</a> is hard to beat for this fairly demanding task.</p>
<p>By contrast, <a href="#listing-11-32">Listing 11-32</a>, which performs the same crossing search but does so with non-string instructions, has 6 instructions and 13 bytes in the loop and takes considerably longer — 1821 us — to complete the sample crossing search. Although we were unable to use repeated <code class="sourceCode nasm"><span class="kw">cmps</span></code> for this particular task, we were nonetheless able to improve performance a great deal by using the string instruction in its non-repeated form.</p>
</section>
</section>
<section id="a-note-about-returning-values" class="level2">
<h2>A Note About Returning Values</h2>
<p>Throughout this chapter I’ve been returning “not found” statuses by passing zero pointers (pointers set to zero) back to the calling routine. This is a commonly used and very flexible means of returning such statuses, since the same registers that are used to return pointers when searches are successful can be used to return zero when searches are not successful. The success or failure of a subroutine can then be tested with code like:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">call</span>  FindCharInString
<span class="kw">and</span>   <span class="kw">si</span>,<span class="kw">si</span>
<span class="kw">jz</span>    CharNotFound</code></pre>
<p>Returning failure statuses as zero pointers is particularly popular in high-level languages such as C, although C returns pointers in either AX, DX:AX, or memory, rather than in SI or DI.</p>
<p>However, there are many other ways of returning statuses in assembler. One particularly effective approach is that of returning success or failure in either the Zero or Carry flag, so that the calling routine can immediately jump conditionally upon return from the subroutine, without the need for any anding, oring, or comparing of any sort. This works out especially well when the proper setting of a flag falls out of the normal functioning of a subroutine. For example, consider the following subroutine, which returns the Zero flag set to 1 if the character in AL is whitespace:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="fu">Whitespace:</span>
    <span class="kw">cmp</span>   <span class="kw">al</span>,<span class="st">&#39; &#39;</span>          <span class="co">;space</span>
    <span class="kw">jz</span>    WhitespaceDone
    <span class="kw">cmp</span>   <span class="kw">al</span>,<span class="dv">9</span>            <span class="co">;tab</span>
    <span class="kw">jz</span>    WhitespaceDone
    <span class="kw">and</span>   <span class="kw">al</span>,<span class="kw">al</span>           <span class="co">;zero byte</span>
<span class="fu">WhitespaceDone:</span>
    <span class="kw">ret</span></code></pre>
<p>The key point here is that the Zero flag is automatically set by the comparisons preceding the <code class="sourceCode nasm"><span class="kw">ret</span></code>. Any test for whitespace would have to perform the same comparisons, so practically speaking we didn’t have to write a single extra line of code to return the subroutine’s status in the Zero flag. Because the return status is in a flag rather than a register, <code class="sourceCode nasm">Whitespace</code> could be called and the outcome handled with a very short sequence of instructions, as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">al</span>,[Char]
<span class="kw">call</span>  Whitespace
<span class="kw">jnz</span>   NotWhitespace</code></pre>
<p>The particular example isn’t important here. What is important is that you realize that in assembler (unlike high-level languages) there are many ways to return statuses, and that it’s possible to save a great deal of code and/or time by taking advantage of that. Now is not the time to pursue the topic further, but we’ll return to the issues of passing values and statuses both to and from assembler subroutines in Volume II of <em>The Zen of Assembly Language</em>.</p>
</section>
<section id="putting-string-instructions-to-work-in-unlikely-places" class="level2">
<h2>Putting String Instructions to Work in Unlikely Places</h2>
<p>I’ve said several times that string instructions are so powerful that you should try to use them even when they don’t seem especially well-matched to a particular application. Now I’m going to back that up with an unlikely application in which the string instructions have served me well over the years: animation.</p>
<p>This section is actually a glimpse into the future. Volume II of <em>The Zen of Assembly Language</em> will take up the topic of animation in much greater detail, since animation truly falls in the category of the flexible mind rather than knowledge. Still, animation is such a wonderful example of what the string instructions can do that we’ll spend a bit of time on it here and now. It’ll be a whirlwind look, with few details and nothing more than a quick glance at theory, for the focus isn’t on animation <em>per se</em>. What’s important is not that you understand how animation works, but rather that you get a feel for the miracles string instructions can perform in places where you wouldn’t think they could serve at all.</p>
<section id="animation-basics" class="level3">
<h3>Animation Basics</h3>
<p>Animation involves erasing and redrawing one or more images quickly enough to fool the eye into perceiving motion, as shown in Figure 11.17.</p>
<figure>
<img src="images/fig11.17RT.png" />
</figure>
<p>Animation is a marginal application for the PC, by which I mean that the 8088 barely has enough horsepower to support decent animation under the best of circumstances. What <em>that</em> means is that the Zen of assembler is an absolute must for PC animation.</p>
<p>Traditionally, microcomputer animation has been performed by exclusive-oring images into display memory; that is, by drawing images by inserting the bits that control their pixels into display memory with the <code class="sourceCode nasm"><span class="kw">xor</span></code> instruction. When an image is first exclusive-ored into display memory at a given location, the image becomes visible. A second exclusive-oring of the image at the same location then erases the image. Why? That’s simply the nature of the exclusive-or operation.</p>
<p>Consider this. When you exclusive-or a 1 bit with another bit once, the other bit is flipped. When you exclusive-or the same 1 bit with that other bit again, the other bit is again flipped — <em>right back to its original state</em>, as shown in Figure 11. 18.</p>
<figure>
<img src="images/fig11.18RT.png" />
</figure>
<p>After all, a bit only has two possible states, so a double flip must restore the bit back to the state in which it started. Since exclusive-oring a 0 bit with another bit never affects the other bit, exclusive-oring a target bit twice with either a 1 or a 0 bit always leaves the target bit in its original state.</p>
<p>Why is exclusive-oring so popular for animation? Simply because no matter how many images overlap, the second exclusive-or of an image always erases it without interfering with any other images. In other words, the perfect reversibility of the exclusive-or operation means that you could exclusive-or each of 10 images once at the same location, drawing the images right on top of each other, then exclusive-or them all again at the same place — and they would all be erased. With exclusive-oring, the drawing or erasing of one image never interferes with the drawing or erasing of other images it overlaps.</p>
<p>If you’re catching all this, great. If not, don’t worry. I’m not going to spend time explaining animation now — better we should wait until Volume II, when we have the time to do it right. The important point is that exclusive-oring is a popular animation technique, primarily because it eliminates the complications of drawing and erasing overlapping images.</p>
<p><a href="#listing-11-33">Listing 11-33</a>, which bounces 10 images around the screen, illustrates animation based on exclusive-oring. When run on an Enhanced Graphics Adapter (EGA), <a href="#listing-11-33">Listing 11-33</a> takes 30.29 seconds to move and redraw every image 500 times. (Note that the long-period Zen timer was used to time <a href="#listing-11-33">Listing 11-33</a>, since we can’t perform much animation within the 54 ms maximum period of the precision Zen timer.)</p>
<p><a href="#listing-11-33">Listing 11-33</a> isn’t a general-purpose animation program. I’ve kept complications to a minimum in order to show basic exclusive-or animation. <a href="#listing-11-33">Listing 11-33</a> allows us to observe the fundamental strengths and weaknesses (primarily the latter) of the exclusive-or approach.</p>
<p>When you run <a href="#listing-11-33">Listing 11-33</a>, you’ll see why exclusive-oring is less than ideal. While overlapping images don’t interfere with each other so far as drawing and erasing go, they do produce some unattractive on-screen effects. In particular, unintended colors and patterns often result when multiple images are exclusive-ored into the same bytes of display memory. Another problem is that exclusive-ored images flicker because they’re constantly being erased and redrawn. (Each image could instead be redrawn at its new location before being erased at the old location, but the overlap effects characteristic of exclusive-oring would still cause flicker.) That’s not all, though. There’s a still more serious problem with exclusive-or based animation…</p>
<p>Exclusive-oring is slow.</p>
<p>The problem isn’t that the <code class="sourceCode nasm"><span class="kw">xor</span></code> instruction itself is particular slow; rather, it’s that the <code class="sourceCode nasm"><span class="kw">xor</span></code> instruction isn’t a string instruction. <code class="sourceCode nasm"><span class="kw">xor</span></code> can’t be repeated with <code class="sourceCode nasm">rep</code>, it doesn’t advance its pointers automatically, and it just isn’t as speedy as, say, <code class="sourceCode nasm"><span class="kw">movs</span></code>. Still, neither <code class="sourceCode nasm"><span class="kw">movs</span></code> nor any other string instruction can perform exclusive-or operations, so it would seem we’re stuck.</p>
<p>We’re hardly stuck, though. On the contrary, we’re bound for glory!</p>
</section>
<section id="string-instruction-based-animation" class="level3">
<h3>String Instruction-Based Animation</h3>
<p>If string instructions can’t perform exclusive-oring, then we’ll just have to figure out a way to animate without exclusive-oring. As it turns out, there’s a <em>very</em> nice way to do this. I learned this approach from Dan Illowsky, who developed it before string instructions even existed, way back in the early days of the Apple II.</p>
<p>First, we’ll give each image a small blank fringe. Then we’ll make it a rule never to move an image by more than the width of its fringe before redrawing it. Finally we’ll draw images by simply copying them to display memory, destroying whatever they overwrite, as shown in Figure 11.19. Now, what does that do for us?</p>
<figure>
<img src="images/fig11.19aRT.png" />
</figure>
<figure>
<img src="images/fig11.19bRT.png" />
</figure>
<p><em>Amazing</em> things. For starters, each image will, as it is redrawn, automatically erase its former incarnation. That means that there’s no flicker, since images are never really erased, but only drawn over themselves. There are also no color effects when images overlap, since only the image that was drawn most recently at any given pixel is visible.</p>
<p>In short, this sort of animation (which I’ll call “block-move animation”) actually looks considerably better than animation based on exclusive-oring. That’s just frosting on the cake, though — the big payoff is speed. With block-move animation we suddenly don’t need to exclusive-or anymore — in fact, <code class="sourceCode nasm">rep <span class="kw">movs</span></code> will work beautifully to draw a whole line of an image in a single instruction. We also don’t need to draw each image twice per move — once to erase the image at its old location and once to draw it at its new location — as we did with exclusive-oring, since the act of drawing the image at a new location serves to erase the old image as well. But wait, there’s more! <code class="sourceCode nasm"><span class="kw">xor</span></code> accesses a given byte of memory twice per draw, once to read the original byte and once to write the modified byte back to memory. With block-move animation, on the other hand, we simply write each byte of an image to memory once and we’re done with that byte. In other words, between the elimination of a separate erasing step and the replacement of read-<code class="sourceCode nasm"><span class="kw">xor</span></code>-write with a single write, block-move animation accesses display memory only about one-third as many times as exclusive-or animation. (The ratio isn’t quite 1 to 4 because the blank fringe makes block-move animation images somewhat larger.)</p>
<p>Are alarm bells going off in your head? They should be. Think back to our journey beneath the programming interface. Think of the cycle-eaters. Ah, you’ve got it! <em>Exclusive-or animation loses about three times as much performance to the display adapter cycle-eater as does block-move animation.</em> What’s more, block-move animation uses the blindingly fast <code class="sourceCode nasm"><span class="kw">movs</span></code> instruction. To top it off, block-move animation loses almost nothing to the prefetch queue cycle-eater or the 8088’s slow branching speed, thanks to the <code class="sourceCode nasm">rep</code> prefix.</p>
<p>Sounds almost too good to be true, doesn’t it? It is true, though: block-move animation relies almost exclusively on one of the two most powerful instructions of the 8088 (<code class="sourceCode nasm"><span class="kw">cmps</span></code> being the other), and avoids the gaping maws of the prefetch queue and display adapter cycle-eaters in the process. Which leaves only one question:</p>
<p>How fast <em>is</em> block-move animation?</p>
<p>Remember, theory is fine, but we don’t trust any code until we’ve timed it. <a href="#listing-11-34">Listing 11-34</a> performs the same animation as <a href="#listing-11-34">Listing 11-34</a>, but with block-move rather than exclusive-or animation. Happily, <a href="#listing-11-34">Listing 11-34</a> lives up to its advance billing, finishing in just 10.35 seconds when run on an EGA. <em>Block-move animation is close to three times as fast as exclusive-oring in this application</em> — and it looks better, too. (You can slow down the animation in order to observe the differences between the two sorts of animation more closely by setting <code class="sourceCode nasm">DELAY</code> to a higher value in each listing.)</p>
<p>Let’s not underplay the appearance issue just because the performance advantage of block-move animation is so great. If you possibly can, enter and run <a href="#listing-11-33">Listings 11-33</a> and <a href="#listing-11-34">11-34</a>. The visual impact of block-move animation’s flicker-free, high-speed animation is startling. It’s hard to imagine that any programmer would go back to exclusive-oring after seeing block-move animation in action.</p>
<p>That’s not to say that block-move animation is perfect. Unlike exclusive-oring, block-move animation wipes out the background unless the background is explicitly redrawn after each image is moved. Block-move animation does produce flicker and fringe effects when images overlap. Block-move animation also limits the maximum distance by which an image can move before it’s redrawn to the width of its fringe.</p>
<p>If block-move animation isn’t perfect, however, it’s <em>much</em> better than exclusive-oring. What’s really noteworthy, however, is that we looked at an application — animation — without preconceived ideas about the best implementation, and came up with an approach that merged the application’s needs with one of the strengths of the PC — the string instructions — while avoiding the cycle-eaters. In the end, we not only improved performance remarkably but also got better animation, in the process turning a seeming minus — the limitations of the string instructions — into a big plus. All in all, what we’ve just done is the Zen of assembler working on all levels: knowledge, flexible mind, and implementation.</p>
<p>Try to use the string instructions for all your time-critical code, even when you think they just don’t fit. Sometimes they don’t — but you can never be sure unless you try… and if they <em>can</em> be made to fit, it will pay off <em>big</em>.</p>
</section>
<section id="notes-on-the-animation-implementations" class="level3">
<h3>Notes on the Animation Implementations</h3>
<p>Spend as much time as you wish perusing <a href="#listing-11-33">Listings 11-33</a> and <a href="#listing-11-34">11-34</a>, but <em>do not worry</em> if they don’t make complete sense to you right now. The point of this exercise was to illustrate the use of the string instructions in an unusual application, not to get you started with animation. In Volume II of <em>The Zen of Assembly Language</em> we’ll return to animation in a big way.</p>
<p>The animation listings are not full-featured, flexible implementations, nor were they meant to be. My intent in creating these programs was to contrast the basic operation and raw performance of exclusive-or and block-move animation. Consequently, I’ve structured the two listings along much the same lines, and while the code is fast, I’ve avoided further optimizations (notably the use of in-line code) that would have complicated matters. We’ll see those additional optimizations in Volume II.</p>
<p>One interesting point to be made about the animation listings is that I’ve assumed in the drawing routines that images always start on even rows of the screen and are always an even number of rows in height. Many people would consider the routines to be incomplete, since they lack the extra code needed to handle the complications of odd start rows and odd heights in 320x200 4-color graphics mode. Of course, that extra code would slow performance and increase program size, but would be deemed necessary in any “full” animation implementation.</p>
<p>Is the handling of odd start rows and odd heights really necessary, though? Not if you can structure your application so that images can always start on even rows and can always be of even heights, and that’s actually easy to do. No one will ever notice whether images move 1 or 2 pixels at a time; the nature of animation is such that the motion of an image appears just as smooth in either case. And why should there be a need for odd image heights? If necessary, images of odd height could be padded out with an extra line. In fact, an extra line can often be used to improve the appearance of an image.</p>
<p>In short, “full” animation implementations will not only run slower than the implementation in <a href="#listing-11-33">Listings 11-33</a> and <a href="#listing-11-34">11-34</a> but may not even yield any noticeable benefits. The lesson is this: only add features that slow your code when you’re sure you need them. High-performance assembler programming is partly an art of eliminating everything but the essentials.</p>
<p>By the way, <a href="#listing-11-33">Listings 11-33</a> and <a href="#listing-11-34">11-34</a> move images a full 4 pixels at a time horizontally, and that’s a bit <em>too</em> far. 2 pixels is a far more visually attractive distance by which to move animated images, especially those that move slowly. However, because each byte of 320x200 4-color mode display memory controls 4 pixels, alignment of images to start in columns that aren’t multiples of 4 is more difficult, although not really that hard once you get the hang of it. Since our goal in this section was to contrast block-move and exclusive-or animation, I didn’t add the extra code and complications required to bit-align the images. We will discuss bit-alignment of images at length in Volume II, however.</p>
</section>
</section>
<section id="a-note-on-handling-blocks-larger-than-64-k-bytes" class="level2">
<h2>A Note on Handling Blocks Larger Than 64 K Bytes</h2>
<p>All the string instruction-based code we’ve seen in this chapter handles only blocks or strings that are 64 K bytes in length or shorter. There’s a very good reason for this, of course — the infernal segmented architecture of the 8088 — but there are nonetheless times when larger memory blocks are needed.</p>
<p>I’m going to save the topic of handling blocks larger than 64 K bytes for Volume II of <em>The Zen of Assembly Language</em>. Why? Well, the trick with code that handles larger memory blocks isn’t getting it to work; that’s relatively easy if you’re willing to perform 32-bit arithmetic and reload the segment registers before each memory access. No, the trick is getting code that handles large memory blocks to work reasonably fast.</p>
<p>We’ve seen that a key to assembler programming lies in converting difficult problems from approaches ill-suited to the 8088 to ones that the 8088 can handle well, and this is no exception. In this particular application, we need to convert the task at hand from one of independently addressing every byte in the 8088’s 1-megabyte address space to one of handling a series of blocks that are each no larger than 64 K bytes, so that we can process up to 64 K bytes at a time very rapidly without touching the segment registers.</p>
<p>The concept is simple, but the implementation is not so simple and requires the flexible mind… and that’s why the handling of memory blocks larger than 64 K bytes will have to wait until Volume II.</p>
<section id="conclusion" class="level3">
<h3>Conclusion</h3>
<p>This chapter had two objectives. First, I wanted you to get a sense of how and when the string instructions can best be applied. Second, I wanted you to heighten your regard for these instructions, which are the best the 8088 has to offer. With any luck, this chapter has both broadened your horizons for string instruction applications and increased your respect for these unique and uniquely powerful members of the 8088’s instruction set.</p>
</section>
</section>
</section>
<section id="chapter-12-dont-jump" class="level1">
<h1>Chapter 12: Don’t Jump!</h1>
<p><em>Don’t jump!</em></p>
<p>Sounds crazy, doesn’t it? After all, a computer is at heart a decision-making machine that decides by branching, and any programmer worth his salt knows that jumps, calls, interrupts, and loops are integral to any program of substance. I’ve led you into some mighty strange places, including unlikely string instruction applications and implausible regions of the 8088’s instruction set, to say nothing of the scarcely-comprehensible cycle-eaters. Is it possible that I’ve finally tipped over the edge into sheer lunacy?</p>
<p>No such luck — I’m merely indulging in a bit of overstatement in a good cause. Of course you’ll need to branch… but since branching is slow — make that <em>very</em> slow — on the 8088, you’ll want to branch as little as possible. If you’re clever, you can often manage to eliminate virtually all branching in the most time-critical portions of your code. Sometimes avoiding branching is merely a matter of rearranging code, and sometimes it involves a few extra bytes and some unusual code. Either way, code that’s branch-free (or nearly so) is one key to high performance.</p>
<p>This business of avoiding branching — a term which covers jumps, subroutine calls, subroutine returns, and interrupts — is as much a matter of the flexible mind as of pure knowledge. You may have noticed that in recent chapters we’ve discussed ways to use instructions more effectively as much as we’ve discussed the instructions themselves. For example, much of the last chapter was about how to put the string instructions to work in unorthodox but effective ways, not about how the string instructions work <em>per se</em>. It’s inevitable that as we’ve accumulated a broad base of knowledge about the 8088 and gained a better sense of how to approach high-performance coding, we’ve developed an itch to put that hard-won knowledge to work in developing superior code. That’s the flexible mind, and we’ll see plenty of it over the next three chapters. Ultimately, we’re building toward Volume II, which will focus on the flexible mind and implementation.</p>
<p>This chapter is emphatically <em>not</em> going to be a comprehensive discussion of all the ways to branch on the 8088. I started this book with the assumption that you were already familiar with assembly language, and we’ve spent many pages since then expanding your assembler knowledge. Chapter 6 discussed the flags that are tested by the various conditional jumps, and the last chapter used branching instructions in a variety of situations. By now I trust you know that <code class="sourceCode nasm"><span class="kw">jz</span></code> branches if the zero flag is set to 1, and that <code class="sourceCode nasm"><span class="kw">call</span></code> pushes the address of the next instruction on the stack and branches to the specified destination. If not, get a good reference book and study the various branching instructions carefully. There’s nothing Zen in their functionality — they do what they’re advertised to do, and that’s that.</p>
<p>On the other hand, there is much Zen in the way the various branching instructions <em>perform</em>. In Chapter 13 we’ll talk about ways to branch as little as possible, and in Chapter 14 we’ll talk about ways to make branches perform as well as possible when you must use them. Right now, let’s find out why it is that branching as little as possible is a desirable goal.</p>
<section id="how-slow-is-it" class="level2">
<h2>How Slow Is It?</h2>
<p>We want to avoid branching for one simple reason: it’s slow. It’s not that there’s anything inherently slow about branching; branching just happens to suffer from a slow implementation on the 8088. Even the venerable Z80 branches about 50% faster than the 8088.</p>
<p>So how slow <em>is</em> branching on the 8088? Well, the answer varies from one type of branch to another, so let’s pick a commonly-used jump — say, <code class="sourceCode nasm"><span class="kw">jmp</span></code> — and see what we find. The official execution time of <code class="sourceCode nasm"><span class="kw">jmp</span></code> is 15 cycles. <a href="#listing-12-1">Listing 12-1</a>, which measures the performance of 1000 <code class="sourceCode nasm"><span class="kw">jmp</span></code> instructions in a row, reports that <code class="sourceCode nasm"><span class="kw">jmp</span></code> actually takes 3.77 us (18 cycles) to execute. (<a href="#listing-12-1">Listing 12-1</a> actually uses <code class="sourceCode nasm"><span class="kw">jmp</span> <span class="dt">short</span></code> rather than <code class="sourceCode nasm"><span class="kw">jmp</span></code>, since the jumps don’t cover much distance. We’ll discuss the distinction between the two in a little while.)</p>
<p>18 cycles is a long time in anybody’s book… long enough to copy a byte from one memory location to another and increment both SI and DI with <code class="sourceCode nasm"><span class="kw">movsb</span></code>, long enough to add two 32-bit values together, long enough to increment a 16-bit register at least 4 times. How could it possibly take the 8088 so long just to load a value into the Instruction Pointer? (Think about it — all a branch really consists of is setting IP, and sometimes CS as well, to point to the desired instruction.) Well, let’s round up the usual suspects — the cycle eaters — and figure out what’s going on. In the process, we’ll surely acquire some knowledge that we can put to good use in creating high-performance code.</p>
</section>
<section id="branching-and-calculation-of-the-target-address" class="level2">
<h2>Branching and Calculation of the Target Address</h2>
<p>Of the 18 cycles <code class="sourceCode nasm"><span class="kw">jmp</span></code> takes to execute in <a href="#listing-12-1">Listing 12-1</a>, 4 cycles seem to be used to calculate the target offset. I can’t state this with absolute certainty, since Intel doesn’t make the inner workings of its instructions public, but it’s most likely true. You see, most of the 8088’s <code class="sourceCode nasm"><span class="kw">jmp</span></code> instructions don’t have the form “load the Instruction Pointer with offset <em>xxxx</em>,” where the <code class="sourceCode nasm"><span class="kw">jmp</span></code> instruction specifies the exact offset to branch to. (This sort of jump is known as an <em>absolute</em> branch, since the destination offset is specified as a fixed, or absolute offset in the code segment. Figure 12.1 shows one of the few jump instructions that does use absolute branching.)</p>
<figure>
<img src="images/fig12.1aRT.png" />
</figure>
<figure>
<img src="images/fig12.1bRT.png" />
</figure>
<p>Rather, most of the 8088’s <code class="sourceCode nasm"><span class="kw">jmp</span></code> instructions have the form “add <em>nnnn</em> to the contents of the Instruction Pointer,” where the byte or word following the <code class="sourceCode nasm"><span class="kw">jmp</span></code> opcode specifies the distance from the current IP to the offset to branch to, as shown in Figure 12.2.</p>
<figure>
<img src="images/fig12.2aRT.png" />
</figure>
<figure>
<img src="images/fig12.2bRT.png" />
</figure>
<p>Jumps that use displacements are known as <em>relative</em> branches, since the destination offset is specified relative to the offset of the current instruction. Relative branches are actually performed by adding a displacement to the value in the Instruction Pointer, and there’s a bit of a trick there.</p>
<p>By the time a relative branching instruction actually gets around to branching, the IP points to the byte <em>after</em> the last byte of the instruction, since the IP has already been used to read in all the bytes of the branching instruction and has advanced to point to the next instruction. As shown in Figure 12.2, relative branches work by adding a displacement to the IP after it has advanced to point to the byte after the branching instruction, <em>not</em> by adding a displacement to the offset of the branching instruction itself.</p>
<p>So, to sum up, most <code class="sourceCode nasm"><span class="kw">jmp</span></code> instructions contain a field which specifies a displacement from the current IP to the target address, rather than a field which specifies the target address directly. (Jumps that <em>don’t</em> use relative branching include <code class="sourceCode nasm"><span class="kw">jmp</span> reg16</code>, <code class="sourceCode nasm"><span class="kw">jmp</span> mem16</code>, and all far jumps. All conditional jumps use relative branching.)</p>
<p>There are definite advantages to the use of relative rather than absolute branches. First, code that uses relative branching will work properly no matter where in memory it is loaded, since relative branch destinations aren’t tied to specific memory offsets. If a block of code is moved to another area of memory, the relative displacements between the instructions remain the same, and so relative branching instructions will still work properly. This property makes relative branches useful in any code that must be moved about in memory, although by and large such code isn’t needed very often.</p>
<p>Second (and more important), when relative branches are used, any branch whose target is within -128 to +127 bytes of the byte after the end of the branching instruction can be specified in a more compact form, with a 1-byte rather than 1-word displacement, as shown in Figure 12.3.</p>
<figure>
<img src="images/fig12.3aRT.png" />
</figure>
<figure>
<img src="images/fig12.3bRT.png" />
</figure>
<p>The key, of course, is that -128 to +127 decimal is equivalent to 0FF80h to 007Fh hexadecimal, which is the range of values that can be specified with a single signed byte. The short jumps to which I referred earlier are such 1-byte-displacement short branches, in contrast to normal jumps, which use full 2-byte displacements. The smaller displacement allows short jump instructions to squeeze into 2 bytes, 1 byte less than a normal jump.</p>
<p>By definition, then, short branches take 1 less instruction byte than normal relative branches. The tradeoff is that short jumps can only reach offsets within the aforementioned 256-address range, while the 1-word displacement of normal branches allows them to reach any offset in the current code segment.</p>
<p>Since most branches are in fact to nearby addresses, the availability of short (1 displacement byte) branches can produce significant savings in code size. In fact, the 8088’s conditional jumps can <em>only</em> use 1-byte displacements, and while that’s sometimes a nuisance when long conditional jumps need to be made, it does indeed help to keep code size down.</p>
<p>There’s also a definite disadvantage to the use of relative branches, and it’s the usual drawback: speed, or rather the lack thereof. Adding a jump displacement to the Instruction Pointer is similar to adding a constant value to a register, a task which takes the 8088 4 cycles. By all appearances, it takes the 8088 about the same 4 cycles to add a jump displacement to the Instruction Pointer. Indeed, although there’s no way to be sure exactly what’s going on inside the 8088 during a <code class="sourceCode nasm"><span class="kw">jmp</span></code>, it does make sense that the 8088 would use the same internal logic to add a constant to a register no matter whether the instruction causing the addition is a <code class="sourceCode nasm"><span class="kw">jmp</span></code> or an <code class="sourceCode nasm"><span class="kw">add</span></code>.</p>
<p>What’s the evidence that the 8088 takes about 4 cycles to add a displacement to IP? Item 1: <code class="sourceCode nasm"><span class="kw">jmp</span> reg16</code>, an instruction which branches directly to the offset (not displacement) stored in a register, executes in just 11 cycles, 4 cycles faster than a normal <code class="sourceCode nasm"><span class="kw">jmp</span></code>. Item 2: <code class="sourceCode nasm"><span class="kw">jmp</span> <span class="kw">segment</span>:offset</code>, the 8088’s far jump that loads both CS and IP at once, executes at the same 15-cycles-per-execution speed as <code class="sourceCode nasm"><span class="kw">jmp</span></code>. While a far jump requires that CS be loaded, it doesn’t involve any displacement arithmetic. The addition of the displacement to IP pretty clearly takes longer than simply loading an offset into IP; otherwise it seems that a near jump would <em>have</em> to be faster than a far jump, by virtue of not having to load CS.</p>
<p>By the way, in this one instance it’s acceptable to speculate on the basis on official execution times rather than on the basis of times reported by the Zen timer. Why? Because we’re theorizing as to what’s going on inside the 8088, and that’s most accurately reflected by the official execution times, which ignore external data bus activity. Actual execution times include instruction fetching time, and since far jumps are 2 to 3 bytes longer than near jumps, the prefetch queue cycle-eater would obscure the comparison between the internal operations of near versus far jumps that we’re trying to make. However, when it comes to evaluating real code performance, as opposed to speculating about the 8088’s internal operations, you should <em>always</em> measure with the Zen timer.</p>
<p>Near subroutine calls (except <code class="sourceCode nasm"><span class="kw">call</span> reg16</code>) also use displacements, and, like near jumps, near calls seem to spend several cycles performing displacement arithmetic. On the other hand, return instructions, which pop into IP offsets previously pushed on the stack by calls, do not perform displacement arithmetic, nor do far calls. Interrupts don’t perform displacement arithmetic either; as we will see, however, interrupts have their own performance problems.</p>
<p>Displacement arithmetic accounts for about 4 of the 18 cycles <code class="sourceCode nasm"><span class="kw">jmp</span></code> takes to execute. That leaves 14 cycles, still an awfully long time. What else is <code class="sourceCode nasm"><span class="kw">jmp</span></code> doing to keep itself busy?</p>
</section>
<section id="branching-and-the-prefetch-queue" class="level2">
<h2>Branching and the Prefetch Queue</h2>
<p>Since the actual execution time of <code class="sourceCode nasm"><span class="kw">jmp</span></code> in <a href="#listing-12-1">Listing 12-1</a> is 3 cycles longer than its official execution time, one or more of the cycle-eaters must be taking those cycles. If past experience is any guide, it’s a pretty good bet that the prefetch queue cycle-eater is rearing its ugly head once again. The DRAM refresh cycle-eater may also be taking some cycles (it usually does), but the 20% discrepancy between the official and actual execution times is far too large to be explained by DRAM refresh alone. In any case, let’s measure the execution time of <code class="sourceCode nasm"><span class="kw">jmp</span></code> with <code class="sourceCode nasm"><span class="kw">imul</span></code> instructions interspersed so that the prefetch queue is full when it comes time for each <code class="sourceCode nasm"><span class="kw">jmp</span></code> to execute.</p>
<p>First, let’s figure out the execution time of <code class="sourceCode nasm"><span class="kw">imul</span></code> when used to calculate the 32-bit product of two 16-bit zero factors. Later, that will allow us to determine how much of the combined execution time of <code class="sourceCode nasm"><span class="kw">imul</span></code> and <code class="sourceCode nasm"><span class="kw">jmp</span></code> is due to <code class="sourceCode nasm"><span class="kw">imul</span></code> alone. (By the way, we’re using <code class="sourceCode nasm"><span class="kw">imul</span></code> rather than <code class="sourceCode nasm"><span class="kw">mul</span></code> because when I tried <code class="sourceCode nasm"><span class="kw">mul</span></code> and <code class="sourceCode nasm"><span class="kw">jmp</span></code> together, overall execution synchronized with DRAM refresh, distorting the results. Each <code class="sourceCode nasm"><span class="kw">mul</span></code>/<code class="sourceCode nasm"><span class="kw">jmp</span></code> pair executed in exactly 144 cycles, with DRAM refresh adding 6 of those cycles by holding up instruction fetching right after the jump. Here we have yet another example of why you should always time code in context — be careful about generalizing from artificial tests like <a href="#listing-12-2">Listing 12-2</a>!) The Zen timer reports that the 1000 <code class="sourceCode nasm"><span class="kw">imul</span></code> instructions in <a href="#listing-12-2">Listing 12-2</a> execute in 26.82 ms, or 26.82 us (128 cycles) per <code class="sourceCode nasm"><span class="kw">imul</span></code>.</p>
<p>Given that, we can determine how long <code class="sourceCode nasm"><span class="kw">jmp</span></code> takes to execute when started with the prefetch queue full. <a href="#listing-12-3">Listing 12-3</a>, which measures the execution time of alternating <code class="sourceCode nasm"><span class="kw">imul</span></code> and <code class="sourceCode nasm"><span class="kw">jmp</span></code> instructions, runs in 31.18 ms. That’s 31.18 us (148.8 cycles) per <code class="sourceCode nasm"><span class="kw">imul</span></code>/<code class="sourceCode nasm"><span class="kw">jmp</span></code> pair, or 20.8 cycles per <code class="sourceCode nasm"><span class="kw">jmp</span></code>.</p>
<p><em>Wait one minute!</em> <code class="sourceCode nasm"><span class="kw">jmp</span></code> takes more than 2 cycles <em>longer</em> when started with the prefetch queue full in <a href="#listing-12-3">Listing 12-3</a> than it did in <a href="#listing-12-1">Listing 12-1</a>. Instructions don’t slow down when the prefetch queue is allowed to fill before they start — if anything, they speed up. Yet a slowdown is just what we’ve found.</p>
<p>What the heck is going on?</p>
<section id="the-prefetch-queue-empties-when-you-branch" class="level3">
<h3>the Prefetch Queue Empties When You Branch</h3>
<p>It’s true that the prefetch queue is full when it comes time for each <code class="sourceCode nasm"><span class="kw">jmp</span></code> to start in <a href="#listing-12-3">Listing 12-3</a>… <em>but it’s also true that the prefetch queue is empty when <code class="sourceCode nasm"><span class="kw">jmp</span></code> ends</em>. To understand why that is and what the implications are, we must consider the nature of the prefetch queue.</p>
<p>We learned way back in Chapter 3 that the Bus Interface Unit of the 8088 reads the bytes immediately following the current instruction into the prefetch queue whenever the external data bus isn’t otherwise in use. This is done in an attempt to anticipate the next few instruction-byte requests that the Execution Unit will issue. Every time that the EU requests an instruction byte and the BIU has guessed right by prefetching that byte, 4 cycles are saved that would otherwise have to be expended on fetching the requested byte while the EU waited, as shown in Figure 12.4.</p>
<figure>
<img src="images/fig12.4aRT.png" />
</figure>
<figure>
<img src="images/fig12.4bRT.png" />
</figure>
<p>What happens if the BIU guesses wrong? Nothing disastrous: since the prefetched bytes are no help in fulfilling the EU’s request, the requested instruction byte must be fetched from memory at a cost of 4 cycles, just as if prefetching had never occurred.</p>
<p>That leaves us with an obvious question. <em>When</em> does the BIU guess wrong? In one case and one case only:</p>
<p>Whenever a branch occurs.</p>
<p>Think of it this way. The BIU prefetches bytes sequentially, starting with the byte after the instruction being executed. So long as no branches occur, those prefetched bytes <em>must</em> be the bytes the EU will want next, since the Instruction Pointer simply marches along from low addresses to high addresses.</p>
<p>When a branch occurs, however, the bytes immediately following the instruction bytes for the branch instruction are no longer necessarily the next bytes the EU will want, as shown in Figure 12.5.</p>
<figure>
<img src="images/fig12.5aRT.png" />
</figure>
<figure>
<img src="images/fig12.5bRT.png" />
</figure>
<p>If they aren’t, the BIU has no choice but to throw away those bytes and start fetching bytes again at the location branched to. In other words, if the BIU gambles that the EU will request instruction bytes sequentially and loses that gamble because of a branch, all pending prefetches of the instruction bytes following the branch instruction in memory are wasted.</p>
<p>That doesn’t make prefetching undesirable. The BIU prefetches only during idle times, so prefetching — even wasted prefetching — doesn’t slow execution down. (At worst, prefetching might slow things down a bit by postponing memory accesses by a cycle or two — but whether and how often that happens, only Intel knows, since it’s a function of the internal logic of the 8088. At any rate, wasted prefetching shouldn’t greatly affect performance.) All that’s lost when you branch is the performance bonus obtained when the 8088 manages to coprocess by prefetching and executing at the same time.</p>
<p>The 8088 could have been designed so that whenever a branch occurs, any bytes in the prefetch queue that are still usable are kept, while other, now-useless bytes are discarded. That would speed processing of code like:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">jz</span>  Skip
    <span class="kw">jmp</span> DistantLabel
<span class="fu">Skip:</span></code></pre>
<p>in the case where <code class="sourceCode nasm"><span class="kw">jz</span></code> jumps, since the instruction byte at the label <code class="sourceCode nasm">Skip</code> might well be in the prefetch queue when the branch occurs. The 8088 could also have been designed to prefetch from both possible “next”instructions at a branch, so that the prefetch queue wouldn’t be empty no matter which way the branch went.</p>
<p>The 8088 could have been designed to do all that and more — but it wasn’t. The BIU simply prefetches sequentially forward from the current instruction byte. Whenever a branch occurs, the prefetch queue is <em>always</em> emptied — even if the branched — to instruction is in the queue — and instruction fetching is started again at the new location, as illustrated by Figure 12.5. While that sounds innocent enough, it has far-reaching implications. After all, what does an empty prefetch queue mean? Right you are…</p>
<p>Branching always — and I do mean <em>always</em> — awakens the prefetch queue cycle-eater.</p>
</section>
<section id="branching-instructions-do-prefetch" class="level3">
<h3>Branching Instructions Do Prefetch</h3>
<p>Things aren’t quite as bad as they might seem, however. As you’ll recall, we decided back in Chapters 4 and 5 that the true execution time of an instruction is the interval from the time when the first byte of the instruction reaches the Execution Unit until the time when the first byte of the next instruction reaches the EU. Since branches always empty the prefetch queue, there obviously must be a 4-cycle delay from the time the branch is completed until the time when the first byte of the branched-to instruction reaches the EU, since that instruction byte must always be fetched from memory. In fact, the 8088 passes the first instruction byte fetched after a branch straight through to the EU as quickly as possible, since there’s no question but what the EU is ready and waiting to execute that byte.</p>
<p>The designers of the 8088 seem to have agreed with our definition of “true” execution time. I’ve previously pointed out that Intel’s official execution time for a given instruction doesn’t include the time required to fetch the bytes of that instruction. That’s not because Intel is hiding anything, but rather because the fetch time for a given instruction can vary considerably depending on the code preceding the instruction, as we’ve seen time and again. That’s not quite the case with branching, however. Whenever a branch occurs, we can be quite certain that the prefetch queue will be emptied, and that at least one prefetch will occur before anything else happens.</p>
<p>What that means is that the 4 cycles required to fetch the first byte of the branched-to instruction can reliably be counted as part of the execution time of a branch, and that’s exactly what Intel does. Although I’ve never seen documentation that explicitly states as much, official execution times that involve branches clearly include an extra 4 cycles for the fetching of the first byte of the branched-to instruction.</p>
<p>What evidence is there for this phenomenon? Well, <a href="#listing-12-1">Listing 12-1</a> is solid evidence. <a href="#listing-12-1">Listing 12-1</a> shows that a branching instruction (<code class="sourceCode nasm"><span class="kw">jmp</span></code>) with an official execution time of 15 cycles actually executes in 18 cycles. If the official execution time didn’t include the fetch time for the first byte of the branched-to instruction, repeated <code class="sourceCode nasm"><span class="kw">jmp</span></code> instructions would take a minimum of 19 cycles to execute, consisting of 15 cycles of EU execution time followed by 4 cycles of BIU fetch time for the first byte of the next <code class="sourceCode nasm"><span class="kw">jz</span></code>. In other words, the 18-cycle time that we actually measured could not happen if the 15-cycle execution time didn’t include the 4 cycles required to fetch the first instruction byte at the branched-to location.</p>
<p>Ironically, branching instructions would superficially appear to be excellent candidates to <em>improve</em> the state of the prefetch queue. After all, <code class="sourceCode nasm"><span class="kw">jmp</span></code> takes 15 cycles to execute, but accesses memory just once, to fetch the first byte of the branched-to instruction. Normally, such an instruction would allow 2 or 3 bytes to be prefetched, and, in fact, it’s quite possible that 2 or 3 bytes <em>are</em> prefetched while <code class="sourceCode nasm"><span class="kw">jmp</span></code> executes… but if that’s true, then those prefetches are wasted. Any bytes that are prefetched during a <code class="sourceCode nasm"><span class="kw">jmp</span></code> are thrown away at the end of the instruction, when the prefetch queue is emptied and the first byte of the instruction at the branched-to address is fetched.</p>
<p>So, the time required to fetch the branched-to instruction accounts for 4 cycles of the unusually long time the 8088 requires to branch. Once again, we’ve fingered the prefetch queue cycle-eater as a prime contributor to poor performance. You might think that for once the 8-bit bus isn’t a factor; after all, the same emptying of the prefetch queue during each branch would occur on an 8086, wouldn’t it?</p>
<p>The prefetch queue would indeed be emptied on an 8086 — but it would refill much more rapidly. Remember, instructions are fetched a word at a time on the 16-bit 8086. In particular, one-half of the time the 4 cycles expended on the critical first fetch after a branch would fetch not 1 but 2 bytes on an 8086 (1 byte if the address branched to is odd, 2 bytes if it is even, since the 8086 can only read words that start at even addresses). By contrast, the 8088 can only fetch 1 byte during the final 4 cycles of a branch, and therein lies the answer to our mystery of how code could possibly slow down when started with the prefetch queue full.</p>
</section>
</section>
<section id="branching-and-the-second-byte-of-the-branched-to-instruction" class="level2">
<h2>Branching and the Second Byte of the Branched-To Instruction</h2>
<p>Although the execution time of each branch includes the 4 cycles required to fetch the first byte of the branched-to instruction, that’s not the end of the impact of branching on instruction fetching. When a branch instruction ends, the EU is just starting to execute the first byte of the branched-to instruction, the BIU is just starting to fetch the following instruction byte… and the prefetch queue is empty. In other words, the single instruction fetch built into the execution time of each branch doesn’t fully account for the prefetch queue cycle-eater consequences of branching, but merely defers them for one byte. No matter how you look at it, the prefetch queue is flat-out empty after every branch.</p>
<p>Now, sometimes the prefetch queue doesn’t eat a single additional cycle after a branching instruction fetches the first byte of the branched-to instruction. That happens when the 8088 doesn’t need a second instruction byte for at least 4 cycles after the branch finishes, thereby giving the BIU enough time to fetch the second instruction byte. For example, consider <a href="#listing-12-4">Listing 12-4</a>, which shows <code class="sourceCode nasm"><span class="kw">jmp</span></code> (actually, <code class="sourceCode nasm"><span class="kw">jmp</span> <span class="dt">short</span></code>, but we’ll just use “<code class="sourceCode nasm"><span class="kw">jmp</span></code>” for simplicity) instructions alternating with <code class="sourceCode nasm"><span class="kw">push</span> <span class="kw">ax</span></code> instructions.</p>
<p>What’s interesting about <code class="sourceCode nasm"><span class="kw">push</span> <span class="kw">ax</span></code> is that it’s a 1-byte instruction that takes 15 cycles to execute but only accesses memory twice, using just 8 cycles in the process. That means that after each branch, in the time during which <code class="sourceCode nasm"><span class="kw">push</span> <span class="kw">ax</span></code> executes, there are 7 cycles free for prefetching the instruction bytes of the next <code class="sourceCode nasm"><span class="kw">jmp</span></code>. That’s long enough to fetch the opcode byte for <code class="sourceCode nasm"><span class="kw">jmp</span></code>, and most of the displacement byte as well, and when <code class="sourceCode nasm"><span class="kw">jmp</span></code> starts to execute, the BIU can likely finish fetching the displacement byte before it’s needed. In <a href="#listing-12-4">Listing 12-4</a>, in other words, the prefetch queue should never be empty either before or after <code class="sourceCode nasm"><span class="kw">jmp</span></code> is executed, and that should make for faster execution.</p>
<p>Incidentally, <code class="sourceCode nasm"><span class="kw">push</span></code> is a good instruction to start a subroutine with, in light of the beneficial prefetch queue effects described above. Why? Because <code class="sourceCode nasm"><span class="kw">push</span></code> allows the 8088 to recover partially from the emptying of the prefetch queue caused by subroutine calls. By happy chance, pushing registers in order to preserve them is a common way to start a subroutine.</p>
<p>At any rate, let’s try out our theories in the real world. <a href="#listing-12-4">Listing 12-4</a> runs in 6704 ms, or 32 cycles per <code class="sourceCode nasm"><span class="kw">push</span> <span class="kw">ax</span></code>/<code class="sourceCode nasm"><span class="kw">jmp</span></code> pair. <code class="sourceCode nasm"><span class="kw">push</span> <span class="kw">ax</span></code> officially runs in 15 cycles, and since it’s a “prefetch-positive” instruction — the prefetch queue tends to be more full when <code class="sourceCode nasm"><span class="kw">push</span> <span class="kw">ax</span></code> finishes than when <code class="sourceCode nasm"><span class="kw">push</span> <span class="kw">ax</span></code> starts — 15 cycles should prove to be the actual execution time as well. <a href="#listing-12-5">Listing 12-5</a> confirms this, running in 3142 microseconds, or exactly 15 cycles per <code class="sourceCode nasm"><span class="kw">push</span> <span class="kw">ax</span></code>.</p>
<p>A quick subtraction reveals that each <code class="sourceCode nasm"><span class="kw">jmp</span></code> in <a href="#listing-12-4">Listing 12-4</a> takes 17 cycles. That’s 1 cycle better than the execution time of <code class="sourceCode nasm"><span class="kw">jmp</span></code> in <a href="#listing-12-1">Listing 12-1</a>, and more than 3 cycles better than the execution time of <code class="sourceCode nasm"><span class="kw">jmp</span></code> in <a href="#listing-12-3">Listing 12-3</a>, confirming our speculations about post-branch prefetching. It seems that we have indeed found the answer to the mystery of how <code class="sourceCode nasm"><span class="kw">jmp</span></code> can run slower when the prefetch queue is allowed to fill before <code class="sourceCode nasm"><span class="kw">jmp</span></code> is started: because the prefetch queue is emptied after a branch, one or more instructions following a branch can suffer from reduced performance at the hands of the prefetch queue cycle-eater. The fetch time for the first instruction byte after the branch is built into the branch, but not the fetch time for the second byte, or the bytes after that.</p>
<p>So exactly what happens when <a href="#listing-12-3">Listing 12-3</a> runs to slow performance by 3-plus cycles relative to <a href="#listing-12-4">Listing 12-4</a>? I can only speculate, but it seems likely that when the first byte of an <code class="sourceCode nasm"><span class="kw">imul</span></code> instruction is fetched, the EU is ready for the second byte of the <code class="sourceCode nasm"><span class="kw">imul</span></code> — the <em>mod-reg-rm</em> byte — after just 1 cycle, as shown in Figure 12.6.</p>
<figure>
<img src="images/fig12.6RT.png" />
</figure>
<p>After all, the EU can’t do much processing of a multiplication until the source and destination are known, so it makes sense that the <em>mod-reg-rm</em> byte would be needed right away. Unfortunately, the branch preceding each <code class="sourceCode nasm"><span class="kw">imul</span></code> in <a href="#listing-12-3">Listing 12-3</a> empties the prefetch queue, so the EU must wait for several cycles while the <em>mod-reg-rm</em> byte is fetched from memory.</p>
<p>In <a href="#listing-12-4">Listing 12-4</a>, on the other hand, the first byte fetched after each branch is the instruction byte for <code class="sourceCode nasm"><span class="kw">push</span> <span class="kw">ax</span></code>. Since that’s the only byte of the instruction, the EU can proceed right through to completion of the instruction without requiring additional instruction bytes, affording ample time for the BIU to fetch at least the first byte of the next <code class="sourceCode nasm"><span class="kw">jmp</span></code>, as shown in Figure 12.7.</p>
<figure>
<img src="images/fig12.7RT.png" />
</figure>
<p>As a result, the prefetch queue cycle-eater has little or no impact on the performance of this code.</p>
<p>Finally, the code in <a href="#listing-12-1">Listing 12-1</a> falls somewhere between <a href="#listing-12-3">Listings 12-3</a> and <a href="#listing-12-4">12-4</a> as regards post-branch prefetching. Presumably, the EU has a more immediate need for the <em>mod-reg-rm</em> byte when executing <code class="sourceCode nasm"><span class="kw">imul</span></code> than it does for the displacement byte when executing <code class="sourceCode nasm"><span class="kw">jmp</span></code>.</p>
<p>Each <code class="sourceCode nasm"><span class="kw">push</span> <span class="kw">ax</span></code>/<code class="sourceCode nasm"><span class="kw">jmp</span></code> pair in <a href="#listing-12-4">Listing 12-4</a> still takes 2 cycles longer than it should according to the official execution times, so at least one cycle-eater must still be active. Perhaps the prefetch queue cycle-eater is still taking 2 cycles, or perhaps the DRAM refresh cycle-eater is taking 1 cycle and the prefetch queue cycle-eater is taking another cycle. There’s really no way to tell where those 2 cycles are going without getting out hardware and watching the 8088 run — and it’s not worth worrying about anyway.</p>
<p>In the grand scheme of things, it matters not a whit which cycle-eater is taking what portion of the cycles in <a href="#listing-12-1">Listings 12-1</a>, <a href="#listing-12-3">12-3</a>, and <a href="#listing-12-4">12-4</a>. Even if it did matter, there’s no point to trying to understand exactly how the prefetch queue behaves after branching. The detailed behavior of the cycle-eaters is highly variable in real code, and is extremely difficult to pin down precisely. Moreover, that behavior depends on the internal logic of the 8088, which is forever hidden from our view.</p>
<p>What <em>is</em> important is that you understand that the true execution times of branching instructions are almost always longer than the official times because the prefetch queue is <em>guaranteed</em> to be empty after each and every branch. True, the fetch time for the first instruction byte after a branch is accounted for in official branching execution times (making those times very slow). However, the prefetch queue is still empty after that first byte is fetched and begins execution, and the time the Execution Unit usually spends waiting for subsequent bytes to arrive is not accounted for in the official execution times.</p>
<p>Sometimes, as in <a href="#listing-12-4">Listing 12-4</a>, there may be no further instruction-fetch penalty following a branch, but those circumstances are few and far between, since they require that a branch be followed by an instruction byte that causes the 8088 not to require another instruction byte for at least 4 cycles. The truth of the matter is that it took me a bit of searching to find an instruction (<code class="sourceCode nasm"><span class="kw">push</span> <span class="kw">ax</span></code>) that met that criterion. In real code, branching almost always incurs a delayed prefetch penalty.</p>
<p>It’s this simple. Branches empty the prefetch queue. Many of the 8088’s fastest instructions run well below their maximum speed when the prefetch queue is empty, and most instructions slow down at least a little. It stands to reason, then, that branches reduce the performance of the branched-to code, with the reduction most severe for the sort of high-performance code we’re most interested in writing.</p>
<section id="dont-jump" class="level3">
<h3>Don’t Jump!</h3>
<p>Slow as they seem from the official execution times, branches are actually even slower than that, since they put the PC in just the right state for the prefetch queue cycle-eater to do its worst. Every time you branch, you expend at least 11 cycles, and usually more… and then you’re left with an empty prefetch queue. Is that the sort of instruction you want mucking up your time-critical code? Hardly. I’ll say it again:</p>
<p><em>Don’t jump!</em></p>
</section>
<section id="now-that-we-know-why-not-to-branch" class="level3">
<h3>Now That We Know Why Not to Branch…</h3>
<p>We’ve accounted for 11 of the 18 cycles that <code class="sourceCode nasm"><span class="kw">jmp</span></code> takes to execute in <a href="#listing-12-1">Listing 12-1</a>: 4 cycles to perform displacement arithmetic, 4 cycles to fetch the first byte of the next <code class="sourceCode nasm"><span class="kw">jmp</span></code>, and 3 cycles lost to the prefetch queue cycle-eater after the branch empties the queue. (Some of that 3-cycle loss may be due to DRAM refresh as well.)</p>
<p>That leaves us with 7 cycles unaccounted for. One of those cycles goes to decoding the instruction, but frankly I’m not certain where the other 6 go. The 8088 has to load the IP with the target address and empty the prefetch queue, but I wouldn’t expect that to take 6 cycles; more like 1 cycle, or 2 at most. Several additional cycles may go to calculating the 20-bit address at which to fetch the first byte of the branched-to instruction. In fact, that’s a pretty good bet: the 8088 takes a minimum of 5 cycles to perform effective address calculations, which would neatly account for most of the remaining 6 cycles. However, I don’t know for sure that that’s the case, and probably never will.</p>
<p>No matter. We’ve established where the bulk of the time goes when a <code class="sourceCode nasm"><span class="kw">jmp</span></code> occurs, and in the process we’ve found that branches are slow indeed — even slower than documented, thanks to the prefetch queue cycle-eater. In other words, we’ve learned why it’s desirable not to branch in high-performance code. Now it’s time to find out how to go about that unusual but essential task.</p>
</section>
</section>
</section>
<section id="chapter-13-not-branching" class="level1">
<h1>Chapter 13: Not-Branching</h1>
<p>Now we know <em>why</em> we don’t want to branch, but we haven’t a clue as to <em>how</em> to manage that trick. After all, decisions still have to be made, loops still have to be iterated through, and so on. Branching is the way we’ve always performed those tasks, and it’s certainly not obvious what the alternatives are, or, for that matter, that alternatives even exist.</p>
<p>While alternatives to branching do indeed exist, they are anything but obvious. Programming without branches — <em>not-branching</em>, in Zen-speak — is without question one of the stranger arts you must master in your growth as a Zen programmer.</p>
<p>Strange — but most rewarding. So let’s get to it!</p>
<section id="think-functionally" class="level2">
<h2>Think Functionally</h2>
<p>The key to not-branching lies in understanding each programming task strictly in terms of what that task needs to do, not in terms of how the task will ultimately be implemented. Put another way, you should not consider how you might implement a task, even in a general way, until you have a clear picture of exactly what results the implementation must produce.</p>
<p>Once you’ve separated the objective from the implementation, you’re free to bring all the capabilities of the 8088 — in their limitless combinations and permutations — to bear in designing the implementation, rather than the limited subset of programming techniques you’ve grown accustomed to using. This is one of the areas in which assembler programmers have a vast advantage over compilers, which can use only the small and inflexible set of techniques their designers built in. Compilers operate by translating human-oriented languages to machine language along a few fixed paths; there’s no way such a rigid code-generation mechanism can properly address the boundless possibilities of the 8088.</p>
<p>Of course, separating the objective and the implementation is more easily said than done, especially given an instruction set in which almost every instruction seems to have been designed for a specific purpose. For example, it’s hard not to think of the <code class="sourceCode nasm"><span class="kw">loop</span></code> instruction when you need to exclusive-or together all the bytes in a block of memory 64 bytes long, and do so as quickly as possible. (Such a cumulative exclusive-or might be used as a check against corrupted data in a block of data about to be transmitted or stored. The speed at which the cumulative exclusive-or could be generated might well determine the maximum error-checked transfer rate supported by the program.)</p>
<p>In this case, as in many others, the objective — a fast cumulative exclusive-or — and the implementation — 64 loops by way of the <code class="sourceCode nasm"><span class="kw">loop</span></code> instruction, with each loop exclusive-oring 1 byte into the cumulative result — are inseparable to the experienced non-Zen programmer.</p>
<p>Why? Consider the solution shown in <a href="#listing-13-1">Listing 13-1</a>. <a href="#listing-13-1">Listing 13-1</a> is obviously well-matched to the task of generating the cumulative exclusive-or for a block of 64 bytes. In fact, it’s so well-matched that few programmers would even contemplate alternatives. The code in <a href="#listing-13-1">Listing 13-1</a> works, it’s easy to write, and it runs in just 503 us. Surely that’s just about as fast as the 8088 can manage to perform this task — after all, the loop involves just three instructions: one <code class="sourceCode nasm"><span class="kw">lodsb</span></code> (string instructions are the fastest around), one register-register <code class="sourceCode nasm"><span class="kw">xor</span></code> (register-register instructions are short and fast), and one <code class="sourceCode nasm"><span class="kw">loop</span></code> (the 8088’s special, fast looping instruction). Who would ever think that performance could be nearly doubled by literally duplicating the code inside the loop 64 times and executing that code sequentially — thereby eliminating branching <em>entirely</em>?</p>
<p>Only a Zen programmer would even consider the possibility, for not-branching simply has no counterpart in non-Zen programming. Not-branching just plain feels <em>wrong</em> at first to any programmer raised on high-level languages. Not-branching goes against the grain and intent of both the 8088 instruction set and virtually all computer-science teachings and high-level languages. That’s only to be expected; language designers and computer-science teachers are concerned with the form of programs, for they’re most interested in making programming more amenable to people — that is, matching implementations to the way people think.</p>
<p>By contrast, Zen programmers are concerned with the functionality of programs. Zen programmers focus on performance and/or program size, and are most interested in matching implementations to the way <em>computers</em> think. The desired application is paramount, but the true Zen comes in producing the necessary result (the functionality) in the best possible way given the computer’s resources.</p>
<p>Zen programmers understand that the objective in generating the cumulative exclusive-or of 64 bytes actually has nothing whatsoever to do with looping. The objective is simply to exclusive-or together the 64 bytes in whatever way the PC can most rapidly accomplish the task, and looping is just one of many possible means to that end. Most programmers have seen and solved similar problems so many times, however, that they instinctively — almost unconsciously — select the <code class="sourceCode nasm"><span class="kw">loop</span></code> instruction from their bag of tricks the moment they see the problem. To these programmers, repetitive processing and <code class="sourceCode nasm"><span class="kw">loop</span></code> are synonymous.</p>
<p>Zen programmers have a bigger bag of tricks, however, and a more flexible view of the world. <a href="#listing-13-2">Listing 13-2</a> shows a Zen solution to the array-sum problem. <a href="#listing-13-2">Listing 13-2</a> performs no branches at all, thanks to the use of in-line code, which we’ll discuss in detail later in this chapter.</p>
<p>Functionally, there’s not much difference between <a href="#listing-13-1">Listings 13-1</a> and <a href="#listing-13-2">13-2</a>. Both listings leave the same cumulative result in AH, leave the same value in SI, and even leave the flags set to the same values. <a href="#listing-13-1">Listing 13-1</a> leaves CX set to zero, while <a href="#listing-13-2">Listing 13-2</a> doesn’t touch CX, but that’s really a point in the favor of <a href="#listing-13-2">Listing 13-2</a>, and could in any case be remedied simply by placing a <code class="sourceCode nasm"><span class="kw">sub</span> <span class="kw">cx</span>,<span class="kw">cx</span></code> at the start of <a href="#listing-13-2">Listing 13-2</a> if necessary.</p>
<p>No, there’s not much to choose from between the two listings… until you see them in action. <a href="#listing-13-2">Listing 13-2</a> calculates the 64-byte cumulative exclusive-or value in just 275 us — more than 82% faster than <a href="#listing-13-1">Listing 13-1</a>. A 5% increase might not be worth worrying about, but we’re talking about nearly <em>doubling</em> the performance of a well-coded three-instruction loop! Clearly, there’s something to this business of Zen programming.</p>
<p>You may object that <a href="#listing-13-2">Listing 13-2</a> is many bytes longer than <a href="#listing-13-1">Listing 13-1</a>, and indeed it is: 184 bytes, to be exact. If you need speed, though, a couple of hundred bytes is a small price to pay for nearly doubling performance — certainly preferable to requiring a more powerful (and expensive) processor, such as an 80286. You may also object that <a href="#listing-13-2">Listing 13-2</a> can only handle blocks that are exactly 64 bytes in length, while the loop in <a href="#listing-13-1">Listing 13-1</a> can be made to handle blocks of any size simply by loading CX with different values. That, too, is true… but you’re missing the point.</p>
<p><a href="#listing-13-2">Listing 13-2</a> is constructed to meet a specific goal as well as possible on the PC. If the goal was different, then <a href="#listing-13-2">Listing 13-2</a> would be different. If blocks of different sizes were required, then we would modify our approach accordingly, possibly by jumping into the series of exclusive-or operations at the appropriate place. If space was tight, perhaps we would use partial in-line code (which we’ll discuss later in this chapter), combining the space-saving qualities of loops with the speed of in-line code. If space was at a premium and performance was not an issue, we might well decide that <code class="sourceCode nasm"><span class="kw">loop</span></code> was the best solution after all. The point is that the Zen programmer has a wide range of approaches to choose from, and in most cases at least one of those choices will handily outperform any standard, one-size-fits-all solution.</p>
<p>In the context of not-branching (which is after all how we got into all this), Zen programming means replicating the functionality of branches without branching. That’s certainly not a goal we’d want to achieve all the time — in many cases branches really are the best (or only) choice — but you’ll be surprised at how often it’s possible to find good substitutes for branches in time-critical code.</p>
<p>For all their reputation as number-crunching machines, computers typically spend most of their time moving data, scanning data, and branching. In the Chapters 10 and 11 we learned how to minimize the time spent moving and scanning data. Now we’re going to attack the other part of the performance equation by learning how to minimize branching.</p>
</section>
<section id="rep-looping-without-branching" class="level2">
<h2><code>rep</code>: Looping Without Branching</h2>
<p>It’s a popular misconception that <code class="sourceCode nasm"><span class="kw">loop</span></code> is the 8088’s fastest instruction for looping. Not so. In truth, it’s <code class="sourceCode nasm">rep</code> that supports far and away the most powerful looping possible on the 8088. In Chapters 10 and 11 we saw again and again that repeated string instructions perform repetitive tasks much, much faster than normal loops do. Not only do repeated string instructions not empty the prefetch queue on every repetition as <code class="sourceCode nasm"><span class="kw">loop</span></code> and other branching instructions do, but they actually eliminate the prefetch queue cycle-eater altogether, since no instruction fetching at all is required while a string instruction repeats.</p>
<p>As we saw in Chapter 9, shifts and rotates by CL also eliminate the prefetch queue cycle-eater, although those instructions don’t pack quite the punch that repeated string instructions do, both because they perform relatively specialized tasks and because there’s not much point to repeating a shift or rotate more than 16 times.</p>
<p>We’ve already discussed repeated string instructions and repeated shifts and rotates in plenty of detail, so I’m not going to spend much more time on them here. However, I would like to offer one hint about using shifts and rotates by CL. As we found in Chapter 9, repeated shifts and rotates are generally faster than individual shifts and rotates when a shift or rotate of 3 or more bits is required. Repeated shifts and rotates are also <em>much</em> faster than shifting 1 bit at a time in a loop; the sequence:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="fu">BitShiftLoop:</span>
    <span class="kw">shr</span>   <span class="kw">ax</span>,<span class="dv">1</span>
    <span class="kw">loop</span>  BitShiftLoop</code></pre>
<p>is far inferior to <code class="sourceCode nasm"><span class="kw">shr</span> <span class="kw">ax</span>,<span class="kw">cl</span></code>.</p>
<p>Nonetheless, repeated shifts and rotates still aren’t <em>fast</em> — instead, you might think of them as less slow than the alternatives. It’s easy to think that shifts and rotates by CL are so fast that they can be used with impunity, since they avoid looping and prefetching, but that’s just not true. A repeated shift or rotate takes 8 cycles just to start, and then takes 4 cycles per bit shifted. Even a 4-bit shift by CL takes 24 cycles, which is not insignificant, and a 16-bit shift by CL takes a full 72 cycles. Use shifts and rotates by CL sparingly, and keep them out of loops whenever you can. Look-up tables, our next topic, are often a faster alternative to multi-bit shifts and rotates.</p>
</section>
<section id="look-up-tables-calculating-without-branching" class="level2">
<h2>Look-Up Tables: Calculating Without Branching</h2>
<p>Like the use of repeated string instructions, the use of look-up tables is a familiar technique that can help avoid branching. Whenever you’re using branching code to perform a calculation, see if you can’t use a look-up table instead; tight as your branching code may be, look-up tables are usually faster still. <a href="#listing-11-26">Listings 11-26</a> and <a href="#listing-11-27">11-27</a> pit a five-instruction sequence that branches no more than once against an equivalent table look-up; you can’t get branching code that’s much tighter than that, and yet the table look-up is much faster.</p>
<p>In short, if you have a calculation to make — even a simple one — see if it isn’t faster to precalculate the answer at assembly time and just look it up at run time.</p>
</section>
<section id="take-the-branch-less-travelled-by" class="level2">
<h2>Take the Branch Less Travelled By</h2>
<p>One of the best ways to avoid branching is to arrange your code so that conditional jumps rarely jump. Usually you can guess which way a given conditional test will most often go, and if that’s the case, you can save a good deal of branching simply by arranging your code so that the conditional jump will fall through — that is, not branch — in the more common case. Sometimes the choice is made on the basis of which case is most time-critical rather than which is most common, but the principle remains the same.</p>
<p>Why is it that falling through conditional jumps is desirable? Simple: none of the horrendous speed loss associated with branching applies to conditional jumps that fall through, <em>because conditional jumps don’t branch when they fall through</em>.</p>
<p>Let’s look at the statistics. It always takes a conditional jump at least 16 cycles to branch, and the total cost in cycles is usually somewhat greater because the prefetch queue is emptied. On the other hand, it takes a conditional jump a maximum of just 8 cycles <em>not</em> to jump, that being the case if the prefetch queue is empty and both bytes of the instruction must be fetched before they can be executed. The official execution time of a conditional jump that doesn’t branch is just 4 cycles, so it is particularly fast to fall through a conditional jump if both bytes of the instruction are waiting in the prefetch queue when it comes time to execute them.</p>
<p>In other words, falling through a conditional jump can be anywhere from 100% to 700% faster than branching, depending on the exact state and behavior of the prefetch queue. As you might imagine, it’s worth going out of your way to reap cycle savings of that magnitude… and that’s why you should arrange your conditional jumps so that they fall through as often as possible.</p>
<p>For example, you’ll recall that in Chapter 11 — in <a href="#listing-11-20">Listing 11-20</a>, to be precise — we tested several characters for inclusion in a small set via repeated <code class="sourceCode nasm"><span class="kw">cmp</span></code>/<code class="sourceCode nasm"><span class="kw">jz</span></code> instruction pairs. We arranged the conditional jumps so that a jump occurred only when a match was made, meaning that at most one branch was performed during any given inclusion test. Put another way, we branched out of the main stream of the subroutine on the less common condition.</p>
<p>You may not have thought much of it at the time, but the arrangement of branches in <a href="#listing-11-20">Listing 11-20</a> was no accident. Tests for four potential matches are involved when testing for inclusion in a set of four characters, and no more than one of those matches can occur during any given test. Given an even distribution of match characters, matching is clearly less common than not matching. If we jumped whenever we <em>didn’t</em> get a match (the more common condition), we’d end up branching as many as three times during a single test, with significantly worse performance the likely result.</p>
<p><a href="#listing-13-3">Listing 13-3</a> shows <a href="#listing-11-20">Listing 11-20</a> modified to branch on non-matches rather than matches. The original branch-on-match version ran in 119 us, and, as predicted, that’s faster than <a href="#listing-13-3">Listing 13-3</a>, which runs in 133 us. That’s not the two-or three-times performance improvement we’ve grown accustomed to seeing (my, how jaded we’ve become!), but it’s significant nonetheless, especially since we’re talking about a very small number of conditional jumps. We’d see a more dramatic difference if we were dealing with a long series of tests.</p>
<p>Another relevant point is that the <em>worst-case</em> performance of <a href="#listing-13-3">Listing 13-3</a> is much worse than that of Listing 11-20. <a href="#listing-13-3">Listing 13-3</a> actually has a shorter best-case time than <a href="#listing-11-20">Listing 11-20</a>, because no branches at all are performed when the test character is ‘A’. On the other hand, <a href="#listing-13-3">Listing 13-3</a> performs three branches when the test character is ‘!’ or is not in the set, and that’s two branches more than <a href="#listing-11-20">Listing 11-20</a> ever performs. When you’re trying to make sure that code always responds within a certain time, worst-case performance can matter more than average performance.</p>
<p>Then, too, if the characters tested are often not in the set, as may well be the case with such a small set, the branching-out approach of <a href="#listing-11-20">Listing 11-20</a> will far outperform the branch-branch-branch approach of <a href="#listing-13-3">Listing 13-3</a>. When <a href="#listing-11-20">Listing 11-20</a> is modified so that none of the five test characters is in the set, its overall execution time scarcely changes, rising by just 8 us, to 127 us. When <a href="#listing-13-3">Listing 13-3</a> is modified similarly, however, its overall execution time rises by a considerably greater amount — 26 us — to 159 us. This neatly illustrates the potential worst-case problem of repeated branching that we just discussed.</p>
<p>There are two lessons here. The first and obvious lesson is that you should arrange your conditional jumps so that they fall through as often as possible. The second lesson is that you must understand the conditions under which your code will operate before you can truly optimize it.</p>
<p>For instance, there’s no way you can evaluate the relative merits of the versions of <code class="sourceCode nasm">CheckTestSetInclusion</code> in <a href="#listing-11-20">Listings 11-20</a> and <a href="#listing-13-3">13-3</a> until you know the mix of characters that will be tested. There’s no such beast as an absolute measure of code speed, only code speed in context. You’ve heard that before as it relates to instruction mix and the prefetch queue, but here we’re dealing with a different aspect of performance. What I mean now is that you must understand the typical and worst-case conditions under which a block of code will run before you can get a handle on its performance and consider possible alternatives.</p>
<p>Your ability to understand and respond to the circumstances under which your assembler code will run gives you a big leg up on high-level language compilers. There’s no way for a compiler to know the typical and/or worst-case conditions under which code will run, let alone which of those conditions is more important in your application.</p>
<p>For instance, suppose that we have one loop which repeats 10 times on average and another loop which repeats 10000 times on average, with both loops executed a variable (not constant) number of times. A C compiler couldn’t know that cycles saved in the second loop would have a 1000-times-greater payoff than cycles saved in the first loop, so it would have to approach both loops in the same way, generating the same sort of code in both cases. What this means is that compiled code is designed for reasonable performance under all conditions… hardly the ticket for greatness.</p>
<section id="put-the-load-on-the-unimportant-case" class="level3">
<h3>Put the Load on the Unimportant Case</h3>
<p>When arranging branching code to branch on the less critical case, don’t be afraid to heap the cycles on that case if that will help the more critical case.</p>
<p>For example, suppose that you need to test whether CX is zero at the start of a long subroutine and return if CX is in fact zero. You’d normally do that with something like:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">LongSubroutine  proc  near
    <span class="kw">jcxz</span>  LongSubroutineEnd
          :
<span class="co">; *** Body of subroutine ***</span>
          :
<span class="fu">LongSubroutineEnd:</span>
    <span class="kw">ret</span>
LongSubroutine  endp</code></pre>
<p>Now, however, assume that the body of the subroutine is more than 127 bytes long. In that case, the 1-byte displacement of <code class="sourceCode nasm"><span class="kw">jcxz</span></code> can’t reach <code class="sourceCode nasm">LongSubroutineEnd</code>, so the last bit of code won’t work.</p>
<p>Well, then, the obvious alternative is:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">LongSubroutine  proc  near
    <span class="kw">and</span>   <span class="kw">cx</span>,<span class="kw">cx</span>
    <span class="kw">jnz</span>   DoLongSubroutine
    <span class="kw">jmp</span>   LongSubroutineEnd
<span class="fu">DoLongSubroutine:</span>
          :
<span class="co">; *** Body of subroutine ***</span>
          :
<span class="fu">LongSubroutineEnd:</span>
    <span class="kw">ret</span>
LongSubroutine  endp</code></pre>
<p>There’s a problem here, though. Every time CX <em>isn’t</em> zero we end up branching, and that’s surely wrong. The case where CX is zero is most likely rare, and is probably of no real interest to us anyway, since it’s a do-nothing case for the subroutine. (At any rate, for the purposes of this example we’ll assume that the CX equal to 0 case is rare and uninteresting.) What’s more, whether the CX equal to 0 case is rare or not, the body of the subroutine is skipped when CX is 0, so that case is bound to be much faster than the other cases. That means that the CX equal to zero case is not only unimportant, but also doesn’t affect the worst-case performance of the subroutine. Yet here we are, adding an extra branch to every single invocation of this subroutine simply to protect against the quick and unimportant case of CX equal to zero.</p>
<p>The tail is wagging the dog.</p>
<p>Instead, let’s heap the branches on the CX equal to zero case, sparing the other, more important cases as much as possible. One solution is:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">LongSubroutineExit  proc  near
    <span class="kw">ret</span>
LongSubroutineExit  endp
<span class="co">;</span>
LongSubroutine      proc  near
    <span class="kw">jcxz</span>  LongSubroutineExit
          :
<span class="co">; *** Body of subroutine ***</span>
          :
    <span class="kw">ret</span>
LongSubroutine      endp</code></pre>
<p>This restores the code to its original, saner state, where the shortest possible time — 6 cycles for a single <code class="sourceCode nasm"><span class="kw">jcxz</span></code> that falls through — is used to guard against the case of CX equal to zero.</p>
<p>If you prefer that your subroutines be exited only from the end, as is for example necessary when a stack frame must be deallocated, there’s another solution:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">LongSubroutineExit  proc  near
    <span class="kw">jmp</span>   LongSubroutineEnd
LongSubroutineExit  endp
<span class="co">;</span>
LongSubroutine      proc  near
    <span class="kw">jcxz</span>  LongSubroutineExit
          :
<span class="co">; *** Body of subroutine ***</span>
          :
<span class="fu">LongSubroutineEnd:</span>
    <span class="kw">ret</span>
LongSubroutine      endp</code></pre>
<p>Now we’ve <em>really</em> put the load on the CX equal to zero case, for two branches must be performed in that case. So what? As far as we’re concerned, the CX equal to zero case can take as long as it pleases, so long as it doesn’t slow down the real work of the subroutine, which is done when CX isn’t equal to zero.</p>
</section>
</section>
<section id="yes-virginia-there-is-a-faster-32-bit-negate" class="level2">
<h2>Yes, Virginia, There <em>Is</em> a Faster 32-Bit Negate!</h2>
<p>In Chapter 9 we came across an extremely fast and compact way to negate 32-bit values, as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">neg</span>   <span class="kw">dx</span>
<span class="kw">neg</span>   <span class="kw">ax</span>
<span class="kw">sbb</span>   <span class="kw">dx</span>,<span class="dv">0</span></code></pre>
<p>This very short sequence involves two register-only negations, one constant-from-register subtraction — and no branches. At the time, I told you that, fast as that code was, at some later point we’d run across a still faster way to negate a 32-bit value.</p>
<p>That time has come. Incredibly, we’re going to speed up 32-bit negates by using a branching instruction. Yes, I know that I’ve been telling you to avoid branching like the plague, but there’s a trick here: we’re not really going to branch. The branching instruction we’re going to use is a conditional jump, and we’re going to fall through the jump almost every time.</p>
<p>There’s a bit of history to this trick, and it’s worth reviewing for the lesson about the Zen of assembler it contains. The story goes as follows:</p>
<p>Having worked out to my satisfaction how the above 32-bit negation worked, I (somewhat egotistically, I admit) asked Dan Illowsky if <em>he</em> knew how to negate a 32-bit value in three instructions.</p>
<p>Well, it took him a while, but he did come up with a working three-instruction solution. Interestingly enough, it wasn’t the solution I had found. Instead, he derived the second solution I mentioned in Chapter 9:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">not</span>   <span class="kw">dx</span>
<span class="kw">neg</span>   <span class="kw">ax</span>
<span class="kw">sbb</span>   <span class="kw">dx</span>,-<span class="dv">1</span></code></pre>
<p>This solution is equivalent to the first solution in functionality, length, and cycle count.</p>
<p>That’s not the end of the tale, however. Taken aback because Dan had come up with a different and equally good solution (demonstrating that my solution wasn’t so profound after all), I commented that while he had managed to <em>match</em> my solution, he surely could never <em>surpass</em> it.</p>
<p><em>Ha!</em></p>
<p>If there’s one word that should set any Zen programmer off like a rocket, it’s “never.” The 8088 instruction set is so rich and varied that there are dozens of ways to do just about anything. For any but the simplest task several of those approaches — and not necessarily the obvious ones — are bound to be good. Whenever you think that you’ve found the best possible solution for anything more complex than incrementing a register, you’re most likely in for a humbling experience.</p>
<p>At any rate, “never” certainly set Dan off. He got a thoughtful look on his face, walked off, and came back five minutes later with a faster implementation. Here it is:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">not</span>   <span class="kw">dx</span>
    <span class="kw">neg</span>   <span class="kw">ax</span>
    <span class="kw">jnc</span>   Negate32BitsCarry
<span class="fu">Negate32BitsDone:</span>
          :
<span class="fu">Negate32BitsIncDX:</span>
    <span class="kw">inc</span>   <span class="kw">dx</span>
    <span class="kw">jmp</span>   <span class="dt">short</span> Negate32BitsDone</code></pre>
<p>where the code at <code class="sourceCode nasm">Negate32BitsCarry</code> is somewhere — anywhere — within a 1-byte displacement (+127 to -128 bytes) of the byte after the <code class="sourceCode nasm"><span class="kw">jnc</span></code> instruction.</p>
<p>It may not <em>look</em> like working 32-bit negation code, but working code it is, believe me. <em>Brilliant</em> working code.</p>
<section id="how-32-bit-negation-works" class="level3">
<h3>How 32-Bit Negation Works</h3>
<p>In order to understand the brilliance of Dan’s code, we first need to get a firm grasp on the mechanics of 32-bit negation. The basic principle of two’s complement negation is that the value to be negated is first notted (that is, all its bits are flipped, from 1 to 0 or 0 to 1), and then incremented. For a 32-bit value stored in DX:AX, negation would ideally follow one of the two sequences shown in Figure 13.1, with all operations performed 32 bits at a time.</p>
<figure>
<img src="images/fig13.1RT.png" />
</figure>
<p>Unfortunately, the 8088 can only handle data 16 bits at a time, so we must perform negation with a series of 16-bit operations like:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">not</span>   <span class="kw">dx</span>
<span class="kw">neg</span>   <span class="kw">ax</span>
<span class="kw">sbb</span>   <span class="kw">dx</span>,-<span class="dv">1</span></code></pre>
<p>as shown in Figure 13.2.</p>
<figure>
<img src="images/fig13.2RT.png" />
</figure>
<p>The purpose of the first operation, notting DX with the <code class="sourceCode nasm"><span class="kw">not</span></code> instruction, is obvious enough: flipping all the bits in the high word of the value. The purpose of the second operation, negating AX, is equally obvious: negating the low word of the value with the <code class="sourceCode nasm"><span class="kw">neg</span></code> instruction, which both nots AX and increments it all at once.</p>
<p>After two instructions, we’ve successfully notted the entire 32-bit value in DX:AX, and we’ve incremented AX as well. All that remains to be done is to complete the full 32-bit increment by incrementing DX if necessary.</p>
<p>When does DX need to be incremented? In one case only — when AX is originally 0, is notted to 0FFFFh, and is incremented back to 0, with a carry out from bit 15 of AX indicating that AX has turned over to 0 and so the notted value in DX must be incremented as well, as shown in Figure 13.3.</p>
<figure>
<img src="images/fig13.3RT.png" />
</figure>
<p>In all other cases, incrementing the 32-bit notted value in DX:AX doesn’t alter DX at all, since incrementing AX doesn’t cause a carry out of bit 15 unless AX is 0FFFFh.</p>
<p>However, due to the way that <code class="sourceCode nasm"><span class="kw">neg</span></code> sets the Carry flag (as if subtraction from zero had occurred), the Carry flag is set by <code class="sourceCode nasm"><span class="kw">neg</span></code> in all cases <em>except</em> the one case in which DX needs to be incremented. Consequently, after <code class="sourceCode nasm"><span class="kw">neg</span> <span class="kw">ax</span></code> we subtract -1 from DX with borrow, with the 1 value of the Carry flag normally offsetting the -1, resulting in a subtraction of 0 from DX. In other words, DX remains unchanged when <code class="sourceCode nasm"><span class="kw">neg</span> <span class="kw">ax</span></code> sets the Carry flag to 1, which is to say in all cases except when AX is originally zero. That’s just what we want; in all those cases the 32-bit negation was actually complete after the first two instructions, since the increment of the notted 32-bit value doesn’t affect DX, as shown in Figure 13.4.</p>
<figure>
<img src="images/fig13.4RT.png" />
</figure>
<p>In the case where AX is originally 0, on the other hand, <code class="sourceCode nasm"><span class="kw">neg</span> <span class="kw">ax</span></code> doesn’t set the Carry flag. This is the one case in which DX must be incremented. In this one case only, <code class="sourceCode nasm"><span class="kw">sbb</span> <span class="kw">dx</span>,-<span class="dv">1</span></code> succeeds in subtracting -1 from DX, since the Carry flag is 0. Again, that’s what we want; in this one case DX is affected when the 32-bit value is incremented, and so incrementing DX completes the 32-bit negation, as shown in Figure 13.5.</p>
<figure>
<img src="images/fig13.5RT.png" />
</figure>
</section>
<section id="how-fast-32-bit-negation-works" class="level3">
<h3>How Fast 32-Bit Negation Works</h3>
<p>Now that we understand what our code has to do, we’re in a position to think about optimizations. We’ll do just what Dan did — look at negation from a functional perspective, understanding exactly what needs to be done and tailoring our code to do precisely that and nothing more.</p>
<p>The breakthrough in Dan’s thinking was the realization that DX only needs to be incremented when AX originally was 0, which normally happens only once in a blue moon (once out of every 64 K evenly-distributed values, to be exact). For all other original values of AX, the bits in DX simply flip in the process of 32-bit negation, and nothing more needs to be done to DX after the initial <code class="sourceCode nasm"><span class="kw">not</span></code>. As we found above, the 32-bit negation is actually complete after the first two instructions for 64 K-1 out of every 64 K possible values to be negated, with the final <code class="sourceCode nasm"><span class="kw">sbb</span></code> almost always leaving DX unchanged.</p>
<p>Improving the code is easy once we’ve recognized that the first two instructions usually complete the 32-bit negation. The only question is how to minimize the overhead taken to check for the rare case in which DX needs to be incremented. A once-in-64 K-times case is more than rare enough to absorb a few extra cycles, so we’ll branch out to increment DX in the case where it needs to be adjusted. The payoff for branching in that one case is that in all other cases a 3-byte, 4-cycle <code class="sourceCode nasm"><span class="kw">sbb</span></code> instruction is replaced by a 2-byte, 4-cycle fall-through of <code class="sourceCode nasm"><span class="kw">jnc</span></code>. In tight code, the 1-byte difference will usually translate into 4 cycles, thanks to the prefetch queue cycle-eater.</p>
<p>Essentially, <code class="sourceCode nasm"><span class="kw">jnc</span></code> is a faster way of doing nothing in the 64 K-1 cases where DX:AX already contains the negated value than <code class="sourceCode nasm"><span class="kw">sbb</span> <span class="kw">dx</span>,-<span class="dv">1</span></code> is. Granted, <code class="sourceCode nasm"><span class="kw">jnc</span></code> is also a slower way of incrementing DX in the one case where that’s necessary, but that’s so infrequent that we can readily trade those extra cycles for the cycles we save on the other cases.</p>
<p>Let’s try out the two 32-bit negates to see how they compare in actual use. <a href="#listing-13-4">Listing 13-4</a>, which uses the original nonbranching 32-bit negation code, runs in 2264 us. <a href="#listing-13-5">Listing 13-5</a>, which uses the branch-on-zero-AX approach to 32-bit negation, runs in 2193 us. A small improvement, to be sure — but it is nonetheless an improvement, and since the test code’s 100:1 ratio of zero to non-zero values is much less than the real world’s ratio of 64 K-1:1 (assuming evenly distributed values), the superiority of the branch-on-zero-AX approach is somewhat greater than this test indicates.</p>
<p>By itself, speeding the negation of 32-bit values by a few cycles isn’t particularly noteworthy. On the other hand, you must surely realize that if it was possible to speed up even the three-instruction, non-branching sequence that we started off with, then it must be possible to speed up just about any code, and that perception is important indeed.</p>
<p>Code for almost <em>any</em> task can be implemented in many different ways, and can in the process usually be made faster than it currently is. It’s not always worth the cost in programming time and/or bytes to speed up code — you must pick your spots carefully, concentrating on loops and other time-critical code — but it can almost always be done. The key to improved performance lies in understanding exactly what the task at hand requires and understanding the context in which the code performs, and then matching that understanding to the resources of the PC.</p>
<p>My own experience is that no matter how many times I study a time-critical sequence of, say, 20-100 instructions, I can always save at least a few more cycles — and sometimes many more — by viewing the code differently and reworking it to match the capabilities of the 8088 more closely. That’s why way back in Chapter 2 I said that “optimize”was not a word to be used lightly. When programming in assembler for the PC, only fools and geniuses consider their code optimized. As for the rest of us… well, we’ll just have to keep working on our time-critical code, trying new approaches and timing the results, with the attitude that our code is good and getting better.</p>
<p>And have we finally found the fastest possible code for 32-bit negation, never to be topped? Lord knows I don’t expect to come across anything faster in the near future. But <em>never</em>?</p>
<p>Don’t bet on it.</p>
</section>
</section>
<section id="arrange-your-code-to-eliminate-branches" class="level2">
<h2>Arrange Your Code to Eliminate Branches</h2>
<p>There are many, many ways to arrange your code to eliminate branches. I’m going to discuss a few here, but don’t consider this to be anything like an exhaustive list. Whenever you use branching instructions where performance matters, take it as a challenge to arrange those instructions for maximum performance and minimum code size.</p>
<section id="preloading-the-less-common-case" class="level3">
<h3>Preloading the Less Common Case</h3>
<p>One of my favorite ways to eliminate jumps comes up when a register must be set to one of two values based on a test condition. For example, suppose that we want to set AL to 0 if DL is less than or equal to 10, and set AL to 1 if DL is greater than 10.</p>
<p>The obvious solution is:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">cmp</span>   <span class="kw">dl</span>,<span class="dv">10</span>             <span class="co">;is DL greater than 10?</span>
    <span class="kw">ja</span>    DLGreaterThan10   <span class="co">;yes, so set AL to 1</span>
    <span class="kw">sub</span>   <span class="kw">al</span>,<span class="kw">al</span>             <span class="co">;DL is less than or equal to 10</span>
    <span class="kw">jmp</span>   <span class="dt">short</span> DLCheckDone
<span class="fu">DLGreaterThan10:</span>
    <span class="kw">mov</span>   <span class="kw">al</span>,<span class="dv">1</span>              <span class="co">;DL is greater than 10</span>
<span class="fu">DLCheckDone:</span></code></pre>
<p>Here we either branch or don’t branch to reach the code that sets AL to the appropriate value; after setting AL, we rejoin the main flow of the code, branching if necessary. Whether DL is greater than 10 or not, a branch is always performed.</p>
<p>Now let’s try this out:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">sub</span>   <span class="kw">al</span>,<span class="kw">al</span>         <span class="co">;assume DL will not be greater than 10</span>
    <span class="kw">cmp</span>   <span class="kw">dl</span>,<span class="dv">10</span>         <span class="co">;is DL greater than 10?</span>
    <span class="kw">jbe</span>   DLCheckDone   <span class="co">;no, so AL is already correct</span>
    <span class="kw">mov</span>   <span class="kw">al</span>,<span class="dv">1</span>          <span class="co">;DL is greater than 10</span>
<span class="fu">DLCheckDone:</span></code></pre>
<p>Here we’ve loaded AL with one of the two possible results <em>before</em> the test. In one of the two possible cases, we’ve guessed right and AL is already correct, so a single branch ends the test-and-set code. In the other possible case, we’ve guessed wrong, so the conditional jump falls through and AL is set properly. (By the way, <code class="sourceCode nasm"><span class="kw">inc</span> <span class="kw">ax</span></code> would be faster than and logically equivalent to <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,<span class="dv">1</span></code> in the above code. Right now, though, we’re focusing on a different sort of optimization, and I’ve opted for clarity rather than maximum speed; I also want you to see that the preload approach is inherently faster, whether or not tricks like <code class="sourceCode nasm"><span class="kw">inc</span> <span class="kw">ax</span></code> are used.)</p>
<p>I’ll admit that it’s more than a little peculiar to go out of our way to set AL twice in some cases; the previous example set AL just once per test-and-set, and that would logically seem to be the faster approach. While we sometimes set AL an extra time with the preload approach, however, we also avoid a good bit of branching, and that’s more than enough to compensate for the extra times AL is set.</p>
<p>Consider this. If DL is less than or equal to 10, then the first example (the “normal” test-and-branch code) performs a <code class="sourceCode nasm"><span class="kw">cmp</span> <span class="kw">dl</span>,<span class="dv">10</span></code> (4 cycles/2 bytes), a <code class="sourceCode nasm"><span class="kw">ja</span> DLGreaterThan10</code> that falls through (4 cycles/2 bytes), a <code class="sourceCode nasm"><span class="kw">sub</span> <span class="kw">al</span>,<span class="kw">al</span></code> (3 cycles/2 bytes), and a <code class="sourceCode nasm"><span class="kw">jmp</span> <span class="dt">short</span> DLCheckDone</code> (15 cycles/2 bytes). The grand total: 26 cycles, 8 instruction bytes and one branch, as shown in Figure 13.6a.</p>
<figure>
<img src="images/fig13.6RT.png" />
</figure>
<p>On the other hand, the preload code of the second example handles the same case with a <code class="sourceCode nasm"><span class="kw">sub</span> <span class="kw">al</span>,<span class="kw">al</span></code> (3 cycles/2 bytes), a <code class="sourceCode nasm"><span class="kw">cmp</span> <span class="kw">dl</span>,<span class="dv">10</span></code> (4 cycles/2 bytes), and a <code class="sourceCode nasm"><span class="kw">jbe</span> DLCheckDone</code> that branches (16 cycles/2 bytes). The total: 23 cycles, 6 instruction bytes and one branch, as shown in Figure 13.7a.</p>
<figure>
<img src="images/fig13.7RT.png" />
</figure>
<p>That’s not much faster than the normal approach, but it is faster.</p>
<p>Now let’s look at the case where DL is greater than 10. Here the test-and-branch code of the first example performs a <code class="sourceCode nasm"><span class="kw">cmp</span> <span class="kw">dl</span>,<span class="dv">10</span></code> (4 cycles/2 bytes), a <code class="sourceCode nasm"><span class="kw">ja</span> DLGreaterThan10</code> that branches (16 cycles/2 bytes), and a <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,<span class="dv">1</span></code> (4 cycles/2 bytes), for a total of 24 cycles, 6 instruction bytes and one branch, as shown in Figure 13.6b.</p>
<p>The preload code of the second example handles the same DL greater than 10 case with a <code class="sourceCode nasm"><span class="kw">sub</span> <span class="kw">al</span>,<span class="kw">al</span></code> (3 cycles/2 bytes), a <code class="sourceCode nasm"><span class="kw">cmp</span> <span class="kw">dl</span>,<span class="dv">10</span></code> (4 cycles/2 bytes), a <code class="sourceCode nasm"><span class="kw">jbe</span> DLCheckDone</code> that doesn’t branch (4 cycles/2 bytes), and a <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,<span class="dv">1</span></code> (4 cycles/2 bytes). The total: 8 instruction bytes -2 bytes more than the test-and-branch code — but just 15 cycles… <em>and no branches</em>, as shown in Figure 13.7b. The lack of a prefetch queue-flushing branch should more than compensate for the two additional instruction bytes that must be fetched.</p>
<p>In other words, the preload code is either 3 or 9 cycles faster than the more familiar test-and-branch code, is 2 bytes shorter overall, and sometimes branches less while never branching more. That’s a clean sweep for the preload code — all because always performing one extra register load made it possible to do away with a branch.</p>
<p>Let’s run the two approaches through the Zen timer. <a href="#listing-13-6">Listing 13-6</a>, which times the test-and-branch code when DL is 10 (causing AL to be set to 0), runs in 10.06 us per test-and-branch. By contrast, <a href="#listing-13-7">Listing 13-7</a>, which times the preload code for the same case, runs in just 8.62 us.</p>
<p>That’s a healthy advantage for the preload code, but perhaps things will change if we test a case where AL is set to 1, by altering <a href="#listing-13-6">Listings 13-6</a> and <a href="#listing-13-7">13-7</a> to set DL to 11 rather than 10 prior to the tests.</p>
<p>Things do indeed change when DL is set to 11. <a href="#listing-13-6">Listing 13-6</a> speeds up to 8.62 ms per test, matching the performance of <a href="#listing-13-7">Listing 13-7</a> when DL was 10. When DL is 11, however, <a href="#listing-13-7">Listing 13-7</a> speeds up to 8.15 us, again comfortably outperforming <a href="#listing-13-6">Listing 13-6</a>.</p>
<p>In short, the preload approach is superior in every respect. While it’s counterintuitive to think that by loading a register an extra time we can actually speed up code, it does work, and that sort of unorthodox but effective technique is what the Zen of assembler is all about.</p>
<p>A final note on the preload approach: arrange your preload code so that the more common case is <em>not</em> preloaded. Once again this is counterintuitive, since it seems that we’re going out of our way to guess wrong about the outcome of the test. Remember, however, that it’s much faster to fall through a conditional jump, and you’ll see why preloading the less common value makes sense. It’s actually faster to fall through the conditional jump and load a value than it is just to branch at the conditional jump, even if the correct value is already loaded.</p>
<p>The results from the two executions of <a href="#listing-13-7">Listing 13-7</a> confirm this. The case where the value preloaded into AL is correct actually runs a good bit more slowly than the case where the conditional jump falls through and a new value must be loaded.</p>
<p><em>Think of your assembler programs not just in terms of their logic but also in terms of how that logic can best be expressed</em> — <em>in terms of cycles and/or bytes</em> — <em>in the highly irregular language of the 8088</em>. The first example in this section — the “normal” approach — seems at first glance to be the ideal expression of the desired test-and-set sequence in 8088 assembler. However, the poor performance of branching instructions renders the normal approach inferior to the preload approach on the 8088, even though preloading is counter to common sense and most programming experience. In short, the best 8088 code can only be arrived at by thinking in terms of the 8088; superior 8088 solutions often seem to be lunacy in other logic systems.</p>
<p>Thinking in terms of the 8088 can be particularly difficult for those of us used to high-level languages, in which programs are pure abstractions far removed from the ugly details of the processor. When programming in a high-level language, it would seem to be faster to preload the correct value and test than to preload an incorrect value, test, and load the correct value. In fact, in any high-level language it would seem most efficient to use an <code>if...then...else</code> structure to handle a test-and-set case such as the one above.</p>
<p>That’s not the way it works on the 8088, though, because not all tests are created equal — tests that branch are much slower than tests that fall through. When you’re programming the 8088 in assembler, the maddening and fascinating capabilities of the processor must become part of your logic system, however illogical the paths down which that perspective leads may seem at times to be.</p>
</section>
<section id="use-the-carry-flag-to-replace-some-branches" class="level3">
<h3>Use the Carry Flag to Replace Some Branches</h3>
<p>Unlike the other flags, the Carry flag can serve as a direct operand to some arithmetic instructions, such as <code class="sourceCode nasm"><span class="kw">rcr</span></code> and <code class="sourceCode nasm"><span class="kw">adc</span></code>. This gives the Carry flag a unique property — it can sometimes be used to alter the value in a register conditionally <em>without branching</em>.</p>
<p>For instance, suppose that we want to count the number of negative values in a 1000-word array, maintaining the count in DX. One way to do this is shown in <a href="#listing-13-8">Listing 13-8</a>, which runs in 12.29 ms. In this code, each value is anded with itself. The resulting setting of the Sign flag indicates whether the value is positive or negative. With the help of a conditional jump, the Sign flag setting controls whether DX is incremented or not.</p>
<p>Speedy and compact as it is, <a href="#listing-13-8">Listing 13-8</a> <em>does</em> involve a conditional jump that branches about half the time… and by now you should be developing a distinct dislike for branching. By using the Carry flag to eliminate branching entirely, we can speed things up quite a bit.</p>
<p><a href="#listing-13-9">Listing 13-9</a> does just that, shifting the sign bit of each tested value into the Carry flag and then adding it — along with zero, since <code class="sourceCode nasm"><span class="kw">adc</span></code> requires two source operands — to DX, as shown in Figure 13.8. (Note that the constant zero is stored in BX for speed, since <code class="sourceCode nasm"><span class="kw">adc</span> <span class="kw">dx</span>,<span class="kw">bx</span></code> is 1 byte shorter and 1 cycle faster than <code class="sourceCode nasm"><span class="kw">adc</span> <span class="kw">dx</span>,<span class="dv">0</span></code>.) The result is that DX is incremented only when the sign bit of the value being tested is 1 — that is, only when the value being tested is negative, which is exactly what we want.</p>
<figure>
<img src="images/fig13.8RT.png" />
</figure>
<p><a href="#listing-13-9">Listing 13-9</a> runs in 10.80 ms. That’s about 14% faster than <a href="#listing-13-8">Listing 13-8</a>, even though the instruction that increments DX in <a href="#listing-13-9">Listing 13-9</a> (<code class="sourceCode nasm"><span class="kw">adc</span> <span class="kw">dx</span>,<span class="kw">bx</span></code>) is actually 1 byte longer and 1 cycle slower than its counterpart in <a href="#listing-13-8">Listing 13-8</a> (<code class="sourceCode nasm"><span class="kw">inc</span> <span class="kw">dx</span></code>). The key to the improved performance is, once again, avoiding branching. In this case that’s made possible by recognizing that a Carry flag-based operation can accomplish a task that we’d usually perform with a conditional jump. You wouldn’t normally think to substitute <code class="sourceCode nasm"><span class="kw">shl</span></code>/<code class="sourceCode nasm"><span class="kw">adc</span></code> for <code class="sourceCode nasm"><span class="kw">and</span></code>/<code class="sourceCode nasm"><span class="kw">jns</span></code>/<code class="sourceCode nasm"><span class="kw">inc</span></code> — they certainly don’t <em>look</em> the least bit similar — but in this particular context the two instruction sequences are equivalent.</p>
<p>The many and varied parts of the 8088’s instruction set are surprisingly interchangeable. Don’t hesitate to mix and match them in unusual ways.</p>
</section>
<section id="never-use-two-jumps-when-one-will-do" class="level3">
<h3>Never Use Two Jumps When One Will Do</h3>
<p>Don’t use a conditional jump followed by an unconditional jump when the conditional jump can do the job by itself. Generally, a conditional jump should only be paired with an unconditional jump when the 1-byte displacement of the conditional jump can’t reach the desired offset — that is, when the offset to be branched to is more than -128 to +127 bytes away.</p>
<p>For example:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">jz</span>  IsZero</code></pre>
<p>works fine unless <code class="sourceCode nasm">IsZero</code> is more than -128 or +127 bytes away from the first byte of the instruction immediately following the <code class="sourceCode nasm"><span class="kw">jz</span></code> instruction. (You’ll recall that we found in the last chapter that conditional jumps, like all jumps that use displacements, actually branch relative to the offset of the start of the following instruction.) If, however, <code class="sourceCode nasm">IsZero</code> <em>is</em> more than -128 or +127 bytes away, the polarity of the conditional jump must be reversed, and the conditional jump must be used to skip around the unconditional jump:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">jnz</span>   NotZero
    <span class="kw">jmp</span>   IsZero
<span class="fu">NotZero:</span></code></pre>
<p>When the conditional jump falls through (in the case that resulted in a branch in the first example), the 2-byte displacement of the unconditional jump can be used to jump to <code class="sourceCode nasm">IsZero</code> no matter where in the code segment <code class="sourceCode nasm">IsZero</code> may be.</p>
<p>Logically, the two examples we’ve just covered are equivalent, branching in exactly the same cases. There’s an obvious difference in the way the two examples <em>run</em>, though — the first example branches in only one of the two cases, while the second example always branches, and is larger too.</p>
<p>In this case, it’s pretty clear which is the code of choice (at least, I <em>hope</em> it is!) — you’d only use a conditional jump around an unconditional jump when a conditional jump alone can’t reach the target label. However, paired jumps can also be eliminated in a number of less obvious situations.</p>
<p>For example, suppose that you want to scan a string until you come to either a character that matches the character in AH or a zero byte, whichever comes first. You might conceptualize the solution as follows:</p>
<ol type="1">
<li>Get the next byte.</li>
<li>If the next byte matches the desired byte, we’ve got a match and we’re done.</li>
<li>If the next byte is zero, we’re done without finding a match.</li>
<li>Repeat 1.</li>
</ol>
<p>That sort of thinking is likely to produce code like that shown in <a href="#listing-13-10">Listing 13-10</a>, which is a faithful line-by-line reproduction of the above sequence.</p>
<p><a href="#listing-13-10">Listing 13-10</a> works perfectly well, finishing in 431 us. However, the loop in <a href="#listing-13-10">Listing 13-10</a> ends with a conditional jump followed by an unconditional jump. With a little code rearrangement, the conditional jump can be made to handle both the test-for-zero and repeat-loop functions, and the unconditional jump can be done away with entirely. All we need do is put the “no-match”handling code right after the conditional jump and change the polarity of the jump from <code class="sourceCode nasm"><span class="kw">jz</span></code> to <code class="sourceCode nasm"><span class="kw">jnz</span></code>, so that the one conditional jump can either fall through if the terminating zero is found or repeat the loop otherwise.</p>
<p>Back in Chapter 11 we saw <a href="#listing-11-11">Listing 11-11</a>, which features just such rearranged code. (<a href="#listing-13-10">Listing 13-10</a> is actually <a href="#listing-11-11">Listing 11-11</a> modified to illustrate the perils of using two jumps when one will do.) <a href="#listing-11-11">Listing 11-11</a> runs in just 375 us. Not only is <a href="#listing-11-11">Listing 11-11</a> faster than <a href="#listing-13-10">Listing 13-10</a>, it’s also shorter by two bytes — the length of the eliminated jump.</p>
<p>Look to streamline your code whenever you see a short unconditional jump paired with a conditional jump. Of course, it’s not always possible to eliminate paired jumps, but you’d be surprised at how often loops can be compacted and speeded up with a little rearrangement.</p>
</section>
<section id="jump-to-the-land-of-no-return" class="level3">
<h3>Jump to the Land of No Return</h3>
<p>It’s not uncommon that the last action before returning at the end of a subroutine is to call another subroutine, as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">call</span>  SaveNewSymbol
    <span class="kw">ret</span>
PromptForSymbol   endp</code></pre>
<p>What’s wrong with this picture? That’s easy: there’s a branch to a branch here. The <code class="sourceCode nasm"><span class="kw">ret</span></code> that ends <code class="sourceCode nasm">SaveNewSymbol</code> branches directly to the <code class="sourceCode nasm"><span class="kw">ret</span></code> that follows the call to <code class="sourceCode nasm">SaveNewSymbol</code> at the end of <code class="sourceCode nasm">PromptForSymbol</code>. Surely there’s a better way!</p>
<p>Indeed there is a better way, and that is to end <code class="sourceCode nasm">PromptForSymbol</code> by jumping to <code class="sourceCode nasm">SaveNewSymbol</code> rather than calling it. To wit:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">jmp</span>   SaveNewSymbol
PromptForSymbol   endp</code></pre>
<p>The <code class="sourceCode nasm"><span class="kw">ret</span></code> at the end of <code class="sourceCode nasm">SaveNewSymbol</code> will serve perfectly well to return to the code that called <code class="sourceCode nasm">PromptForSymbol</code>, and by doing this we’ll save one complete <code class="sourceCode nasm"><span class="kw">ret</span></code> plus the performance difference between <code class="sourceCode nasm"><span class="kw">jmp</span></code> and <code class="sourceCode nasm"><span class="kw">call</span></code> — all without changing the logic of the code in the least.</p>
<p>One <em>caveat</em> regarding <code class="sourceCode nasm"><span class="kw">jmp</span></code> in the place of <code class="sourceCode nasm"><span class="kw">call</span></code>/<code class="sourceCode nasm"><span class="kw">ret</span></code>: make sure that the types — near or far — of the two subroutines match. If <code class="sourceCode nasm">SaveNewSymbol</code> is near-callable but <code class="sourceCode nasm">PromptForSymbol</code> happens to be far-callable, then the <code class="sourceCode nasm"><span class="kw">ret</span></code> instructions at the ends of the two subroutines are <em>not</em> equivalent, since near and far <code class="sourceCode nasm"><span class="kw">ret</span></code> instructions perform distinctly different actions. Mismatch <code class="sourceCode nasm"><span class="kw">ret</span></code> instructions in this way and you’ll unbalance the stack, in the process most likely crashing your program — so exercise caution when replacing <code class="sourceCode nasm"><span class="kw">call</span></code>/<code class="sourceCode nasm"><span class="kw">ret</span></code> with <code class="sourceCode nasm"><span class="kw">jmp</span></code>.</p>
</section>
<section id="dont-be-afraid-to-duplicate-code" class="level3">
<h3>Don’t Be Afraid to Duplicate Code</h3>
<p>Whenever you use an unconditional jump, ask yourself, “Do I <em>really</em> need that jump?” Often the answer is yes… but not always.</p>
<p>What are unconditional jumps used for? Generally, they’re used to allow a conditionally-executed section of code to rejoin the main flow of program execution. For example, consider the following:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="co">;</span>
<span class="co">; Subroutine to set AH to 1 if AL contains the</span>
<span class="co">; character &#39;Y&#39;, AH to 0 otherwise.</span>
<span class="co">;</span>
<span class="co">; Input:</span>
<span class="co">;     AL = character to check</span>
<span class="co">;</span>
<span class="co">; Output;</span>
<span class="co">;     AH = 1 if AL contains &#39;Y&#39;, 0 otherwise</span>
<span class="co">;</span>
<span class="co">; Registers altered: AH</span>
<span class="co">;</span>
CheckY    proc    near
    <span class="kw">cmp</span>   <span class="kw">al</span>,<span class="st">&#39;Y&#39;</span>
    <span class="kw">jnz</span>   CheckYNo
    <span class="kw">mov</span>   <span class="kw">ah</span>,<span class="dv">1</span>              <span class="co">;it is indeed &#39;Y&#39;</span>
    <span class="kw">jmp</span>   <span class="dt">short</span> CheckYDone
<span class="fu">CheckYNo:</span>
    <span class="kw">sub</span>   <span class="kw">ah</span>,<span class="kw">ah</span>             <span class="co">;it&#39;s not &#39;Y&#39;</span>
<span class="fu">CheckYDone:</span>
    <span class="kw">ret</span>
CheckY    endp</code></pre>
<p>(You’ll instantly recognize that the whole subroutine could be speeded up simply by preloading one of the values, as we learned a few sections back. In this particular case, however, we have a still better option available.) You’ll notice that <code class="sourceCode nasm"><span class="kw">jmp</span> <span class="dt">short</span> CheckYDone</code>, the one unconditional jump in the above subroutine, doesn’t actually serve much purpose. Sure, it rejoins the rest of the code after handling the case where AL is ‘Y’, but all that happens at that point is a return to the calling code. Surely it doesn’t make sense to expend the time and 2 bytes required by a <code class="sourceCode nasm"><span class="kw">jmp</span> <span class="dt">short</span></code> just to get to a <code class="sourceCode nasm"><span class="kw">ret</span></code> instruction. Far better to simply replace the <code class="sourceCode nasm"><span class="kw">jmp</span> <span class="dt">short</span></code> with a <code class="sourceCode nasm"><span class="kw">ret</span></code>:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">CheckY    proc  near
    <span class="kw">cmp</span>   <span class="kw">al</span>,<span class="st">&#39;Y&#39;</span>
    <span class="kw">jnz</span>   CheckYNo
    <span class="kw">mov</span>   <span class="kw">ah</span>,<span class="dv">1</span>        <span class="co">;it is indeed &#39;Y&#39;</span>
    <span class="kw">ret</span>
<span class="fu">CheckYNo:</span>
    <span class="kw">sub</span>   <span class="kw">ah</span>,<span class="kw">ah</span>       <span class="co">;it&#39;s not &#39;Y&#39;</span>
<span class="fu">CheckYDone:</span>
    <span class="kw">ret</span>
CheckY    endp</code></pre>
<p>The net effect: the code is 1 byte shorter, the time required for a branch is saved about half the time — <em>and there is absolutely no change in the logic of the code</em>. It’s important that you understand that <code class="sourceCode nasm"><span class="kw">jmp</span> <span class="dt">short</span></code> was basically a <code class="sourceCode nasm"><span class="kw">nop</span></code> instruction in the first example, since all it did was unconditionally branch to another branching instruction, as shown in Figure 13.9.</p>
<figure>
<img src="images/fig13.9RT.png" />
</figure>
<p>We removed the unconditional jump simply by replacing it with a copy of the code that it branched to.</p>
<p>The basic principle here is that of duplicating code. Many unconditional jumps can be eliminated by replacing the jump with a copy of the code at the jump destination. (Unconditional jumps used for looping are an exception. As we found earlier, however, unconditional jumps used to end loops can often be replaced by conditional jumps, improving both performance and code size in the process.) Often the destination code is many bytes long, and in such cases code duplication doesn’t pay. However, in many other cases, such as the example shown above, code duplication is an unqualified winner, saving both cycles and bytes.</p>
<p>There are also cases where code duplication saves cycles but costs bytes, and then you’ll have to decide which of the two matters more on a case-by-case basis. For instance, suppose that the last example required that AL be anded with 0DFh (not 20h) after the test for ‘Y’. The standard code would be:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="co">;</span>
<span class="co">; Subroutine to set AH to 1 if AL contains the</span>
<span class="co">; character &#39;Y&#39;, AH to 0 otherwise. AL is then forced to</span>
<span class="co">; uppercase. (AL must be a letter.)</span>
<span class="co">;</span>
<span class="co">; Input:</span>
<span class="co">;     AL = character to check (must be a letter)</span>
<span class="co">;</span>
<span class="co">; Output;</span>
<span class="co">;     AH = 1 if AL contains &#39;Y&#39;, 0 otherwise</span>
<span class="co">;     AL = character to check forced to uppercase</span>
<span class="co">;</span>
<span class="co">; Registers altered: AX</span>
<span class="co">;</span>
CheckY    proc  near
    <span class="kw">cmp</span>   <span class="kw">al</span>,<span class="st">&#39;Y&#39;</span>
    <span class="kw">jnz</span>   CheckYNo
    <span class="kw">mov</span>   <span class="kw">ah</span>,<span class="dv">1</span>              <span class="co">;it is indeed &#39;Y&#39;</span>
    <span class="kw">jmp</span>   <span class="dt">short</span> CheckYDone
<span class="fu">CheckYNo:</span>
    <span class="kw">sub</span>   <span class="kw">ah</span>,<span class="kw">ah</span>             <span class="co">;it&#39;s not &#39;Y&#39;</span>
<span class="fu">CheckYDone:</span>
    <span class="kw">and</span>   <span class="kw">al</span>,<span class="kw">not</span><span class="bn"> 20h        </span><span class="co">;make it uppercase</span>
    <span class="kw">ret</span>
CheckY    endp</code></pre>
<p>The duplicate-code implementation would be:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">CheckY    proc  near
    <span class="kw">cmp</span>   <span class="kw">al</span>,<span class="st">&#39;Y&#39;</span>
    <span class="kw">jnz</span>   CheckYNo
    <span class="kw">mov</span>   <span class="kw">ah</span>,<span class="dv">1</span>        <span class="co">;it is indeed &#39;Y&#39;</span>
    <span class="kw">and</span>   <span class="kw">al</span>,<span class="kw">not</span><span class="bn"> 20h  </span><span class="co">;make it uppercase</span>
    <span class="kw">ret</span>
<span class="fu">CheckYNo:</span>
    <span class="kw">sub</span>   <span class="kw">ah</span>,<span class="kw">ah</span>       <span class="co">;it&#39;s not &#39;Y&#39;</span>
<span class="fu">CheckYDone:</span>
    <span class="kw">and</span>   <span class="kw">al</span>,<span class="kw">not</span><span class="bn"> 20h  </span><span class="co">;make it uppercase</span>
    <span class="kw">ret</span>
CheckY    endp</code></pre>
<p>with both <code class="sourceCode nasm"><span class="kw">and</span></code> and <code class="sourceCode nasm"><span class="kw">ret</span></code> duplicated at the end of each of the two possible paths through the subroutine.</p>
<p>The decision as to which of the two above implementations is preferable is by no means cut and dried. The duplicated-code implementation is certainly faster, since it still avoids a branch in half the cases. On the other hand, the duplicated-code implementation is also 1 byte longer, since a 2-byte <code class="sourceCode nasm"><span class="kw">jmp</span> <span class="dt">short</span></code> is replaced with a 3-byte sequence of <code class="sourceCode nasm"><span class="kw">and</span></code> and <code class="sourceCode nasm"><span class="kw">ret</span></code>. Neither sequence is superior on all counts, so the choice between the two depends on context and your own preferences.</p>
<p>Duplicated code is counter to all principles of structured programming. As we’ve learned, that’s not inherently a bad thing — when you need performance, it can be most useful to discard conventions and look for fresh approaches.</p>
<p>Nonetheless, it’s certainly possible to push the duplicated-code approach too far. As the code to be duplicated becomes longer and/or more complex, the duplicated-code approach becomes less appealing. In addition to the bytes that duplicating longer code can cost, there’s also the risk that you’ll modify the code at only one of the duplicated locations as you alter the program. For this reason, duplicated code sequences longer than a <code class="sourceCode nasm"><span class="kw">ret</span></code> and perhaps one other instruction should be used only when performance is at an absolute premium.</p>
</section>
<section id="inside-loops-is-where-branches-really-hurt" class="level3">
<h3>Inside Loops Is Where Branches Really Hurt</h3>
<p>Branches always hurt performance, but where they really hurt is inside loops. There, the performance loss incurred by a single branching instruction is magnified by the number of loop repetitions. It’s important that you understand that not all branches are created equal, so that you can focus on eliminating or at least reducing the branches that most affect performance — and those branches are usually inside loops.</p>
<p>How can we apply this knowledge? By making every effort to use techniques such as duplicated code, in-line code (which we’ll see shortly), and preloading values inside loops, and by simply moving decision-making out of loops whenever we can. Let’s take a look at an example of using duplicated code within a loop, in order to see how easily cycle-saving inside a loop can pay off.</p>
</section>
<section id="two-loops-can-be-better-than-one" class="level3">
<h3>Two Loops Can Be Better Than One</h3>
<p>Suppose that we want to determine whether there are more negative or non-negative values in an array of 8-bit signed values. <a href="#listing-13-11">Listing 13-11</a> does that in 3.60 ms for the sample array by using a straightforward and compact test-and-branch approach.</p>
<p>There’s nothing wrong with <a href="#listing-13-11">Listing 13-11</a>, but there <em>is</em> an unconditional jump. We’d just as soon do away with that unconditional jump, especially since it’s in a loop. Unfortunately, the instruction the unconditional jump branches to isn’t a simple <code class="sourceCode nasm"><span class="kw">ret</span></code> — it’s a <code class="sourceCode nasm"><span class="kw">loop</span></code> instruction, and we all know that loops must end in one place, at the loop bottom.</p>
<p><em>Hmmmm.</em> Why must loops end in one place? There’s no particular reason that I can think of, apart from habit, so let’s try duplicating some code and ending the loop in <em>two</em> places. <a href="#listing-13-12">Listing 13-12</a>, which does exactly that, runs in just 3.05 ms. That’s an improvement of 18% — quite a return for the 1 byte the duplicated-code approach adds.</p>
<p>It’s evident that eliminating branching instructions inside loops can result in handsome performance gains for relatively little effort. That’s why I urge you to focus your optimization efforts on loops. While we’re on this important topic, let’s look at another way to eliminate branches inside loops.</p>
</section>
<section id="make-up-your-mind-once-and-for-all" class="level3">
<h3>Make Up Your Mind Once and for All</h3>
<p>If you find yourself making a decision inside a loop, for heaven’s sake see if you can manage to make that decision <em>before</em> the loop. Why decide every time through the loop when you can decide just once at the outset?</p>
<p>Consider <a href="#listing-13-13">Listing 13-13</a>, in which the contents of DL are used to decide whether to convert each character to uppercase while copying one string to another string. <a href="#listing-13-13">Listing 13-13</a>, which runs in 3.03 ms for the sample string, is representative of the situation in which a parameter passed to a subroutine selects between different modes of operation.</p>
<p>The failing of <a href="#listing-13-13">Listing 13-13</a> is that the decision as to whether to convert to uppercase is made over and over, once for each character. We’d be much better off if we could make the decision just once at the start of the subroutine, moving the decision-making (particularly the branching) out of the loop.</p>
<p>There are a number of ways to do this. One is shown in <a href="#listing-13-14">Listing 13-14</a>. Here, a single branch outside the loop is used to force the test for inclusion in the lowercase to function also as the test for whether conversion is desired. If conversion isn’t desired, AH, which normally contains the start of the lowercase range, is set to 0FFh. This has the effect of causing the lowercase test always to fail on the first conditional jump if conversion isn’t desired, just as was the case in <a href="#listing-13-13">Listing 13-13</a>. Consequently, performance stays just about the same when conversion to uppercase isn’t desired.</p>
<p>However, when lowercase conversion <em>is</em> desired, <a href="#listing-13-14">Listing 13-14</a> performs one less test each time through the loop than does <a href="#listing-13-13">Listing 13-13</a>, because a separate test to find out whether conversion is desired is no longer needed. We’ve already performed the test for whether conversion is desired at the start of the subroutine — outside the loop — so the code inside the loop can sail through the copy-and-convert process at full speed. The result is that <a href="#listing-13-14">Listing 13-14</a> runs in 2.76 ms, significantly faster than <a href="#listing-13-13">Listing 13-13</a>.</p>
<p>In <a href="#listing-13-14">Listing 13-14</a>, we’ve really only moved the test as to whether conversion is desired out of the loop in the case where conversion is indeed desired. When conversion isn’t desired, a branch is still performed every time through the loop, just as in <a href="#listing-13-13">Listing 13-13</a>. If we’re willing to duplicate a bit of code, we can also move the branch out of the loop when conversion isn’t desired, as shown in <a href="#listing-13-15">Listing 13-15</a>. There’s a cost in size for this optimization — 7 bytes — but execution time is cut to just 2.35 us, a 29% improvement over <a href="#listing-13-13">Listing 13-13</a>.</p>
<p>Moreover, <a href="#listing-13-15">Listing 13-15</a> could easily be speeded up further by using the word-at-a-time or <code class="sourceCode nasm"><span class="kw">scas</span></code>/<code class="sourceCode nasm"><span class="kw">movs</span></code> techniques we encountered in Chapter 11. Why is it easier to do this to <a href="#listing-13-15">Listing 13-15</a> than to <a href="#listing-13-13">Listing 13-13</a>? It’s easier because we’ve completely separated the instruction sequences for the two modes of operation of the subroutine, so we have fewer instructions and simpler code to optimize in whichever case we try to speed up.</p>
<p>Remember, not all branches are created equal. If you have a choice between branching once before a loop and branching once every time through the loop, it’s really like choosing between one branch and dozens or hundreds (however many times the loop is repeated) of branches. Even when it costs a few extra bytes, that’s not a particularly hard choice to make, is it?</p>
</section>
<section id="dont-come-calling" class="level3">
<h3>Don’t Come Calling</h3>
<p>Jumps aren’t the 8088’s only branching instructions. Calls, returns, and interrupts branch as well. Interrupts aren’t usually repeated unnecessarily inside loops, although you should try to handle data obtained through DOS interrupts in large blocks, rather than a character at a time, as we’ll see in the next chapter.</p>
<p>By definition, returns can’t be executed repeatedly inside loops, since a return branches out of a loop back to the calling code.</p>
<p>That leaves calls… and calls in loops are in fact among the great cycle-wasters of the 8088.</p>
<p>Consider what the <code class="sourceCode nasm"><span class="kw">call</span></code> instruction does. First it pushes the Instruction Pointer onto the stack, and then it branches. That’s like pairing a <code class="sourceCode nasm"><span class="kw">push</span></code> and a <code class="sourceCode nasm"><span class="kw">jmp</span></code> — a gruesome prospect from a performance perspective. Actually, things aren’t <em>that</em> bad; the official execution time of <code class="sourceCode nasm"><span class="kw">call</span></code>, at 23 cycles, is only 8 cycles longer than that of <code class="sourceCode nasm"><span class="kw">jmp</span></code>. Nonetheless, you should cast a wary eye on any instruction that takes 23 cycles to execute <em>and</em> empties the prefetch queue.</p>
<p>The cycles spent executing <code class="sourceCode nasm"><span class="kw">call</span></code> aren’t the end of the performance loss associated with calling a subroutine, however. Once you’re done with a subroutine, you have to branch back to the calling code. The instruction that does that, <code class="sourceCode nasm"><span class="kw">ret</span></code>, takes another 20 cycles and empties the prefetch queue again. On balance, then, a subroutine call expends 43 cycles on overhead operations and empties the prefetch queue not once but <em>twice</em>!</p>
<p>Fine, you say, but what’s the alternative? After all, subroutines are fundamental to good programming — we can’t just do away with them altogether.</p>
<p>By and large, that’s true, but inside time-critical loops there’s no reason why we can’t eliminate calls simply by moving the called code into the loop. Replacing the subroutine call with a macro is the simplest way to do this. For example, suppose that we have a subroutine called <code class="sourceCode nasm">IsPrintable</code>, which tests whether the character in AL is a printable character (in the range 20h to 7Eh). <a href="#listing-13-16">Listing 13-16</a> shows a loop that calls this subroutine in the process of copying only printable characters from one string to another string. Call and all, <a href="#listing-13-16">Listing 13-16</a> runs in 3.48 ms for the test string.</p>
<p><a href="#listing-13-17">Listing 13-17</a> is functionally identical to <a href="#listing-13-16">Listing 13-16</a>. In <a href="#listing-13-17">Listing 13-17</a>, however, the call to the subroutine <code class="sourceCode nasm">IsPrintable</code> has been converted to the expansion of the macro <code class="sourceCode nasm">IS_PRINTABLE</code>, eliminating the <code class="sourceCode nasm"><span class="kw">call</span></code> and <code class="sourceCode nasm"><span class="kw">ret</span></code> instructions. How much difference does that change from call to macro expansion make? <a href="#listing-13-17">Listing 13-17</a> runs in 2.21 ms, 57% faster than <a href="#listing-13-16">Listing 13-16</a>. <a href="#listing-13-16">Listing 13-16</a><em>spends over one-third of its entire execution time simply calling <code class="sourceCode nasm">IsPrintable</code> and returning from that subroutine!</em></p>
<p>While the superior performance of <a href="#listing-13-17">Listing 13-17</a> clearly illustrates the price paid for subroutine calls, that listing by no means applies all of the optimizations made possible by the elimination of the calls that plagued <a href="#listing-13-16">Listing 13-16</a>. It’s true that the macro <code class="sourceCode nasm">IS_PRINTABLE</code> eliminates the subroutine call, but there are still internal branches in <code class="sourceCode nasm">IS_PRINTABLE</code>, and there’s still a <code class="sourceCode nasm"><span class="kw">cmp</span></code> instruction that sets the Zero flag on success. In other words, <a href="#listing-13-17">Listing 13-17</a> hasn’t taken full advantage of moving the code into the loop; it has simply taken the call and return overhead out of determining whether a character is printable.</p>
<p><a href="#listing-13-18">Listing 13-18</a> does take full advantage of moving the test code into the loop, by eliminating the macro and thereby eliminating the need to place a return status in the Zero flag. Instead, <a href="#listing-13-18">Listing 13-18</a> branches directly to <code class="sourceCode nasm">NotPrintable</code> if a character is found to be non-printable, eliminating the intermediate conditional jump that <a href="#listing-13-17">Listing 13-17</a> performed. It’s also no longer necessary to test the Zero flag to see whether the character is printable before storing it in the destination array, since any character that passes the two comparisons for inclusion in the printable range must be printable. The upshot is that <a href="#listing-13-18">Listing 13-18</a> runs in just 1.74 ms, 27% faster than <a href="#listing-13-17">Listing 13-17</a> and 100% faster than <a href="#listing-13-16">Listing 13-16</a>.</p>
<p><a href="#listing-13-18">Listing 13-18</a> illustrates two useful optimizations in the case where a character is found to be printable. First, there’s no need to branch to the bottom of the loop just to branch back to the top of the loop, so <a href="#listing-13-18">Listing 13-18</a> just branches directly to the top of the loop after storing each printable character. The same is done when a non-printable character greater than 7Eh is detected. The point here is that it’s fine to branch back to the top of a loop from multiple places. Second, there’s no way that a printable character can end a string (zero isn’t a printable character), so we don’t bother testing for the terminating zero after storing a printable character; again, the same is true for non-printable characters greater than 7Eh. When you duplicate code, it’s not necessary to duplicate any portion of the code that performs no useful function in the new location.</p>
<p>Whenever you use a subroutine or a macro, you’re surrendering some degree of control over your code in exchange for ease of programming. In particular, the use of subroutines involves a direct trade-off of decreased performance for reduced code size and greater modularity. In general, ease of programming, reduced code size, and modularity are highly desirable attributes… but not in time-critical code.</p>
<p>Try to eliminate calls from your tight loops and time-critical code. If the code called is large, that may not be possible, but then you have to ask yourself what such a large subroutine is doing in your time-critical code in the first place. It may also be beneficial to eliminate macros in time-critical code. Whether or not that’s the case depends on the nature of the macros, but at least make sure you understand what code you’re really writing. In this pursuit, it can be useful to generate a listing file in order to see the code the assembler is actually generating.</p>
<p>As I mentioned above, there are three objections to moving subroutines into loops: size, modularity, and ease of programming. Let’s quickly address each of these points.</p>
<p>Sure, code gets bigger when you move subroutines into loops: performance is often a balancing of program size and performance. That’s why you should concentrate on applying the techniques in this chapter (and, indeed, all the performance-enhancing techniques presented in <em>The Zen of Assembly Language</em>) to time-critical code, where a few extra bytes can buy a great many cycles.</p>
<p>On the other hand, code doesn’t really have to be less modular when subroutines are moved into loops. Macros are just as modular as subroutines, in the sense that in your code both are one-line entries that perform a well-defined set of actions. In any case, in discussing moving subroutine code into loops we’re generally talking about moving relatively few instructions into any given loop, since the call/return overhead becomes proportionately less significant for longer subroutines (although never insignificant, if you’re really squeezed for cycles). Modularity shouldn’t be a big issue with short instruction sequences.</p>
<p>Finally, as to ease of programming: if you want easy programming, program in C or Pascal, or, better yet, COBOL. Assembler subroutine and macro libraries are fine for run-of-the-mill code, but when it comes to the high-performance, time-critical parts of your programs, it’s your ability to write the hard assembler code that will set you apart. Assembler isn’t easy, but any competent programmer can eventually get almost any application to work in assembler. The Zen of assembler lies not in making an application work, but in making it work as well as it possibly can, given the strengths and limitations of the PC.</p>
</section>
<section id="smaller-isnt-always-better" class="level3">
<h3>Smaller Isn’t <em>Always</em> Better</h3>
<p>You’ve no doubt noticed that this chapter seems to have repeatedly violated the rule that “smaller is better.” Not so, given the true meaning of the rule. “Smaller is better” applies to instruction prefetching, where fewer bytes to be fetched means less time waiting for instruction bytes. Subroutine calls don’t fall into this category, even though they reduce overall program size.</p>
<p>Subroutines merely allow you to run the same instructions from multiple places in a program. That reduces program size, since the code only needs to appear in one place, but there are no fewer bytes to be fetched on any given call than if the code of the subroutine were to be placed directly into the calling code. In fact, instruction fetching becomes <em>more</em> of a problem with subroutines, since the prefetch queue is emptied twice, and the call and return instruction bytes must be fetched, as well.</p>
<p>In short, while subroutines are great for reducing program size and have a host of other virtues as regards program design, modularity, and maintenance, they don’t come under the “smaller is better” rule, and are, in fact, lousy for performance. Much the same — smaller is slower — can be said of branches of many sorts. Of all the branching instructions, loops are perhaps the worst “smaller is slower” offender. We’re going to close out this chapter with a discussion of the potent in-line-code alternative to looping — yet another way to trade a few bytes for a great many cycles.</p>
</section>
</section>
<section id="loop-may-not-be-bad-but-lord-knows-its-not-good-in-line-code" class="level2">
<h2><code>loop</code> May Not Be Bad, but Lord Knows It’s Not Good: In-Line Code</h2>
<p>One of the great misconceptions of 8088 programming is that <code class="sourceCode nasm"><span class="kw">loop</span></code> is a good instruction for looping. It’s true that <code class="sourceCode nasm"><span class="kw">loop</span></code> is designed especially for looping. It’s also true that <code class="sourceCode nasm"><span class="kw">loop</span></code> is the 8088’s best looping instruction. But <em>good</em>?</p>
<p>No way.</p>
<p>You see, <code class="sourceCode nasm"><span class="kw">loop</span></code> is a branching instruction, and not an especially fast branching instruction, at that. The official execution time of <code class="sourceCode nasm"><span class="kw">loop</span></code> is 17 cycles, which makes it just 1 cycle faster than the similar construct <code class="sourceCode nasm"><span class="kw">dec</span> <span class="kw">cx</span></code>/<code class="sourceCode nasm"><span class="kw">jnz</span></code>, although <code class="sourceCode nasm"><span class="kw">loop</span></code> is also 1 byte shorter. Like all branching instructions, <code class="sourceCode nasm"><span class="kw">loop</span></code> empties the prefetch queue, so it is effectively even slower than it would appear to be. I don’t see how you can call an instruction that takes in the neighborhood of 20 cycles just to repeat a loop good. Better than the obvious alternatives, sure, and pleasantly compact and easy to use if you don’t much care about speed — but not <em>good</em>.</p>
<p>Look at it this way. Suppose you have a program containing a loop that zeros the high bit of each byte in a 100-byte array, as shown in <a href="#listing-13-19">Listing 13-19</a>, which runs in 1023 us. What percent of that overall execution time do you suppose this program spends just decrementing CX and branching back to the top of the loop — that is, looping? Ten percent?</p>
<p>No. Twenty percent?</p>
<p>No.</p>
<p><em>Thirty</em> percent?</p>
<p>No, but you’re getting warm… <a href="#listing-13-19">Listing 13-19</a> spends <em>forty-five percent</em> of the total execution time looping. (That figure was arrived at by comparing the execution time of <a href="#listing-13-20">Listing 13-20</a>, which uses no branches and which we’ll get to shortly, to the execution time of <a href="#listing-13-19">Listing 13-19</a>.) Yes, you read that correctly — in a loop which accesses memory twice and which contains a second instruction in addition to the memory-accessing instruction, <code class="sourceCode nasm"><span class="kw">loop</span></code> manages to take nearly one-half of the total execution time. Appalling?</p>
<p>You bet.</p>
<p>Still, while <code class="sourceCode nasm"><span class="kw">loop</span></code> may not be much faster than other branching instructions, it is nonetheless <em>somewhat</em> faster, and it’s also more compact. We know we’re losing a great deal of performance to the 8088’s abysmal branching speed, but there doesn’t seem to be much we can do about it.</p>
<p>But of course there is something we can do, as is almost always the case with the 8088. Let’s look at exactly what <code class="sourceCode nasm"><span class="kw">loop</span></code> is used for, and then let’s see if we can produce the same functionality in a different way.</p>
<p>Well, <code class="sourceCode nasm"><span class="kw">loop</span></code> is used to repeat a given sequence of instructions multiple times… and that’s about all. What can we do with that job description?</p>
<p>Heck, that’s <em>easy</em>. We’ll eliminate branching and loop counting entirely by <em>literally</em> repeating the instructions, as shown in Figure 13.10.</p>
<figure>
<img src="images/fig13.10RT.png" />
</figure>
<p>Instead of using <code class="sourceCode nasm"><span class="kw">loop</span></code> to execute the same code, say, 10 times, we’ll just line up 10 repetitions of the code inside the loop, and then execute the 10 repetitions one after another. This is known as <em>in-line code</em>, because the repetitions of the code are lined up in order rather than being separated by branches. (In-line code is sometimes used to refer to subroutine code that’s brought into the main code, eliminating a call, a technique we discussed in the last section. However, I’m going to use the phrase “in-line code” only to refer to code that’s repeated by assembling multiple instances and running them back-to-back rather than in a loop.)</p>
<p><a href="#listing-13-20">Listing 13-20</a> shows in-line code used to speed up <a href="#listing-13-19">Listing 13-19</a>. The <code class="sourceCode nasm"><span class="kw">loop</span></code> instruction is gone, replaced with a <code class="sourceCode nasm">rept</code> directive that creates 100 back-to-back instances of the code inside the loop of <a href="#listing-13-19">Listing 13-19</a>. The performance improvement is dramatic: <a href="#listing-13-20">Listing 13-20</a> runs in 557 us, more than 83% faster than <a href="#listing-13-19">Listing 13-19</a>.</p>
<p>Often-enormous improvement in performance is the good news about in-line code. Often-enormous increase in code size — depending on the number of repetitions and the amount of code in the loop — is the bad news. <a href="#listing-13-20">Listing 13-20</a> is nearly 300 bytes larger than <a href="#listing-13-19">Listing 13-19</a>. On the other hand, we’re talking about nearly doubling performance by adding those extra bytes. Yes, once again we’ve encountered the trade-off between bytes and cycles that pops up so often when we set out to improve performance: in-line code can be used to speed up just about any loop, but the cost in bytes ranges from modest to prohibitively high. Still, when you need flat-out performance, in-line code is a tried and true way to get a sizable performance boost.</p>
<p>In-line code has another benefit beside eliminating branching. When in-line code is used, CX (or whatever register would otherwise have been used as a loop counter) is freed up. An extra 16-bit register is always welcome in high-performance code.</p>
<p>You may well object at this point that in-line code is fine when the number of repetitions of a loop is known in advance and is always the same, but how often is that the case? Not all that often, I admit, but it does happen. For example, think back to our animation examples in Chapter 11. The example that used exclusive-or-based animation looped once for each word exclusive-ored into display memory, and always drew the same number of words per line. That sounds like an excellent candidate for in-line code, and in fact it is.</p>
<p><a href="#listing-13-21">Listing 13-21</a> shows the <code class="sourceCode nasm">XorImage</code> subroutine from <a href="#listing-11-33">Listing 11-33</a> revised to use in-line code to draw each line without branching. Instead, the four instructions that draw the four words of the image are duplicated four times, in order to draw a whole line at a time. This frees up not only CX but also BP, which in <a href="#listing-11-33">Listing 11-33</a> was used to reload the number of words per line each time through the loop. That has a ripple effect which lets us avoid using BX, saving a <code class="sourceCode nasm"><span class="kw">push</span></code> and a <code class="sourceCode nasm"><span class="kw">pop</span></code>, and also allows us to store the offset from odd lines to even lines in a register for added speed.</p>
<p>The net effect of the in-line code in <a href="#listing-13-21">Listing 13-21</a> is far from trivial. When this version of <code class="sourceCode nasm">XorImage</code> is substituted for the version in <a href="#listing-11-33">Listing 11-33</a>, execution time drops from 30.29 seconds to 24.21 seconds, a 25% improvement in overall performance. Put another way, the <code class="sourceCode nasm"><span class="kw">loop</span></code> instructions in the two loops that draw the even and odd lines in <a href="#listing-11-33">Listing 11-33</a> take up about one out of every five cycles that the entire program uses! Bear in mind that we’re not talking now about a program that zeros the high bits of bytes in three-instruction loops; we’re talking about a program that performs complex animation and accesses display memory heavily… in other words, a program that does many time-consuming things besides looping.</p>
<p>To drive the point home, let’s modify <a href="#listing-11-34">Listing 11-34</a> to use in-line code, as well. <a href="#listing-11-34">Listing 11-34</a> uses <code class="sourceCode nasm">rep <span class="kw">movsw</span></code> to draw each line, so there are no branches to get rid of during line drawing, and consequently no way to put in-line code to work there. There is, however, a loop that’s used to repeat the drawing of each pair of rows in the image. That’s not <em>nearly</em> so intensive a loop as the line-drawing loop was in <a href="#listing-11-33">Listing 11-33</a>; instead of being repeated once for every word that’s drawn, it’s repeated just once every two lines, or 10 words.</p>
<p>Nonetheless, when the in-line version of <code class="sourceCode nasm">BlockDrawImage</code> shown in <a href="#listing-13-22">Listing 13-22</a> is substituted for the version in <a href="#listing-11-34">Listing 11-34</a>, overall execution time drops from 10.35 seconds to 9.69 seconds, an improvement of nearly 7%. Not earthshaking — but in demanding applications such as animation, where every cycle counts, it’s certainly worth expending a few hundred extra bytes to get that extra speed.</p>
<p>The 7% improvement we got with <a href="#listing-13-22">Listing 13-22</a> is more impressive when you consider that the bulk of the work in <a href="#listing-11-34">Listing 11-34</a> is done with <code class="sourceCode nasm">rep <span class="kw">movsw</span></code>. If you take a moment to contemplate the knowledge that 7% of overall execution time in <a href="#listing-11-34">Listing 11-34</a> is used by just 20 <code class="sourceCode nasm"><span class="kw">dec</span> <span class="kw">dx</span></code>/<code class="sourceCode nasm"><span class="kw">jnz</span></code> pairs per image draw (and remember that cycle-eating display memory is accessed 400 times for every 20 <code class="sourceCode nasm"><span class="kw">dec</span> <span class="kw">dx</span></code>/<code class="sourceCode nasm"><span class="kw">jnz</span></code> pairs executed), you’ll probably reach the conclusion that <code class="sourceCode nasm"><span class="kw">loop</span></code> really isn’t a very good instruction for high-performance looping.</p>
<p>And you’ll be right.</p>
<section id="branched-to-in-line-code-flexibility-needed-and-found" class="level3">
<h3>Branched-To In-Line Code: Flexibility Needed and Found</h3>
<p>What we’ve just seen is “pure” in-line code, where a loop that’s always repeated a fixed number of times is converted to in-line code by simply repeating the contents of the loop however many times the loop was repeated. The above animation examples notwithstanding, pure in-line code isn’t used very often. Why? Because loops rarely repeat a fixed number of times, and pure in-line code isn’t flexible enough to handle a variable number of repetitions. With pure in-line code, if you put five repetitions of a loop in-line, you’ll always get five repetitions, no more and no less. Most looping applications demand more flexibility than that.</p>
<p>As it turns out, however, it’s no great trick to modify pure in-line code to replace loops that repeat a variable number of times, so long as you know the maximum number of times you’ll ever want to repeat the loop. The basic concept is shown in Figure 13.11.</p>
<figure>
<img src="images/fig13.11RT.png" />
</figure>
<p>The loop code is repeated in-line as many times as the maximum possible number of loop repetitions. Then the specified repetition count is used to jump right into the in-line code at the distance from the end of the in-line code that will produce the desired number of repetitions. This mechanism, known as <em>branched-to in-line code</em>, is almost startlingly simple, but powerful nonetheless.</p>
<p>Let’s convert the in-line code example of <a href="#listing-13-20">Listing 13-20</a> to use branched-to in-line code. <a href="#listing-13-23">Listing 13-23</a> shows this implementation. First, in-line code to support up to the maximum possible number of repetitions (in this case, 200) is created with <code class="sourceCode nasm">rept</code>. Then the start offset in the in-line code that will result in the desired number of repetitions is calculated, by multiplying the number of instruction bytes per repetition by the desired number of repetitions, and subtracting the result from the offset of the end of the table. As a result, <a href="#listing-13-23">Listing 13-23</a> can handle any number of repetitions between 0 and 200, and does so with just one branch, the <code class="sourceCode nasm"><span class="kw">jmp</span> <span class="kw">cx</span></code> that branches into the in-line code.</p>
<p>The performance price for the flexibility of <a href="#listing-13-23">Listing 13-23</a> is small; the code runs in 584 us, just 27 us slower than <a href="#listing-13-20">Listing 13-20</a>. Moreover, <a href="#listing-13-23">Listing 13-23</a> could be speeded up a bit by multiplying by 3 with a shift-and-add sequence rather than the notoriously slow <code class="sourceCode nasm"><span class="kw">mul</span></code> instruction; I used <code class="sourceCode nasm"><span class="kw">mul</span></code> in order to illustrate the general case and because I didn’t want to obscure the workings of branched-to in-line code.</p>
<p>Branched-to in-line code retains almost all of the performance advantages of in-line code, without the inflexibility. Branched-to in-line code does everything <code class="sourceCode nasm"><span class="kw">loop</span></code> does, and does it without branching inside the loop. Branched-to in-line code is sort of the poor man’s <code class="sourceCode nasm">rep</code>, capable of repeating any instruction or sequence of instructions without branching, just as <code class="sourceCode nasm">rep</code> does for string instructions. It’s true that branched-to in-line code doesn’t really eliminate the prefetch-queue cycle-eater as <code class="sourceCode nasm">rep</code> does, since each instruction byte in branched-to in-line code must still be fetched. On the other hand, it’s also true that branched-to in-line code eliminates the constant prefetch-queue flushing of <code class="sourceCode nasm"><span class="kw">loop</span></code>, and that’s all to the good.</p>
<p>In short, branched-to in-line code allows repetitive processing based on non-string instructions to approach its performance limits on the 8088 by eliminating branching, thereby doing away with not only the time required to branch but also the nasty prefetch-queue effects of branching. When you need flat-out speed for repetitive tasks, branched-to in-line code is often a good bet.</p>
<p>That’s not to say that branched-to in-line code is perfect. The hitch is that you must allow for the maximum number of repetitions when setting up branched-to in-line code. If you’re performing checksums on data blocks no larger than 64 bytes, the maximum size is no problem, but if you’re working with large arrays, the maximum size can easily be either unknown or so large that the resulting in-line code would simply be too large to use. For example, the in-line code in <a href="#listing-13-23">Listing 13-23</a> is 600 bytes long, and would swell to 60,000 bytes long if the maximum number of repetitions were 20,000 rather than 200. In-line code can also become too large to be practical after just a few repetitions if the code to be repeated is lengthy. Finally, lengthy branched-to in-line code isn’t well-suited for tasks such as scanning arrays, since the in-line code can easily be too long to allow the 1-byte displacements of conditional jumps to branch out of the in-line code when a match is found.</p>
<p>Clearly, branched-to in-line code is not the ideal solution for all situations. Branched-to in-line code is great if both the maximum number of repetitions and the code to be repeated are small, or if performance is so important that you’re willing to expend a great many bytes to speed up your code. For applications that don’t fit within those parameters, however, a still more flexible in-line solution is needed.</p>
<p>Which brings us to partial in-line code.</p>
</section>
<section id="partial-in-line-code" class="level3">
<h3>Partial In-Line Code</h3>
<p><em>Partial in-line code</em> is a hybrid of normal looping and pure in-line code. Partial in-line code performs a few repetitions back-to-back without branching, as in-line code does, and then loops. As such, partial in-line code offers much of the performance improvement of in-line code, along with much of the compactness of normal loops. While partial in-line code isn’t as fast as pure or branched-to in-line code, it’s still fast, and because it’s relatively compact, it overcomes most of the size-related objections to in-line code.</p>
<p>Let’s go back to our familiar example of zeroing the high bit of each byte in an array to see partial in-line code in action. In <a href="#listing-13-19">Listing 13-19</a> we saw this example implemented with a loop, in <a href="#listing-13-20">Listing 13-20</a> we saw it implemented with pure in-line code, and in <a href="#listing-13-23">Listing 13-23</a> we saw it implemented with branched-to in-line code. <a href="#listing-13-24">Listing 13-24</a> shows yet another version, this time using partial in-line code.</p>
<p>The key to <a href="#listing-13-24">Listing 13-24</a> is that it performs four in-line bit-clears, then loops. This means that <a href="#listing-13-24">Listing 13-24</a> loops just once for every four bits cleared. While that means that <a href="#listing-13-24">Listing 13-24</a> still branches 25 times, that’s 75 times fewer than the loop-only version, <a href="#listing-13-19">Listing 13-19</a>, certainly a vast improvement. And while the <code class="sourceCode nasm">ClearHighBits</code> subroutine is 13 bytes larger in <a href="#listing-13-24">Listing 13-24</a> than in <a href="#listing-13-19">Listing 13-19</a>, it’s nearly 300 bytes smaller than in the pure in-line version, <a href="#listing-13-20">Listing 13-20</a>. If <a href="#listing-13-24">Listing 13-24</a> can run anywhere near as fast as <a href="#listing-13-20">Listing 13-20</a>, it’ll be a winner.</p>
<p><a href="#listing-13-24">Listing 13-24</a> is indeed a winner, running in 688 us. That’s certainly slower than pure in-line code — <a href="#listing-13-20">Listing 13-20</a> is about 24% faster — but it’s a whole lot faster than pure looping. <a href="#listing-13-24">Listing 13-24</a> outperforms <a href="#listing-13-19">Listing 13-19</a> by close to 50% — <em>at a cost of just 13 bytes</em>. That’s a terrific return for the extra bytes expended, proportionally much better than the 83% improvement <a href="#listing-13-20">Listing 13-20</a> brings at a cost of 295 bytes. To put it another way, in this example the performance improvement of partial in-line code over pure looping is about 49%, at a cost of 13 bytes, while the improvement of pure in-line code over partial in-line code is only 24%, at a cost of 282 bytes.</p>
<p>If you need absolute maximum speed, in-line code is the ticket… but partial in-line code offers similar performance improvements in a far more generally usable form. If size is your driving concern, then <code class="sourceCode nasm"><span class="kw">loop</span></code> is the way to go.</p>
<p>As always, no one approach is perfect in all situations. The three approaches to handling repetitive code that we’ve discussed — in-line code, partial in-line code, and looping — give you a solid set of tools to use for handling repetitive tasks, but it’s up to you to evaluate the trade-offs between performance, size, and program complexity and then select the proper techniques for your particular applications. There are no easy answers in top-notch assembler programming — but at least now you have a set of tools with which to craft good solutions.</p>
<p>There are many, many ways to use in-line code. We’ve seen some already, we’ll see more over the remainder of this chapter, and you’ll surely discover others yourself. Whenever you must loop in time-critical code, take a moment to see if you can’t use in-line code in one of its many forms instead.</p>
<p>The rewards can be rich indeed.</p>
</section>
<section id="partial-in-line-code-limitations-and-workarounds" class="level3">
<h3>Partial In-Line Code: Limitations and Workarounds</h3>
<p>The partial in-line code implementation in <a href="#listing-13-24">Listing 13-24</a> is somewhat more flexible than the pure in-line code implementation in <a href="#listing-13-20">Listing 13-20</a>, but not by much. The partial in-line code in <a href="#listing-13-24">Listing 13-24</a> is capable of handling only repetition counts that happen to be multiples of four, since four repetitions are performed each time through the loop. That’s fine for repetitive tasks that always involve repetition counts that happen to be multiples of four; unfortunately, such tasks are the exception rather than the rule. In order to be generally useful, partial in-line code must be able to support any number of repetitions at all.</p>
<p>As it turns out, that’s not a problem. The flexibility of branched-to in-line code can easily be coupled with the compact size of partial in-line code. As an example, let’s modify the branched-to in-line code of <a href="#listing-13-23">Listing 13-23</a> to use partial in-line code.</p>
<p>The basic principle when branching into partial in-line code is similar to that for standard branched-to in-line code. The key is still to branch to the location in the in-line code from which the desired number of repetitions will occur. The difference with branched-to partial in-line code is that the branching-to process only needs to handle any odd repetitions that can’t be handled by a full loop, as shown in Figure 13.12.</p>
<figure>
<img src="images/fig13.12RT.png" />
</figure>
<p>In other words, if partial in-line code performs <em>n</em> repetitions per loop and we want to perform <em>m</em> repetitions, the branching-to process only needs to handle <em>m</em> modulo <em>n</em> repetitions.</p>
<p>For example, if we want to perform 15 repetitions with partial in-line code that performs 4 repetitions per loop, we need to branch so as to perform the first 15 modulo 4 = 3 repetitions during the first, partial pass through the loop. After that, 3 full passes through the loop will handle the other 12 repetitions.</p>
<p><a href="#listing-13-25">Listing 13-25</a>, a branched-to partial in-line code version of our familiar bit-clearing example, should help to make this clear. The version of <code class="sourceCode nasm">ClearHighBits</code> in <a href="#listing-13-25">Listing 13-25</a> first calculates the number of repetitions modulo 4. Since each pass through the loop performs 4 repetitions, the number of repetitions modulo 4 is the number of repetitions to be performed on the first, partial pass through the loop in order to handle repetition counts that aren’t multiples of 4. <a href="#listing-13-25">Listing 13-25</a> then uses this value to calculate the offset in the partial in-line code to branch to in order to cause the correct number of repetitions to occur on that first pass.</p>
<p>Incidentally, multiplication by 3 in <a href="#listing-13-25">Listing 13-25</a> is performed not with <code class="sourceCode nasm"><span class="kw">mul</span></code>, but with a much faster shift-and-add sequence. As we mentioned earlier, the same could have been done in <a href="#listing-13-23">Listing 13-23</a>, but <code class="sourceCode nasm"><span class="kw">mul</span></code> was used there in order to handle the general case and avoid obscuring the mechanics of the branching-to process. In the next chapter we’ll see a jump-table-based approach that does away with the calculation of the target offset in the in-line code entirely, in favor of simply looking up the target address.</p>
<p>Next, <a href="#listing-13-25">Listing 13-25</a> divides the repetition count by 4, since 4 repetitions are performed each time through the loop. That value must then be incremented to account for the first pass through the loop — and that’s it! All we need do is branch to the correct location in the partial in-line code and let it rip. And rip it does, with <a href="#listing-13-25">Listing 13-25</a> running in just 713 us. Yes, that is indeed considerably slower than the 584 us time of the branched-to in-line code of <a href="#listing-13-23">Listing 13-23</a>, but it’s much faster than the 1023 us of <a href="#listing-13-19">Listing 13-19</a>. Then, too, <a href="#listing-13-25">Listing 13-25</a> is only 32 bytes larger than <a href="#listing-13-19">Listing 13-19</a>, while <a href="#listing-13-23">Listing 13-23</a> is more than 600 bytes larger.</p>
<p><a href="#listing-13-25">Listing 13-25</a>, the branched-to partial in-line code, has an additional advantage over <a href="#listing-13-23">Listing 13-23</a>, the branched-to in-line code, and that’s the ability to handle an array of <em>any</em> size up to 64 K-1. With in-line code, the largest number of repetitions that can be handled is determined by the number of times the code is physically repeated. Partial in-line code suffers from no such restriction, since it loops periodically. In fact, branched-to partial in-line code implementations can handle any case normal loops can handle, tend to be only a little larger, and are much faster for all but very small repetition counts.</p>
<p><a href="#listing-13-25">Listing 13-25</a> itself isn’t <em>quite</em> equivalent to a <code class="sourceCode nasm"><span class="kw">loop</span></code>-based loop. Given an initial count of zero, <code class="sourceCode nasm"><span class="kw">loop</span></code> performs 64 K repetitions, while <a href="#listing-13-25">Listing 13-25</a> performs 0 repetitions in the same case. That’s not necessarily a disadvantage; <code class="sourceCode nasm"><span class="kw">loop</span></code>-based loops are often preceded with <code class="sourceCode nasm"><span class="kw">jcxz</span></code> in order to cause zero counts to produce 0 repetitions. However, <a href="#listing-13-25">Listing 13-25</a> can easily be modified to treat an initial count of zero as 64 K; I chose to perform 0 repetitions given a zero count in <a href="#listing-13-25">Listing 13-25</a> only because it made for code that was easier to explain and understand. <a href="#listing-13-26">Listing 13-26</a> shows the <code class="sourceCode nasm">ClearHighBits</code> subroutine of <a href="#listing-13-25">Listing 13-25</a> modified to perform 64 K repetitions given an initial count of zero.</p>
<p>It’s worth noting that the <code class="sourceCode nasm"><span class="kw">inc</span> <span class="kw">ax</span></code> in <a href="#listing-13-26">Listing 13-26</a> could be eliminated if the line:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">dx</span>,offset InLineBitClearEnd</code></pre>
<p>were changed to:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">dx</span>,offset InLineBitClearEnd<span class="dv">-3</span></code></pre>
<p>This change has no effect on overall functionality, because the net effect of <code class="sourceCode nasm"><span class="kw">inc</span> <span class="kw">ax</span></code> in <a href="#listing-13-26">Listing 13-26</a> is merely to subtract 3 from the offset of the end of the partial in-line code. I omitted this optimization in the interests of making <a href="#listing-13-26">Listing 13-26</a> comprehensible, but as a general practice arithmetic should be performed at assembly time rather than at run time whenever possible.</p>
<p>By the way, there’s nothing special about using 4 repetitions in partial in-line code. 8 repetitions or even 16 could serve as well, and, in fact, speed increases as the number of partial in-line repetitions increases. However, size increases proportionately as well, offsetting part of the advantage of using partial in-line code. Partial in-line code using 4 repetitions strikes a nice balance between size and speed, eliminating 75% of the branches without adding too many instruction bytes.</p>
</section>
<section id="partial-in-line-code-and-strings-a-good-match" class="level3">
<h3>Partial In-Line Code and Strings: A Good Match</h3>
<p>One case in which the poor repetition granularity of partial in-line code (that is, the inability of partial in-line loops to deal unaided with repetition counts that aren’t exact multiples of the number of repetitions per partial in-line loop) causes no trouble at all is in handling zero-terminated strings. Since there is no preset repetition count for processing such strings, it doesn’t matter in the least that the lengths of the strings won’t always be multiples of the number of repetitions in a single partial in-line loop. When handling zero-terminated strings, it doesn’t matter if the terminating condition occurs at the start of partial in-line code, the end, or somewhere in-between, since a conditional jump will branch out equally well from anywhere in partial in-line code. As a result, there’s no need to branch into partial in-line code when handling zero-terminated strings.</p>
<p>As usual, an example is the best explanation. Back in <a href="#listing-11-25">Listing 11-25</a>, we used <code class="sourceCode nasm"><span class="kw">lodsw</span></code> and <code class="sourceCode nasm"><span class="kw">scasw</span></code> inside a loop to find the first difference between two zero-terminated strings. We used word — rather than byte-sized string instructions to speed processing; interestingly, much of the improvement came not from accessing memory a word at a time but rather from cutting the number of loops in half, since two bytes were processed per loop. We’re going to use partial in-line code to speed up <a href="#listing-11-25">Listing 11-25</a> further by eliminating still more branches.</p>
<p><a href="#listing-13-27">Listing 13-27</a> is our partial in-line version of <a href="#listing-11-25">Listing 11-25</a>. I’ve chosen a repetition granularity of 8 repetitions per loop both for speed and to show you that granularities other than 4 can be used. There’s no need to add code to branch into the partial in-line code, since there’s no repetition count for a zero-terminated string. Note that I’ve separated the eighth repetition of the partial in-line code from the first seven, so that the eighth repetition can jump directly back to the top of the loop if it doesn’t find the terminating zero. If I lumped all 8 repetitions together in a <code class="sourceCode nasm">rept</code> block, an unconditional jump would have to follow the partial in-line code in order to branch back to the top of the loop. While that would work, it would result in a conditional jump/unconditional jump pair… and well we know to steer clear of those when we’re striving for top performance.</p>
<p><a href="#listing-13-27">Listing 13-27</a> runs in 278 us, 10% faster than <a href="#listing-11-25">Listing 11-25</a>. Considering how heavily optimized <a href="#listing-11-25">Listing 11-25</a> already was, what with the use of word-sized string instructions, that’s a healthy improvement. What’s more, <a href="#listing-13-27">Listing 13-27</a> isn’t markedly more complicated than <a href="#listing-11-25">Listing 11-25</a>; actually, the only difference is that the contents of the loop are repeated 8 times rather than once.</p>
<p>As you can see, partial in-line code is ideal for the handling of zero-terminated strings. Once again, partial in-line code is a poor man’s <code class="sourceCode nasm">rep</code>; in fact, in string and similar applications, you might think of partial in-line code as a substitute for the sorely-missed <code class="sourceCode nasm">rep</code> prefix for the flexible but slow <code class="sourceCode nasm"><span class="kw">lods</span></code>/<code class="sourceCode nasm"><span class="kw">stos</span></code> and <code class="sourceCode nasm"><span class="kw">lods</span></code>/<code class="sourceCode nasm"><span class="kw">scas</span></code> instruction pairs.</p>
</section>
<section id="labels-and-in-line-code" class="level3">
<h3>Labels and In-Line Code</h3>
<p>That just about does it for our discussion of in-line code. However, there’s one more in-line code item we need to discuss, and that’s the use of labels in in-line code.</p>
<p>Suppose that for some reason you need to use a label somewhere inside in-line code. For example, consider the following:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    rept  <span class="dv">4</span>
    <span class="kw">lodsb</span>
    <span class="kw">cmp</span>   <span class="kw">al</span>,<span class="st">&#39;a&#39;</span>
    <span class="kw">jb</span>    NotUppercase
    <span class="kw">cmp</span>   <span class="kw">al</span>,<span class="st">&#39;z&#39;</span>
    <span class="kw">ja</span>    NotUppercase
    <span class="kw">and</span>   <span class="kw">al</span>,<span class="kw">not</span><span class="bn"> 20h</span>
<span class="fu">NotUppercase:</span>
    <span class="kw">stosb</span>
    endm</code></pre>
<p>In this example, the label <code class="sourceCode nasm">NotUppercase</code> is inside in-line code used to convert 4 characters in a row to uppercase. While the code seems simple enough, it nonetheless has one serious problem:</p>
<p>It won’t assemble.</p>
<p>Why is that? The problem is that the line defining the label is inside a <code class="sourceCode nasm">rept</code> block, so it’s literally assembled multiple times. As it would at any time, MASM complains when asked to define two labels with the same name.</p>
<p>The solution should be straightforward: declare the label local to the <code class="sourceCode nasm">rept</code> block with the <code class="sourceCode nasm">local</code> directive, which exists for just such emergencies. For example, the following code should do the trick:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    rept  <span class="dv">4</span>
    local NotUppercase
    <span class="kw">lodsb</span>
    <span class="kw">cmp</span>   <span class="kw">al</span>,<span class="st">&#39;a&#39;</span>
    <span class="kw">jb</span>    NotUppercase
    <span class="kw">cmp</span>   <span class="kw">al</span>,<span class="st">&#39;z&#39;</span>
    <span class="kw">ja</span>    NotUppercase
    <span class="kw">and</span>   <span class="kw">al</span>,<span class="kw">not</span><span class="bn"> 20h</span>
<span class="fu">NotUppercase:</span>
    <span class="kw">stosb</span>
    endm</code></pre>
<p>It should — but it doesn’t, at least not with MASM 5.0. While the <code class="sourceCode nasm">local</code> directive does indeed solve our problem when assembled with TASM, it just doesn’t work correctly when assembled with MASM 5.0. There’s no use asking why — the bugs and quirks of MASM are just a fact of life in assembler programming.</p>
<p>So, what’s the solution to our local label problem when using MASM? One possibility is counting bytes and jumping relative to the program counter, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">rept  <span class="dv">4</span>
<span class="kw">lodsb</span>
<span class="kw">cmp</span>   <span class="kw">al</span>,<span class="st">&#39;a&#39;</span>
<span class="kw">jb</span>    <span class="dv">$</span>+<span class="dv">8</span>
<span class="kw">cmp</span>   <span class="kw">al</span>,<span class="st">&#39;z&#39;</span>
<span class="kw">ja</span>    <span class="dv">$</span>+<span class="dv">4</span>
<span class="kw">and</span>   <span class="kw">al</span>,<span class="kw">not</span><span class="bn"> 20h</span>
<span class="kw">stosb</span>
endm</code></pre>
<p>It’s not elegant, but it does work. Another possibility is defining a macro that contains the code in the <code class="sourceCode nasm">rept</code> block, since <code class="sourceCode nasm">local</code> <em>does</em> work in macros. For example, the following assembles properly under MASM 5.0:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">MAKE_UPPER    macro
    local   NotUppercase
    <span class="kw">lodsb</span>
    <span class="kw">cmp</span>     <span class="kw">al</span>,<span class="st">&#39;a&#39;</span>
    <span class="kw">jb</span>      NotUppercase
    <span class="kw">cmp</span>     <span class="kw">al</span>,<span class="st">&#39;z&#39;</span>
    <span class="kw">ja</span>      NotUppercase
    <span class="kw">and</span>     <span class="kw">al</span>,<span class="kw">not</span><span class="bn"> 20h</span>
<span class="fu">NotUppercase:</span>
    <span class="kw">stosb</span>
    endm
            :
    rept    <span class="dv">4</span>
    MAKE_UPPER
    endm</code></pre>
</section>
</section>
<section id="a-note-on-self-modifying-code" class="level2">
<h2>A Note on Self-Modifying Code</h2>
<p>Just so you won’t think I’ve forgotten about it, let’s briefly discuss self-modifying code. For those of you unfamiliar with this demon of modern programming, self-modifying code is a once-popular coding technique whereby a program modifies its own code — changes its own instruction bytes — on the fly in order to alter its operation without the need for tests and branches. (Remember how back in Chapter 3 we learned that code is just one kind of data? Self-modifying code is a logical extension of that concept.) Nowadays, self-modifying code is strongly frowned-upon, on the grounds that it makes for hard-to-follow, hard-to debug programs.</p>
<p>“Frowned upon, eh?” you think. “Sounds like fertile ground for a little Zen programming, doesn’t it?” Yes, it does. Nonetheless, I <em>don’t</em> recommend that you use self-modifying code, at least not self-modifying code in the classic sense. Not because it’s frowned-upon, of course, but rather because I haven’t encountered any cases where in-line code, look-up tables, jump vectors, jumping through a register or some other 8088 technique didn’t serve just about as well as self-modifying code.</p>
<p>Granted, there may be a small advantage to, say, directly modifying the displacement in a <code class="sourceCode nasm"><span class="kw">jmp</span></code> instruction rather than jumping to the address stored in a word-sized memory variable, but in-line code really <em>is</em> hard to debug and follow, and is hard to write, as well (consider the complexities of simply calculating a jump displacement). I haven’t seen cases where in-line code brings the sort of significant performance improvement that would justify its drawbacks. That’s not to say such cases don’t exist; I’m sure they do. I just haven’t encountered them.</p>
<p>Self-modifying code has an additional strike against it in the form of the prefetch queue. If you modify an instruction byte after it’s been fetched by the Bus Interface Unit, it’s the original, unmodified byte that’s executed, since that’s the byte that the 8088 read. That’s particularly troublesome because the various members of the 8086 family have prefetch queues of differing lengths, so self-modifying code that works on the PC might not work at all on an AT or a Model 80. A branch always empties the prefetch queue and forces it to reload, but even that might not be true with future 8086-family processors.</p>
<p>To sum up, my experience is that in the context of the 8086 family, self-modifying code offers at best small performance improvements, coupled with significant risk and other drawbacks. That’s not the case with some other processors, especially those with less-rich instruction sets and no prefetch queue. However, <em>The Zen of Assembly Language</em> is concerned only with the 8086 family, and in that context my final word on self-modifying code of the sort we’ve been discussing is:</p>
<p>Why bother?</p>
<p>On the other hand, I’ve only been discussing self-modifying code in the classic sense, where individual instructions are altered. For instance, the operand to <code class="sourceCode nasm"><span class="kw">cmp</span> <span class="kw">al</span>, immed8</code> might be modified to change an inclusion range; in such a case, why not just use <code class="sourceCode nasm"><span class="kw">cmp</span> <span class="kw">al</span>,reg</code> and load the new range bound into the appropriate register? It’s simpler, easier to follow, and actually slightly faster.</p>
<p>There’s another sort of self-modifying code, however, that operates on a grander scale. Consider a program that uses code overlays. Code is swapped in from disk to memory and then executed; obviously the instruction bytes in the overlay region are changed, so that’s self-modifying code. Or consider a program that builds custom code for a special, complex purpose in a buffer and then executes the generated code; that’s self-modifying code as well. Some programs are built out of loosely-coupled, relocatable blocks of code residing in a heap under a memory manager, with the blocks moved around memory and to and from disk as they’re needed; that’s certainly self-modifying code, in the sense that the instructions stored at particular memory locations change constantly. Finally, loadable drivers, such as graphics drivers for many windowing environments, are self-modifying code of a sort, since they are loaded as data from the disk into memory by the driver-based program and then executed.</p>
<p>My point is that you shouldn’t think of code as immovable and unchangeable. I’ve found that it’s not worth the trouble and risk to modify individual instructions, but in large or complex programs it can be most worthwhile to treat blocks of code as if they were data. The topic is a large one, and this is not the place to explore it, but always keep in mind that even if self-modifying code in its classic sense isn’t a great idea on the 8088, the notion that code is just another sort of data is a powerful and perfectly valid concept.</p>
<section id="conclusion-1" class="level3">
<h3>Conclusion</h3>
<p>Who would have thought that not-branching could offer such variety, to say nothing of such substantial performance improvements? You’ll find that not-branching is an excellent exercise for developing your assembler skills, requiring as it does a complete understanding of what your code needs to do, thorough knowledge of the 8088 instruction set, the ability to approach programming problems in non-intuitive ways, knowledge as to when the effort involved in not-branching is justified by the return, and a balancing of relative importance of saving bytes and cycles in a given application.</p>
<p>In other words, not-branching is a perfect Zen exercise. Practice it often and well!</p>
</section>
</section>
</section>
<section id="chapter-14-if-you-must-branch" class="level1">
<h1>Chapter 14: If You Must Branch…</h1>
<p>Not-branching is a terrific performance tool, but realistically you <em>are</em> going to branch — and frequently at that, for the branching instructions are both compact and most useful for making decisions. Do your best to avoid branches in your time-critical code, and when you must branch, do so intelligently. By “intelligently” I mean, among other things, avoiding far branches whenever possible, getting multiple tests out of a single instruction, using the special looping instructions, and using jump tables. We’ll look at these and various other cycle-and/or byte-saving branching techniques over the course of this chapter.</p>
<p>This chapter differs from the last few chapters in that it offers no spectacularly better approaches, no massive savings of cycles. Instead, it’s a collection of things to steer clear of and tips that save a few cycles and/or bytes. Taken together, the topics in this chapter should give you some new perspectives on writing branching code, along with a few more items for your programming toolkit.</p>
<p>Remember, though, that relatively fast as some of the techniques in this chapter may be, it’s still faster not to branch at all!</p>
<section id="dont-go-far" class="level2">
<h2>Don’t Go Far</h2>
<p>Far branches are branches that load both CS and IP, by contrast with near branches, which only load IP. Whatever you do, don’t use far branches — jumps, calls, and returns — any more than you absolutely must. Far calls and returns, in particular, tend to bulk up code and slow performance greatly, as the bloated size and sluggish performance of C programs written in the large code model readily attest.</p>
<p>Surprisingly, far jumps — direct far jumps, at least — aren’t all that bad. A direct far jump — a far jump to a label, such as <code class="sourceCode nasm"><span class="kw">jmp</span> far <span class="dt">ptr</span> Target</code> — is big, at 5 bytes, but its EU execution time is exactly the same as that of a near jump to a label — 15 cycles. Of course, it can take extra cycles to fetch all 5 bytes, and, as with all branches, the prefetch queue is emptied; still and all, a direct jump isn’t much worse than its near counterpart.</p>
<p>The same cannot be said for an indirect far jump — that is, a far jump to the segment:offset address contained in a memory variable, as in <code class="sourceCode nasm"><span class="kw">jmp</span> <span class="dt">dword</span> <span class="dt">ptr</span> [Vector]</code>. While such an instruction is no larger than its near counterpart — both are 1 byte long plus the usual 1 to 3 bytes of <em>mod-reg-rm</em> addressing — it <em>is</em> much slower than an indirect near jump, and that’s saying a lot. Where an indirect near jump takes at least 27 cycles to execute, an indirect far jump takes at least 37 cycles… one reason why jump and call tables that branch to near routines are <em>much</em> preferred to those that branch to far routines. (We’ll discuss jump and call tables at the end of this chapter.)</p>
<p>Far calls and returns are worse yet. Near returns must pop IP from the stack. Far returns must pop CS as well, and those two additional memory accesses must cost at least 8 cycles. In all, far returns execute in 32 cycles, 12 cycles slower than near returns. That’s not in itself so bad, especially when you consider that far returns are only 1 byte long, just like near returns.</p>
<p>Now, however, consider that far returns must be paired with far calls. So what, you ask? Simply this: no matter how you slice it, far calls are bad news. The basic problem is that far calls perform a slew of memory accesses. All far calls must push 4 bytes (the CS:IP of the return address) onto the stack: that alone takes 16 cycles. Direct far calls are 5 bytes long, which is likely to cause the prefetch queue to eat more than a few cycles, while indirect far calls must read the 4 bytes that point to the destination from memory, at a cost of 16 more cycles. The total bill: direct far calls take 36 cycles and 5 bytes, while indirect far calls take at least 58 cycles.</p>
<p>58 cycles — and where there’s a far call, there’s a far return yet to come. Together, an indirect far call and the corresponding return take at least 90 cycles — as long as or longer than an 8-bit divide! Even a direct far call and the corresponding return together take at least 68 cycles — and very possibly more when you add in the prefetch queue effects of fetching a 5-byte instruction and emptying the prefetch queue twice.</p>
<p>Let’s see just how bad far calls are. In the last chapter, we compared the performance of a subroutine in <a href="#listing-13-16">Listing 13-16</a> with that of a macro in <a href="#listing-13-17">Listing 13-17</a>. The subroutine in <a href="#listing-13-16">Listing 13-16</a> — <code class="sourceCode nasm">IsPrintable</code> — is called with a near <code class="sourceCode nasm"><span class="kw">call</span></code> and returns with a near <code class="sourceCode nasm"><span class="kw">ret</span></code>. Given that quite a bit besides the <code class="sourceCode nasm"><span class="kw">call</span></code> and <code class="sourceCode nasm"><span class="kw">ret</span></code> occurs each time the subroutine is called — including several branches and two memory accesses — how much slower do you suppose overall performance would be if <code class="sourceCode nasm">IsPrintable</code> were entered and exited with far branches?</p>
<p>Quite a bit, as it turns out. <a href="#listing-13-16">Listing 13-16</a> ran in 3.48 ms. <a href="#listing-14-1">Listing 14-1</a>, which is identical to <a href="#listing-13-16">Listing 13-16</a> save that <code class="sourceCode nasm">IsPrintable</code> is a far procedure, takes 4.32 ms to finish. In other words, the simple substitution of a near <code class="sourceCode nasm"><span class="kw">call</span></code>/<code class="sourceCode nasm"><span class="kw">ret</span></code> for a far <code class="sourceCode nasm"><span class="kw">call</span></code>/<code class="sourceCode nasm"><span class="kw">ret</span></code> results in a 24% performance increase.</p>
<p>I don’t think I really have to interpret those results for you, but just in case…</p>
<p>Don’t branch. If you must branch, don’t branch far. If you must branch far, don’t use far calls and returns unless you absolutely, positively can’t help it. (Don’t even consider software interrupts; as we’ll see later, interrupts make far calls look fast.) Unfortunately, it’s easy to fall into using far calls and returns, since that’s the obvious way to implement large applications on the PC. High-level languages make it particularly easy to fall into the far-call trap, because the source code for a large code model program (that is, a program using far calls by default) is no different than that for a small code model program.</p>
<p>Even in assembler, far calls seem fairly harmless at first glance. The Zen timer reveals the truth, however — far calls cost dearly in the performance department. Far calls, whether direct to a label or indirect through a call table (as we’ll see later), cost dearly in code size, too.</p>
<p>If you catch my drift: don’t use far calls unless you have no choice!</p>
<section id="how-to-avoid-far-branches" class="level3">
<h3>How to Avoid Far Branches</h3>
<p>Ideally, all the code in a given program should fit in one 64 Kb segment, eliminating the need for far branching altogether. Even in bigger programs, however, it’s often possible to keep most of the branches near.</p>
<p>For example, few programs with more than 64 Kb of code (large code model programs) are written in pure assembler; usually the bulk of the program is written in C, Pascal, or the like, with assembler used when speed is of the essence. In such programs all the assembler code will often fit in a single 64 Kb segment, and the complete control assembler gives you over segment naming makes it easy to place multiple assembler modules in the same code segment. Once that’s done, all branches within the assembler code can be near, even though branches between the high-level language code and the assembler code must be far, as shown in Figure 14.1.</p>
<figure>
<img src="images/fig14.1RT.png" />
</figure>
<p>Many compilers allow you to specify the segment names used for individual modules, if you so desire. If your compiler supports code segment naming and also supports near procedures in the large code model (as, for example, Turbo C does), you could actually make near calls not only within your assembler code, but also <em>into</em> that code from the high-level language. The key is giving selected high-level language modules and your assembler code identical code segment names, so they’ll share a single code segment, then using the <code class="sourceCode nasm">near</code> keyword to declare the assembler subroutines as near externals in the high-level language code.</p>
<p>In fact, you can readily benefit from localized near branching even if you’re not using assembler at all. You can use the <code class="sourceCode nasm">near</code> keyword to declare routines that are referenced only within one high-level language module to be near routines, allowing the compiler to generate near rather than far calls to those routines. As noted above, you can even place several modules in the same code segment and use near calls for functions referenced only within those modules that share the same segment.</p>
<p>In short, in the code that really matters you can often enjoy the performance advantage of small code model programming — that is, near branches — even when your program has more than 64 Kb of code and so must use the large code model overall.</p>
<p>Whether you’re programming in assembler or a high-level language, one great benefit of using near rather than far subroutines is the reduction in the size of jump and call tables that near subroutines make possible. While the address of a near subroutine can be specified as a 1-word table entry, a full doubleword is required to specify the segment and offset of a far subroutine. It doesn’t take a genius to figure out that we can cut the size of a jump or call table in half if we can convert the subroutines it branches to from far to near, as shown in Figure 14.2.</p>
<figure>
<img src="images/fig14.2RT.png" />
</figure>
<p>When we add the space savings of near-branching jump and call tables to the performance advantages of indirect near branches that we explored earlier, we can readily see that it’s worth going to a good deal of trouble to make the near-branching variety of jump and call tables whenever possible. We’ll return to the topic of jump and call tables at the end of this chapter.</p>
</section>
<section id="odds-and-ends-on-branching-far" class="level3">
<h3>Odds and Ends on Branching Far</h3>
<p>When programming in the large code model, you’ll often encounter the case where one assembler subroutine calls another assembler subroutine that resides in the same code segment. Naturally, you’d like to use a near rather than far call; unfortunately, if the called subroutine is also called from outside the module, it may well have to be a far subroutine — that is, it may return with a far return. That means that a near call can’t be used, since the far return would attempt to pop CS:IP while the near call would push only IP.</p>
<p>All is not lost, however — you can <em>fake</em> a far call, and save a byte in the process. If you think about it, the only difference between a far call to a near label and a near call is that the far call pushes CS before it pushes IP, and we can accomplish that by pushing CS before making a near call. That is:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">push</span>  <span class="kw">cs</span>
<span class="kw">call</span>  near <span class="dt">ptr</span> FarSubroutine</code></pre>
<p>is equivalent to:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">call</span>  far <span class="dt">ptr</span> FarSubroutine</code></pre>
<p>when <code class="sourceCode nasm">FarSubroutine</code> is in the same segment as the calling code. Since a direct near call is 2 bytes shorter than a direct far call and <code class="sourceCode nasm"><span class="kw">push</span> <span class="kw">cs</span></code> is only 1 byte long, we actually come out 1 byte ahead by pushing CS and making a near call. According to the official cycle counts, the push/near call approach is 1 cycle slower; however, the alternative approach requires that 1 more instruction byte be fetched, so the scales could easily tip the other way.</p>
<p>One more item on far calls, and then we’ll get on to other topics. Often it’s necessary to perform a far branch to an address specified by an entry in a look-up table. That’s generally no problem — we point to the table entry, perform an indirect far branch, and away we go.</p>
<p>Sometimes, however — in certain types of reentrant interrupt handlers and dispatchers, for example — it’s necessary to perform an indirect far branch without altering the registers in any way, and without modifying memory. How can we perform such a branch without building a doubleword pointer in memory, to say nothing of leaving the registers unchanged?</p>
<p>The answer is that we <em>can</em> build a doubleword pointer in memory — on the stack. We can perform a far branch to anywhere in memory simply by putting CS and IP onto the stack (in that order, with CS at the higher address), then performing a far return. To wit:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="co">;</span>
<span class="co">; Branches to the entry in VectorTable that&#39;s indicated</span>
<span class="co">; by the index in BX. All registers are preserved.</span>
<span class="co">;</span>
<span class="co">; VectorTable is in CS, so DS doesn&#39;t need to be set to</span>
<span class="co">; any particular segment.</span>
<span class="co">;</span>
FarBranchByIndex  proc  near
    <span class="kw">sub</span>   <span class="kw">sp</span>,<span class="dv">4</span>                      <span class="co">;make room for the target address</span>
    <span class="kw">push</span>  <span class="kw">bp</span>                        <span class="co">;preserve all registers we&#39;ll change</span>
    <span class="kw">mov</span>   <span class="kw">bp</span>,<span class="kw">sp</span>                     <span class="co">;point 1 word above the stack space</span>
                                    <span class="co">; we&#39;ve reserved for the target address</span>
    <span class="kw">push</span>  <span class="kw">bx</span>
    <span class="kw">push</span>  <span class="kw">ax</span>
    <span class="kw">shl</span>   <span class="kw">bx</span>,<span class="dv">1</span>                      <span class="co">;convert index to doubleword look-up</span>
    <span class="kw">shl</span>   <span class="kw">bx</span>,<span class="dv">1</span>
    <span class="kw">mov</span>   <span class="kw">ax</span>,<span class="kw">cs</span>:[VectorTable+<span class="kw">bx</span>]    <span class="co">;get target offset</span>
    <span class="kw">mov</span>   [<span class="kw">bp</span><span class="dv">+2</span>],<span class="kw">ax</span>                 <span class="co">;put target offset onto stack</span>
    <span class="kw">mov</span>   <span class="kw">ax</span>,<span class="kw">cs</span>:[VectorTable+<span class="kw">bx</span><span class="dv">+2</span>]  <span class="co">;get target segment</span>
    <span class="kw">mov</span>   [<span class="kw">bp</span><span class="dv">+4</span>],<span class="kw">ax</span>                 <span class="co">;put target segment onto stack</span>
    <span class="kw">pop</span>   <span class="kw">ax</span>                        <span class="co">;restore all registers we&#39;ve changed</span>
    <span class="kw">pop</span>   <span class="kw">bx</span>
    <span class="kw">pop</span>   <span class="kw">bp</span>
    <span class="kw">ret</span>
FarBranchByIndex  endp</code></pre>
<p>To carry this line of thought to its logical extreme, we could even preserve the states of the flags by executing a <code class="sourceCode nasm"><span class="kw">pushf</span></code> before allocating the stack space, and then performing an <code class="sourceCode nasm"><span class="kw">iret</span></code> rather than a far <code class="sourceCode nasm"><span class="kw">ret</span></code> to branch to the target.</p>
<p>The sort of branching shown above is an example of how flexible the 8088’s instruction set can be, especially if you’re willing to use instructions in unusual ways, like hand-constructing far return addresses on the stack. This example certainly isn’t ideal for most tasks… but it’s available if you need the particular service it delivers. In truth, the only limit on the strange jobs the 8088 can be coaxed into doing is your creativity. Speed may sometimes be a problem with the 8088, but flexibility shouldn’t be.</p>
</section>
</section>
<section id="replacing-call-and-ret-with-jmp" class="level2">
<h2>Replacing <code>call</code> and <code>ret</code> With <code>jmp</code></h2>
<p>Enough of far branches, already. Let’s continue with some interesting ways to replace <code class="sourceCode nasm"><span class="kw">call</span></code> and <code class="sourceCode nasm"><span class="kw">ret</span></code> with <code class="sourceCode nasm"><span class="kw">jmp</span></code>.</p>
<p>Suppose that we’ve got a subroutine that’s only called from one place in an entire program. That might be the case with a subroutine called through a call table from a central dispatch point, for example. Well, then, there’s really no reason to call and return; instead, we can simply jump to the subroutine, and then jump back to the instruction after the call point, saving some cycles in the process.</p>
<p>For example, consider the code in <a href="#listing-14-2">Listing 14-2</a>, which is yet another modification of the printable character filtering program of <a href="#listing-13-16">Listing 13-16</a>. The modification in <a href="#listing-14-2">Listing 14-2</a> is that the call to <code class="sourceCode nasm">IsPrintable</code> has been replaced with a jump to the subroutine, and the return from <code class="sourceCode nasm">IsPrintable</code> has been replaced with a second jump, this time to the instruction after the jump that invoked the subroutine.</p>
<p>That simple change cuts overall execution time to 3.09 ms, an improvement of more than 12%. Granted, part of the improvement is due to the use of short jumps, each of which reduces prefetching by 1 byte over normal jumps; when:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="dt">db</span>  <span class="dv">128</span> dup(?)</code></pre>
<p>is placed between <code class="sourceCode nasm">IsPrintable</code> and the rest of the code, forcing the use of jumps with normal 2-byte displacements, overall execution time rises to 3.33 ms, less than 5% faster than the original version. All that means, however, is that the <code class="sourceCode nasm"><span class="kw">jmp</span></code>-<code class="sourceCode nasm"><span class="kw">jmp</span></code> technique as a replacement for <code class="sourceCode nasm"><span class="kw">call</span></code>-<code class="sourceCode nasm"><span class="kw">ret</span></code> is most desirable when short jumps can be used. That’s particularly true since two normal jumps total 6 bytes in length, 2 bytes longer than a <code class="sourceCode nasm"><span class="kw">call</span></code>-<code class="sourceCode nasm"><span class="kw">ret</span></code> pair.</p>
<p>In truth, <a href="#listing-14-2">Listing 14-2</a> doesn’t demonstrate a particularly good application for replacing <code class="sourceCode nasm"><span class="kw">call</span></code>-<code class="sourceCode nasm"><span class="kw">ret</span></code> with <code class="sourceCode nasm"><span class="kw">jmp</span></code>-<code class="sourceCode nasm"><span class="kw">jmp</span></code>. As shown in <a href="#listing-14-2">Listing 14-2</a>, <code class="sourceCode nasm">IsPrintable</code> could only be called from one place in the program, the <code class="sourceCode nasm">CopyPrintable</code> subroutine, and we usually want more flexibility in invoking our subroutines than that. (Otherwise we might just as well make the subroutines macros and move them right into the calling code.) That’s why subroutines called through call tables are much better candidates for the <code class="sourceCode nasm"><span class="kw">jmp</span></code>-<code class="sourceCode nasm"><span class="kw">jmp</span></code> technique, since such subroutines often really are invoked from just one place.</p>
<section id="flexibility-ad-infinitum" class="level3">
<h3>Flexibility <em>Ad Infinitum</em></h3>
<p>If more flexibility is needed than the last example provides, are we fated always to use <code class="sourceCode nasm"><span class="kw">call</span></code>-<code class="sourceCode nasm"><span class="kw">ret</span></code> rather than <code class="sourceCode nasm"><span class="kw">jmp</span>-<span class="kw">jmp</span></code>? Well, the theme of this chapter seems to be the infinite flexibility of the 8088’s instruction set, so it should come as no surprise to you that the answer is: not at all. Usually, you <em>will</em> want to use <code class="sourceCode nasm"><span class="kw">call</span></code>-<code class="sourceCode nasm"><span class="kw">ret</span></code>, since it’s by far the simplest solution and often the fastest as well… but there <em>are</em> alternatives, and they can be quite handy in a pinch.</p>
<p>Consider this. Suppose that you’ve got a set of subroutines that are called via a call table. Next, suppose that it’s desirable that any of the subroutines be able to end at any point and return to the central dispatching point — <em>without cleaning up the stack</em>. That is, it must be possible to return from anywhere in any subroutine called through the call table, discarding whatever variables, return addresses and so on happen to be on the stack at the time.</p>
<p>Well, that’s no great trick; we can simply jump back to the dispatch point, where the original (pre-call) stack pointer could be retrieved from a memory variable and loaded into SP. I know it’s a strange thought, but it’s perfectly legal to clear the stack simply by reloading SP. Now, however, suppose that the call table can be started from any of several locations. That means that a simple direct jump will no longer serve to return us to the calling code, since the calling code could be in any of several places. We certainly can’t use <code class="sourceCode nasm"><span class="kw">call</span></code> and <code class="sourceCode nasm"><span class="kw">ret</span></code> either, since the return address could well be buried under data pushed on the stack at any given time.</p>
<p>The solution is simple: place the return address in a register before jumping at the central dispatch point, preserve the register throughout each subroutine, and return by branching to the offset in the register. The code would look something like this:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">mov</span>   [OriginalSP],<span class="kw">sp</span>           <span class="co">;save the stack state</span>
<span class="fu">DispatchLoopTop:</span>
          :                         <span class="co">;point BX to desired entry</span>
          :                         <span class="co">; in VectorTable</span>
    <span class="kw">mov</span>   <span class="kw">di</span>,offset DispatchReturn  <span class="co">;put the return address in DI,</span>
                                    <span class="co">; pointing to the instruction</span>
                                    <span class="co">; after the jump</span>
    <span class="kw">jmp</span>   [VectorTable+<span class="kw">bx</span>]          <span class="co">;jump to desired subroutine</span>
<span class="fu">DispatchReturn:</span>                     <span class="co">;subroutines return here</span>
    <span class="kw">mov</span>   <span class="kw">sp</span>,[OriginalSP]           <span class="co">;restore the stack state</span>
    <span class="kw">jmp</span>   DispatchLoopTop
          :
<span class="fu">Subroutine1:</span>                        <span class="co">;one of the subroutines</span>
          :                         <span class="co">; called through VectorTable</span>
          :                         <span class="co">;DI is preserved throughout</span>
          :                         <span class="co">; Subroutine1</span>
    <span class="kw">jmp</span>   <span class="kw">di</span>                        <span class="co">;return to the calling code</span></code></pre>
<p>Make no mistake: this approach has its flaws. For one thing, it ties up a 16-bit register for the duration of each subroutine, and registers are scarce enough as it is. (The return address could instead be stored in a memory variable, but that reduces performance and causes reentrancy problems.) For another, it wastes bytes, since the <code class="sourceCode nasm"><span class="kw">jmp</span> <span class="kw">di</span></code> instruction used to return to the dispatcher is 1 byte longer than <code class="sourceCode nasm"><span class="kw">ret</span></code>, and the <code class="sourceCode nasm"><span class="kw">mov</span></code>-<code class="sourceCode nasm"><span class="kw">jmp</span></code> pair used by the dispatcher is 3 bytes longer than <code class="sourceCode nasm"><span class="kw">call</span></code>. Yet another fault is the inherently greater complexity of the code, which brings with it an increased probability of bugs.</p>
<p>Nonetheless, the above approach offers the flexibility we need — and then some. Think for a moment, and you’ll realize that we can, if we wish, return anywhere at all with the above approach. For example, the following saves a branch by returning right to <code class="sourceCode nasm">DispatchLoopTop</code>:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">mov</span>   [OriginalSP],<span class="kw">sp</span>             <span class="co">;save the stack state</span>
<span class="fu">DispatchLoopTop:</span>
    <span class="kw">mov</span>   <span class="kw">sp</span>,[OriginalSP]             <span class="co">;restore the stack state</span>
          :                           <span class="co">;point BX to desired entry</span>
          :                           <span class="co">; in VectorTable</span>
    <span class="kw">mov</span>   <span class="kw">di</span>,offset DispatchLoopTop   <span class="co">;put the return address in DI,</span>
                                      <span class="co">; pointing to the top of the loop</span>
    <span class="kw">jmp</span>   [VectorTable+<span class="kw">bx</span>]            <span class="co">;jump to desired subroutine</span>
          :
<span class="fu">Subroutine1:</span>                          <span class="co">;one of the subroutines</span>
          :                           <span class="co">; called through VectorTable</span>
          :                           <span class="co">;DI is preserved throughout</span>
          :                           <span class="co">; Subroutine1</span>
    <span class="kw">jmp</span>   <span class="kw">di</span>                          <span class="co">;return to the calling code</span></code></pre>
<p>(You don’t have to jump through a register to return to an instruction other than the one after the calling instruction; just push the desired return address onto the stack and jump to a subroutine. For example, the following:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="fu">DispatchLoopTop:</span>
          :                           <span class="co">;point BX to desired entry</span>
          :                           <span class="co">; in VectorTable</span>
    <span class="kw">mov</span>   <span class="kw">ax</span>,offset DispatchLoopTop   <span class="co">;push the return address</span>
    <span class="kw">push</span>  <span class="kw">ax</span>                          <span class="co">; on the stack</span>
    <span class="kw">jmp</span>   [VectorTable+<span class="kw">bx</span>]            <span class="co">;jump to desired subroutine</span>
          :
<span class="fu">Subroutine1:</span>                          <span class="co">;one of the subroutines</span>
          :                           <span class="co">; called through VectorTable</span>
    <span class="kw">ret</span>                               <span class="co">;return to the calling code</span></code></pre>
<p>pushes <code class="sourceCode nasm">DispatchLoopTop</code> before jumping, so each subroutine returns to <code class="sourceCode nasm">DispatchLoopTop</code> rather than to the instruction after the <code class="sourceCode nasm"><span class="kw">jmp</span></code>.)</p>
<p>Surprisingly, flexibility is not the only virtue of the return-through-register approach — under the right circumstances, performance can benefit as well, since a branch through a register is only 2 bytes long and executes in just 11 cycles. <a href="#listing-14-3">Listing 14-3</a> shows <a href="#listing-14-2">Listing 14-2</a> modified to store the return address in BP. While this code is a tad longer than <a href="#listing-14-2">Listing 14-2</a>, since BP must be loaded, <a href="#listing-14-3">Listing 14-3</a> executes in 3.03 ms — slightly <em>faster</em> than <a href="#listing-14-2">Listing 14-2</a>. The key is that BP is loaded only once, outside the loop, in <code class="sourceCode nasm">CopyPrintable</code>, so the extra overhead of loading BP is spread over the many repetitions of the loop. Meanwhile, the 4-cycle performance advantage of <code class="sourceCode nasm"><span class="kw">jmp</span> <span class="kw">bp</span></code> over <code class="sourceCode nasm"><span class="kw">jmp</span> <span class="dt">short</span> IsPrintableReturn</code> is gained every time through the loop.</p>
<p>What’s more, the version of <code class="sourceCode nasm">IsPrintable</code> in <a href="#listing-14-3">Listing 14-3</a> can be called from anywhere, so long as the calling code sets BP to the return address. By contrast, <code class="sourceCode nasm">IsPrintable</code> is hardwired to return only to <code class="sourceCode nasm">CopyPrintable</code> in <a href="#listing-14-2">Listing 14-2</a>.</p>
<p>Once again, the point is not that you should generally replace <code class="sourceCode nasm"><span class="kw">call</span></code>-<code class="sourceCode nasm"><span class="kw">ret</span></code> with one of the many flavors of <code class="sourceCode nasm"><span class="kw">jmp</span></code>-<code class="sourceCode nasm"><span class="kw">jmp</span></code>, but rather that you should understand the unusual flexibility that <code class="sourceCode nasm"><span class="kw">jmp</span></code>-<code class="sourceCode nasm"><span class="kw">jmp</span></code> offers. It’s a bonus that <code class="sourceCode nasm"><span class="kw">jmp</span></code>-<code class="sourceCode nasm"><span class="kw">jmp</span></code> can sometimes improve performance; the main point is that the flexibility of this approach lets you perform an odd lot of slightly improbable but sometimes most useful tasks.</p>
</section>
<section id="tinkering-with-the-stack-in-a-subroutine" class="level3">
<h3>Tinkering With the Stack in a Subroutine</h3>
<p>Let’s look at an example of the slightly-improbable that jumping through a register makes easy. Suppose that we want to be able to call a subroutine that allocates a specified number of bytes on the stack, then returns. That doesn’t seem at first glance to be possible, since the allocated bytes would bury the return address beneath them, preventing the subroutine from returning until it deallocated the bytes.</p>
<p>Ah, but now we know about jumping through a register, so the solution’s obvious. Here’s the desired subroutine:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="co">;</span>
<span class="co">; Allocates space on the stack.</span>
<span class="co">;</span>
<span class="co">; Input:</span>
<span class="co">;     CX = # of bytes to allocate</span>
<span class="co">;</span>
<span class="co">; Output: none</span>
<span class="co">;</span>
<span class="co">; Registers altered: AX, SP</span>
<span class="co">;</span>
AllocateStackSpace  proc  near
    <span class="kw">pop</span>   <span class="kw">ax</span>                    <span class="co">;retrieve the return address</span>
    <span class="kw">sub</span>   <span class="kw">sp</span>,<span class="kw">cx</span>                 <span class="co">;allocate the space on the stack</span>
    <span class="kw">jmp</span>   <span class="kw">ax</span>                    <span class="co">;return to the calling code</span>
AllocateStackSpace  endp</code></pre>
<p>If we can tinker with the stack in a subroutine with such impunity, it would seem that with the 8088’s instruction set we could do just about anything one could imagine — and indeed we can. Given the in-depth understanding of the 8088 that we’ve acquired, there’s really nothing we can’t do, given enough execution time. It’s just a matter of putting the pieces of the puzzle — the 8088’s instructions — together, and that’s what the Zen of assembler is all about.</p>
<p>As a simple example, consider the following. Once upon a time, Jeff Duntemann needed to obtain the IP of a particular instruction. Normally, that’s no problem: the value of any label can be loaded into a general-purpose register as an immediate value. That wouldn’t do in Jeff’s situation, however, because his code was in-line assembler code in a Pascal program. The code was nothing more than a series of hex bytes that could be compiled directly into the program at any location at all; because the code could be placed at any location, the current IP couldn’t be represented by any label or immediate value. Given that IP can’t be read directly, what was Jeff to do?</p>
<p>The solution was remarkably simple… given a solid understanding of the 8088’s instruction set and a flexible mind. The <code class="sourceCode nasm"><span class="kw">call</span></code> instruction pushes the IP of the next instruction, so Jeff just called the very next instruction and popped the IP of that instruction from the stack as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">call</span>  <span class="dv">$</span>+<span class="dv">3</span>   <span class="co">;pushes IP and branches to the next instruction</span>
<span class="kw">pop</span>   <span class="kw">ax</span>    <span class="co">;gets the IP of this instruction</span></code></pre>
<p>It’s not exactly what <code class="sourceCode nasm"><span class="kw">call</span></code> was intended for, but it solved Jeff’s problem — and results are what matter most in assembler programming.</p>
</section>
</section>
<section id="use-int-only-when-you-must" class="level2">
<h2>Use <code>int</code> Only When You Must</h2>
<p>Before we get on with more ways to branch efficiently, let’s discuss <code class="sourceCode nasm"><span class="kw">int</span></code> for a moment. <code class="sourceCode nasm"><span class="kw">int</span></code> is an oddball among branching instructions, in that it performs a far branch to the address stored at the corresponding interrupt vector in the 1 Kb table of interrupt vectors starting at 0000:0000. <code class="sourceCode nasm"><span class="kw">int</span></code> not only pushes a return CS:IP address, as would a far call, but pushes the FLAGS register as well.</p>
<p><code class="sourceCode nasm"><span class="kw">int</span></code> operates as it does because it’s really more of a hardware instruction than a software instruction. When interrupts are enabled (via the Interrupt flag) and one of the 8088’s hardware interrupts occurs, the 8088 automatically executes an <code class="sourceCode nasm"><span class="kw">int</span></code> instruction at the end of the current instruction. Because the currently executing code can be interrupted at any time, the exact state of the registers and flags <em>must</em> be preserved; hence the pushing of the FLAGS register. The <code class="sourceCode nasm"><span class="kw">iret</span></code> instruction provides a neat method for restoring the flags and branching back to continue the interrupted code.</p>
<p>From the perspective of servicing hardware that can require attention at any time, the 8088’s interrupt mechanism is ideal. Interrupts are location — and code — independent; no matter what code you’re executing, where that code resides, or what the setting of the registers are, an interrupt will branch to the correct interrupt handler and allow you to restore the state of the 8088 when you’re done.</p>
<p>From a software perspective, the interrupt mechanism is considerably less ideal. Since an <code class="sourceCode nasm"><span class="kw">int</span></code> instruction must be executed to perform a software interrupt, there’s no possibility of asynchronous execution of a software interrupt, and hence no real need to save the state of the flags. What’s more, <code class="sourceCode nasm"><span class="kw">int</span></code> is astonishingly slow, making almost any sort of branch — yes, even a far call — preferable.</p>
<p>How slow is <code class="sourceCode nasm"><span class="kw">int</span></code>? <em>Slow</em>. <code class="sourceCode nasm"><span class="kw">int</span></code> itself takes 71 cycles and empties the prefetch queue, and <code class="sourceCode nasm"><span class="kw">iret</span></code> takes an additional 44 cycles and empties the prefetch queue again. At 115 cycles and two queue flushes a pop, you won’t be using <code class="sourceCode nasm"><span class="kw">int</span></code> too often in your time-critical code!</p>
<p>Why would you ever want to use <code class="sourceCode nasm"><span class="kw">int</span></code>? The obvious answer is that you <em>must</em> use <code class="sourceCode nasm"><span class="kw">int</span></code> to invoke DOS and BIOS functions. <code class="sourceCode nasm"><span class="kw">int</span></code> is used for these services because it’s a handy way to provide entry points into routines that may move around in memory. No matter where the BIOS keyboard interface resides (and it may well move from one version of the BIOS to another, to say nothing of memory-resident programs that intercept keystrokes), it can always be accessed with <code class="sourceCode nasm"><span class="kw">int</span><span class="bn"> 16h</span></code>. Basically, <code class="sourceCode nasm"><span class="kw">int</span></code> is a useful way to access code that’s external to the program that’s running and consequently can’t be branched to directly.</p>
<p>IBM left a number of interrupt vectors free for application program use, and that, along with the knowledge that <code class="sourceCode nasm"><span class="kw">int</span></code> is a compact 2 bytes in length, might start you thinking that you could use <code class="sourceCode nasm"><span class="kw">int</span></code> rather than <code class="sourceCode nasm"><span class="kw">call</span></code> to branch to routines <em>within</em> a program. After all, in a large code model program <code class="sourceCode nasm"><span class="kw">int</span></code> is 3 bytes shorter than a direct call.</p>
<p>It’s a nice idea — but not, as a general rule, a <em>good</em> idea. For one thing, you might well find that your chosen interrupt vectors conflict with those used by a memory-resident program. There aren’t very many available vectors, and interrupt conflicts can easily crash a computer. Also, <code class="sourceCode nasm"><span class="kw">int</span></code> is just too slow to be of much use; you’d have to have a powerful need to save space and an equally powerful insensitivity to performance to even consider using <code class="sourceCode nasm"><span class="kw">int</span></code>. Also, because there aren’t many interrupt vectors, you’ll probably find yourself using a register to pass function numbers. Having to load a register pretty much wipes out the space savings <code class="sourceCode nasm"><span class="kw">int</span></code> offers, and because the interrupt handler will have to perform another branch internally in order to vector to the code for the desired function, performance will be even worse.</p>
<p>In short, reserve <code class="sourceCode nasm"><span class="kw">int</span></code> for accessing DOS and BIOS services and for those applications where there simply is no substitute — applications in which location independence is paramount.</p>
<section id="beware-of-letting-dos-do-the-work" class="level3">
<h3>Beware of Letting Dos Do the Work</h3>
<p>Interrupts are so slow that it often pays to go to considerable trouble to move them out of loops. Consider character-by-character processing of a text file, as for example when converting the contents of a text file to uppercase. In such an application it’s easiest to avoid the complications of buffering text by letting DOS feed you one character at a time, as shown in Figure 14.3.</p>
<figure>
<img src="images/fig14.3RT.png" />
</figure>
<p><a href="#listing-14-4">Listing 14-4</a> illustrates the approach of letting DOS do the work on a character-by-character basis. <a href="#listing-14-4">Listing 14-4</a> reads characters from the standard input, converts them to uppercase, and prints the results to the standard output, interacting with DOS a character at a time at both the input and output stages. <a href="#listing-14-4">Listing 14-4</a> takes 2.009 seconds to convert the contents of the file TEST.TXT, shown in Figure 14.4, to uppercase and send the result to the standard output.</p>
<p>(There’s a slight complication in timing <a href="#listing-14-4">Listing 14-4</a>. <a href="#listing-14-4">Listing 14-4</a> must be assembled and linked with LZTIME.BAT, since it takes more than 54 ms to run. However, <a href="#listing-14-4">Listing 14-4</a> expects to receive characters from the standard input when it executes. When run with the standard input <em>not</em> redirected, as occurs when LZTIME.BAT completes assembly and linking, <a href="#listing-14-4">Listing 14-4</a> waits indefinitely for input from the keyboard.</p>
<figure>
<img src="images/fig14.4RT.png" />
</figure>
<p>Consequently, after the link is complete — when the program is waiting for keyboard input — you must press Ctrl-Break to stop the program and type:</p>
<pre class="cmd"><code>LZTEST &lt;TEST.TXT</code></pre>
<p>at the DOS prompt to time the code in <a href="#listing-14-4">Listing 14-4</a>. The same is true for <a href="#listing-14-5">Listing 14-5</a>.)</p>
<p>The problem with the approach of <a href="#listing-14-4">Listing 14-4</a> is that all the overhead of calling a DOS function — including an <code class="sourceCode nasm"><span class="kw">int</span></code> and an <code class="sourceCode nasm"><span class="kw">iret</span></code> — occurs twice for each character, once during input and once during output. We can easily avoid all that simply by reading a sizable block of text with a single DOS call, processing it a character at a time <em>in place</em> (thereby avoiding the overhead of interrupts and DOS calls), and printing it out as a block with a single DOS call, as shown in Figure 14.5.</p>
<figure>
<img src="images/fig14.5RT.png" />
</figure>
<p>This process can be repeated a block at a time until the source file runs out of characters.</p>
<p><a href="#listing-14-5">Listing 14-5</a>, which implements the block-handling approach, runs in 818 ms — about 145% faster that <a href="#listing-14-4">Listing 14-4</a>. Forget about disk access time and screen input and output time, to say nothing of the time required to loop and convert characters to uppercase — <a href="#listing-14-4">Listing 14-4</a><em>spends well over half of its time just performing the overhead associated with asking DOS to retrieve characters one at a time</em>.</p>
<p>I rest my case.</p>
</section>
</section>
<section id="forward-references-can-waste-time-and-space" class="level2">
<h2>Forward References Can Waste Time and Space</h2>
<p>Many 8088 instructions offer special compressed forms. For example, <code class="sourceCode nasm"><span class="kw">jmp</span></code>, which is normally 3 bytes long, can use the 2-byte <code class="sourceCode nasm"><span class="kw">jmp</span> <span class="dt">short</span></code> form when the target in within the range of a 1-byte displacement, as we found in Chapter 12. The word-sized forms of the arithmetic instructions — <code class="sourceCode nasm"><span class="kw">cmp</span></code>, <code class="sourceCode nasm"><span class="kw">add</span></code>, <code class="sourceCode nasm"><span class="kw">and</span></code>, and the like — have similarly shortened forms when used with immediate operands that can fit within a signed byte; such operands are stored in a byte rather than a word and are automatically sign-extended before being used.</p>
<p>As yet another example, any instruction that uses a <em>mod-reg-rm</em> byte and has a displacement field — <code class="sourceCode nasm">Index</code> in <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,[<span class="kw">bx</span>+Index]</code>, for example — is a byte shorter if the displacement fits within a signed byte. In fact, if <code class="sourceCode nasm">Index</code> is 0 in <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,[<span class="kw">bx</span>+Index]</code>, the displacement field can be done away with entirely, saving 2 bytes. (The potential waste of 2 bytes also applies when SI or DI is used with a displacement, but not when BP is used; the organization of the <em>mod-reg-rm</em> byte requires that BP-based addressing have at least a 1-byte displacement, so only 1 byte at most can be wasted.)</p>
<p>Obviously, we’d like the assembler to use the shortest possible forms of compressible instructions such as those mentioned above, and the assembler does just that <em>when it knows enough to do so</em> — which is not always the case.</p>
<p>Consider this. If the assembler comes to a <code class="sourceCode nasm"><span class="kw">jmp</span></code> instruction, a great deal depends on whether the jump goes backward or forward. If it’s a backward jump, the target label is already defined, and the assembler knows exactly how far away the jump destination is. If a backward destination is within the range of a 1-byte displacement, a short jump is generated; otherwise, a normal jump with a 2-byte displacement is generated. Either way, you can rest assured that the assembler has assembled the shortest possible jump.</p>
<p>Not so with a forward jump. In this case, the target label hasn’t been reached yet, so the assembler hasn’t the faintest idea of how far away it is. Either type of jump <em>might</em> be appropriate, but the assembler won’t know until the target label is reached in the course of assembly. The assembler can’t wait until then to decide how big to make the jump, though. The jump size <em>must</em> be set before assembly can continue past the jump instruction; otherwise, the assembler wouldn’t know where to place the next instruction.</p>
<p>Faced with such a dilemma, the assembler takes the only possible way out: it reserves space for the larger possibility, a normal jump. Later, when the target label becomes defined, the jump is assembled as a short jump if possible, but the damage has already been done; since 3 bytes were originally reserved for the jump, 3 bytes must be used, and a <code class="sourceCode nasm"><span class="kw">nop</span></code> is stuffed in after the short jump. That is, a jump to the very next instruction, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">jmp</span>   NearLabel
<span class="fu">NearLabel:</span></code></pre>
<p>assembles to the following:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">jmp</span>   <span class="dt">short</span> NearLabel
    <span class="kw">nop</span>
<span class="fu">NearLabel:</span></code></pre>
<p>From a speed perspective, that’s fine, but why waste a byte on a <code class="sourceCode nasm"><span class="kw">nop</span></code>? The correct code is:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">jmp</span>   <span class="dt">short</span> NearLabel
<span class="fu">NearLabel:</span></code></pre>
<p>Now consider the case of forward references to structure elements. The following <code class="sourceCode nasm"><span class="kw">mov</span></code>:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">      <span class="kw">mov</span>   <span class="kw">ax</span>,[<span class="kw">bx</span>+FirstEntry]
            :
EntryList   <span class="kw">struc</span>
FirstEntry  <span class="dt">dw</span>    ?
SecondEntry <span class="dt">dw</span>    ?
ThirdEntry  <span class="dt">dw</span>    ?
EntryList   <span class="kw">struc</span></code></pre>
<p>assembles with a 2-byte displacement field, while this <code class="sourceCode nasm"><span class="kw">mov</span></code>:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">EntryList   <span class="kw">struc</span>
FirstEntry  <span class="dt">dw</span>    ?
SecondEntry <span class="dt">dw</span>    ?
ThirdEntry  <span class="dt">dw</span>    ?
EntryList   <span class="kw">struc</span>
            :
      <span class="kw">mov</span>   <span class="kw">ax</span>,[<span class="kw">bx</span>+FirstEntry]</code></pre>
<p>assembles with no displacement field at all. Again, the assembler has no way of knowing on a forward reference how much space will be required for the displacement field, and must assume the worst. Unlike the previous <code class="sourceCode nasm"><span class="kw">jmp</span></code> example, however, performance as well as code size suffers in this case, since the additional displacement bytes must be fetched and a more complex effective address calculation must be made.</p>
<p>The same is true of forward-referenced immediate operands to the arithmetic instructions, and, indeed, of forward-referenced operands to any instruction that has a compressed form. You can improve the quality of your code considerably by avoiding forward references to data of all sorts (this will also speed up assembly a bit) and by explicitly using <code class="sourceCode nasm"><span class="kw">jmp</span> <span class="dt">short</span></code> whenever it will reach on forward jumps.</p>
<section id="the-right-assembler-can-help" class="level3">
<h3>The Right Assembler Can Help</h3>
<p>Avoiding inefficient forward references can be a frustrating task, involving many assembly errors from short jumps that you thought <em>might</em> reach their destinations but which turned out not to. What’s more, MASM doesn’t tell you when it encounters inefficient forward references, so there’s no easy way to identify opportunities to save bytes and/or cycles by using short jumps and by moving data and equates so as to avoid forward references.</p>
<p>In short, there’s no good way to avoid inefficient code with <em>MASM</em> — but it’s a different story with TASM and OPTASM. TASM can detect inefficient code as it assembles, issuing warnings to that effect if you so desire. You do then need to reedit your source code to correct the inefficient code, but once that’s done you can relax in the knowledge that the assembler is generating the best possible machine language code from your source code.</p>
<p>OPTASM goes TASM one better. OPTASM can actually assemble the most efficient possible code automatically, with no intervention on your part required. Be warned, however, that I’ve heard that OPTASM is mostly but not 100% MASM-compatible. On the other hand, Borland claims TASM is 100% MASM-compatible, and I’ve found no reason to dispute that claim.</p>
<p>I wouldn’t be surprised if MASM added inefficient-code handling features in a future version, because it’s so obviously useful and because it’s easy to do (at least to the extent of issuing inefficient code warnings). In any case, if you’re interested in generating the tightest, fastest possible code, it’s generally worth your while to use an assembler that can handle inefficient code in one way or another. Unlike almost everything else we’ve encountered in this book, saving bytes and/or cycles by eliminating inefficient code requires virtually no effort, given an assembler that helps you do the job.</p>
<p>If you aren’t using an assembler that can help you generate efficient forward branches, use backward branches whenever possible. One reason is that MASM can select the smallest possible displacement for unconditional backward jumps. Another reason is that macros can be used to generate efficient code for backward <em>conditional</em> jumps, as we’ll see later in this chapter.</p>
</section>
</section>
<section id="saving-space-with-branches" class="level2">
<h2>Saving Space With Branches</h2>
<p>When you’re interested in saving space while losing as little performance as possible, you should use jumps in order to share as much code as possible between similar routines. For example, suppose you’ve got a routine, <code class="sourceCode nasm">SampleSub</code>, which performs the equivalent of a switch statement with three separate cases, depending on the value in BX. Suppose that each of the cases can succeed or fail, and that <code class="sourceCode nasm">TestSub</code> returns AX equal to 0 for success or 1 for failure. Suppose further that on failure the byte-sized memory variable <code class="sourceCode nasm">ErrorCode</code> must be set to indicate which case failed.</p>
<p>One possible implementation is:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">SampleSub   proc  near
      <span class="kw">and</span>   <span class="kw">bx</span>,<span class="kw">bx</span>
      <span class="kw">jz</span>    Case0
      <span class="kw">dec</span>   <span class="kw">bx</span>
      <span class="kw">jz</span>    Case1
<span class="co">; Default case.</span>
            :                               <span class="co">;code to handle the default case</span>
      <span class="kw">jz</span>    SampleSubSuccess                <span class="co">;if success, set AX properly</span>
      <span class="kw">mov</span>   [ErrorCode],DEFAULT_CASE_ERROR
      <span class="kw">mov</span>   <span class="kw">ax</span>,<span class="dv">1</span>
      <span class="kw">ret</span>
<span class="fu">Case0:</span>
            :                               <span class="co">;code to handle the case of BX=1</span>
      <span class="kw">jz</span>    SampleSubSuccess                <span class="co">;if success, set AX properly</span>
      <span class="kw">mov</span>   [ErrorCode],CASE0_ERROR
      <span class="kw">mov</span>   <span class="kw">ax</span>,<span class="dv">1</span>
      <span class="kw">ret</span>
<span class="fu">Case1:</span>
            :                               <span class="co">;code to handle the case of BX=2</span>
      <span class="kw">jz</span>    SampleSubSuccess                <span class="co">;if success, set AX properly</span>
      <span class="kw">mov</span>   [ErrorCode],CASE1_ERROR
      <span class="kw">mov</span>   <span class="kw">ax</span>,<span class="dv">1</span>
      <span class="kw">ret</span>
<span class="fu">SampleSubSuccess:</span>
      <span class="kw">sub</span>   <span class="kw">ax</span>,<span class="kw">ax</span>                           <span class="co">;return success status</span>
      <span class="kw">ret</span>
SampleSub   endp</code></pre>
<p>In this implementation, all cases jump to the common code at <code class="sourceCode nasm">Success</code> when they succeed, so that the code to return a success status appears just once but serves all three cases.</p>
<p>Although it’s not quite so obvious, we can shrink the code a good bit by doing the same for the failure case, as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">SampleSub   proc  near
      <span class="kw">and</span>   <span class="kw">bx</span>,<span class="kw">bx</span>
      <span class="kw">jz</span>    Case0
      <span class="kw">dec</span>   <span class="kw">bx</span>
      <span class="kw">jz</span>    Case1
<span class="co">; Default case.</span>
            :                       <span class="co">;code to handle the default case</span>
      <span class="kw">jz</span>    SampleSubSuccess        <span class="co">;if success, set AX properly</span>
      <span class="kw">mov</span>   <span class="kw">al</span>,DEFAULT_CASE_ERROR
      <span class="kw">jmp</span>   <span class="dt">short</span> SampleSubFailure  <span class="co">;set error code &amp; status</span>
<span class="fu">Case0:</span>
            :                       <span class="co">;code to handle the case of BX=1</span>
      <span class="kw">jz</span>    SampleSubSuccess        <span class="co">;if success, set AX properly</span>
      <span class="kw">mov</span>   <span class="kw">al</span>,CASE0_ERROR
      <span class="kw">jmp</span>   <span class="dt">short</span> SampleSubFailure  <span class="co">;set error code &amp; status</span>
<span class="fu">Case1:</span>
            :                       <span class="co">;code to handle the case of BX=2</span>
      <span class="kw">jz</span>    SampleSubSuccess        <span class="co">;if success, set AX properly</span>
      <span class="kw">mov</span>   <span class="kw">al</span>,CASE1_ERROR
<span class="fu">SampleSubFailure:</span>
      <span class="kw">mov</span>   [ErrorCode],<span class="kw">al</span>
      <span class="kw">mov</span>   <span class="kw">ax</span>,<span class="dv">1</span>
      <span class="kw">ret</span>
<span class="fu">SampleSubSuccess:</span>
      <span class="kw">sub</span>   <span class="kw">ax</span>,<span class="kw">ax</span>                   <span class="co">;return success status</span>
      <span class="kw">ret</span>
SampleSub   endp</code></pre>
<p>Although this latter version doesn’t look much different from the original, it’s a full 10 bytes shorter, and functionally equivalent. (If there were more cases, we’d save proportionally more bytes, too.) This substantial reduction in size results from two factors: the instruction pair <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ax</span>,<span class="dv">1</span></code>/<code class="sourceCode nasm"><span class="kw">ret</span></code> appears once rather than three times, saving 8 bytes, and three <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,immed</code> instructions along with one accumulator-specific direct-addressed memory access replace three <em>mod-reg-rm</em> direct-addressed memory accesses, saving 6 bytes. Those 14 bytes saved more than offset the 4 bytes added by two <code class="sourceCode nasm"><span class="kw">jmp</span> <span class="dt">short</span></code> instructions.</p>
<p>There are two points to be made here. First, we can save many bytes by jumping to common exit code from various places in a subroutine, provided that the common exit code performs a reasonably lengthy task that would otherwise have to be performed at the end of a number of code sequences. (If the common exit code is just a <code class="sourceCode nasm"><span class="kw">ret</span></code>, we’re better off executing a 1-byte <code class="sourceCode nasm"><span class="kw">ret</span></code> in several places in the subroutine than we are executing a 2-byte <code class="sourceCode nasm"><span class="kw">jmp</span> <span class="dt">short</span></code> just to get to the <code class="sourceCode nasm"><span class="kw">ret</span></code>, as we saw in the last chapter.)</p>
<p>Second, we can save bytes by altering our code a bit to allow common exit code to do more than it normally would. This is illustrated in the above example in that each of the cases loads an error code into AL, rather than storing it to memory, so that a single accumulator-specific direct-addressed <code class="sourceCode nasm"><span class="kw">mov</span></code> can store the error code to memory. Off the top, it would seem that the error-code setting belongs in the separate cases, since each case stores a different error value, but with a little ingenuity, a single memory-accessing instruction can do the trick.</p>
<p>The idea of sharing common exit code can be extended across several functions. Suppose that we’ve got two subroutines that end by popping DI, SI, and BP, then returning. Suppose also that in case of success these subroutines return AX set to 0, while in case of failure they return AX set to a non-zero error code.</p>
<p>There’s absolutely no reason why the two subroutines shouldn’t share a considerable amount of exit code, along the following lines:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">Subroutine1   proc  near
      <span class="kw">push</span>    <span class="kw">bp</span>
      <span class="kw">mov</span>     <span class="kw">bp</span>,<span class="kw">sp</span>
      <span class="kw">push</span>    <span class="kw">si</span>
      <span class="kw">push</span>    <span class="kw">di</span>
              :           <span class="co">;body of subroutine, putting an error code in AX and</span>
              :           <span class="co">; branching to Exit on failure, or falling through in</span>
              <span class="co">;           ; case of success</span>
<span class="fu">Success:</span>
      <span class="kw">sub</span>     <span class="kw">ax</span>,<span class="kw">ax</span>
<span class="fu">Exit:</span>
      <span class="kw">pop</span>     <span class="kw">di</span>
      <span class="kw">pop</span>     <span class="kw">si</span>
      <span class="kw">pop</span>     <span class="kw">bp</span>
      <span class="kw">ret</span>
Subroutine1   endp
Subroutine2   proc  near
      <span class="kw">push</span>    <span class="kw">bp</span>
      <span class="kw">mov</span>     <span class="kw">bp</span>,<span class="kw">sp</span>
      <span class="kw">push</span>    <span class="kw">si</span>
      <span class="kw">push</span>    <span class="kw">di</span>
              :           <span class="co">;body of subroutine, putting an error code in AX and</span>
              :           <span class="co">; branching to Exit on failure, or falling through in</span>
              <span class="co">;           ; case of success</span>
      <span class="kw">jmp</span>     Success
Subroutine2 endp</code></pre>
<p>Here we’ve saved 3 or 4 bytes by replacing 6 bytes of exit code that would normally appear at the end of <code class="sourceCode nasm">Subroutine2</code> with a 2-or 3-byte jump. What’s more, we could do the same for any number of subroutines that can use the same exit code; at worst, a 3-byte normal jump would be required to reach <code class="sourceCode nasm">Success</code> or <code class="sourceCode nasm">Exit</code>. Naturally, larger savings would result from sharing lengthier exit code.</p>
<p>The key here is realizing that in assembler there’s no need for a clean separation between subroutines. If multiple subroutines end with the same instructions, they might as well share those instructions. Of course, performance will suffer a little from the extra branch all but one of the subroutines will have to make in order to reach the common code. Once again, we’ve acquired a new tool that has both costs and benefits; this time it’s a tool that saves bytes while expending cycles. Deciding when that’s a good tradeoff is your business, to be judged on a case by case basis. Sometimes this new tool is desirable, sometimes not… but either way, making that sort of decision properly is a key to good assembler code.</p>
<section id="multiple-entry-points" class="level3">
<h3>Multiple Entry Points</h3>
<p>At the other end of a subroutine, we can save bytes by providing multiple entry points. In one use, multiple entry points are an extension of the common exit code concept we just discussed, with the idea being the sharing of as much code as possible, via branches into the middle as well as the start of subroutines. If two subroutines share the whole last half of their code in common, then one can branch into the other at that point. If some tasks require only the last one-third of the code in a subroutine, then a call could be made directly to the appropriate point in the subroutine; in this case, one subroutine would be a proper subset of the other, and wouldn’t exist as separate code at all.</p>
<p>Assembler facilitates that sort of sharing of code, because if we really want to, we can always set up the registers, flags and stack to match the requirements of a subroutine’s code at any entry point. In other words, if we want to branch into the middle of a subroutine, the complete control of the PC that is possible only in assembler allows us to set up the state of the PC as needed to enter that code. (Recall our tinkering with the stack earlier in this chapter…) Whether it’s worth going to the trouble of doing so is another question entirely, but never forget that assembler lets you put the PC into any state you choose at any time.</p>
<p>There’s another meaning to multiple entry points, as well, and that’s the technique of using several front-end entry points to a subroutine in order to set up commonly-used parameters. I can best explain this by way of example.</p>
<p>Imagine that we’ve got a subroutine, <code class="sourceCode nasm">SpeakerControl</code>, that’s called with one parameter, passed in AX. A call to <code class="sourceCode nasm">SpeakerControl</code> with AX set to 0 turns off the PC’s speaker, while a call with AX set to 1 turns on the speaker.</p>
<p>Now imagine that <code class="sourceCode nasm">SpeakerControl</code> is called from dozens — perhaps hundreds — of places in a program. Every time <code class="sourceCode nasm">SpeakerControl</code> is called, a 2-or 3-byte instruction must be used to set AX to the desired state. If there are 100 calls to <code class="sourceCode nasm">SpeakerControl</code>, approximately 250 bytes are used simply selecting the mode of operation of <code class="sourceCode nasm">SpeakerControl</code>.</p>
<p>Instead, why not simply provide two front-end entry points to <code class="sourceCode nasm">SpeakerControl</code>, one to turn the speaker on (<code class="sourceCode nasm">SpeakerOn</code>) and one to turn the speaker off (<code class="sourceCode nasm">SpeakerOff</code>)? The code would be as simple as this:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="co">; Turns the speaker on.</span>
SpeakerOn   proc  near
      <span class="kw">mov</span>   <span class="kw">ax</span>,<span class="dv">1</span>
      <span class="kw">jmp</span>   <span class="dt">short</span> SpeakerControl
SpeakerOn   endp
<span class="co">; Turns the speaker off.</span>
SpeakerOff  proc  near
      <span class="kw">sub</span>   <span class="kw">ax</span>,<span class="kw">ax</span>
SpeakerOff  endp
<span class="co">;</span>
<span class="co">; Turns the speaker on or off.</span>
<span class="co">;</span>
<span class="co">; Input:</span>
<span class="co">;     AX = 1 to turn the speaker on</span>
<span class="co">;        = 0 to turn the speaker off</span>
<span class="co">;</span>
<span class="co">; Output:</span>
<span class="co">;     none</span>
<span class="co">;</span>
SpeakerControl  proc  near
                :</code></pre>
<p>Now, instead of:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">ax</span>,<span class="dv">1</span>
<span class="kw">call</span>  SpeakerControl</code></pre>
<p>we can simply use:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">call</span>  SpeakerOn</code></pre>
<p>and we could likewise use <code class="sourceCode nasm">SpeakerOff</code> instead of calling <code class="sourceCode nasm">SpeakerControl</code> with AX equal to 0. At the cost of the 7 bytes taken by the two front-end functions, we would save 250 bytes worth of parameter-setting code, for a net savings of 243 bytes.</p>
<p>The principle of using front-end functions that set common parameter values applies to high-level language code as well. In fact, it may apply even better to high-level language code, since it takes 3 to 4 bytes to push a constant parameter onto the stack. The downside of using this technique in a high-level language is much the same as the downside of using it in assembler — it involves extra branching, so it’s slower. (In high-level language code, performance will also be slowed by the time required to push any additional parameters that must be passed through the front-end functions.)</p>
<p>Trading off cycles for bytes… so what else is new?</p>
</section>
<section id="a-brief-zen-exercise-in-branching-and-not-branching" class="level3">
<h3>A Brief Zen Exercise in Branching (And Not-Branching)</h3>
<p>Just for fun, we’re going to take a moment to look at several ways in which branching and not-branching can be used to improve a simple bit of code. I’m not going to dwell on the mechanisms or merits of the various approaches; by this point you should have the knowledge and tools to do that yourself.</p>
<p>The task at hand is simple: increment a 32-bit value in DX:AX. The obvious solution is:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">add</span>   <span class="kw">ax</span>,<span class="dv">1</span>
<span class="kw">adc</span>   <span class="kw">dx</span>,<span class="dv">0</span></code></pre>
<p>which comes in at 6 bytes and 8 Execution Unit cycles.</p>
<p>If we’re willing to sacrifice performance, we can save 2 bytes by branching:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">inc</span>   <span class="kw">ax</span>
    <span class="kw">jnz</span>   IncDone
    <span class="kw">inc</span>   <span class="kw">dx</span>
<span class="fu">IncDone:</span></code></pre>
<p>However, this approach usually takes 18 cycles and empties the prefetch queue, since the case where AX turns over to 0 (and so no branch occurs) is only 1 out of 64 K possible cases. We can adjust for that at the cost of an additional byte with:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">inc</span>   <span class="kw">dx</span>
    <span class="kw">inc</span>   <span class="kw">ax</span>
    <span class="kw">jz</span>    IncDone
    <span class="kw">dec</span>   <span class="kw">dx</span>
<span class="fu">IncDone:</span></code></pre>
<p>which preincrements DX, then usually falls through the conditional jump and decrements DX back to its original state. This approach is 5 bytes long, but usually takes 10 cycles to execute.</p>
<p>Along the lines of our discussion of 32-bit negation in the last chapter, we can also use conditional branching to improve performance, as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">inc</span>   <span class="kw">ax</span>
    <span class="kw">jz</span>    IncDX
<span class="fu">IncDone:</span>
          :
<span class="fu">IncDX:</span>
    <span class="kw">inc</span>   <span class="kw">dx</span>
    <span class="kw">jmp</span>   IncDone</code></pre>
<p>This approach requires the same 6 bytes as the original approach, but takes only 3 bytes and 6 cycles along the usual execution path.</p>
<p>Finally, if the branch-out technique of the last case isn’t feasible, we could preload two registers with the values 1 and 0, to speed and shorten the addition:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">bx</span>,<span class="dv">1</span>
<span class="kw">sub</span>   <span class="kw">cx</span>,<span class="kw">cx</span>
      :
<span class="kw">add</span>   <span class="kw">ax</span>,<span class="kw">bx</span>
<span class="kw">adc</span>   <span class="kw">dx</span>,<span class="kw">cx</span></code></pre>
<p>This would reduce the actual addition code to 4 bytes and 6 cycles, although it would require 9 bytes overall. Such an approach would make little sense unless BX and CX were preloaded outside a loop and the 32-bit addition occurred repeatedly inside the loop… but then it doesn’t make sense expending the energy for <em>any</em> of these optimizations unless either the code is inside a time-critical loop or bytes are in extremely short supply.</p>
<p>Remember, you must pick and choose your spots when you optimize at a detailed instruction-by-instruction level. When you optimize for speed, identify the portions of your programs that significantly affect overall performance and/or make an appreciable difference in response time, and focus your detailed optimization efforts on fine-tuning that code, especially inside loops.</p>
<p>Optimizing for space rather than speed is less focused — you should save bytes wherever you can — but most assembler optimization on the PC is in fact for speed, since there’s a great deal of memory available relative to the few bytes that can be saved over the course of a few assembler instructions. However, in certain applications, such as BIOS code and ROMable process-control code, size optimization is sometimes critical. In such applications, you’d want to use subroutines as much as possible (and, yes, perhaps even interrupts), and design those subroutines to share as much code as possible. You’d probably also want to use mini-interpreters, which we’ll discuss in Volume II of <em>The Zen of Assembly Language</em>.</p>
<p>At any rate, knowing when and where optimization is worth the effort is as important as knowing how to optimize. Without the “when” and “where,”the “how” is useless; you’ll spend all your time tweaking code without seeing the big picture, and you’ll never accomplish anything of substance.</p>
</section>
</section>
<section id="double-duty-tests" class="level2">
<h2>Double-Duty Tests</h2>
<p>There are a number of ways to get multiple uses out of a single instruction that sets the flags. Sometimes the multiple use is available because multiple flags are set, and sometimes the multiple use is available because the instruction that sets the flags performs other tasks as well. Let’s look at some examples.</p>
<p>Suppose that we have eight 1-bit flags stored in a single byte-sized memory variable, <code class="sourceCode nasm">StateFlags</code>, as shown in Figure 14.6.</p>
<figure>
<img src="images/fig14.6RT.png" />
</figure>
<p>In order to check whether a high-or medium-priority event is pending, as indicated by bits 7 and 6 of <code class="sourceCode nasm">StateFlags</code>, we’d normally use something like:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">al</span>,[StateFlags]
<span class="kw">test</span>  <span class="kw">al</span><span class="bn">,80h                      </span><span class="co">;high-priority event pending?</span>
<span class="kw">jnz</span>   HandleHighPriorityEvent     <span class="co">;yes</span>
<span class="kw">test</span>  <span class="kw">al</span><span class="bn">,40h                      </span><span class="co">;medium-priority event pending?</span>
<span class="kw">jnz</span>   HandleMediumPriorityEvent   <span class="co">;yes</span></code></pre>
<p>or perhaps, if we were clever, the slightly faster sequence:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">al</span>,[StateFlags]
<span class="kw">shl</span>   <span class="kw">al</span>,<span class="dv">1</span>                        <span class="co">;high-priority event pending?</span>
<span class="kw">jc</span>    HandleHighPriorityEvent     <span class="co">;yes</span>
<span class="kw">shl</span>   <span class="kw">al</span>,<span class="dv">1</span>                        <span class="co">;medium-priority event pending?</span>
<span class="kw">jc</span>    HandleMediumPriorityEvent   <span class="co">;yes</span></code></pre>
<p>If we think for a moment, however, we’ll realize that shifting a value to the left has a most desirable property. <code class="sourceCode nasm"><span class="kw">shl</span></code> not only sets the Carry flag to reflect carry out of the most significant bit of the result, but also sets the Sign flag to reflect the value stored <em>into</em> the most significant bit of the result.</p>
<p>Do you see it now? After a register is shifted 1 bit to the left, the Carry and Sign flags are set to reflect the states of the <em>two</em> most significant bits originally stored in that register. That means that we can replace the above code with:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">al</span>,[StateFlags]
<span class="kw">shl</span>   <span class="kw">al</span>,<span class="dv">1</span>                        <span class="co">;high-or medium-priority event pending?</span>
<span class="kw">jc</span>    HandleHighPriorityEvent     <span class="co">;high-priority event pending</span>
<span class="kw">js</span>    HandleMediumPriorityEvent   <span class="co">;medium-priority event pending</span></code></pre>
<p>which is one full instruction shorter.</p>
<p>Stretching this idea still further, we could relocate three of our flags to bits 7, 6, and 5 of <code class="sourceCode nasm">EventFlags</code>, with bits 4-0 always set to 0, as shown in Figure 14.7.</p>
<figure>
<img src="images/fig14.7RT.png" />
</figure>
<p>Then, if the first two tests failed, a zero/non-zero test would serve to determine whether the flag in bit 5 is set, and we could get <em>three</em> tests out of a single operation:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">al</span>,[EventFlags]
<span class="kw">shl</span>   <span class="kw">al</span>,<span class="dv">1</span>                        <span class="co">;high-, medium-, or low-</span>
                                  <span class="co">; priority event pending?</span>
<span class="kw">jc</span>    HandleHighPriorityEvent     <span class="co">;high-priority event pending</span>
<span class="kw">js</span>    HandleMediumPriorityEvent   <span class="co">;medium-priority event pending</span>
<span class="kw">jnz</span>   HandleLowPriorityEvent      <span class="co">;low-priority event pending</span></code></pre>
<section id="using-loop-counters-as-indexes" class="level3">
<h3>Using Loop Counters as Indexes</h3>
<p>There’s another way to get double-duty from tests, in this case by combining the counting function of a loop counter with the indexing function of an index used inside the loop.</p>
<p>Consider the following, which is a standard way to generate a checksum byte for an array:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">mov</span>   <span class="kw">cx</span>,TEST_ARRAY_LENGTH
    <span class="kw">sub</span>   <span class="kw">bx</span>,<span class="kw">bx</span>
    <span class="kw">sub</span>   <span class="kw">al</span>,<span class="kw">al</span>
<span class="fu">ChecksumLoop:</span>
    <span class="kw">add</span>   <span class="kw">al</span>,[TestArray+<span class="kw">bx</span>]
    <span class="kw">inc</span>   <span class="kw">bx</span>
    <span class="kw">loop</span>  ChecksumLoop</code></pre>
<p>(Yes, I know that this could be speeded up and shrunk by loading BX with the offset of <code class="sourceCode nasm">TestArray</code> outside the loop, but bear with me while we look at a specific optimization.)</p>
<p>Now consider the following:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">mov</span>   <span class="kw">bx</span>,TEST_ARRAY_LENGTH
    <span class="kw">sub</span>   <span class="kw">al</span>,<span class="kw">al</span>
<span class="fu">ChecksumLoop:</span>
    <span class="kw">add</span>   <span class="kw">al</span>,[TestArray+<span class="kw">bx</span><span class="dv">-1</span>]
    <span class="kw">dec</span>   <span class="kw">bx</span>
    <span class="kw">jnz</span>   ChecksumLoop</code></pre>
<p>This second version generates the same checksum as the earlier code, but is 1 instruction and 2 bytes shorter, and slightly faster, as well. Rather than maintaining separate loop counter and array index values, the second version uses BX for both purposes. The key to being able to do this is the realization that it’s equally valid to start processing at either end of the array. Whenever that’s the case, look to process at the high end and count toward zero if you can, because it’s easier to test for zero than any other value.</p>
<p>By the way, while it’s easiest to check for counting down to zero, it’s reasonably easy to check for counting <em>past</em> zero as well, so long as the initial count is 32 K or less: just test the Sign flag. For instance, the following is yet another version of the checksum code, this time ending the loop when BX counts down past zero to 0FFFFh:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">mov</span>   <span class="kw">bx</span>,TEST_ARRAY_LENGTH<span class="dv">-1</span>
    <span class="kw">sub</span>   <span class="kw">al</span>,<span class="kw">al</span>
<span class="fu">ChecksumLoop:</span>
    <span class="kw">add</span>   <span class="kw">al</span>,[TestArray+<span class="kw">bx</span>]
    <span class="kw">dec</span>   <span class="kw">bx</span>
    <span class="kw">jns</span>   ChecksumLoop</code></pre>
<p>Note that BX now starts off with the index of the last element of the array rather than the length of the array, so no adjustment by 1 is needed when each element of the array is addressed. So long as TEST_ARRAY_LENGTH is 32 K or less, this version isn’t generally better or worse than the last version; both versions are the same length and execute at the same speed. However, the Sign flag is set when either 0 <em>or</em> any value greater than 32 K is decremented, so if TEST_ARRAY_LENGTH exceeds 32 K the checksum loop in the last example will end prematurely — and incorrectly.</p>
</section>
</section>
<section id="the-looping-instructions" class="level2">
<h2>The Looping Instructions</h2>
<p>And so we come to the 8088’s special looping instructions: <code class="sourceCode nasm"><span class="kw">jcxz</span></code>, <code class="sourceCode nasm"><span class="kw">loop</span></code>, <code class="sourceCode nasm"><span class="kw">loopz</span></code>, and <code class="sourceCode nasm"><span class="kw">loopnz</span></code>. You undoubtedly know how <code class="sourceCode nasm"><span class="kw">jcxz</span></code> and <code class="sourceCode nasm"><span class="kw">loop</span></code> work by now — we’ve certainly used them often enough over the last few chapters. As a quick refresher, <code class="sourceCode nasm"><span class="kw">jcxz</span></code> branches if and only if CX is zero, and <code class="sourceCode nasm"><span class="kw">loop</span></code> decrements CX and branches <em>unless</em> the new value in CX is zero. None of the looping instructions — not even <code class="sourceCode nasm"><span class="kw">loop</span></code>, which decrements CX — affects the 8088’s flags in any way; we saw that put to good use in a loop that performed multi-word addition in Chapter 9.</p>
<p>(In fact, the only branching instruction of the 8088 that affects the FLAGS register are the interrupt-related instructions. <code class="sourceCode nasm"><span class="kw">int</span></code> sets the Interrupt and Trap flags to 0, disabling interrupts and single-stepping, as does <code class="sourceCode nasm"><span class="kw">into</span></code> when the Overflow flag is 1, while <code class="sourceCode nasm"><span class="kw">iret</span></code> sets the entire FLAGS register to the 16-bit value popped from the stack.)</p>
<p>Given that we’re already familiar with <code class="sourceCode nasm"><span class="kw">jcxz</span></code> and <code class="sourceCode nasm"><span class="kw">loop</span></code>, we’ll take a look at the useful and often overlooked <code class="sourceCode nasm"><span class="kw">loopz</span></code> and <code class="sourceCode nasm"><span class="kw">loopnz</span></code>, and then we’ll touch on a few items of interest involving <code class="sourceCode nasm"><span class="kw">jcxz</span></code> and <code class="sourceCode nasm"><span class="kw">loop</span></code>. Always bear in mind, however, that while the special looping instructions are more efficient than the other branching instructions, they’re still branching instructions — and that means that they’re still slow. When performance matters, not-branching is the way to go.</p>
<section id="loopz-and-loopnz" class="level3">
<h3><code>loopz</code> and <code>loopnz</code></h3>
<p><code class="sourceCode nasm"><span class="kw">loopz</span></code> and <code class="sourceCode nasm"><span class="kw">loopnz</span></code> (also known as <code class="sourceCode nasm"><span class="kw">loope</span></code> and <code class="sourceCode nasm"><span class="kw">loopne</span></code>, respectively) are essentially <code class="sourceCode nasm"><span class="kw">loop</span></code> with a little something extra added. <code class="sourceCode nasm"><span class="kw">loopz</span></code> (which we can remember as “loop while zero,” as we did with <code class="sourceCode nasm">repz</code>) decrements CX and then branches unless either CX is 0 <em>or</em> the Zero flag is 0. Likewise, <code class="sourceCode nasm"><span class="kw">loopnz</span></code> (“loop while not zero”) decrements CX and branches unless either CX is 0 <em>or</em> the Zero flag is 1. Depending on whether they branch or not, these instructions are anywhere from 0 to 2 cycles slower than <code class="sourceCode nasm"><span class="kw">loop</span></code>, but all three instructions are the same size, 2 bytes.</p>
<p><code class="sourceCode nasm"><span class="kw">loopz</span></code> and <code class="sourceCode nasm"><span class="kw">loopnz</span></code> provide an extremely compact way to repeat a loop up to a maximum number of repetitions while waiting for an event that affects the Zero flag to occur. If, when the loop ends, the Zero flag isn’t in the sought-after state, then the event hasn’t occurred within the maximum number of repetitions.</p>
<p>For example, suppose that we want to search an array for the first entry that matches a particular character. Normally, we would do that with <code class="sourceCode nasm">repnz <span class="kw">scasb</span></code>, but in this particular case we need to perform a case-insensitive search. <a href="#listing-14-6">Listing 14-6</a> shows a standard solution to this problem, which tests for a match and branches out of the loop when a match is found, or falls through the bottom of the loop if no match exists. <a href="#listing-14-6">Listing 14-6</a> runs in 1134 us for the test case.</p>
<p>You can probably see where we’re heading. The <code class="sourceCode nasm"><span class="kw">jz</span></code>/<code class="sourceCode nasm"><span class="kw">loop</span></code> pair at the bottom of the loop in <a href="#listing-14-6">Listing 14-6</a> is an obvious candidate for conversion to <code class="sourceCode nasm"><span class="kw">loopnz</span></code>, and <a href="#listing-14-7">Listing 14-7</a> takes advantage of just that conversion. Essentially, the test for a match is moved out of the loop in <a href="#listing-14-7">Listing 14-7</a>, with <code class="sourceCode nasm"><span class="kw">loopnz</span></code> replacing <code class="sourceCode nasm"><span class="kw">loop</span></code> in order to allow the loop to end either on a match or at the end of the array. The result: <a href="#listing-14-7">Listing 14-7</a> runs in 1036 us, more than 9% faster than <a href="#listing-14-7">Listing 14-7</a>. Not a <em>massive</em> improvement..but not a bad payoff for replacing one instruction and moving another.</p>
<p>(Food for thought: <a href="#listing-14-6">Listings 14-6</a> and <a href="#listing-14-7">14-7</a> could be speeded up by storing uppercase and lowercase versions of the search byte in separate registers and simply comparing each byte of the array to <em>both</em> versions. The extra comparison would be a good deal faster than the code used in <a href="#listing-14-6">Listings 14-6</a> and <a href="#listing-14-7">14-7</a> to convert each byte of the array to uppercase.)</p>
</section>
<section id="how-you-loop-matters-more-than-you-might-think" class="level3">
<h3>How You Loop Matters More Than You Might Think</h3>
<p>In the last chapter, I lambasted <code class="sourceCode nasm"><span class="kw">loop</span></code> as a slow looping instruction. Well, it <em>is</em> slow — but if you must perform repetitive tasks by branching — that is, if you must loop — <code class="sourceCode nasm"><span class="kw">loop</span></code> is a good deal faster than other branching instructions. To drive that point home, I’m going to measure the performance of the case-insensitive search program of <a href="#listing-14-6">Listing 14-6</a> with the looping code implemented as follows: with <code class="sourceCode nasm"><span class="kw">loop</span></code>, with <code class="sourceCode nasm"><span class="kw">dec</span> reg16/<span class="kw">jnz</span></code>, with <code class="sourceCode nasm"><span class="kw">dec</span> reg8/<span class="kw">jnz</span></code>, with <code class="sourceCode nasm"><span class="kw">dec</span> mem8/<span class="kw">jnz</span></code>, and with <code class="sourceCode nasm"><span class="kw">dec</span> mem16/<span class="kw">jnz</span></code>. (Remember that <code class="sourceCode nasm"><span class="kw">dec</span> reg16</code> is faster than <code class="sourceCode nasm"><span class="kw">dec</span> reg8</code>, and that byte-sized memory accesses are faster than word-sized accesses.)</p>
<p><a href="#listing-14-6">Listing 14-6</a> already shows the <code class="sourceCode nasm"><span class="kw">loop</span></code>-based implementation. <a href="#listing-14-8">Listings 14-8</a> through <a href="#listing-14-11">14-11</a> show the other implementations. Here are the results:</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Looping code</th>
<th style="text-align: left;">Listing</th>
<th style="text-align: left;">Time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">loop CaseInsensitiveSearchLoop</td>
<td style="text-align: left;"><a href="#listing-14-6">14-6</a></td>
<td style="text-align: left;">1134 us</td>
</tr>
<tr class="even">
<td style="text-align: left;">Dec cx/jnz CaseInsensitiveSearchLoop</td>
<td style="text-align: left;"><a href="#listing-14-8">14-8</a></td>
<td style="text-align: left;">1199 us</td>
</tr>
<tr class="odd">
<td style="text-align: left;">dec cl/jnz CaseInsensitiveSearchLoop</td>
<td style="text-align: left;"><a href="#listing-14-9">14-9</a></td>
<td style="text-align: left;">1252 us</td>
</tr>
<tr class="even">
<td style="text-align: left;">dec [BCount]/jnz CaseInsensitiveSearchLoop</td>
<td style="text-align: left;"><a href="#listing-14-10">14-10</a></td>
<td style="text-align: left;">1540 us</td>
</tr>
<tr class="odd">
<td style="text-align: left;">dec [WCount]/jnz CaseInsensitiveSearchLoop</td>
<td style="text-align: left;"><a href="#listing-14-11">14-11</a></td>
<td style="text-align: left;">1652 us</td>
</tr>
</tbody>
</table>
<p>While the incremental performance differences between the various implementations are fairly modest, <code class="sourceCode nasm"><span class="kw">loop</span></code> is the clear winner, and is the shortest of the bunch as well.</p>
<p>Whenever you must branch in order to loop, use the <code class="sourceCode nasm"><span class="kw">loop</span></code> instruction if you possibly can. The superiority of <code class="sourceCode nasm"><span class="kw">loop</span></code> holds true only in the realm of branching instructions, for not — branching is <em>much</em> faster than looping with any of the branching instructions… but when space is at a premium, <code class="sourceCode nasm"><span class="kw">loop</span></code> is hard to beat.</p>
</section>
</section>
<section id="only-jcxz-can-test-and-branch-in-a-single-bound" class="level2">
<h2>Only <code>jcxz</code> Can Test <em>and</em> Branch in a Single Bound</h2>
<p><code class="sourceCode nasm"><span class="kw">jcxz</span></code> is the only 8088 instruction that can both test a register and branch according to the outcome. Most of the applications for this unusual property of <code class="sourceCode nasm"><span class="kw">jcxz</span></code> are well-known, most notably avoiding division by zero and guarding against zero counts in loops. You may, however, find other, less obvious, applications if you stretch your mind a little.</p>
<p>For example, suppose that we have an animation program that needs to be speed-synchronized. This program has a delay loop built into each pass through the main loop; however, the proper delay will vary from processor to processor and from one display adapter to another, so the delay will need to be adjusted as the program runs.</p>
<p>Let’s say that ideally the program should perform exactly 600 passes through the main loop every 10 seconds. In order to monitor its compliance with that standard, the program counts down a word-sized counter every time it completes the main loop. In a perfect world, the counter would reach zero precisely as the 10-second mark is reached.</p>
<p>That’s not very likely to happen, of course. The program can easily detect if it’s running too fast; if the counter reaches zero before the 10-second mark is reached, the delay needs to be increased. The quicker the counter reaches zero, the greater the necessary increase in the delay.</p>
<p>If the program does reach the 10-second mark without the counter reaching zero, then it’s running too slowly, and the delay needs to be decreased. The higher the remaining count, the greater the amount by which the delay needs to be decreased, so we need to know not only that the counter hasn’t reached zero but also the exact remaining count. At the same time, we need to reset the counter to its initial value in preparation for the next 10-second timing period.</p>
<p>We could do that easily enough with:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">mov</span>   <span class="kw">ax</span>,[SyncCount]            <span class="co">;get remaining count</span>
    <span class="kw">mov</span>   [SyncCount],INITIAL_COUNT
                                  <span class="co">;set count back to initial value</span>
    <span class="kw">and</span>   <span class="kw">ax</span>,<span class="kw">ax</span>                   <span class="co">;is the count 0?</span>
    <span class="kw">jz</span>    MainLoop                <span class="co">;yes, so we&#39;re dead on and no</span>
                                  <span class="co">; adjustment is needed</span>
<span class="co">; The count isn&#39;t zero, so the program is running too slowly.</span>
<span class="co">; Decrease the delay proportionately to the value in AX.</span></code></pre>
<p>With <code class="sourceCode nasm"><span class="kw">jcxz</span></code> and a little creativity, however, we can tighten the code considerably:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">mov</span>   <span class="kw">cx</span>,INITIAL_COUNT
    <span class="kw">xchg</span>  [SyncCount],<span class="kw">cx</span>    <span class="co">;get remaining count and set count</span>
                            <span class="co">; back to initial value</span>
    <span class="kw">jcxz</span>  MainLoop          <span class="co">;if the count is 0, we&#39;re dead on</span>
                            <span class="co">; and no adjustment is needed</span>
<span class="co">; The count isn&#39;t zero, so the program is running too slowly.</span>
<span class="co">; Decrease the delay proportionately to the value in CX.</span></code></pre>
<p>With these changes, we’ve managed to trim a 13-byte sequence by 4 bytes — 30% — even though the original sequence used the accumulator-specific direct-addressed form of <code class="sourceCode nasm"><span class="kw">mov</span></code>. There’s nothing more profound here than familiarity with the 8088’s instruction set and a willingness to mix and match instructions inventively — which, when you get right down to it, is where some of the best 8088 code comes from.</p>
<p>Try it yourself and see!</p>
</section>
<section id="jump-and-call-tables" class="level2">
<h2>Jump and Call Tables</h2>
<p>Given that you’ve got an index that’s associated with the execution of certain code, jump and call tables allow you to branch very quickly to the corresponding code. A jump or call table is nothing more than an array of code addresses organized to correspond to some index value; the index can then be used to look up the matching address in the table, so that a branch can be made to that address.</p>
<p>The only difference between call tables and jump tables is the type of branch made. Both types of tables consist of nothing but addresses, and the distinction lies solely in whether the code using the table chooses to call or jump to the looked-up addresses. Jump tables are used in switch-type situations, where one of several paths through a routine is chosen, while call tables are used for applications such as function dispatchers, where one of several subroutines is executed. For simplicity, I’ll refer to both sorts of tables as jump tables from now on.</p>
<p>The operation of a sample jump table is shown in Figure 14. 8.</p>
<figure>
<img src="images/fig14.8RT.png" />
</figure>
<p>An index into the table is used to look up one of the entries in the table, and an indirect branch is performed to the address contained in that entry.</p>
<p>The size of a jump table entry can be either 2 or 4 bytes, depending on whether near or far branches are used by the code that branches through the jump table. As we discussed earlier, the 2-byte jump table entries used with near branches are vastly preferable to the 4-byte jump table entries used with far branches, for two reasons: 2-byte-per-entry jump tables are half the size of equivalent 4-byte-per-table jump tables, and near indirect branches are much faster than far indirect branches, especially when <code class="sourceCode nasm"><span class="kw">call</span></code> and <code class="sourceCode nasm"><span class="kw">ret</span></code> are used.</p>
<p>So, what’s so great about jump tables? Simply put, they’re usually the fastest way to turn an index into execution of the corresponding code. In the sorts of applications jump tables are best suited to, we basically already know which routine we want to branch to, thanks to the index — it’s just a matter of getting there as fast as possible and in the fewest bytes, and jump tables are winners on both counts.</p>
<p>For example, suppose that we have a program that monitors the serial port and needs to branch quickly to 1 of 128 subroutines, depending on which one of the 128 7-bit ASCII characters is in AL. We could do that with 127 <code class="sourceCode nasm"><span class="kw">cmp</span></code> instructions followed by conditional jumps, something like this:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">and</span>   <span class="kw">al</span><span class="bn">,7fh    </span><span class="co">;make it 7-bit ASCII</span>
          :
    <span class="kw">cmp</span>   <span class="kw">al</span>,<span class="dv">8</span>
    <span class="kw">jae</span>   Above7
    <span class="kw">cmp</span>   <span class="kw">al</span>,<span class="dv">4</span>
    <span class="kw">jae</span>   Above3
    <span class="kw">cmp</span>   <span class="kw">al</span>,<span class="dv">2</span>
    <span class="kw">jae</span>   Above1
    <span class="kw">and</span>   <span class="kw">al</span>,<span class="kw">al</span>
    <span class="kw">jnz</span>   Is1
<span class="co">; The character is ASCII 0.</span>
          :
<span class="co">; The character is ASCII 1.</span>
<span class="fu">Is1:</span></code></pre>
<p>However, this approach would take a <em>lot</em> of code to handle all 128 characters — somewhere between 4 and 7 bytes for each character after the first, or between 508 and 889 bytes in all. It would be slow as well, since seven comparisons and conditional jumps would be required to identify each character. Worse yet, some of the conditional jumps would have to be implemented as reverse-polarity conditional jumps around unconditional jumps, since conditional jumps only have a range of +127 to -128 bytes — and we know how slow jumps around jumps can be.</p>
<p>The failing of the above approach is that it uses code to translate a value in AL into a routine’s offset to be loaded into IP. Because the mapping of values to offsets covers every value from 0 through 127 and is well-defined, it can be handled far more efficiently in the form of data than in the form of endless test-and-branch code. How? By constructing a table of offsets — a jump table — with the position of each routine’s offset in the table corresponding to the value used to select that routine:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">Jump7BitASCIITable  label   <span class="dt">word</span>
    <span class="dt">dw</span>    Is0, Is1, Is2, Is3, Is4, Is5, Is6, Is7
    <span class="dt">dw</span>    Is8, Is9, Is10, Is11, Is12, Is13, Is14, Is15
    :
    <span class="kw">mov</span>   <span class="kw">bl</span>,<span class="kw">al</span>
    <span class="kw">and</span>   <span class="kw">bx</span><span class="bn">,7fh                    </span><span class="co">;make it 7-bit ASCII and make it a word</span>
    <span class="kw">shl</span>   <span class="kw">bx</span>,<span class="dv">1</span>                      <span class="co">;*2 for lookup in a table of word-sized offsets</span>
    <span class="kw">jmp</span>   [Jump7BitASCIITable+<span class="kw">bx</span>]   <span class="co">;jump to handler for value</span></code></pre>
<p>The jump table approach is not only faster (by a long shot — only four instructions and one branch are involved), it’s also <em>much</em> more compact. Only 267 bytes are needed, less than half as many as required by the compare-and-branch approach.</p>
<p>It’s not much of a contest, is it?</p>
<p>This may remind you of our experience with look-up tables in Chapter 7, and well it might, for a jump table is just another sort of look-up table. When a task is such that it can be solved by looking up a result rather than calculating it, the look-up approach almost invariably wins. It matters not a whit whether the desired result is a bit pattern, a multiplication product, or a code address.</p>
<section id="partial-jump-tables" class="level3">
<h3>Partial Jump Tables</h3>
<p>Jump tables work well even with less neatly organized index-to-offset mappings. Suppose, for example, that the ASCII character handler of the last example only needs to branch to unique handlers for the 32 control characters, with the other 96 characters handled by a single routine. That would greatly reduce the number of comparisons required by the compare-and-branch approach, improving performance and shrinking the code to less than 150 bytes. On the other hand, our jump-table implementation wouldn’t shrink at all, since one jump-table entry would still be needed for each 7-bit ASCII character, although the entries for all the non-control character entries would be the same, as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">Jump7BitASCIITable  label   <span class="dt">word</span>
    <span class="dt">dw</span>    Is0, Is1, Is2, Is3, Is4, Is5, Is6, Is7
    <span class="dt">dw</span>    Is8, Is9, Is10, Is11, Is12, Is13, Is14, Is15
    <span class="dt">dw</span>    Is16, Is17, Is18, Is19, Is20, Is21, Is22, Is23
    <span class="dt">dw</span>    Is24, Is25, Is26, Is27, Is28, Is29, Is30, Is31
    <span class="dt">dw</span>    <span class="dv">96</span> dup (IsNormalChar)
    :
    <span class="kw">mov</span>   <span class="kw">bl</span>,<span class="kw">al</span>
    <span class="kw">and</span>   <span class="kw">bx</span><span class="bn">,7fh                    </span><span class="co">;make it 7-bit ASCII and make it a word</span>
    <span class="kw">shl</span>   <span class="kw">bx</span>,<span class="dv">1</span>                      <span class="co">;*2 for lookup in a table of word-sized offsets</span>
    <span class="kw">jmp</span>   [Jump7BitASCIITable+<span class="kw">bx</span>]   <span class="co">;jump to handler for value</span></code></pre>
<p>While the duplicate entries work perfectly well, all branching to the same place, they do waste bytes.</p>
<p>What of jump tables in this case?</p>
<p>Well, the pure jump table code would indeed be somewhat larger than the compare-and-branch code, but it would still be much faster. One of the wonders of jump tables is that they never require more than one branch, and no compare-and-branch approach that performs anything more complex than a yes/no decision can make that claim.</p>
<p>Matters are not so cut and dried as they might seem, however. We’ve learned that there are always other options, and this is no exception. Just as we achieved good results with a hybrid of in-line code and looping in the last chapter, we can come up with a better solution here by mixing the two approaches. We can compare-and-branch to handle the 96 normal characters, then use a reduced jump table to handle the 32 control characters, as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">JumpControlCharTable  label   <span class="dt">word</span>
    <span class="dt">dw</span>    Is0, Is1, Is2, Is3, Is4, Is5, Is6, Is7
    <span class="dt">dw</span>    Is8, Is9, Is10, Is11, Is12, Is13, Is14, Is15
    <span class="dt">dw</span>    Is16, Is17, Is18, Is19, Is20, Is21, Is22, Is23
    <span class="dt">dw</span>    Is24, Is25, Is26, Is27, Is28, Is29, Is30, Is31
    :
    <span class="kw">cmp</span>   <span class="kw">al</span><span class="bn">,20h                      </span><span class="co">;is it a control character?</span>
    <span class="kw">jnb</span>   IsNormalChar                <span class="co">;no-handle as a normal character</span>
    <span class="kw">mov</span>   <span class="kw">bl</span>,<span class="kw">al</span>                       <span class="co">;handle control characters through look-up table</span>
    <span class="kw">and</span>   <span class="kw">bx</span><span class="bn">,7fh                      </span><span class="co">;make it 7-bit ASCII and make it a word</span>
    <span class="kw">shl</span>   <span class="kw">bx</span>,<span class="dv">1</span>                        <span class="co">;*2 for lookup in a table of word-sized offsets</span>
    <span class="kw">jmp</span>   [JumpControlCharTable+<span class="kw">bx</span>]   <span class="co">;jump to handler for value</span></code></pre>
<p>This partial jump table approach requires the execution of a maximum of just 6 instructions and 1 branch, and is just 79 bytes long — still vastly superior to the compare-and-branch approach, and, on balance, superior to the pure jump table approach as well.</p>
<p>Granted, pure jump table code would be slightly faster, since it’s 2 instructions shorter, but that’s just our familiar trade-off of speed for size. In this case that’s an easy trade-off to make, since the speed difference is negligible and the size difference is great. The greater the number of tests required before performing the branch through the jump table in a partial jump table approach, the greater the performance loss and the less the space savings relative to a pure jump table approach. As usual, the decision is yours to make on a case by case basis.</p>
</section>
<section id="generating-jump-table-indexes" class="level3">
<h3>Generating Jump Table Indexes</h3>
<p>There are many ways to generate indexes into jump tables. Sometimes indexes are passed in as parameters by calling routines, as in a function dispatcher. Sometimes indexes are read from ports or from memory. Indexes may also be looked up in <em>other</em> tables. For example, a keyboard handler might use <code class="sourceCode nasm">repnz <span class="kw">scasw</span></code> to find the index for the current 16-bit key code in a key-mapping table, then use that index to jump to the appropriate key-handling routine via a jump table, as shown in <a href="#listing-14-12">Listing 14-12</a>, which runs in 504 us for the sample keystrokes. (<a href="#listing-14-12">Listing 14-12</a> is a modification of the key-handling jump table code we saw in <a href="#listing-11-17">Listing 11-17</a>.)</p>
<p>Why not simply put the address of each key handler right next to the corresponding 16-bit key code in a single look-up table, so no calculation is needed in order to perform the second look-up? For one thing, the second look-up takes hardly any time at all in <a href="#listing-14-12">Listing 14-12</a>, since the calculation of the jump table address is performed as a <em>mod-reg-rm</em> calculation by:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">jmp</span>   <span class="kw">cs</span>:[KeyJumpTable+<span class="kw">di</span><span class="dv">-2</span>-offset KeyLookUpTable]</code></pre>
<p>Even if the second look-up were slow, however, the two-table approach would still be preferable. You see, contiguous data arrays are required in order to use <code class="sourceCode nasm">repnz <span class="kw">scasw</span></code>, and, as we learned a few chapters back, it’s worth structuring your code so that repeated string instructions can be used whenever possible.</p>
<p>Does it really make that much difference to structure the table so that <code class="sourceCode nasm">rep <span class="kw">scasw</span></code> can be used? It surely does. <a href="#listing-14-13">Listing 14-13</a>, which uses a single look-up table containing both key codes and handler addresses, takes 969 us to run — nearly twice as long as <a href="#listing-14-12">Listing 14-12</a>.</p>
<p>Design your code to use repeated string instructions!</p>
<p>At any rate, jump tables operate in the same basic way no matter how indexes are generated; an index is used to look up an address to branch to. The rule as to when you should use a jump table is equally simple: whenever you find yourself branching to one of several addresses based on one of a set of consecutive values, you should almost certainly use a jump table. If the values aren’t consecutive but are bunched, you might want to use the partial jump table approach, filtering out the oddball cases and branching on those that are tightly grouped. Finally, if speed is paramount, the pure jump table approach is the way to go, even if that means making a large table containing many unused or duplicate entries.</p>
</section>
<section id="jump-tables-macros-and-branched-to-in-line-code" class="level3">
<h3>Jump Tables, Macros and Branched-To In-Line Code</h3>
<p>In the last chapter, we simply calculated the destination offset whenever we needed to branch into in-line code. That approach is fine when the offset calculations involve nothing more than a few shifts and adds, but it can reduce performance considerably if a <code class="sourceCode nasm"><span class="kw">mul</span></code> instruction must be used. Then, too, the calculated-offset approach only works if every repeated code block in the target in-line code is exactly the same size. That won’t be the case if, for example, some repeated code blocks use short branches while others use normal branches, as shown in Figure 14.9.</p>
<figure>
<img src="images/fig14.9RT.png" />
</figure>
<p>In such a case, a jump table is the preferred solution. Selecting an offset and branching to it through a jump table takes only a few instructions, and is certainly faster than multiplying. Jump tables can also handle repeated in-line code blocks of varying sizes, since jump tables store offsets that can point anywhere and can be arranged in any order, rather than being limited to calculations based on a fixed block size.</p>
<p>Let’s look at the use of a jump table to handle a case where in-line code blocks do vary in size. Suppose that we’re writing a subroutine that will search the first <em>n</em> bytes of a zero-terminated string of up to 80 bytes in length for a given character. We want to use pure in-line code for speed, but that’s more easily said than done. The in-line code performs conditional jumps when checking for both matches and terminating zeros; unfortunately, the entire in-line code sequence is so long that the 1-byte displacement of a conditional jump can’t reach the termination labels from the in-line code blocks that are smack in the middle of the in-line code. We could solve this problem by using conditional jumps around unconditional jumps in all cases, but that seems like an awful waste given that many of the blocks <em>could</em> use conditional jumps.</p>
<p>What we really want to do is use conditional jumps in some in-line code blocks — whenever a 1-byte displacement will reach — and jumps around jumps in other blocks. Unfortunately, that would mean that some blocks were larger than others, and <em>that</em> would mean that there was no easy way to calculate the start offset of the desired block.</p>
<p>The answer (surprise!) is to use a jump table, as shown in <a href="#listing-14-14">Listing 14-14</a>. The jump table simply stores the start offset of each in-line code block, regardless of how large that block may be. While the jump table is 162 bytes in size, there’s no speed penalty for using it, since the process of looking up a table entry and branching accordingly requires only a few instructions. Indeed, it’s often faster to use a jump table in this way than it is to calculate the target offset even when the repeated in-line code blocks <em>are</em> all the same size.</p>
<p>How does <a href="#listing-14-14">Listing 14-14</a> generate in-line code blocks of varying sizes? The macro <code class="sourceCode nasm">CHECK_CHAR</code>, which is used to generate each in-line code block, actually calculates the distance from the end of each conditional jump to the target label, and uses the <code class="sourceCode nasm">if</code> directive to assemble a single conditional jump if a 1-byte displacement will reach the target label, or a conditional jump around an unconditional jump if necessary. In some cases a conditional jump does reach, while in others it doesn’t; as a result, the in-line code blocks vary in size.</p>
<p><a href="#listing-14-14">Listing 14-14</a> illustrates the use of a clever technique that’s most useful for generating jump tables that point to in-line code: macro text substitution. In order to generate a unique label for each repeated code block, the assembler variable <code class="sourceCode nasm">BLOCK_NUMBER</code> is initially set to zero, and then incremented each time a new code block is created. (Note that <code class="sourceCode nasm">BLOCK_NUMBER</code> is a variable used during assembly, not a variable used by the assembler program. Such variables are used to control assembly, and the program being assembled has no knowledge of them at run time.)</p>
<p>The value of <code class="sourceCode nasm">BLOCK_NUMBER</code> is passed to <code class="sourceCode nasm">CHECK_CHAR</code>, the macro that creates each instance of the repeated code, as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">CHECK_CHAR   <span class="ot">%BLOCK_NUMBER</span></code></pre>
<p>The macro sees this passed parameter as the parameter <code class="sourceCode nasm">NUMBER</code>. Thanks to the percent-sign, the assembler actually makes the value of <code class="sourceCode nasm">BLOCK_NUMBER</code> into a text string when it passes it to <code class="sourceCode nasm">CHECK_CHAR</code>; that text string is then substituted wherever the parameter <code class="sourceCode nasm">NUMBER</code> appears in the macro.</p>
<p>What’s really interesting is what comes of butting <code class="sourceCode nasm">&amp;NUMBER&amp;</code> up against the text “CheckChar” in the macro <code class="sourceCode nasm">CHECK_CHAR</code>, as follows:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">CheckChar&amp;NUMBER&amp;:</code></pre>
<p>(The ampersands (‘&amp;’) around <code class="sourceCode nasm">NUMBER</code> ensure that the assembler knows that parameter substitution should take place; otherwise, when <code class="sourceCode nasm">NUMBER</code> is butted up against other text, as it is above, the assembler has no way of knowing whether to treat <code class="sourceCode nasm">NUMBER</code> as a parameter or as part of a longer text string.) A text representation of the value of <code class="sourceCode nasm">NUMBER</code> is substituted into the above line, so if <code class="sourceCode nasm">NUMBER</code> is 2, the line becomes:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="fu">CheckChar2:</span></code></pre>
<p>If <code class="sourceCode nasm">NUMBER</code> is 10, the line becomes:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="fu">CheckChar10:</span></code></pre>
<p>Do you see what we’ve done? We’ve created a unique label for each repeated code block, since <code class="sourceCode nasm">BLOCK_NUMBER</code> is incremented after each code block is created. Better yet, the labels are organized in a predictable manner, with the first code block labelled with <code class="sourceCode nasm">CheckChar0</code>, the second labelled with <code class="sourceCode nasm">CheckChar1</code>, and so on.</p>
<p>It should be pretty clear that this is an ideal set-up for a jump table. There are a couple of tricks here, however. First, if we want to check at most one character, we must branch to not the first but the <em>last</em> repeated in-line code block, and that code block is labelled with <code class="sourceCode nasm">CheckChar79</code>. That means that our jump table should look something like this:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">CheckCharJumpTable  label   <span class="dt">word</span>
    <span class="dt">dw</span>    NoMatch
    <span class="dt">dw</span>    CheckChar79, CheckChar78, CheckChar77, CheckChar76
    <span class="dt">dw</span>    CheckChar75, CheckChar74, CheckChar73, CheckChar72
    :
    <span class="dt">dw</span>    CheckChar3, CheckChar2, CheckChar1, CheckChar0</code></pre>
<p>with the maximum number of characters to check used as the index into the table. That way, a maximum check count of 1 will branch to the last repeated in-line code block, a maximum count of 2 will branch to the next to last block, and so on.</p>
<p>That brings us to the second trick: why do all the typing involved in creating the above table, when we’ve already seen that labels created with macros can do the work for us? The following is a <em>much</em> easier way to create the jump table:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">MAKE_CHECK_CHAR_LABEL   macro   NUMBER
        <span class="dt">dw</span>    CheckChar&amp;NUMBER&amp;
        endm
              :
SearchTable   label   <span class="dt">word</span>
        <span class="dt">dw</span>    NoMatch
BLOCK_NUMBER=MAX_SEARCH_LENGTH<span class="dv">-1</span>
        rept  MAX_SEARCH_LENGTH
        MAKE_CHECK_CHAR_LABEL <span class="ot">%BLOCK_NUMBER</span>
BLOCK_NUMBER=BLOCK_NUMBER<span class="dv">-1</span>
        endm</code></pre>
<p><a href="#listing-14-14">Listing 14-14</a> puts all of the above together, creating and using unique labels in both the in-line code and the jump table. Figure 14.10 illustrates <a href="#listing-14-14">Listing 14-14</a> in action.</p>
<figure>
<img src="images/fig14.10RT.png" />
</figure>
<p>Study both the listing and the figure carefully, for macros, repeat blocks, jump tables, and in-line code working together are potent indeed.</p>
<p>Now for the kicker: all that fancy coding actually doesn’t even pay off in this particular case. <a href="#listing-14-14">Listing 14-14</a> runs in 1013 us. <a href="#listing-14-15">Listing 14-15</a>, which uses a standard loop approach, runs in 988 us! Not only is <a href="#listing-14-15">Listing 14-15</a> faster, but it’s also hundreds of bytes shorter and much simpler than <a href="#listing-14-14">Listing 14-14</a> — and, unlike <a href="#listing-14-14">Listing 14-14</a>, <a href="#listing-14-15">Listing 14-15</a> can handle strings of any length. Frankly, there’s no reason to recommend <a href="#listing-14-14">Listing 14-14</a> over <a href="#listing-14-15">Listing 14-15</a>, and good reason not to.</p>
<p>Why have I spent all this time developing <em>slower</em> code? Forget the specific example: the idea was to show you how jump tables can be used to branch into in-line code, even when the in-line code consists of code blocks of varying lengths. The particular example I chose doesn’t benefit from these techniques because it was selected for illustrative rather than practical purposes. While there are good applications for jump tables that branch into in-line code — plenty of them! — they tend to be lengthy and complex, and I decided to choose an example that was short enough so that the decidedly non-obvious techniques used could be readily understood.</p>
<p>Why does this particular example not benefit much from the use of branched to in-line code? The answer is that too few of the branches in <a href="#listing-14-14">Listing 14-14</a> are able to use a 1-byte conditional jump. As a result, many of the branches — especially those between the middle and end of the in-line code, which tend to be executed most often — must use jumps around jumps. The end result is that <em>two</em> branches, in the form of jumps around jumps, are often performed for each byte checked in <a href="#listing-14-14">Listing 14-14</a>, while only one branch — a <code class="sourceCode nasm"><span class="kw">loop</span></code> — is performed for each byte checked in <a href="#listing-14-15">Listing 14-15</a>.</p>
<p>In truth, the best way to speed up this code would be partial in-line code, which would allow <em>all</em> the branches to use 1-byte displacements. A double-scan approach, using a repeated string instruction to search for the terminating zero and then another string instruction to search for the desired character, might also serve well.</p>
<p>Just to demonstrate the flexibility of macros, jump tables, and branched-to in-line code, however, <a href="#listing-14-16">Listing 14-16</a> is a modification of <a href="#listing-14-14">Listing 14-14</a> that branches out with 1-byte displacements at <em>both</em> ends of the in-line code, using conditional jumps around unconditional jumps only in the middle of the in-line code, where 1-byte displacements can’t reach past either end. As predicted, <a href="#listing-14-16">Listing 14-16</a> is, at 908 us, a good bit faster than <a href="#listing-14-14">Listings 14-14</a> and <a href="#listing-14-15">14-15</a>. (Bear in mind that the relative performances of these listings could change considerably given different search parameters. <em>There is no such thing as absolute performance</em>. Know the conditions under which your code will run!)</p>
<p><a href="#listing-14-16">Listing 14-16</a> isn’t <em>blazingly</em> fast, but it is fast enough to remind us that branched-to in-line code is a most attractive option… and now jump tables let us use branched-to in-line code in more situations than ever, and often with improved speed, as well.</p>
</section>
</section>
<section id="forward-references-rear-their-collective-ugly-head-once-more" class="level2">
<h2>Forward References Rear Their Collective Ugly Head Once More</h2>
<p>You may have noticed that <code class="sourceCode nasm">CHECK_CHAR2</code>, the macro in <a href="#listing-14-16">Listing 14-16</a> that assembles in-line code blocks that use conditional jumps forward to <code class="sourceCode nasm">NoMatch2</code> and <code class="sourceCode nasm">MatchFound2</code>, is a bit different from <code class="sourceCode nasm">CHECK_CHAR</code>, which assembles blocks that use backward jumps. <code class="sourceCode nasm">CHECK_CHAR</code> uses the <code class="sourceCode nasm">if</code> directive to determine whether a conditional jump can be used, assembling a jump around a jump if a conditional jump won’t reach. <code class="sourceCode nasm">CHECK_CHAR2</code>, on the other hand, always assembles a conditional jump.</p>
<p>The reason is this: when the assembler performs arithmetic for use in <code class="sourceCode nasm">if</code> directives, all the values in the expression must already be known when the <code class="sourceCode nasm">if</code> is encountered. In particular, the offset of a forward-referenced label can’t be used in <code class="sourceCode nasm">if</code> arithmetic. Why? When performing <code class="sourceCode nasm">if</code> arithmetic with a forward-referenced label, the assembler doesn’t know whether the <code class="sourceCode nasm">if</code> is true until the forward-referenced label has been assembled. That creates a nasty paradox, since the assembler can’t assemble the label, which follows the <code class="sourceCode nasm">if</code>, until the <code class="sourceCode nasm">if</code> has been evaluated and the code associated with the <code class="sourceCode nasm">if</code> has or hasn’t been assembled. The assembler resolves this chicken-and-egg problem by reporting an error.</p>
<p>The upshot is that while a line like:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">if (<span class="dv">$</span>-BackwardReferencedLabel)</code></pre>
<p>is fine, a line like:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">if (ForwardReferencedLabel-<span class="dv">$</span>)</code></pre>
<p>is not. Alas, that means that there’s no way to have a macro do automatic jump sizing for branches to forward-referenced labels — hence the lack of conditional assembly in <code class="sourceCode nasm">CHECK_CHAR2</code> — although there’s no problem with backward-referenced labels, as evidenced by <code class="sourceCode nasm">CHECK_CHAR</code>. In fact, I arrived at the optimum number of repetitions of <code class="sourceCode nasm">CHECK_CHAR2</code> in <a href="#listing-14-16">Listing 14-16</a> by rough calculation followed by trial-and-error… and that’s what you’ll have to do when trying to get maximum performance out of forward branches in in-line code.</p>
<p>Actually, there is an alternative to trial-and-error: as I mentioned earlier, assemblers that detect and/or correct suboptimal branches can help considerably in optimizing forward in-line branches. If you’re using MASM, however, backward branches, which macros (or even the assembler, for unconditional branches) can easily optimize, should be used whenever possible.</p>
<p>A final note: macros can easily obscure the true nature of your code, since you don’t see the actual code that’s assembled when you scan a listing containing macros. That problem becomes all the more acute when the <code class="sourceCode nasm">if</code> directive is used to produce conditionally assembled code. Whenever you’re not sure exactly what code you’re assembling, generate an assembler listing file that shows macro expansions, or take a look at the actual code with a debugger.</p>
<section id="still-and-all-dont-jump" class="level3">
<h3>Still and All… Don’t Jump!</h3>
<p>All of the wonderful branching tricks we’ve encountered in this chapter notwithstanding, you’re still better off from a performance perspective when you don’t branch. Granted, branching can often be beneficial from a code-size perspective, but performance is more often an issue than is size. Also, the improvements in performance that can be achieved by not-branching are relatively far greater than the improvements in size that can be achieved by judicious branching.</p>
<p>Think back again to <a href="#listing-11-27">Listing 11-27</a>, in which we sped up a case-insensitive string comparison considerably simply by looking up the uppercase version of each character in a table instead of using a mere five instructions — and at most one branch — to convert each character to uppercase. <em>Only rarely can code-only calculations, especially calculations that involve branching, beat table look-ups.</em> What’s more, we could speed the code up a good deal more by using pure or partial in-line code rather than looping every two characters. If we wanted to, we could effectively eliminate nearly every single branch in the string-comparison code — and the code would be much the faster for it.</p>
<p>No matter how tight your code is, if it branches it <em>can</em> be made faster. Whether it <em>is</em> made faster is purely a matter of: a) your ability to bring techniques such as table look-ups and in-line code to bear, and b) your willingness to trade the extra bytes those techniques require for the cycles they save. To that list I might add a third, slightly different condition: c) the degree to which the performance of the code matters.</p>
<p>Never waste your time optimizing non-critical code for speed. There’s too much time-critical code in the world that <em>needs</em> improving to squander effort on initialization code, code outside loops, and the like.</p>
</section>
<section id="this-concludes-our-tour-of-the-8088s-instruction-set" class="level3">
<h3>This Concludes Our Tour of the 8088’s Instruction Set</h3>
<p>And with that, we’ve come to the end of our long journey through the 8088’s strange but powerful instruction set. We haven’t covered all the variations of all the instructions — not by a long shot — but we have done the major ones, and we’ve gotten a good look at what the 8088 has to offer. As a sort of continuing education on the instruction set, you would do well to scan through Appendix A and/or other instruction set summaries periodically. I’ve been doing that for seven years now, and I still find useful new tidbits in the instruction set from time to time.</p>
<p>We’ve also come across a great many tricks, tips, and optimizations in our travels — but Lord knows we haven’t seen them all! Thanks to the virtually infinite permutations of which the 8088’s instruction set is capable, as well as the inherent and unpredictable variation of the execution time of any given instruction, PC code optimization is now and forever an imperfect art. Nonetheless, we’ve learned a great deal, and with that knowledge and the Zen timer in hand, we’re well along the path to becoming expert code artists.</p>
</section>
</section>
</section>
<section id="chapter-15-other-processors" class="level1">
<h1>Chapter 15: Other Processors</h1>
<p>Now that we’ve spent 14 chapters learning how to write good assembler code for the 8088, it’s time to acknowledge that there are other widely-used processors in the 8088’s family: the 8086, the 80286, and the 80386, to name but a few. None of the other processors are as popular as the 8088 yet, but some — most notably the 80386 — are growing in popularity, and it’s likely that any code you write for general distribution will end up running on those processors as well as on the 8088.</p>
<p><em>Omigod</em>! Does that mean that you need to learn as much about those processors as you’ve learned about the 8088? Not at all. We’ll see why shortly, but for now, take my word for it: the 8088 is the processor for which you should optimize.</p>
<p>Nonetheless, in this chapter we’ll take a quick look at optimizations for other processors, primarily the 80286 and the 80386. Why? Well, many of the optimizations for those processors are similar to those for the 8088, and it’s useful to know which of the rules we’ve learned are generally applicable to the whole family (all the major ones, as it turns out). Also, one particular optimization for other 8086-family processors — data alignment — is so easy to implement, costs so little, and has such a large payback that you might want to apply it routinely to your code even though it has no effect on 8088 performance.</p>
<p>Finally, I’d like to get you started in the right direction if you <em>are</em> primarily interested in optimization for the 80286 and its successors. After all, the 8088 is going to go out of style <em>someday</em> (although that’s certainly not happening anytime soon), and OS/2 and its ilk are creeping up on us. You have the Zen timer, and you’ve learned much about how to evaluate and improve code performance; with a bit of a head start here, you should be able to develop your own expertise in 80286/80386 coding if you so desire.</p>
<section id="why-optimize-for-the-8088" class="level2">
<h2>Why Optimize for the 8088?</h2>
<p>The great lurking unanswered question is: given that the 80286 and the 80386 (and the 80486 someday) are the future of PC-compatible computing, why optimize for the 8088? Why not use all the extra instructions and features of the newer processors to supercharge your code so it will run as fast as possible on the fastest computers?</p>
<p>There are several reasons. Each by itself is probably ample reason to optimize for the 8088; together, they make a compelling argument for 8088-specific optimization. Briefly put, the reasons are:</p>
<ul>
<li>The 8088 is the lowest common denominator of the 8086 family for both compatibility and performance.</li>
<li>The market for software that runs on the 8088 is enormous.</li>
<li>The 8088 is the 8086-family processor for which optimization pays off most handsomely.</li>
<li>The 8088 is the only 8086-family processor which comes in a single consistent system configuration — the IBM PC.</li>
<li>The major 8088 optimizations work surprisingly well on the 80286 and 80386.</li>
</ul>
<p>As we discuss these reasons below, bear in mind that when I say “8088,”I mean “8088 as used in the IBM PC,” for it’s the widespread use of the PC that makes the 8088 the assembler programmer’s chip of choice.</p>
<p>That said, let’s tackle our original question again, this time in more detail: why optimize for the 8088?</p>
<p>For starters, the 8088 is the lowest common denominator of the 8086 family, unless you’re writing applications for an operating system that doesn’t even run on an 8088 -OS/2, an 80286/80386-specific version of Unix, or the like. Code written for the 8088 will run on all of the other chips in the 8086 family, while code written for the 80286 or the 80386 won’t run on the 8088 if any of the special features and/or instructions of those chips are used.</p>
<p>It stands to reason, then, that code written for the 8088 has the broadest market and is the most generally useful code around. That status should hold well into the twenty-first century, given that every 8086-family processor Intel has ever introduced has provided full backward compatibility with the 8088. If any further proof is needed, hardware and/or software packages that allow 8088 code to be run are available for a number of computers built around non-Intel processors, including the Apple Macintosh, the Commodore Amiga, and a variety of 68XXX-based workstations.</p>
<p>The 8088 is the lowest common denominator of the 8086 family in terms of performance as well as code compatibility. No 8086-family chip runs slower than the 8088, and it’s a safe bet that none ever will. By definition, any code that runs adequately fast on an 8088 is bound to be more than adequate on any other 8086-family processor. Unless you’re willing to forgo the 8088 market altogether, then, it certainly makes sense to optimize your code for the 8088.</p>
<p>The 8088 is also the processor for which optimization pays off best. The slow memory access, too-small 8-bit bus, and widely varying instruction execution times of the 8088 mean that careful coding can produce stunning improvements in performance. Over the past few chapters we’ve seen that it’s possible to double and even triple the performance of already-tight 8088 assembler code. While the 80286 and 80386 certainly offer optimization possibilities, their superior overall performance results partly from eliminating some of the worst bottlenecks of the 8088, so it’s harder to save cycles by the bushel. Then, too, the major optimizations for the 8088 — keep instructions short, use the registers, use string instructions, and the like — also serve well on the 80286 and 80386, so optimization for the 8088 results in code that is reasonably well optimized across the board.</p>
<p>Finally, the 8088 is the only 8086-family processor that comes in one consistent system configuration — the IBM PC. There are 8088-based computers that run at higher clock speeds than the IBM PC, but, to the best of my knowledge, all 8088-based PC compatible computers have zero-wait-state memory. By contrast, the 80286 comes in two flavors: classic one-wait-state AT, and souped-up zero-wait-state AT… and additional variations will surely appear as high-speed 80286s become available. The 80386 is available in a multitude of configurations: static-column RAM, cached memory, and interleaved memory, to name a few, with each of those available in several versions.</p>
<p>What all that means is that while you can rely on fast code on one PC being fast code on any PC, that’s not the case with 80286 and 80386 computers. 80286/80386 performance can vary considerably, depending on how your code interacts with a particular computer’s memory architecture. As a result, it’s only on the PC that it pays to fine-tune your assembler code down to the last few cycles.</p>
<p>So. I hope I’ve convinced you that the 8088 is the best place to focus your optimization efforts. In any case, let’s tour the rest of the 8086 family.</p>
</section>
<section id="which-processors-matter" class="level2">
<h2>Which Processors Matter?</h2>
<p>While the 8086 family is a large one, only a few members of the family — which includes the 8088, 8086, 80188, 80186, 80286, 80386SX, and 80386 — really matter.</p>
<p>The 80186 and 80188 never really caught on for use in PC compatibles, and don’t require further discussion.</p>
<p>The 8086, which is a good bit faster than the 8088, was used fairly widely for a while, but has largely been superseded by the 80286 as the chip of choice for better-than-8088 performance. (The 80386 is the chip of choice for flat-out performance, but it’s the 80286 that’s generally used in computers that are faster but not much more expensive than 8088-based PCs.) Besides, the 8086 has exactly the same Execution Unit instruction execution times as the 8088, so much of what we’ve learned about the 8088 is directly applicable to the 8086. The only difference between the two processors is that the 8086 has a 16-rather than 8-bit bus, as we found back in Chapter 3. That means that the 8086 suffers less from the prefetch queue and 8-bit bus cycle-eaters than does the 8088.</p>
<p>That’s not to say that the 8086 doesn’t suffer from those cycle-eaters at all; it just suffers less than the 8088 does. Instruction fetching is certainly still a bottleneck on the 8086. For example, the 8086’s Execution Unit can execute register-only instructions such as <code class="sourceCode nasm"><span class="kw">shl</span></code> and <code class="sourceCode nasm"><span class="kw">inc</span></code> twice as fast as the Bus Interface Unit can fetch those instructions. Of course, that is a considerable improvement over the 8088, which can execute those instructions <em>four</em> times as fast as they can be fetched.</p>
<p>Oddly enough, the 8-bit bus cycle-eater is also still a problem on the 8086, even though the 8086’s bus is 16 bits wide. While the 8086 is indeed capable of fetching words as rapidly as bytes, that’s true only for words that start at even addresses. Words that start at odd addresses are fetched with two memory accesses, since the 8086 is capable of performing word-sized accesses only to even addresses. We’ll discuss this phenomenon in detail when we get to the 80286.</p>
<p>In summary, the 8086 is much like the 8088, save that the prefetch queue cycle-eater is less of a problem and that word-sized accesses should be made to even addresses. Both these differences mean that code running on an 8086 always runs either exactly as fast as or faster than it would run on an 8088, so the rule still is: optimize for the 8088, and the code will perform even better on an 8086.</p>
<p>That leaves us with the high-end chips: the 80826, the 80386SX, and the 80386. At this writing, it’s unclear whether the 80386SX is going to achieve widespread popularity; it may turn out that the relatively small cost advantage the 80386SX enjoys over the 80386 isn’t enough to offset its relatively large performance disadvantage. After all, the 80386SX suffers from the same debilitating problem that looms over the 8088 — a too-small bus. Internally, the 80386SX is a 32-bit processor, but externally, it’s a 16-bit processor… and we know what <em>that</em> sort of mismatch can lead to!</p>
<p>Given its uncertain acceptance, I’m not going to discuss the 80386SX in detail. If you do find yourself programming for the 80386SX, follow the same general rules we’ve established for the 8088: use short instructions, use the registers as heavily as possible, and don’t branch. In other words, avoid memory, since the 80386SX is by definition better at processing data internally than it is at accessing memory.</p>
<p>Which leaves us with just two processors, the 80286 and the 80386.</p>
<section id="the-80286-and-the-80386" class="level3">
<h3>The 80286 and the 80386</h3>
<p>There’s no question but what the 80286 and 80386 are very popular processors. The 8088 is still more widely used than either of its more powerful descendants, but the gap is narrowing, and the more powerful processors can only gain in popularity as their prices comes down and memory — which both can use in huge quantities — becomes cheaper. All in all, it’s certainly worth our while to spend some time discussing 80286/80386 optimization.</p>
<p>We’re only going to talk about real-mode operation of the 80286 and 80386, however. Real mode is the mode in which the processors basically act like 8088s (albeit with some new instructions), running good old MS-DOS. By contrast, protected mode offers a whole new memory management scheme, one which isn’t supported by the 8088. Only code specifically written for protected mode can run in that mode; it’s an alien and hostile environment for MS-DOS programs.</p>
<p>In particular, segments are different creatures in protected mode. They’re selectors — indexes into a table of segment descriptors — rather than plain old registers, and can’t be set arbitrarily. That means that segments can’t be used for temporary storage or as part of a fast indivisible 32-bit load from memory, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">les</span>   <span class="kw">ax</span>,<span class="dt">dword</span> <span class="dt">ptr</span> [LongVar]
<span class="kw">mov</span>   <span class="kw">dx</span>,<span class="kw">es</span></code></pre>
<p>which loads <code class="sourceCode nasm">LongVar</code> into DX:AX faster than:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm"><span class="kw">mov</span>   <span class="kw">ax</span>,<span class="dt">word</span> <span class="dt">ptr</span> [LongVar]
<span class="kw">mov</span>   <span class="kw">dx</span>,<span class="dt">word</span> <span class="dt">ptr</span> [LongVar<span class="dv">+2</span>]</code></pre>
<p>Protected mode uses those altered segment registers to offer access to a great deal more memory than real mode: the 80286 supports 16 megabytes of memory, while 80386 supports 4 gigabytes (4 K megabytes) of physical memory and 64 <em>terabytes</em> (64 K gigabytes!) of virtual memory. There’s a price to pay for all that memory: protected-mode code tends to run a bit more slowly than equivalent real mode code, since instructions that load segments run more slowly in protected mode than in real mode.</p>
<p>Also, in protected mode your programs generally run under an operating system (OS/2, Unix, or the like) that exerts much more control over the computer than does MS-DOS. Protected-mode operating systems can generally run multiple programs simultaneously, and the performance of any one program may depend far less on code quality than on how efficiently the program uses operating system services and how often and under what circumstances the operating system preempts the program. Protected mode programs are often nothing more than collections of operating system calls, and the performance of whatever code <em>isn’t</em> operating-system oriented may depend primarily on how large a timeslice the operating system gives that code to run in.</p>
<p>In short, protected mode programming is a different kettle of fish altogether from what we’ve seen in <em>The Zen of Assembly Language</em>. There’s certainly a Zen to protected mode… but it’s not the Zen we’ve been learning, and now is not the time to pursue it further.</p>
</section>
</section>
<section id="things-mother-never-told-you-part-ii" class="level2">
<h2>Things Mother Never Told You, Part II</h2>
<p>Under the programming interface, the 80286 and 80386 differ considerably from the 8088. Nonetheless, with one exception and one addition, the cycle-eaters remain much the same on computers built around the 80286 and 80386. Next, we’ll review each of the familiar cycle-eaters as they apply to the 80286 and 80386, and we’ll look at the new member of the gang, the data alignment cycle-eater.</p>
<p>The one cycle-eater that vanishes on the 80286 and 80386 is the 8-bit bus cycle-eater. The 80286 is a 16-bit processor both internally and externally, and the 80386 is a 32-bit processor both internally and externally, so the Execution Unit/Bus Interface Unit size mismatch that plagues the 8088 is eliminated. Consequently, there’s no longer any need to use byte-sized memory variables in preference to word-sized variables, at least so long as word-sized variables start at even addresses, as we’ll see shortly. On the other hand, access to byte-sized variables still isn’t any <em>slower</em> than access to word-sized variables, so you can use whichever size suits a given task best.</p>
<p>You might think that the elimination of the 8-bit bus cycle-eater would mean that the prefetch queue cycle-eater would also vanish, since on the 8088 the prefetch queue cycle-eater is a side effect of the 8-bit bus. That would seem all the more likely given that both the 80286 and the 80386 have larger prefetch queues than the 8088 (6 bytes for the 80286, 16 bytes for the 80386) and can perform memory accesses, including instruction fetches, in far fewer cycles than the 8088.</p>
<p>However, the prefetch queue cycle-eater <em>doesn’t</em> vanish on either the 80286 or the 80386, for several reasons. For one thing, branching instructions still empty the prefetch queue, so instruction fetching still slows things down after most branches; when the prefetch queue is empty, it doesn’t much matter how big it is. (Even apart from emptying the prefetch queue, branches aren’t particularly fast on the 80286 or the 80386, at a minimum of seven-plus cycles apiece. Avoid branching whenever possible.)</p>
<p>After a branch it <em>does</em> matter how fast the queue can refill, and there we come to the second reason the prefetch queue cycle-eater lives on: the 80286 and 80386 are so fast that sometimes the Execution Unit can execute instructions faster than they can be fetched, even though instruction fetching is <em>much</em> faster on the 80286 and 80836 than on the 8088.</p>
<p>(All other things being equal, too-slow instruction fetching is more of a problem on the 80286 than on the 80386, since the 80386 fetches 4 instruction bytes at a time versus the 2 instruction bytes fetched per memory access by the 80286. However, the 80386 also typically runs at least twice as fast as the 80286, meaning that the 80386 can easily execute instructions faster than they can be fetched unless very high-speed memory is used.)</p>
<p>The most significant reason that the prefetch queue cycle-eater not only survives but prospers on the 80286 and 80386, however, lies in the various memory architectures used in computers built around the 80286 and 80286. Due to the memory architectures, the 8-bit bus cycle-eater is replaced by a new form of the wait-state cycle-eater: wait states on accesses to normal system memory.</p>
<section id="system-wait-states" class="level3">
<h3>System Wait States</h3>
<p>The 80286 and 80386 were designed to lose relatively little performance to the prefetch queue cycle-eater… <em>when used with zero-wait-state memory</em> — memory that can complete memory accesses so rapidly that no wait states are needed. However, true zero-wait-state memory is almost never used with those processors. Why? Because memory that can keep up with an 80286 is fairly expensive, and memory that can keep up with an 80386 is <em>very</em> expensive. Instead, computer designers use alternative memory architectures that offer more performance for the dollar — but less performance overall — than zero-wait-state memory. (It <em>is</em> possible to build zero-wait-state systems for the 80286 and 80386; it’s just so expensive that it’s rarely done.)</p>
<p>The IBM AT and true compatibles use one-wait-state memory (some AT clones use zero-wait-state memory, but such clones are less common than one-wait-state AT clones). 80386 systems use a wide variety of memory systems, including high-speed caches, interleaved memory, and static-column RAM, that insert anywhere from 0 to about 5 wait states (and many more if 8-or 16-bit memory expansion cards are used); the exact number of wait states inserted at any given time depends on the interaction between the code being executed and the memory system it’s running on. The performance of most 80386 memory systems can vary greatly from one memory access to another, depending on factors such as what data happens to be in the cache and which interleaved bank and/or RAM column was accessed last.</p>
<p>The many memory systems in use make it impossible for us to optimize for 80286/80386 computers with the precision to which we’ve become accustomed on the 8088. Instead, we must write code that runs reasonably well under the varying conditions found in the 80286/80386 arena.</p>
<p>The wait states that occur on most accesses to system memory in 80286 and 80386 computers mean that nearly every access to system memory — memory in the DOS’s normal 640 Kb memory area — is slowed down. (Accesses in computers with high-speed caches may be wait-state-free if the desired data is already in the cache, but will certainly encounter wait states if the data isn’t cached; this phenomenon produces highly variable instruction execution times.) While this is our first encounter with system memory wait states, we have run into a wait-state cycle-eater before: the display adapter cycle-eater, which we discussed way back in Chapter 4. System memory generally has fewer wait states per access than display memory. However, system memory is also accessed far more often than display memory, so system memory wait states hurt plenty — and the place they hurt most is instruction fetching.</p>
<p>Consider this. The 80286 can store an immediate value to memory, as in <code class="sourceCode nasm"><span class="kw">mov</span> [WordVar],<span class="dv">0</span></code>, in just 3 cycles. However, that instruction is 6 bytes long. The 80286 is capable of fetching 1 word every 2 cycles; however, the one-wait-state architecture of the AT stretches that to 3 cycles. Consequently, 9 cycles are needed to fetch the 6 instruction bytes. On top of that, 3 cycles are needed to write to memory, bringing the total memory access time to 12 cycles. On balance, memory access time — especially instruction prefetching — greatly exceeds execution time, to the extent that this particular instruction can take up to four times as long to run as it does to execute in the Execution Unit.</p>
<p>And that, my friend, is unmistakably the prefetch queue cycle-eater. I might add that the prefetch queue cycle-eater is in rare good form in the above example: a 4-to-1 ratio of instruction fetch time to execution time is in a class with the best (or worst!) we’ve found on the 8088.</p>
<p>Let’s check out the prefetch queue cycle-eater in action. <a href="#listing-15-1">Listing 15-1</a> times <code class="sourceCode nasm"><span class="kw">mov</span> [WordVar],<span class="dv">0</span></code>. The Zen timer reports that on a one-wait-state 10-MHz AT clone (the computer used for all tests in this chapter), <a href="#listing-15-1">Listing 15-1</a> runs in 1.27 us per instruction. That’s 12.7 cycles per instruction, just as we calculated above. (That extra seven-tenths of a cycle comes from DRAM refresh, which we’ll get to shortly.)</p>
<p>What does this mean? It means that, practically speaking, the 80286 as used in the AT doesn’t have a 16-bit bus. From a performance perspective, the 80286 in an AT has two-thirds of a 16-bit bus (a 10.7-bit bus?), since every bus access on an AT takes 50% longer than it should. An 80286 running at 10 MHz <em>should</em> be able to access memory at a maximum rate of 1 word every 200 ns; in a 10-MHz AT, however, that rate is reduced to 1 word every 300 ns by the one-wait-state memory.</p>
<p>In short, a close relative of our old friend the 8-bit bus cycle-eater — the system memory wait state cycle-eater — haunts us still on all but zero-wait-state 80286 and 80386 computers, and that means that the prefetch queue cycle-eater is alive and well. (The system memory wait state cycle-eater isn’t really a new cycle-eater, but rather a variant of the general wait state cycle-eater, of which the display adapter cycle-eater is another variant.) While the 80286 in the AT can fetch instructions much faster than can the 8088 in the PC, it can execute those instructions faster still.</p>
<p>The picture is less clear in the 80386 world, since there are so many different memory architectures, but similar problems can occur in any computer built around an 80286 or 80386. The prefetch queue cycle-eater is even a factor — albeit a lesser one — on zero-wait-state machines, both because branching empties the queue and because some instructions can outrun even zero-wait-state instruction fetching. (<a href="#listing-15-1">Listing 15-1</a> would take at least 8 cycles per instruction on a zero-wait-state AT — 5 cycles longer than the official execution time.)</p>
<p>To summarize:</p>
<ul>
<li>Memory-accessing instructions don’t run at their official speeds on non-zero-wait-state 80286/80386 computers.</li>
<li>The prefetch queue cycle-eater reduces performance on 80286/80386 computers, particularly when non-zero-wait-state memory is used.</li>
<li>Branches generally execute at less than their rated speeds on the 80286 and 80386, since the prefetch queue is emptied.</li>
<li>The extent to which the prefetch queue and wait states affect performance varies from one 80286/80386 computer to another, making precise optimization impossible.</li>
</ul>
<p>What’s to be learned from all this? Several things:</p>
<ul>
<li>Keep your instructions short.</li>
<li>Keep it in the registers; avoid memory, since memory generally can’t keep up with the processor.</li>
<li>Don’t jump.</li>
</ul>
<p>Of course, those are exactly the rules we’ve developed for the 8088. Isn’t it convenient that the same general rules apply across the board?</p>
</section>
<section id="data-alignment" class="level3">
<h3>Data Alignment</h3>
<p>Thanks to its 16-bit bus, the 80286 can access word-sized memory variables just as fast as byte-sized variables. There’s a catch, however: that’s only true for word-sized variables that start at even addresses. When the 80286 is asked to perform a word-sized access starting at an odd address, it actually performs two separate accesses, each of which fetches 1 byte, just as the 8088 does for all word-sized accesses.</p>
<p>Figure 15.1 illustrates this phenomenon.</p>
<figure>
<img src="images/fig15.1RT.png" />
</figure>
<p>The conversion of word-sized accesses to odd addresses into double byte-sized accesses is transparent to memory-accessing instructions; all any instruction knows is that the requested word has been accessed, no matter whether 1 word-sized access or 2 byte-sized accesses were required.</p>
<p>The penalty for performing a word-sized access starting at an odd address is easy to calculate: two accesses take twice as long as one access. In other words, the effective capacity of the 80286’s external data bus is <em>halved</em> when a word-sized access to an odd address is performed.</p>
<p>That, in a nutshell, is the data alignment cycle-eater, the one new cycle-eater of the 80286 and 80386. (The data alignment cycle-eater is a close relative of the 8088’s 8-bit bus cycle-eater, but since it behaves differently — occurring only at odd addresses — and is avoided with a different workaround, we’ll consider it to be a new cycle-eater.)</p>
<p>The way to deal with the data alignment cycle-eater is straightforward: <em>don’t perform word-sized accesses to odd addresses on the 80286 if you can help it</em>. The easiest way to avoid the data alignment cycle-eater is to place the directive <code class="sourceCode nasm">even</code> before each of your word-sized variables. <code class="sourceCode nasm">even</code> forces the offset of the next byte assembled to be even by inserting a <code class="sourceCode nasm"><span class="kw">nop</span></code> if the current offset is odd; consequently, you can ensure that any word-sized variable can be accessed efficiently by the 80286 simply by preceding it with <code class="sourceCode nasm">even</code>.</p>
<p><a href="#listing-15-2">Listing 15-2</a>, which accesses memory a word at a time with each word starting at an odd address, runs on a 10-MHz AT clone in 1.27 us per repetition of <code class="sourceCode nasm"><span class="kw">movsw</span></code>, or 0.64 us per word-sized memory access. That’s 6-plus cycles per word-sized access, which breaks down to two separate memory accesses — 3 cycles to access the high byte of each word and 3 cycles to access the low byte of each word, the inevitable result of non-word-aligned word-sized memory accesses — plus a bit extra for DRAM refresh.</p>
<p>On the other hand, <a href="#listing-15-3">Listing 15-3</a>, which is exactly the same as <a href="#listing-15-2">Listing 15-2</a> save that the memory accesses are word-aligned (start at even addresses), runs in 0.64 us per repetition of <code class="sourceCode nasm"><span class="kw">movsw</span></code>, or 0.32 us per word-sized memory access. That’s 3 cycles per word-sized access — exactly twice as fast as the non-word-aligned accesses of <a href="#listing-15-2">Listing 15-2</a>, just as we predicted.</p>
<p>The data alignment cycle-eater has intriguing implications for speeding up 80286/80386 code. The expenditure of a little care and a few bytes to make sure that word-sized variables and memory blocks are word-aligned can literally double the performance of certain code running on the 80286; even if it doesn’t double performance, word alignment usually helps and never hurts.</p>
<p>In fact, word alignment provides such an excellent return on investment on the 80286 that it’s the one 80286-specific optimization that I recommend for assembler code in general. (Actually, word alignment pays off on the 80386 too, as we’ll see shortly.) True, word alignment costs a few bytes and doesn’t help the code that most needs help — code running on the 8088. Still, it’s hard to resist a technique that boosts 80286 performance so dramatically without losing 8088 compatibility in any way or hurting 8088 performance in the least.</p>
</section>
<section id="code-alignment" class="level3">
<h3>Code Alignment</h3>
<p>Lack of word alignment can also interfere with instruction fetching on the 80286, although not to the extent that it interferes with access to word-sized memory variables. The 80286 prefetches instructions a word at a time; even if a given instruction doesn’t begin at an even address, the 80286 simply fetches the first byte of that instruction at the same time that it fetches the last byte of the previous instruction, as shown in Figure 15.2, then separates the bytes internally. That means that in most cases instructions run just as fast whether they’re word-aligned or not.</p>
<figure>
<img src="images/fig15.2RT.png" />
</figure>
<p>There is, however, a non-word-alignment penalty on <em>branches</em> to odd addresses. On a branch to an odd address, the 80286 is only able to fetch 1 useful byte with the first instruction fetch following the branch, as shown in Figure 15.3.</p>
<figure>
<img src="images/fig15.3RT.png" />
</figure>
<p>In other words, lack of word alignment of the target instruction for any branch effectively cuts the instruction-fetching power of the 80286 in half for the first instruction fetch after that branch. While that may not sound like much, you’d be surprised at what it can do to tight loops; in fact, a brief story is in order.</p>
<p>When I was developing the Zen timer, I used my trusty 10-MHz AT clone to verify the basic functionality of the timer by measuring the performance of simple instruction sequences. I was cruising along with no problems until I timed the following code:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">mov</span>   <span class="kw">cx</span>,<span class="dv">1000</span>
    <span class="kw">call</span>  ZTimerOn
<span class="fu">LoopTop:</span>
    <span class="kw">loop</span>  LoopTop
    <span class="kw">call</span>  ZTimerOff</code></pre>
<p>Now, the above code <em>should</em> run in, say, about 12 cycles per loop at most. Instead, it took over 14 cycles per loop, an execution time that I could not explain in any way. After rolling it around in my head for a while, I took a look at the code under a debugger… and the answer leaped out at me. <em>The loop began at an odd address!</em> That meant that two instruction fetches were required each time through the loop; one to get the opcode byte of the <code class="sourceCode nasm"><span class="kw">loop</span></code> instruction, which resided at the end of one word-aligned word, and another to get the displacement byte, which resided at the start of the next word-aligned word.</p>
<p>One simple change brought the execution time down to a reasonable 12.5 cycles per loop:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">mov</span>   <span class="kw">cx</span>,<span class="dv">1000</span>
    <span class="kw">call</span>  ZTimerOn
    even
<span class="fu">LoopTop:</span>
    <span class="kw">loop</span>  LoopTop
    <span class="kw">call</span>  ZTimerOff</code></pre>
<p>While word-aligning branch destinations can improve branching performance, it’s a nuisance and can increase code size a good deal, so it’s not worth doing in most code. Besides, <code class="sourceCode nasm">even</code> inserts a <code class="sourceCode nasm"><span class="kw">nop</span></code> instruction if necessary, and the time required to execute a <code class="sourceCode nasm"><span class="kw">nop</span></code> can sometimes cancel the performance advantage of having a word-aligned branch destination. Consequently, it’s best to word-align only those branch destinations that can be reached solely by branching. I recommend that you only go out of your way to word-align the start offsets of your subroutines, as in:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    even
FindChar  proc  near
          .
          .</code></pre>
<p>In my experience, this simple practice is the one form of code alignment that consistently provides a reasonable return for bytes and effort expended, although sometimes it also pays to word-align tight time-critical loops.</p>
</section>
<section id="alignment-and-the-80386" class="level3">
<h3>Alignment and the 80386</h3>
<p>So far we’ve only discussed alignment as it pertains to the 80286. What, you may well ask, of the 80386?</p>
<p>The 80386 benefits most from <em>doubleword</em> alignment. Every memory access that crosses a doubleword boundary forces the 80386 to perform two memory accesses, effectively doubling memory access time, just as happens with memory accesses that cross word boundaries on the 80286.</p>
<p>The rule for the 80386 is: word-sized memory accesses should be word-aligned (it’s impossible for word-aligned word-sized accesses to cross doubleword boundaries), and doubleword-sized memory accesses should be doubleword-aligned. However, in real (as opposed to protected) mode, doubleword-sized memory accesses are rare, so the simple word-alignment rule we’ve developed for the 80286 serves for the 80386 in real mode as well.</p>
<p>As for code alignment… the subroutine start word-alignment rule of the 80286 serves reasonably well there too, since it avoids the worst case, where just 1 byte is fetched on entry to a subroutine. While optimum performance would dictate doubleword alignment of subroutines, that takes 3 bytes, a high price to pay for an optimization that improves performance only on the 80386.</p>
</section>
<section id="alignment-and-the-stack" class="level3">
<h3>Alignment and the Stack</h3>
<p>One side-effect of the data alignment cycle-eater of the 80286 and 80386 is that you should <em>never</em> allow the stack pointer to become odd. (You can make the stack pointer odd by adding an odd value to it or subtracting an odd value from it, or by loading it with an odd value.) An odd stack pointer on the 80286 or 80386 will significantly reduce the performance of <code class="sourceCode nasm"><span class="kw">push</span></code>, <code class="sourceCode nasm"><span class="kw">pop</span></code>, <code class="sourceCode nasm"><span class="kw">call</span></code>, and <code class="sourceCode nasm"><span class="kw">ret</span></code>, as well as <code class="sourceCode nasm"><span class="kw">int</span></code> and <code class="sourceCode nasm"><span class="kw">iret</span></code>, which are executed to invoke DOS and BIOS functions, handle keystrokes and incoming serial characters, and manage the mouse. I know of a Forth programmer who vastly improved the performance of a complex application on the AT simply by forcing the Forth interpreter to maintain an even stack pointer at all times.</p>
<p>An interesting corollary to this rule is that you shouldn’t <code class="sourceCode nasm"><span class="kw">inc</span></code> SP twice to add 2, even though that’s more efficient than using <code class="sourceCode nasm"><span class="kw">add</span> <span class="kw">sp</span>,<span class="dv">2</span></code>. The stack pointer is odd between the first and second <code class="sourceCode nasm"><span class="kw">inc</span></code>, so any interrupt occurring between the two instructions will be serviced more slowly than it normally would. The same goes for decrementing twice; use <code class="sourceCode nasm"><span class="kw">sub</span> <span class="kw">sp</span>,<span class="dv">2</span></code> instead.</p>
<p><em>Keep the stack pointer even at all times.</em></p>
</section>
<section id="the-dram-refresh-cycle-eater-still-an-act-of-god" class="level3">
<h3>The Dram Refresh Cycle-Eater: Still an Act of God</h3>
<p>The DRAM refresh cycle-eater is the cycle-eater that’s least changed from its 8088 form on the 80286 and 80386. In the AT, DRAM refresh uses a little over 5% of all available memory accesses, slightly less than it uses in the PC, but in the same ballpark. While the DRAM refresh penalty varies somewhat on various AT clones and 80386 computers (in fact, a few computers are built around static RAM, which requires no refresh at all), the 5% figure is a good rule of thumb.</p>
<p>Basically, the effect of the DRAM refresh cycle-eater is pretty much the same throughout the PC-compatible world: fairly small, so it doesn’t greatly affect performance; unavoidable, so there’s no point in worrying about it anyway; and a nuisance, since it results in fractional cycle counts when using the Zen timer. Just as with the PC, a given code sequence on the AT can execute at varying speeds at different times, as a result of the interaction between the code and the DRAM refresh timing.</p>
<p>There’s nothing much new with DRAM refresh on 80286/80386 computers, then. Be aware of it, but don’t concern yourself overly — DRAM refresh is still an act of God, and there’s not a blessed thing you can do about it.</p>
</section>
<section id="the-display-adapter-cycle-eater-1" class="level3">
<h3>The Display Adapter Cycle-Eater</h3>
<p>And finally we come to the last of the cycle-eaters, the display adapter cycle-eater. There are two ways of looking at this cycle-eater on 80286/80386 computers: 1) it’s much worse than it was on the PC, or, 2) it’s just about the same as it was on the PC.</p>
<p>Either way, the display adapter cycle-eater is extremely bad news on 80286/80386 computers.</p>
<p>The two ways of looking at the display adapter cycle-eater on 80286/80386 computers are actually the same. As you’ll recall from Chapter 4, display adapters offer only a limited number of accesses to display memory during any given period of time. The 8088 is capable of making use of most but not all of those slots with <code class="sourceCode nasm">rep <span class="kw">movsw</span></code>, so the number of memory accesses allowed by a display adapter such as an EGA is reasonably well matched to an 8088’s memory access speed. Granted, access to an EGA slows the 8088 down considerably — but, as we’re about to find out, “considerably” is a relative term. What an EGA does to PC performance is nothing compared to what it does to faster computers.</p>
<p>Under ideal conditions, an 80286 can access memory much, much faster than an 8088. A 10-MHz 80286 is capable of accessing a word of system memory every 0.20 us with <code class="sourceCode nasm">rep <span class="kw">movsw</span></code>, dwarfing the 1 byte every 1.31 us that the 8088 in a PC can manage. However, access to display memory is anything but ideal for an 80286. For one thing, most display adapters are 8-bit devices. (While a few are 16-bit devices, they’re the exception.) One consequence of that is that only 1 byte can be read or written per access to display memory; word-sized accesses to 8-bit devices are automatically split into 2 separate byte-sized accesses by the AT’s bus. Another consequence is that accesses are simply slower; the AT’s bus always inserts 3 wait states on accesses to 8-bit devices, since it must assume that such devices were designed for PCs and may not run reliably at AT speeds.</p>
<p>However, the 8-bit size of most display adapters is but one of the two factors that reduce the speed with which the 80286 can access display memory. Far more cycles are eaten by the inherent memory-access limitations of display adapters — that is, the limited number of display memory accesses that display adapters make available to the 80286. Look at it this way: if <code class="sourceCode nasm">rep <span class="kw">movsw</span></code> on a PC can use more than half of all available accesses to display memory, then how much faster can code running on an 80286 or 80386 possibly run when accessing display memory?</p>
<p>That’s right — less than twice as fast.</p>
<p>In other words, instructions that access display memory won’t run a whole lot faster on ATs and faster computers than they do on PCs. That explains one of the two viewpoints expressed at the beginning of this section: the display adapter cycle-eater is just about the same on high-end computers as it is on the PC, in the sense that it allows instructions that access display memory to run at just about the same speed on all computers.</p>
<p>Of course, the picture is quite a bit different when you compare the performance of instructions that access display memory to the <em>maximum</em> performance of those instructions. Instructions that access display memory receive many more wait states when running on an 80286 than they do on an 8088. Why? While the 80286 is capable of accessing memory much more often than the 8088, we’ve seen that the frequency of access to display memory is determined not by processor speed but by the display adapter. As a result, both processors are actually allowed just about the same maximum number of accesses to display memory in any given time. By definition, then, the 80286 must spend many more cycles waiting than does the 8088.</p>
<p>And that explains the second viewpoint expressed above regarding the display adapter cycle-eater vis-a-vis the 80286 and 80386. The display adapter cycle-eater, as measured in cycles lost to wait states, is indeed much worse on AT-class computers than it is on the PC, and it’s worse still on more powerful computers.</p>
<p>How bad is the display adapter cycle-eater on an AT? Back in Chapter 3, we measured the performance of <code class="sourceCode nasm">rep <span class="kw">movsw</span></code> accessing system memory in a PC and display memory on an EGA installed in a PC. Access to EGA memory proved to be more than twice as slow as access to system memory; <a href="#listing-3-1">Listing 3-1</a>, which accessed EGA memory, ran in 26.06 ms, while <a href="#listing-3-2">Listing 3-2</a>, which accessed system memory, ran in 11.24 ms.</p>
<p>When the same two listings are run on an EGA-equipped 10-MHz AT clone, the results are startling. <a href="#listing-3-2">Listing 3-2</a> accesses system memory in just 1.31 ms, more than eight times faster than on the PC. <a href="#listing-3-1">Listing 3-1</a> accesses EGA memory in 16.12 ms — considerably less than twice as fast as on the PC, and well over ten times as slow as <a href="#listing-3-1">Listing 3-1</a>. <em>The display adapter cycle-eater can slow an AT</em> — <em>or even an 80386 computer</em> — <em>to near-PC speeds when display memory is accessed.</em></p>
<p>I know that’s hard to believe, but the display adapter cycle-eater gives out just so many display memory accesses in a given time, and no more, no matter how fast the processor is. In fact, the faster the processor, the more the display adapter cycle-eater hurts the performance of instructions that access display memory. The display adapter cycle-eater is not only still present in 80286/80386 computers, it’s worse than ever.</p>
<p>What can we do about this new, more virulent form of the display adapter cycle-eater? The workaround is the same as it was on the PC:</p>
<p><em>Access display memory as little as you possibly can.</em></p>
</section>
</section>
<section id="new-instructions-and-features" class="level2">
<h2>New Instructions and Features</h2>
<section id="new-instructions-and-features-the-80286" class="level3">
<h3>New Instructions and Features: The 80286</h3>
<p>The 80286 and 80386 offer a number of new instructions. The 80286 has a relatively small number of instructions that the 8088 lacks, while the 80386 has those instructions and quite a few more, along with new addressing modes and data sizes. We’ll discuss the 80286 and the 80386 separately in this regard.</p>
<p>The 80286 has a number of instructions designed for protected-mode operations. As I’ve said, we’re not going to discuss protected mode in <em>The Zen of Assembly Language</em>; in any case, protected-mode instructions are generally used only by operating systems. (I should mention that the 80286’s protected mode brings with it the ability to address 16 Mb of memory, a considerable improvement over the 8088’s 1 Mb. In real mode, however, programs are still limited to 1 Mb of addressable memory on the 80286. In either mode, each segment is still limited to 64 Kb.)</p>
<p>There are also a handful of 80286-specific real-mode instructions, and they can be quite useful. <code class="sourceCode nasm"><span class="kw">bound</span></code> checks array bounds. <code class="sourceCode nasm"><span class="kw">enter</span></code> and <code class="sourceCode nasm"><span class="kw">leave</span></code> support compact and speedy stack frame construction and removal, ideal for interfacing to high-level languages such as C and Pascal. <code class="sourceCode nasm"><span class="kw">ins</span></code> and <code class="sourceCode nasm"><span class="kw">outs</span></code> are new string instructions that support efficient data transfer between memory and I/O ports. Finally, <code class="sourceCode nasm"><span class="kw">pusha</span></code> and <code class="sourceCode nasm"><span class="kw">popa</span></code> push and pop all eight general-purpose registers.</p>
<p>A couple of old instructions gain new features on the 80286. For one, the 80286 version of <code class="sourceCode nasm"><span class="kw">push</span></code> is capable of pushing a constant on the stack. For another, the 80286 allows all shifts and rotates to be performed for not just 1 bit or the number of bits specified by CL, but for any constant number of bits.</p>
<p>These new instructions are fairly powerful, if not earthshaking. Nonetheless, it would be foolish to use them unless you’re intentionally writing a program that will run only on the 80286 and 80386. That’s because none of the 80286-specific instructions does anything you can’t do reasonably well with some combination of 8088 instructions… and if you do use even one of the 80286-specific instructions, you’ve thrown 8088 compatibility out the window. In other words, you’ll be sacrificing the ability to run on most of the computers in the PC-compatible market in return for a relatively minor improvement in performance and program size.</p>
<p>If you’re programming in protected mode, or if you’ve already decided that you don’t want your programs to run on 8088-based computers, sure, use the 80286-specific instructions. Otherwise, give them a wide berth.</p>
</section>
<section id="new-instructions-and-features-the-80386" class="level3">
<h3>New Instructions and Features: The 80386</h3>
<p>The 80386 is somewhat more complex than the 80286 as regards new features. Once again, we won’t discuss protected mode, which on the 80386 comes with the ability to address up to 4 gigabytes per segment and 64 terabytes in all. In real mode (and in virtual-86 mode, which allows the 80386 to multitask MS-DOS applications, and which is identical to real mode so far as MS-DOS programs are concerned), programs running on the 80386 are still limited to 1 Mb of addressable memory and 64 Kb per segment.</p>
<p>The 80386 has many new instructions, as well as new registers, addressing modes and data sizes that have trickled down from protected mode. Let’s take a quick look at these new real-mode features.</p>
<p>Even in real mode, it’s possible to access many of the 80386’s new and extended registers. Most of these registers are simply 32-bit extensions of the 16-bit registers of the 8088. For example, EAX is a 32-bit register containing AX as its lower 16 bits, EBX is a 32-bit register containing BX as its lower 16 bits, and so on. There are also two new segment registers, FS and GS.</p>
<p>The 80386 also comes with a slew of new real-mode instructions beyond those supported by the 8088 and 80286. These instructions can scan data on a bit-by-bit basis, set the Carry flag to the value of a specified bit, sign-extend or zero-extend data as it’s moved, set a register or memory variable to 1 or 0 on the basis of any of the conditions that can be tested with conditional jumps, and more. What’s more, both old and new instructions support 32-bit operations on the 80386. For example, it’s relatively simple to copy data in chunks of 4 bytes on an 80386, even in real mode, by using the <code class="sourceCode nasm"><span class="kw">movsd</span></code> (“move string double”) instruction, or to negate a 32-bit value with <code class="sourceCode nasm"><span class="kw">neg</span> <span class="kw">eax</span></code>. (That’s a whole lot less complicated than our fancy 32-bit negation code of past chapters, eh?)</p>
<p>Finally, it’s possible in real mode to use the 80386’s new addressing modes, in which <em>any</em> 32-bit general-purpose register can be used to address memory. What’s more, multiplication of memory-addressing registers by 2, 4, or 8 for look-ups in word, doubleword, or quadword tables can be built right into the memory addressing mode. In protected mode, these new addressing modes allow you to address a full 4 gigabytes per segment, but in real mode you’re still limited to 64 Kb, even with 32-bit registers and the new addressing modes. Having shown you these wonders, I’m going to snatch them away. All these features are available only on the 80386; code using them won’t even run on the 80286, let alone the 8088. If you’re going to go to the trouble of using 80386-specific features, thereby eliminating any chance of running on PCs and ATs, you might as well go all the way and write 80386 protected-mode code. That way, you’ll be able to take full advantage of the new addressing modes and larger segments, rather than working with the subset of 80386 features that’s available in real mode.</p>
<p>And 80386 protected mode programming, my friend, is quite a different journey from the one we’ve been taking. While the 80386 in protected mode bears some resemblance to the 8088, the resemblance isn’t all that strong. The protected-mode 80386 is a wonderful processor to program, and a good topic — a <em>terrific</em> topic — for some book to cover in detail… but this is not that book.</p>
<p>To sum up: stick to the 8088’s instruction set, registers, and addressing modes, unless you’re willing to sacrifice completely the ability to run on the bulk of PC-compatible computers. 80286-specific instructions don’t have a big enough payback to compensate for the inability to run on 8088-based computers, while 80386-specific instructions limit your market so sharply that you might as well go to protected mode and get the full benefits of the 80386.</p>
</section>
</section>
<section id="optimization-rules-the-more-things-change" class="level2">
<h2>Optimization Rules: The More Things Change…</h2>
<p>Let’s see what we’ve learned about 80286/80386 optimization. Mostly what we’ve learned is that our familiar PC cycle-eaters still apply, although in somewhat different forms, and that the major optimization rules for the PC hold true on ATs and 80386-based computers. You won’t go wrong on high-end MS-DOS computers if you keep your instructions short, use the registers heavily and avoid memory, don’t branch, and avoid accessing display memory like the plague.</p>
<p>Although we haven’t touched on them, repeated string instructions are still desirable on the 80286 and 80386, since they provide a great deal of functionality per instruction byte and eliminate both the prefetch queue cycle-eater and branching. However, string instructions are not quite so spectacularly superior on the 80286 and 80386 as they are on the 8088, since non-string memory-accessing instructions have been speeded up considerably on the newer processors.</p>
<p>There’s one cycle-eater with new implications on the 80286 and 80386, and that’s the data alignment cycle-eater. From the data alignment cycle-eater we get a new rule: word-align your word-sized variables, and start your subroutines at even addresses. This rule doesn’t hurt 8088 performance or compatibility, improves 80286 and 80386 performance considerably, is easy to implement, and costs relatively few bytes, so it’s worth applying even though it doesn’t improve the performance of 8088 code.</p>
<p>Basically, what we’ve found is that the broad optimization rules for the 8088, plus the word-alignment rule, cover the 80286 and 80386 quite nicely. What <em>that</em> means is that if you optimize for the 8088 and word-align word-sized memory accesses, you’ll get solid performance on all PC-compatible computers. What’s more, it means that if you’re writing code specifically for the 80286 and/or 80386, you already have a good feel for optimizing that code.</p>
<p>In short, what you’ve already learned in <em>The Zen of Assembly Language</em> will serve you well across the entire PC family.</p>
<section id="detailed-optimization" class="level3">
<h3>Detailed Optimization</h3>
<p>While the major 8088 optimization rules hold true on computers built around the 80286 and 80386, many of the instruction-specific optimizations we’ve learned no longer hold, for the execution times of most instructions are quite different on the 80286 and 80386 than on the 8088. We have already seen one such example of the sometimes vast difference between 8088 and 80286/80386 instruction execution times: <code class="sourceCode nasm"><span class="kw">mov</span> [WordVar],<span class="dv">0</span></code>, which has an Execution Unit execution time of 20 cycles on the 8088, has an EU execution time of just 3 cycles on the 80286 and 2 cycles on the 80386.</p>
<p>In fact, the performance of virtually all memory-accessing instructions has been improved enormously on the 80286 and 80386. The key to this improvement is the near elimination of effective address (EA) calculation time. Where an 8088 takes from 5 to 12 cycles to calculate an EA, an 80286 or 80386 usually takes no time whatsoever to perform the calculation. If a base+index+displacement addressing mode, such as <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">ax</span>,[WordArray+<span class="kw">bx</span>+<span class="kw">si</span>]</code>, is used on an 80286 or 80386, 1 cycle is taken to perform the EA calculation, but that’s both the worst case and the only case in which there’s any EA overhead at all.</p>
<p>The elimination of EA calculation time means that the EU execution time of memory-addressing instructions is much closer to the EU execution time of register-only instructions. For instance, on the 8088 <code class="sourceCode nasm"><span class="kw">add</span> [WordVar]<span class="bn">,100h</span></code> is a 31-cycle instruction, while <code class="sourceCode nasm"><span class="kw">add</span> <span class="kw">dx</span><span class="bn">,100h</span></code> is a 4-cycle instruction — a ratio of nearly 8 to 1. By contrast, on the 80286 <code class="sourceCode nasm"><span class="kw">add</span> [WordVar]<span class="bn">,100h</span></code> is a 7-cycle instruction, while <code class="sourceCode nasm"><span class="kw">add</span> <span class="kw">dx</span><span class="bn">,100h</span></code> is a 3-cycle instruction — a ratio of just 2.3 to 1.</p>
<p>It would seem, then, that it’s less necessary to use the registers on the 80286 than it was on the 8088, but that’s simply not the case, for reasons we’ve already seen. The key is this: the 80286 can execute memory-addressing instructions so fast that there’s no spare instruction prefetching time during those instructions, so the prefetch queue runs dry, especially on the AT, with its one-wait-state memory. On the AT, the 6-byte instruction <code class="sourceCode nasm"><span class="kw">add</span> [WordVar]<span class="bn">,100h</span></code> is effectively at least a 15-cycle instruction, because 3 cycles are needed to fetch each of the three instruction words and 6 more cycles are needed to read <code class="sourceCode nasm">WordVar</code> and write the result back to memory.</p>
<p>Granted, the register-only instruction <code class="sourceCode nasm"><span class="kw">add</span> <span class="kw">dx</span><span class="bn">,100h</span></code> also slows down — to 6 cycles — because of instruction prefetching, leaving a ratio of 2.5 to 1. Now, however, let’s look at the performance of the same code on an 8088. The register-only code would run in 16 cycles (4 instruction bytes at 4 cycles per byte), while the memory-accessing code would run in 40 cycles (6 instruction bytes at 4 cycles per byte, plus 2 word-sized memory accesses at 8 cycles per word). That’s a ratio of 2.5 to 1, <em>exactly the same as on the 80286</em>.</p>
<p>This is all theoretical. We put our trust not in theory but in actual performance, so let’s run this code through the Zen timer. On a PC, <a href="#listing-15-4">Listing 15-4</a>, which performs register-only addition, runs in 3.62 ms, while <a href="#listing-15-5">Listing 15-5</a>, which performs addition to a memory variable, runs in 10.05 ms. On a 10-MHz AT clone, <a href="#listing-15-4">Listing 15-4</a> runs in 0.64 ms, while <a href="#listing-15-5">Listing 15-5</a> runs in 1.80 ms. Obviously, the AT is much faster… but the ratio of <a href="#listing-15-5">Listing 15-5</a> to <a href="#listing-15-4">Listing 15-4</a> is virtually identical on both computers, at 2.78 for the PC and 2.81 for the AT. If anything, the register-only form of <code class="sourceCode nasm"><span class="kw">add</span></code> has a slightly <em>larger</em> advantage on the AT than it does on the PC in this case.</p>
<p>Theory confirmed.</p>
<p>What’s going on? Simply this: instruction fetching is controlling overall execution time on <em>both</em> processors. Both the 8088 in a PC and the 80286 in an AT can execute the bytes of the instructions in <a href="#listing-15-4">Listings 15-4</a> and <a href="#listing-15-5">15-5</a> faster than they can be fetched. Since the instructions are exactly the same lengths on both processors, it stands to reason that the ratio of the overall execution times of the instructions should be the same on both processors as well. Instruction length controls execution time, and the instruction lengths are the same — therefore the ratios of the execution times are the same. The 80286 can both fetch and execute instruction bytes faster than the 8088 can, so code executes much faster on the 80286; nonetheless, because the 80286 can also execute those instruction bytes much faster than it can fetch them, overall performance is still largely determined by the size of the instructions.</p>
<p>Is this always the case? No. When the prefetch queue is full, memory-accessing instruction on the 80286 and 80386 are much faster relative to register-only instructions than they are on the 8088. Given the system wait states prevalent on 80286 and 80386 computers, however, the prefetch queue is likely to be empty quite a bit, especially when code consisting of instructions with short Execution Unit execution times is executed. Of course, that’s just the sort of code we’re likely to write when we’re optimizing, so the performance of high-speed code is more likely to be controlled by instruction size than by EU execution time on most 80286 and 80386 computers, just as it is on the PC.</p>
<p>All of which is just a way of saying that faster memory access and EA calculation notwithstanding, it’s just as desirable to keep instructions short and memory accesses to a minimum on the 80286 as it is on the 8088. And we know full well that the way to do that is to use the registers as heavily as possible, use string instructions, use short forms of instructions, and the like.</p>
<p>The more things change, the more they remain the same…</p>
</section>
<section id="dont-sweat-the-details" class="level3">
<h3>Don’t Sweat the Details</h3>
<p>We’ve just seen how a major difference between the 80286 and 8088 — the virtual elimination of effective address calculation time — leaves the major optimization rules pretty much unchanged. While there are many details about 80286 and 80386 code performance that differ greatly from the 8088 (for example, the 80386’s barrel shifter allows you to shift or rotate a value <em>any</em> number of bits in just 3 cycles, and <code class="sourceCode nasm"><span class="kw">mul</span></code> and <code class="sourceCode nasm"><span class="kw">div</span></code> are much, much faster on the newer processors), those details aren’t worth worrying about unless you’re abandoning the 8088 entirely. Even then, the many variations in memory architecture and performance between various 80286 and 80386 computers make it impractical to focus too closely on detailed 80286/80386 optimizations.</p>
<p>In short, there’s little point in even considering 80286/80386 optimizations when you’re writing code that will also run on the 8088. If the 8088 isn’t one of the target processors for a particular piece of code, you can use Intel’s publications, which list cycle times for both real and protected mode, and the Zen timer to optimize for the 80286 and/or 80386. (You will probably have to modify the Zen timer before you can run it under a protected-mode operating system; it was designed for use under MS-DOS in real mode and has only been tested in that mode. Some operating systems provide built-in high-precision timing services that could be used in place of the Zen timer.)</p>
<p>Always bear in mind, however, that your optimization control is not so fine on 80286/80386 computers as it is on the PC, unless you can be sure that your code will run only on a particular processor (either 80286 or 80386, but not both) with a single, well-understood memory architecture. As 80286 and 80386 machines of various designs proliferate, that condition becomes increasingly difficult to fulfill.</p>
<p>On balance, my final word on 80286/80386 real-mode optimization in this: <em>with the sole exception of word-aligning your word-sized variables and subroutines, optimize only for the 8088</em>. You’ll get the best possible performance on the slowest computer — the PC — and excellent performance across the entire spectrum of PC-compatible computers.</p>
<p>When you get right down to it, isn’t that everything you could ask for from a real-mode program?</p>
</section>
</section>
<section id="popf-and-the-80286" class="level2">
<h2><code>popf</code> and the 80286</h2>
<p>We’ve one final 80286-related item to discuss: the hardware malfunction of <code class="sourceCode nasm"><span class="kw">popf</span></code> under certain circumstances on the 80286.</p>
<p>The problem is this: sometimes <code class="sourceCode nasm"><span class="kw">popf</span></code> permits interrupts to occur when interrupts are initially off and the setting popped into the Interrupt flag from the stack keeps interrupts off. In other words, an interrupt can happen even though the Interrupt flag is never set to 1. (For further details, see “Chips in Transition,” <em>PC Tech Journal</em>, April, 1986.)</p>
<p>Now, I don’t want to blow this particular bug out of proportion. It only causes problems in code that cannot tolerate interrupts under any circumstances, and that’s a rare sort of code, especially in user programs. However, some code really does need to have interrupts absolutely disabled, with no chance of an interrupt sneaking through. For example, a critical portion of a disk BIOS might need to retrieve data from the disk controller the instant it becomes available; even a few hundred microseconds of delay could result in a sector’s worth of data misread. In this case, one misplaced interrupt during a <code class="sourceCode nasm"><span class="kw">popf</span></code> could result in a trashed hard disk if that interrupt occurs while the disk BIOS is reading a sector of the File Allocation Table.</p>
<p>There is a workaround for the <code class="sourceCode nasm"><span class="kw">popf</span></code> bug. While the workaround is easy to use, it’s considerably slower than <code class="sourceCode nasm"><span class="kw">popf</span></code>, and costs a few bytes as well, so you won’t want to use it in code that can tolerate interrupts. On the other hand, in code that truly cannot be interrupted, you should view those extra cycles and bytes as cheap insurance against mysterious and erratic program crashes.</p>
<p>One obvious reason to discuss the <code class="sourceCode nasm"><span class="kw">popf</span></code> workaround is that it’s useful. Another reason is that the workaround is an excellent example of the Zen of assembler, in that there’s a well-defined goal to be achieved but no obvious way to do so. The goal is to reproduce the functionality of the <code class="sourceCode nasm"><span class="kw">popf</span></code> instruction without using <code class="sourceCode nasm"><span class="kw">popf</span></code>, and the place to start is by asking exactly what <code class="sourceCode nasm"><span class="kw">popf</span></code> does.</p>
<p>All <code class="sourceCode nasm"><span class="kw">popf</span></code> does is pop the word on top of the stack into the FLAGS register, as shown in Figure 15.4.</p>
<figure>
<img src="images/fig15.4RT.png" />
</figure>
<p>How can we do that without <code class="sourceCode nasm"><span class="kw">popf</span></code>? Of course, the 80286’s designers intended us to use <code class="sourceCode nasm"><span class="kw">popf</span></code> for this purpose, and didn’t intentionally provide any alternative approach, so we’ll have to devise an alternative approach of our own. To do that, we’ll have to search for instructions that contain some of the same functionality as <code class="sourceCode nasm"><span class="kw">popf</span></code>, in the hope that one of those instructions can be used in some way to replace <code class="sourceCode nasm"><span class="kw">popf</span></code>.</p>
<p>Well, there’s only one instruction other than <code class="sourceCode nasm"><span class="kw">popf</span></code> that loads the FLAGS register directly from the stack, and that’s <code class="sourceCode nasm"><span class="kw">iret</span></code>, which loads the FLAGS register from the stack as it branches, as shown in Figure 15.5.</p>
<figure>
<img src="images/fig15.5RT.png" />
</figure>
<p><code class="sourceCode nasm"><span class="kw">iret</span></code> has no known bugs of the sort that plagues <code class="sourceCode nasm"><span class="kw">popf</span></code>, so it’s certainly a candidate to replace <code class="sourceCode nasm"><span class="kw">popf</span></code> in non-interruptible applications. Unfortunately, <code class="sourceCode nasm"><span class="kw">iret</span></code> loads the FLAGS register with the <em>third</em> word down on the stack, not the word on top of the stack, as is the case with <code class="sourceCode nasm"><span class="kw">popf</span></code>; the far return address that <code class="sourceCode nasm"><span class="kw">iret</span></code> pops into CS:IP lies between the top of the stack and the word popped into the FLAGS register.</p>
<p>Obviously, the segment:offset that <code class="sourceCode nasm"><span class="kw">iret</span></code> expects to find on the stack above the pushed flags isn’t present when the stack is set up for <code class="sourceCode nasm"><span class="kw">popf</span></code>, so we’ll have to adjust the stack a bit before we can substitute <code class="sourceCode nasm"><span class="kw">iret</span></code> for <code class="sourceCode nasm"><span class="kw">popf</span></code>. What we’ll have to do is push the segment:offset of the instruction after our workaround code onto the stack right above the pushed flags. <code class="sourceCode nasm"><span class="kw">iret</span></code> will then branch to that address and pop the flags, ending up at the instruction after the workaround code with the flags popped. That’s just the result that would have occurred had we executed <code class="sourceCode nasm"><span class="kw">popf</span></code> — with the bonus that no interrupts can accidentally occur when the Interrupt flag is 0 both before and after the pop.</p>
<p>How can we push the segment:offset of the next instruction? Well, think back to our discussion in the last chapter of finding the offset of the next instruction by performing a near call to that instruction. We can do something similar here, but in this case we need a far call, since <code class="sourceCode nasm"><span class="kw">iret</span></code> requires both a segment and an offset. We’ll also branch backward so that the address pushed on the stack will point to the instruction we want to continue with. The code works out like this:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    <span class="kw">jmp</span>   <span class="dt">short</span> popfskip
<span class="fu">popfiret:</span>
    <span class="kw">iret</span>                    <span class="co">;branches to the instruction after the</span>
                            <span class="co">; call, popping the word below the address</span>
                            <span class="co">; pushed by CALL into the FLAGS register</span>
<span class="fu">popfskip:</span>
    <span class="kw">call</span>  far <span class="dt">ptr</span> popfiret
                            <span class="co">;pushes the segment:offset of the next</span>
                            <span class="co">; instruction on the stack just above</span>
                            <span class="co">; the flags word, setting things up so</span>
                            <span class="co">; that IRET will branch to the next</span>
                            <span class="co">; instruction and pop the flags</span>
<span class="co">; When execution reaches the instruction following this comment,</span>
<span class="co">; the word that was on top of the stack when JMP SHORT POPFSKIP</span>
<span class="co">; was reached has been popped into the FLAGS register, just as</span>
<span class="co">; if a POPF instruction had been executed.</span></code></pre>
<p>The operation of this code is illustrated in Figure 15.6.</p>
<figure>
<img src="images/fig15.6RT.png" />
</figure>
<p>The <code class="sourceCode nasm"><span class="kw">popf</span></code> workaround can best be implemented as a macro; we can also emulate a far call by pushing CS and performing a near call, thereby shrinking the workaround code by 1 byte:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">EMULATE_POPF  macro
    local popfskip, popfiret
    <span class="kw">jmp</span>   <span class="dt">short</span> popfskip
<span class="fu">popfiret:</span>
    <span class="kw">iret</span>
<span class="fu">popfskip:</span>
    <span class="kw">push</span>  <span class="kw">cs</span>
    <span class="kw">call</span>  popfiret
    endm</code></pre>
<p>(By the way, the flags can be popped much more quickly if you’re willing to alter a register in the process. For example, the following macro emulates <code class="sourceCode nasm"><span class="kw">popf</span></code> with just one branch, but wipes out AX:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">EMULATE_POPF_TRASH_AX   macro
    <span class="kw">push</span>  <span class="kw">cs</span>
    <span class="kw">mov</span>   <span class="kw">ax</span>,offset <span class="dv">$</span>+<span class="dv">5</span>
    <span class="kw">push</span>  <span class="kw">ax</span>
    <span class="kw">iret</span>
    endm</code></pre>
<p>It’s not a perfect substitute for <code class="sourceCode nasm"><span class="kw">popf</span></code>, since <code class="sourceCode nasm"><span class="kw">popf</span></code> doesn’t alter any registers, but it’s faster and shorter than <code class="sourceCode nasm">EMULATE_POPF</code> when you can spare the register. If you’re using 286-specific instructions, you can use:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">    .<span class="dv">286</span>
          :
EMULATE_POPF  macro
    <span class="kw">push</span>  <span class="kw">cs</span>
    <span class="kw">push</span>  offset <span class="dv">$</span>+<span class="dv">4</span>
    <span class="kw">iret</span>
    endm</code></pre>
<p>which is shorter still, alters no registers, and branches just once. (Of course, this version of <code class="sourceCode nasm">EMULATE_POPF</code> won’t work on an 8088.)</p>
<p>The standard version of <code class="sourceCode nasm">EMULATE_POPF</code> is 6 bytes longer than <code class="sourceCode nasm"><span class="kw">popf</span></code> and much slower, as you’d expect given that it involves three branches. Anyone in their right mind would prefer <code class="sourceCode nasm"><span class="kw">popf</span></code> to a larger, slower, three-branch macro — given a choice. In non-interruptible code, however, there’s no choice; the safer — if slower — approach is the best. (Having people associate your programs with crashed computers is <em>not</em> a desirable situation, no matter how unfair the circumstances under which it occurs.)</p>
<p>Anyway, the overall inferiority of <code class="sourceCode nasm">EMULATE_POPF</code> is almost never an issue, because <code class="sourceCode nasm">EMULATE_POPF</code> is unlikely to be used either often or in situations where performance matters. <code class="sourceCode nasm"><span class="kw">popf</span></code> is neither a frequently-used instruction nor an instruction that’s often used in time-critical code; as we found in Chapter 8, <code class="sourceCode nasm"><span class="kw">lahf</span></code>/<code class="sourceCode nasm"><span class="kw">sahf</span></code> is superior to <code class="sourceCode nasm"><span class="kw">pushf</span></code>/<code class="sourceCode nasm"><span class="kw">popf</span></code> for most applications. Besides, all this only matters when the flags need to be popped in non-interruptible code, a situation that rarely arises.</p>
<p>And now you know the nature of and the workaround for the <code class="sourceCode nasm"><span class="kw">popf</span></code> bug. Whether you ever need the workaround or not, it’s a neatly packaged example of the tremendous flexibility of the 8088’s instruction set… and of the value of the Zen of assembler.</p>
</section>
<section id="coprocessors-and-peripherals" class="level2">
<h2>Coprocessors and Peripherals</h2>
<p>Up to this point, we’ve concentrated on the various processors in the 8088 family. There are also a number of coprocessors in use in the PC world, and they can affect the performance of some programs every bit as much as processors can. Unfortunately, while processors are standard equipment (I should hope every computer comes with one!) not a single coprocessor is standard. Every PC-compatible computer can execute the 8088 instruction <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">al</span>,<span class="dv">1</span></code>, but the same cannot be said of the 8087 numeric coprocessor instruction <code class="sourceCode nasm"><span class="kw">fld</span> [MemVar]</code>, to say nothing of instructions for the coprocessors on a variety of graphics, sound, and other adapters available for the PC. Then, too, there are many PC peripherals that offer considerable functionality without being true coprocessors — VGAs and serial adapters, to name just two — but not a one of those is standard either.</p>
<p>Coprocessors and peripherals are just about as complex as processors, and require similarly detailed explanations of programming techniques. However, because of the lack of standards, you’ll only want to learn about a given coprocessor or peripheral if it affects your work. By contrast, you had no choice but to learn about the 8088, since it affects everything you do on a PC.</p>
<p>If you’re interested in programming a particular coprocessor or peripheral, you can always find a book, an article, or at least a data sheet that addresses that interest. You may not find the quality or quantity of reference material you’d like, especially for the more esoteric coprocessors, but there is surely enough information available to get you started; otherwise no one else would be able to program that coprocessor or peripheral either. (Remember, as an advanced assembler programmer, you’re now among the programming elite. There just aren’t very many people who understand as much about microcomputer programming as you do. That may be a strange thought, but roll it around in your head for a while — I suspect you’ll get to like it.)</p>
<p>Once you’ve gotten started with a given coprocessor or adapter, you can put the Zen approach to work in a new context. Gain a thorough understanding of the resources and capabilities the new environment has to offer, and learn to think in terms of matching those capabilities to your applications.</p>
<section id="a-brief-note-on-the-8087" class="level3">
<h3>A Brief Note on the 8087</h3>
<p>The 8087, 80287 and 80387 are the most common and important PC coprocessors. These numeric coprocessors improve the performance of floating-point arithmetic far beyond the speeds possible with an 8088 alone, performing operations such as floating-point addition, subtraction, multiplication, division, absolute value, comparison, and square root. The 80287 is similar to the 8087, but with protected mode support; the 80387 adds some new functions, including sine and cosine. (For the remainder of this section I’ll use the term “8087” to cover all 8087-family numeric coprocessors.)</p>
<p>While the 8087 is widely used, and is frequently used by high-level language programs, it is rarely programmed directly in assembler. This is true partly because floating-point arithmetic is relatively slow, even with an 8087, so the cycle savings achievable via assembler are relatively small as a percentage of overall execution time. Also, 8087 instructions are so specialized that they generally offer less rich optimization opportunities than do 8088 instructions.</p>
<p>Given the specialized nature of 8087 assembler programming, and given that 8087 programming is largely a separate topic from 8088 programming (although the processors do have their common points, such as addressing modes), I’m not going to tackle the 8087 in this book. I will offer one general tip, however:</p>
<p><em>Keep your arithmetic variables in the 8087’s data registers as much as you possibly can.</em> (There are eight 80-bit data registers, organized as an internal stack.) “Keep it in the registers” is a rule we’ve become familiar with on the 8088, and it will stand us in equally good stead on the 8087.</p>
<p>Why? Well, the 8087 works with an internal 10-byte format, rather than the 2-, 4-, and 8-byte integer and floating-point formats we’re familiar with. Whenever an 8087 instruction loads data from or stores data to a memory variable that’s in a 2-, 4-, or 8-byte format, the 8087 must convert the data format accordingly… and it takes the 8087 dozens of cycles to perform those conversions. Even apart from the conversion time, it takes a number of cycles just to copy 2 to 10 bytes to or from memory.</p>
<p>For example, it takes the 8087 between 51 and 97 cycles (including effective address calculation time and the 4-cycle-per-word 8-bit bus penalty) just to push a floating-point value from memory onto the 8087’s data register stack. By contrast, it takes just 17 to 22 cycles to push a value from an internal register onto the data register stack. Ideally, the value you need will have been left on top of the 8087 register stack as the result of the last operation, in which case no load time at all is required.</p>
<p>Intensive use of the 8087’s data registers is one area in which assembler code can substantially outperform high-level language code. High-level languages tend to use the 8087 for only one operation — or, at most, one high-level language statement — at a time, loading the data registers from scratch for each operation. Most high-level languages load the operands for each operation into the 8087’s data registers, perform the operation, and store the result back to memory… then start the whole process over again for the next operation, even if the two operations are related.</p>
<p>What you can do in assembler, of course, is use the 8087’s data registers much as you’ve learned to use the 8088’s general-purpose registers: load often-used values into the data registers, keep results around if you’ll need them later, and keep intermediate results in the data registers rather than storing them to memory. Also, remember that you often have the option of either popping or not popping source operands from the top of the stack, and that data registers other than ST(0) can often serve as destination operands.</p>
<p>In short, the 8087 has both a generous set of data registers and considerable flexibility in how those registers can be used. Take full advantage of those resources when you write 8087 code.</p>
<p>Before we go, one final item about the 8087. The 8087 is a true coprocessor, fully capable of executing instructions in parallel with the 8088. In other words, the 8088 can continue fetching and executing instructions while the 8087 is processing one of its lengthy instructions. While that makes for excellent performance, problems can arise if a second 8087 instruction is fetched and started before the first 8087 instruction has finished. To avoid such problems, MASM automatically inserts a <code class="sourceCode nasm"><span class="kw">wait</span></code> instruction before each 8087 instruction. <code class="sourceCode nasm"><span class="kw">wait</span></code> simply tells the 8088 to wait until the 8087 has finished its current instruction before continuing. In short, MASM neatly and invisibly avoids one sort of potential 8087 synchronization problem.</p>
<p>There’s a second sort of potential 8087 synchronization problem, however, and this one you must guard against, for it isn’t taken care of by MASM: instructions accessing memory out of sequence. The 8088 is fully capable of executing new instructions while a lengthy 8087 instruction that precedes those 8088 instructions executes. One of those later 8088 instructions can, for example, easily read a memory location before the 8087 instruction writes to it. In other words, given an 8087 instruction that accesses a memory variable, it’s possible for an 8088 instruction that follows that 8087 instruction to access that memory variable <em>before</em> the 8087 instruction does.</p>
<p>Clearly, serious problems can arise if instructions access memory out of sequence. To avoid such problems, you should explicitly place a <code class="sourceCode nasm"><span class="kw">wait</span></code> instruction between any 8087 instruction that accesses a memory variable and any following 8088 instructions that could possibly access that same variable.</p>
<p>That doesn’t by any stretch of the imagination mean that you should put <code class="sourceCode nasm"><span class="kw">wait</span></code> after all of your 8087 instructions. On the contrary, the rule is that you should use <code class="sourceCode nasm"><span class="kw">wait</span></code> only when there’s the potential for out-of-sequence 8087 and 8088 memory accesses, and then only immediately before the instructions during which the conflict might arise. The rest of the time, you can boost performance by omitting <code class="sourceCode nasm"><span class="kw">wait</span></code> and letting the 8088 and 8087 coprocess.</p>
</section>
<section id="conclusion-2" class="level3">
<h3>Conclusion</h3>
<p>Despite all the other processors, coprocessors, and peripherals in the PC family, the 8088 is still the best place to focus your optimization efforts. If your code runs well on an 8088, it will run well on every 8086-family processor well into the twenty-first century, and even on a number of computers built around other processors as well. Good performance and the largest possible market — what more could you want?</p>
<p>That’s enough of being practical. No one programs extensively in assembler just because it’s useful; also required is a certain fondness for the sorts of puzzles assembler programming presents. For that sort of programmer, there’s nothing better than the weird but wonderful 8088. Admit it — strange as 8088 assembler programming is…</p>
<p>…isn’t it <em>fun</em>?</p>
</section>
</section>
</section>
<section id="chapter-16-onward-to-the-flexible-mind" class="level1">
<h1>Chapter 16: Onward to the Flexible Mind</h1>
<p>And so we come to the end of our journey through knowledge. More precisely, we’ve come to the end of that part of <em>The Zen of Assembly Language</em> that’s dedicated to knowledge, for no matter how long you or I continue to program the 8088, there will always be more to learn about this surprising processor.</p>
<p>If The Zen of assembler were merely a matter of instructions and cycle times, I would spend a few pages marvelling at the wonders we’ve seen, then congratulate you on arriving at a mastery of assembler and bid you farewell. I won’t do that, though, for in truth we’ve merely arrived at a resting place from whence our journey will continue anew in Volume II of <em>The Zen of Assembly Language</em>. There are marvels aplenty to come, so we’ll just catch our breath, take a brief look back to see how far we’ve come… and then it’s on to the flexible mind.</p>
<p>The flexible mind notwithstanding, congratulations are clearly in order <em>right now</em>. You’ve mastered a great deal — in fact, you’ve absorbed just about as much knowledge about assembler as any mortal could in so short a time. You’ve undoubtedly learned much more than you realize just yet; only with experience will everything you’ve seen in this volume sink in fully.</p>
<p>As important as the amount you’ve learned is the nature of your knowledge. We haven’t just thrown together a collection of unrelated facts in this volume; we’ve divined the fundamental nature and basic optimization rules of the PC. We’ve explored the architectures of the PC and the 8088, and we’ve seen how those underlying factors greatly influence the performance of all assembler code — and, by extension, the performance of all code that runs on the PC. We’ve learned which members of the instruction set are best suited to various tasks, we’ve come across unexpected talents in many instructions, and we’ve learned to view instructions in light of what they <em>can</em> do, not what they were designed to do. Best of all, we’ve learned to use the Zen timer to check our assumptions and to help us continue to learn and hone our skills.</p>
<p>What all this amounts to is a truly excellent understanding of instruction performance on the PC. That’s important — critically important — but it’s not the whole picture. The knowledge we’ve acquired is merely the foundation for the flexible mind, which enables us to transform task specifications into superior assembler code. In turn, application implementations — whole programs — are built upon the flexible mind. So, while we’ve built a strong foundation, we’ve a ways yet to go in completing our mastery of the Zen of assembler.</p>
<p>The flexible mind and implementation are what Volume II of <em>The Zen of Assembly Language</em> is all about. Volume II develops the concept of the flexible mind from the bottom up, starting at the level of implementing the most efficient code for a small, well-defined task, continuing on through algorithm implementation, and extending to designing custom assembler-based mini-languages tailored to various applications. We’ll learn how to search and sort data quickly, how to squeeze every cycle out of a line-drawing routine, how to let data replace code (with tremendous program-size benefits), and how to do animation. The emphasis every step of the way will be on outperforming standard techniques by using our new knowledge in innovative ways to create the best possible 8088 code for each task.</p>
<p>Finally, we’ll put everything we’ve learned together by designing and implementing an animation application. The PC isn’t renowned as a game machine (to put it mildly!), but by the time we’re through, I promise you won’t be able to tell the difference between the graphics on your PC and those in an arcade. The key, of course, is the flexible mind, the ability to bring together the needs of the application and the capabilities of the PC -with often-spectacular results.</p>
<p>So, while we’ve gone a mighty long way toward mastering the Zen of assembler, we haven’t arrived yet. That’s all to the good, though. Until now, interesting as our explorations have been, we’ve basically been doing grunt work — learning cycle times and the like. What’s coming up next is the <em>really</em> fun stuff — taking what we’ve learned and using that knowledge to create the wondrous tasks and applications that are possible only with the very best assembler code.</p>
<p>In short, in Volume II we’ll experience the full spectrum of the Zen of assembler, from the details that we now know so well to the magnificent applications that make it all worthwhile.</p>
<section id="a-taste-of-what-youve-learned" class="level2">
<h2>A Taste of What You’ve Learned</h2>
<p>Before we leave Volume I, I’d like to give you a taste of both what’s to come and what you already know. Why do you need to see what you already know? The answer is that you’ve surely learned much more than you realize right now. The example we’ll look at involves strong elements of the flexible mind, and what we’ll find is that there’s no neat dividing line between knowledge and the flexible mind… and that we have already ventured much farther across the fuzzy boundary between the two than you’d ever imagine.</p>
<p>We’ll also see that the flexible mind involves knowledge and intuition — but no deep dark mysteries. Knowledge you have in profusion, and, as you’ll see, your intuition is growing by leaps and bounds. (Try to stay one step ahead of me as we optimize the following routine. I suspect you’ll be surprised at how easy it is.) I’m presenting this last example precisely because I’d like you to see how well you already understand the flexible mind.</p>
<p>On to our final example…</p>
</section>
<section id="zenning" class="level2">
<h2>Zenning</h2>
<p>In Jeff Duntemann’s excellent book <em>Complete Turbo Pascal, Third Edition</em> (published by Scott, Foresman and Company), there’s a small assembler subroutine that’s designed to be called from a Turbo Pascal program in order to fill the screen or a system-memory screen buffer with a specified character/attribute pair in text mode. This subroutine involves only 21 instructions and works perfectly well; nonetheless, with what we know we can compact the subroutine tremendously, and speed it up a bit as well. To coin a verb, we can “Zen” this already-tight assembler code to an astonishing degree. In the process, I hope you’ll get a feel for how advanced your assembler skills have become.</p>
<p>The code is as follows (the code is Jeff’s, with many letters converted to lowercase in order to match the style of <em>Zen of Assembly Language</em>, but the comments are mine):</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">OnStack   <span class="kw">struc</span>       <span class="co">;data that&#39;s stored on the stack after PUSH BP</span>
OldBP     <span class="dt">dw</span>      ?   <span class="co">;caller&#39;s BP</span>
RetAddr   <span class="dt">dw</span>      ?   <span class="co">;return address</span>
Filler    <span class="dt">dw</span>      ?   <span class="co">;character to fill the buffer with</span>
Attrib    <span class="dt">dw</span>      ?   <span class="co">;attribute to fill the buffer with</span>
BufSize   <span class="dt">dw</span>      ?   <span class="co">;number of character/attribute pairs to fill</span>
BufOfs    <span class="dt">dw</span>      ?   <span class="co">;buffer offset</span>
BufSeg    <span class="dt">dw</span>      ?   <span class="co">;buffer segment</span>
EndMrk    <span class="dt">db</span>      ?   <span class="co">;marker for the end of the stack frame</span>
OnStack   ends
<span class="co">;</span>
ClearS    proc    near
    <span class="kw">push</span>  <span class="kw">bp</span>                        <span class="co">;save caller&#39;s BP</span>
    <span class="kw">mov</span>   <span class="kw">bp</span>,<span class="kw">sp</span>                     <span class="co">;point to stack frame</span>
    <span class="kw">cmp</span>   <span class="dt">word</span> <span class="dt">ptr</span> [<span class="kw">bp</span>].BufSeg,<span class="dv">0</span>    <span class="co">;skip the fill if a null</span>
    <span class="kw">jne</span>   Start                     <span class="co">; pointer is passed</span>
    <span class="kw">cmp</span>   <span class="dt">word</span> <span class="dt">ptr</span> [<span class="kw">bp</span>].BufOfs,<span class="dv">0</span>
    <span class="kw">je</span>    Bye
<span class="fu">Start:</span> <span class="kw">cld</span>                          <span class="co">;make STOSW count up</span>
    <span class="kw">mov</span>   <span class="kw">ax</span>,[<span class="kw">bp</span>].Attrib            <span class="co">;load AX with attribute parameter</span>
    <span class="kw">and</span>   <span class="kw">ax</span><span class="bn">,0ff00h                 </span><span class="co">;prepare for merging with fill char</span>
    <span class="kw">mov</span>   <span class="kw">bx</span>,[<span class="kw">bp</span>].Filler            <span class="co">;load BX with fill char</span>
    <span class="kw">and</span>   <span class="kw">bx</span><span class="bn">,0ffh                   </span><span class="co">;prepare for merging with attribute</span>
    <span class="kw">or</span>    <span class="kw">ax</span>,<span class="kw">bx</span>                     <span class="co">;combine attribute and fill char</span>
    <span class="kw">mov</span>   <span class="kw">bx</span>,[<span class="kw">bp</span>].BufOfs            <span class="co">;load DI with target buffer offset</span>
    <span class="kw">mov</span>   <span class="kw">di</span>,<span class="kw">bx</span>
    <span class="kw">mov</span>   <span class="kw">bx</span>,[<span class="kw">bp</span>].BufSeg            <span class="co">;load ES with target buffer segment</span>
    <span class="kw">mov</span>   <span class="kw">es</span>,<span class="kw">bx</span>
    <span class="kw">mov</span>   <span class="kw">cx</span>,[<span class="kw">bp</span>].BufSize           <span class="co">;load CX with buffer size</span>
    rep   <span class="kw">stosw</span>                     <span class="co">;fill the buffer</span>
<span class="fu">Bye:</span> <span class="kw">mov</span>  <span class="kw">sp</span>,<span class="kw">bp</span>                     <span class="co">;restore original stack pointer</span>
    <span class="kw">pop</span>   <span class="kw">bp</span>                        <span class="co">; and caller&#39;s BP</span>
    <span class="kw">ret</span>   EndMrk-RetAddr<span class="dv">-2</span>          <span class="co">;return, clearing the parms from the stack</span>
ClearS    endp</code></pre>
<p>The first thing you’ll notice about the above code is that <code class="sourceCode nasm">ClearS</code> uses a <code class="sourceCode nasm">rep <span class="kw">stosw</span></code> instruction. That means that we’re not going to improve performance by any great amount, no matter how clever we are. While we can eliminate some cycles, the bulk of the work in <code class="sourceCode nasm">ClearS</code> is done by that one repeated string instruction, and there’s no way to improve on that.</p>
<p>Does that mean that the above code is as good as it can be? Hardly. While the speed of <code class="sourceCode nasm">ClearS</code> is very good, there’s another side to the optimization equation: size. The whole of <code class="sourceCode nasm">ClearS</code> is 52 bytes long as it stands — but, as we’ll see, that size is hardly graven in stone.</p>
<p>Where do we begin with <code class="sourceCode nasm">ClearS</code>? For starters, there’s an instruction in there that serves no earthly purpose — <code class="sourceCode nasm"><span class="kw">mov</span> <span class="kw">sp</span>,<span class="kw">bp</span></code>. SP is guaranteed to be equal to BP at that point anyway, so why reload it with the same value? Removing that instruction saves us 2 bytes.</p>
<p>Well, that was certainly easy enough! We’re not going to find any more totally non-functional instructions in <code class="sourceCode nasm">ClearS</code>, however, so let’s get on to some serious optimizing. We’ll look first for cases where we know of better instructions for particular tasks than those that were chosen. For example, there’s no need to load any register, whether segment or general-purpose, through BX; we can eliminate two instructions by simply loading ES and DI directly:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">ClearS    proc  near
    <span class="kw">push</span>  <span class="kw">bp</span>                      <span class="co">;save caller&#39;s BP</span>
    <span class="kw">mov</span>   <span class="kw">bp</span>,<span class="kw">sp</span>                   <span class="co">;point to stack frame</span>
    <span class="kw">cmp</span>   <span class="dt">word</span> <span class="dt">ptr</span> [<span class="kw">bp</span>].BufSeg,<span class="dv">0</span>  <span class="co">;skip the fill if a null</span>
    <span class="kw">jne</span>   Start                   <span class="co">; pointer is passed</span>
    <span class="kw">cmp</span>   <span class="dt">word</span> <span class="dt">ptr</span> [<span class="kw">bp</span>].BufOfs,<span class="dv">0</span>
    <span class="kw">je</span>    Bye
<span class="fu">Start:</span> <span class="kw">cld</span>                        <span class="co">;make STOSW count up</span>
    <span class="kw">mov</span>   <span class="kw">ax</span>,[<span class="kw">bp</span>].Attrib          <span class="co">;load AX with attribute parameter</span>
    <span class="kw">and</span>   <span class="kw">ax</span><span class="bn">,0ff00h               </span><span class="co">;prepare for merging with fill char</span>
    <span class="kw">mov</span>   <span class="kw">bx</span>,[<span class="kw">bp</span>].Filler          <span class="co">;load BX with fill char</span>
    <span class="kw">and</span>   <span class="kw">bx</span><span class="bn">,0ffh                 </span><span class="co">;prepare for merging with attribute</span>
    <span class="kw">or</span>    <span class="kw">ax</span>,<span class="kw">bx</span>                   <span class="co">;combine attribute and fill char</span>
    <span class="kw">mov</span>   <span class="kw">di</span>,[<span class="kw">bp</span>].BufOfs          <span class="co">;load DI with target buffer offset</span>
    <span class="kw">mov</span>   <span class="kw">es</span>,[<span class="kw">bp</span>].BufSeg          <span class="co">;load ES with target buffer segment</span>
    <span class="kw">mov</span>   <span class="kw">cx</span>,[<span class="kw">bp</span>].BufSize         <span class="co">;load CX with buffer size</span>
    rep   <span class="kw">stosw</span>                   <span class="co">;fill the buffer</span>
<span class="fu">Bye:</span>
    <span class="kw">pop</span>   <span class="kw">bp</span>                      <span class="co">;restore caller&#39;s BP</span>
    <span class="kw">ret</span>   EndMrk-RetAddr<span class="dv">-2</span>        <span class="co">;return, clearing the parms from the stack</span>
ClearS    endp</code></pre>
<p>(The <code class="sourceCode nasm">OnStack</code> structure definition doesn’t change in any of our examples, so I’m not going clutter up this chapter by reproducing it for each new version of <code class="sourceCode nasm">ClearS</code>.)</p>
<p>Okay, loading ES and DI directly saves another 4 bytes. We’ve squeezed a total of 6 bytes — about 11% — out of <code class="sourceCode nasm">ClearS</code>. What next?</p>
<p>Well, <code class="sourceCode nasm"><span class="kw">les</span></code> would serve better than two <code class="sourceCode nasm"><span class="kw">mov</span></code> instructions for loading ES and DI:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">ClearS    proc  near
    <span class="kw">push</span>  <span class="kw">bp</span>                        <span class="co">;save caller&#39;s BP</span>
    <span class="kw">mov</span>   <span class="kw">bp</span>,<span class="kw">sp</span>                     <span class="co">;point to stack frame</span>
    <span class="kw">cmp</span>   <span class="dt">word</span> <span class="dt">ptr</span> [<span class="kw">bp</span>].BufSeg,<span class="dv">0</span>    <span class="co">;skip the fill if a null</span>
    <span class="kw">jne</span>   Start                     <span class="co">; pointer is passed</span>
    <span class="kw">cmp</span>   <span class="dt">word</span> <span class="dt">ptr</span> [<span class="kw">bp</span>].BufOfs,<span class="dv">0</span>
    <span class="kw">je</span>    Bye
<span class="fu">Start:</span> <span class="kw">cld</span>                          <span class="co">;make STOSW count up</span>
    <span class="kw">mov</span>   <span class="kw">ax</span>,[<span class="kw">bp</span>].Attrib            <span class="co">;load AX with attribute parameter</span>
    <span class="kw">and</span>   <span class="kw">ax</span><span class="bn">,0ff00h                 </span><span class="co">;prepare for merging with fill char</span>
    <span class="kw">mov</span>   <span class="kw">bx</span>,[<span class="kw">bp</span>].Filler            <span class="co">;load BX with fill char</span>
    <span class="kw">and</span>   <span class="kw">bx</span><span class="bn">,0ffh                   </span><span class="co">;prepare for merging with attribute</span>
    <span class="kw">or</span>    <span class="kw">ax</span>,<span class="kw">bx</span>                     <span class="co">;combine attribute and fill char</span>
    <span class="kw">les</span>   <span class="kw">di</span>,<span class="dt">dword</span> <span class="dt">ptr</span> [<span class="kw">bp</span>].BufOfs  <span class="co">;load ES:DI with target buffer segment:offset</span>
    <span class="kw">mov</span>   <span class="kw">cx</span>,[<span class="kw">bp</span>].BufSize           <span class="co">;load CX with buffer size</span>
    rep   <span class="kw">stosw</span>                     <span class="co">;fill the buffer</span>
<span class="fu">Bye:</span>
    <span class="kw">pop</span>   <span class="kw">bp</span>                        <span class="co">;restore caller&#39;s BP</span>
    <span class="kw">ret</span>   EndMrk-RetAddr<span class="dv">-2</span>          <span class="co">;return, clearing the parms from the stack</span>
ClearS    endp</code></pre>
<p>That’s good for another 3 bytes. We’re down to 43 bytes, and counting.</p>
<p>We can save 3 more bytes by clearing the low and high bytes of AX and BX, respectively, by using <code class="sourceCode nasm"><span class="kw">sub</span> reg8,reg8</code> rather than anding 16-bit values:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">ClearS    proc  near
    <span class="kw">push</span>  <span class="kw">bp</span>                        <span class="co">;save caller&#39;s BP</span>
    <span class="kw">mov</span>   <span class="kw">bp</span>,<span class="kw">sp</span>                     <span class="co">;point to stack frame</span>
    <span class="kw">cmp</span>   <span class="dt">word</span> <span class="dt">ptr</span> [<span class="kw">bp</span>].BufSeg,<span class="dv">0</span>    <span class="co">;skip the fill if a null</span>
    <span class="kw">jne</span>   Start                     <span class="co">; pointer is passed</span>
    <span class="kw">cmp</span>   <span class="dt">word</span> <span class="dt">ptr</span> [<span class="kw">bp</span>].BufOfs,<span class="dv">0</span>
    <span class="kw">je</span>    Bye
<span class="fu">Start:</span> <span class="kw">cld</span>                          <span class="co">;make STOSW count up</span>
    <span class="kw">mov</span>   <span class="kw">ax</span>,[<span class="kw">bp</span>].Attrib            <span class="co">;load AX with attribute parameter</span>
    <span class="kw">sub</span>   <span class="kw">al</span>,<span class="kw">al</span>                     <span class="co">;prepare for merging with fill char</span>
    <span class="kw">mov</span>   <span class="kw">bx</span>,[<span class="kw">bp</span>].Filler            <span class="co">;load BX with fill char</span>
    <span class="kw">sub</span>   <span class="kw">bh</span>,<span class="kw">bh</span>                     <span class="co">;prepare for merging with attribute</span>
    <span class="kw">or</span>    <span class="kw">ax</span>,<span class="kw">bx</span>                     <span class="co">;combine attribute and fill char</span>
    <span class="kw">les</span>   <span class="kw">di</span>,<span class="dt">dword</span> <span class="dt">ptr</span> [<span class="kw">bp</span>].BufOfs  <span class="co">;load ES:DI with target buffer segment:offset</span>
    <span class="kw">mov</span>   <span class="kw">cx</span>,[<span class="kw">bp</span>].BufSize           <span class="co">;load CX with buffer size</span>
    rep   <span class="kw">stosw</span>                     <span class="co">;fill the buffer</span>
<span class="fu">Bye:</span>
    <span class="kw">pop</span>   <span class="kw">bp</span>                        <span class="co">;restore caller&#39;s BP</span>
    <span class="kw">ret</span>   EndMrk-RetAddr<span class="dv">-2</span>          <span class="co">;return, clearing the parms from the stack</span>
ClearS    endp</code></pre>
<p>Now we’re down to 40 bytes — more than 20% smaller than the original code. That’s pretty much it for simple instruction-substitution optimizations. Now let’s look for instruction-rearrangement optimizations.</p>
<p>It seems strange to load a word value into AX and then throw away AL. Likewise, it seems strange to load a word value into BX and then throw away BH. However, those steps are necessary because the two modified word values are ored into a single character/attribute word value that is then used to fill the target buffer.</p>
<p>Let’s step back and see what this code really <em>does</em>, though. All it does in the end is load 1 byte addressed relative to BP into AH and another byte addressed relative to BP into AL. Heck, we can just do that directly! Presto — we’ve saved another 6 bytes, and turned two word-sized memory accesses into byte-sized memory accesses as well:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">ClearS    proc  near
    <span class="kw">push</span>  <span class="kw">bp</span>                          <span class="co">;save caller&#39;s BP</span>
    <span class="kw">mov</span>   <span class="kw">bp</span>,<span class="kw">sp</span>                       <span class="co">;point to stack frame</span>
    <span class="kw">cmp</span>   <span class="dt">word</span> <span class="dt">ptr</span> [<span class="kw">bp</span>].BufSeg,<span class="dv">0</span>      <span class="co">;skip the fill if a null</span>
    <span class="kw">jne</span>   Start                       <span class="co">; pointer is passed</span>
    <span class="kw">cmp</span>   <span class="dt">word</span> <span class="dt">ptr</span> [<span class="kw">bp</span>].BufOfs,<span class="dv">0</span>
    <span class="kw">je</span> Bye
<span class="fu">Start:</span> <span class="kw">cld</span> <span class="co">;make STOSW count up</span>
    <span class="kw">mov</span>   <span class="kw">ah</span>,<span class="dt">byte</span> <span class="dt">ptr</span> [<span class="kw">bp</span>].Attrib[<span class="dv">1</span>]  <span class="co">;load AH with attribute</span>
    <span class="kw">mov</span>   <span class="kw">al</span>,<span class="dt">byte</span> <span class="dt">ptr</span> [<span class="kw">bp</span>].Filler     <span class="co">;load AL with fill char</span>
    <span class="kw">les</span>   <span class="kw">di</span>,<span class="dt">dword</span> <span class="dt">ptr</span> [<span class="kw">bp</span>].BufOfs    <span class="co">;load ES:DI with target buffer segment:offset</span>
    <span class="kw">mov</span>   <span class="kw">cx</span>,[<span class="kw">bp</span>].BufSize             <span class="co">;load CX with buffer size</span>
    rep   <span class="kw">stosw</span>                       <span class="co">;fill the buffer</span>
<span class="fu">Bye:</span>
    <span class="kw">pop</span>   <span class="kw">bp</span>                          <span class="co">;restore caller&#39;s BP</span>
    <span class="kw">ret</span>   EndMrk-RetAddr<span class="dv">-2</span>            <span class="co">;return, clearing the parms from the stack</span>
ClearS    endp</code></pre>
<p>(We could get rid of yet another instruction by having the calling code pack both the attribute and the fill value into the same word, but that’s not part of the specification for this particular routine.)</p>
<p>Another nifty instruction-rearrangement trick saves 6 more bytes. <code class="sourceCode nasm">ClearS</code> checks to see whether the far pointer is null (zero) at the start of the routine… then loads and uses that same far pointer later on. Let’s get that pointer into memory and keep it there; that way we can check to see whether it’s null with a single comparison, and can use it later without having to reload it from memory:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">ClearS    proc  near
    <span class="kw">push</span>  <span class="kw">bp</span>                        <span class="co">;save caller&#39;s BP</span>
    <span class="kw">mov</span>   <span class="kw">bp</span>,<span class="kw">sp</span>                     <span class="co">;point to stack frame</span>
    <span class="kw">les</span>   <span class="kw">di</span>,<span class="dt">dword</span> <span class="dt">ptr</span> [<span class="kw">bp</span>].BufOfs  <span class="co">;load ES:DI with target buffer segment:offset</span>
    <span class="kw">mov</span>   <span class="kw">ax</span>,<span class="kw">es</span>                     <span class="co">;put segment where we can test it</span>
    <span class="kw">or</span>    <span class="kw">ax</span>,<span class="kw">di</span>                     <span class="co">;is it a null pointer?</span>
    <span class="kw">je</span>    Bye                       <span class="co">;yes, so we&#39;re done</span>
<span class="fu">Start:</span> <span class="kw">cld</span>                          <span class="co">;make STOSW count up</span>
    <span class="kw">mov</span> <span class="kw">ah</span>,<span class="dt">byte</span> <span class="dt">ptr</span> [<span class="kw">bp</span>].Attrib[<span class="dv">1</span>]  <span class="co">;load AH with attribute</span>
    <span class="kw">mov</span> <span class="kw">al</span>,<span class="dt">byte</span> <span class="dt">ptr</span> [<span class="kw">bp</span>].Filler     <span class="co">;load AL with fill char</span>
    <span class="kw">mov</span> <span class="kw">cx</span>,[<span class="kw">bp</span>].BufSize             <span class="co">;load CX with buffer size</span>
    rep <span class="kw">stosw</span>                       <span class="co">;fill the buffer</span>
<span class="fu">Bye:</span>
    <span class="kw">pop</span>   <span class="kw">bp</span>                        <span class="co">;restore caller&#39;s BP</span>
    <span class="kw">ret</span>   EndMrk-RetAddr<span class="dv">-2</span>          <span class="co">;return, clearing the parms from the stack</span>
ClearS    endp</code></pre>
<p>Well. Now we’re down to 28 bytes, having reduced the size of this subroutine by nearly 50%. Only 13 instructions remain. Realistically, how much smaller can we make this code?</p>
<p>About one-third smaller yet, as it turns out — but in order to do that, we must stretch our minds and use the 8088’s instructions in unusual ways. Let me ask you this: what do most of the instructions in the current version of <code class="sourceCode nasm">ClearS</code> do?</p>
<p>Answer: they either load parameters from the stack frame or set up the registers so that the parameters can be accessed. Mind you, there’s nothing wrong with the stack-frame-oriented instructions used in <code class="sourceCode nasm">ClearS</code>; those instructions access the stack frame in a highly efficient way, exactly as the designers of the 8088 intended, and just as the code generated by a high-level language would. That means that we aren’t going to be able to improve the code if we don’t bend the rules a bit.</p>
<p>Let’s think… the parameters are sitting on the stack, and most of our instruction bytes are being used to read bytes off the stack with BP-based addressing… we need a more efficient way to address the stack… <em>the stack</em>… THE STACK!</p>
<p>Ye gods! That’s easy — we can use the <em>stack pointer</em> to address the stack. While it’s true that the stack pointer can’t be used for <em>mod-reg-rm</em> addressing, as BP can, it <em>can</em> be used to pop data off the stack — and <code class="sourceCode nasm"><span class="kw">pop</span></code> is a 1-byte instruction. Instructions don’t get any shorter than that.</p>
<p>There is one detail to be taken care of before we can put our plan into action: the return address — the address of the calling code — is on top of the stack, so the parameters we want can’t be reached with <code class="sourceCode nasm"><span class="kw">pop</span></code>. That’s easily solved, however — we’ll just pop the return address into an unused register, then branch through that register when we’re done, as we learned to do in Chapter 14. As we pop the parameters, we’ll also be removing them from the stack, thereby neatly avoiding the need to discard them when it’s time to return.</p>
<p>With that problem dealt with, here’s the Zenned version of <code class="sourceCode nasm">ClearS</code>:</p>
<pre class="sourceCode nasm"><code class="sourceCode nasm">ClearS    proc  near
    <span class="kw">pop</span>   <span class="kw">dx</span>      <span class="co">;get the return address</span>
    <span class="kw">pop</span>   <span class="kw">ax</span>      <span class="co">;put fill char into AL</span>
    <span class="kw">pop</span>   <span class="kw">bx</span>      <span class="co">;get the attribute</span>
    <span class="kw">mov</span>   <span class="kw">ah</span>,<span class="kw">bh</span>   <span class="co">;put attribute into AH</span>
    <span class="kw">pop</span>   <span class="kw">cx</span>      <span class="co">;get the buffer size</span>
    <span class="kw">pop</span>   <span class="kw">di</span>      <span class="co">;get the offset of the buffer origin</span>
    <span class="kw">pop</span>   <span class="kw">es</span>      <span class="co">;get the segment of the buffer origin</span>
    <span class="kw">mov</span>   <span class="kw">bx</span>,<span class="kw">es</span>   <span class="co">;put the segment where we can test it</span>
    <span class="kw">or</span>    <span class="kw">bx</span>,<span class="kw">di</span>   <span class="co">;null pointer?</span>
    <span class="kw">je</span>    Bye     <span class="co">;yes, so we&#39;re done</span>
    <span class="kw">cld</span>           <span class="co">;make STOSW count up</span>
    rep   <span class="kw">stosw</span>   <span class="co">;do the string store</span>
<span class="fu">Bye:</span>
    <span class="kw">jmp</span>   <span class="kw">dx</span>      <span class="co">;return to the calling code</span>
ClearS    endp</code></pre>
<p>At long last, we’re down to the bare metal. This version of <code class="sourceCode nasm">ClearS</code> is just 19 bytes long. That’s just 37% as long as the original version, <em>without any change whatsoever in the functionality <code class="sourceCode nasm">ClearS</code> makes available to the calling code</em>. The code is bound to run a bit faster too, given that there are far fewer instruction bytes and fewer memory accesses.</p>
<p>All in all, the Zenned version of <code class="sourceCode nasm">ClearS</code> is a vast improvement over the original. Probably not the best possible implementation — <em>never say never!</em> — but an awfully good one.</p>
</section>
<section id="knowledge-and-beyond" class="level2">
<h2>Knowledge and Beyond</h2>
<p>There is a point to all this Zenning above and beyond showing off some neat tricks we’ve learned (and a trick or two we’ll learn more about in Volume II). The real point is to illustrate the breadth of knowledge you now possess, and the tremendous power that knowledge has when guided by the flexible mind.</p>
<p>Consider the optimizations we made to <code class="sourceCode nasm">ClearS</code> above. Our initial optimizations resulted purely from knowing particular facts about the 8088, and nothing more. We knew, for example, that segment registers do not have to be loaded from memory by way of general-purpose registers but can instead be loaded directly, so we made that change.</p>
<p>As optimizations became harder to come by, however, we shifted from applying pure knowledge to coming up with creative solutions that involved understanding and reworking the code as a whole. We started out by compacting individual instructions and bits of code, but in the end we came up with a solution that applied our knowledge of the PC to implementing the functionality of the entire subroutine as efficiently as possible.</p>
<p>And that, simply put, is the flexible mind.</p>
<p>Think back. Did you have any trouble following the optimizations to <code class="sourceCode nasm">ClearS</code>? I very much doubt it; in fact, I would guess that you were ahead of me much of the way. So, you see, you already have a good feel for the flexible mind.</p>
<p>There will be much more of the flexible mind in Volume II of <em>The Zen of Assembly Language</em>, but it won’t be an abrupt change from what we’ve been doing; rather, it will be a gradual raising of our focus from learning the nuts and bolts of the PC to building applications with those nuts and bolts. We’ve trekked through knowledge and beyond; now it’s time to seek out ways to bring the magic of the Zen of assembler to the real world of applications.</p>
<p>I hope you’ll join me for the journey.</p>
</section>
</section>
<section id="expanded-listings" class="level1">
<h1>Expanded Listings</h1>
<section id="listing-2-1" class="level2">
<h2>Listing 2-1</h2>
<p>;</p>
<p><strong>; *** Listing 2-1 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; The precision Zen timer (PZTIMER.ASM)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Uses the 8253 timer to time the performance of code that takes</strong></p>
<p><strong>; less than about 54 milliseconds to execute, with a resolution</strong></p>
<p><strong>; of better than 10 microseconds.</strong></p>
<p><strong>;</strong></p>
<p><strong>; By Michael Abrash 4/26/89</strong></p>
<p><strong>;</strong></p>
<p><strong>; Externally callable routines:</strong></p>
<p><strong>;</strong></p>
<p><strong>; ZTimerOn: Starts the Zen timer, with interrupts disabled.</strong></p>
<p><strong>;</strong></p>
<p><strong>; ZTimerOff: Stops the Zen timer, saves the timer count,</strong></p>
<p><strong>; times the overhead code, and restores interrupts to the</strong></p>
<p><strong>; state they were in when ZTimerOn was called.</strong></p>
<p><strong>;</strong></p>
<p><strong>; ZTimerReport: Prints the net time that passed between starting</strong></p>
<p><strong>; and stopping the timer.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: If longer than about 54 ms passes between ZTimerOn and</strong></p>
<p><strong>; ZTimerOff calls, the timer turns over and the count is</strong></p>
<p><strong>; inaccurate. When this happens, an error message is displayed</strong></p>
<p><strong>; instead of a count. The long-period Zen timer should be used</strong></p>
<p><strong>; in such cases.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Interrupts *MUST* be left off between calls to ZTimerOn</strong></p>
<p><strong>; and ZTimerOff for accurate timing and for detection of</strong></p>
<p><strong>; timer overflow.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: These routines can introduce slight inaccuracies into the</strong></p>
<p><strong>; system clock count for each code section timed even if</strong></p>
<p><strong>; timer 0 doesn’t overflow. If timer 0 does overflow, the</strong></p>
<p><strong>; system clock can become slow by virtually any amount of</strong></p>
<p><strong>; time, since the system clock can’t advance while the</strong></p>
<p><strong>; precison timer is timing. Consequently, it’s a good idea</strong></p>
<p><strong>; to reboot at the end of each timing session. (The</strong></p>
<p><strong>; battery-backed clock, if any, is not affected by the Zen</strong></p>
<p><strong>; timer.)</strong></p>
<p><strong>;</strong></p>
<p><strong>; All registers, and all flags except the interrupt flag, are</strong></p>
<p><strong>; preserved by all routines. Interrupts are enabled and then disabled</strong></p>
<p><strong>; by ZTimerOn, and are restored by ZTimerOff to the state they were</strong></p>
<p><strong>; in when ZTimerOn was called.</strong></p>
<p><strong>;</strong></p>
<p><strong>Code segment word public ‘CODE’</strong></p>
<p><strong>assume cs:Code, ds:nothing</strong></p>
<p><strong>public ZTimerOn, ZTimerOff, ZTimerReport</strong></p>
<p><strong>;</strong></p>
<p><strong>; Base address of the 8253 timer chip.</strong></p>
<p><strong>;</strong></p>
<p><strong>BASE_8253 equ 40h</strong></p>
<p><strong>;</strong></p>
<p><strong>; The address of the timer 0 count registers in the 8253.</strong></p>
<p><strong>;</strong></p>
<p><strong>TIMER_0_8253 equ BASE_8253 + 0</strong></p>
<p><strong>;</strong></p>
<p><strong>; The address of the mode register in the 8253.</strong></p>
<p><strong>;</strong></p>
<p><strong>MODE_8253 equ BASE_8253 + 3</strong></p>
<p><strong>;</strong></p>
<p><strong>; The address of Operation Command Word 3 in the 8259 Programmable</strong></p>
<p><strong>; Interrupt Controller (PIC) (write only, and writable only when</strong></p>
<p><strong>; bit 4 of the byte written to this address is 0 and bit 3 is 1).</strong></p>
<p><strong>;</strong></p>
<p><strong>OCW3 equ 20h</strong></p>
<p><strong>;</strong></p>
<p><strong>; The address of the Interrupt Request register in the 8259 PIC</strong></p>
<p><strong>; (read only, and readable only when bit 1 of OCW3 = 1 and bit 0</strong></p>
<p><strong>; of OCW3 = 0).</strong></p>
<p><strong>;</strong></p>
<p><strong>IRR equ 20h</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to emulate a POPF instruction in order to fix the bug in some</strong></p>
<p><strong>; 80286 chips which allows interrupts to occur during a POPF even when</strong></p>
<p><strong>; interrupts remain disabled.</strong></p>
<p><strong>;</strong></p>
<p><strong>MPOPF macro</strong></p>
<p><strong>local p1, p2</strong></p>
<p><strong>jmp short p2</strong></p>
<p><strong>p1: iret ;jump to pushed address &amp; pop flags</strong></p>
<p><strong>p2: push cs ;construct far return address to</strong></p>
<p><strong>call p1 ; the next instruction</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to delay briefly to ensure that enough time has elapsed</strong></p>
<p><strong>; between successive I/O accesses so that the device being accessed</strong></p>
<p><strong>; can respond to both accesses even on a very fast PC.</strong></p>
<p><strong>;</strong></p>
<p><strong>DELAY macro</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>endm</strong></p>
<p><strong>OriginalFlags db ? ;storage for upper byte of</strong></p>
<p><strong>; FLAGS register when</strong></p>
<p><strong>; ZTimerOn called</strong></p>
<p><strong>TimedCount dw ? ;timer 0 count when the timer</strong></p>
<p><strong>; is stopped</strong></p>
<p><strong>ReferenceCount dw ? ;number of counts required to</strong></p>
<p><strong>; execute timer overhead code</strong></p>
<p><strong>OverflowFlag db ? ;used to indicate whether the</strong></p>
<p><strong>; timer overflowed during the</strong></p>
<p><strong>; timing interval</strong></p>
<p><strong>;</strong></p>
<p><strong>; String printed to report results.</strong></p>
<p><strong>;</strong></p>
<p><strong>OutputStr label byte</strong></p>
<p><strong>db 0dh, 0ah, ‘Timed count:’, 5 dup (?)</strong></p>
<p><strong>ASCIICountEnd label byte</strong></p>
<p><strong>db ‘microseconds’, 0dh, 0ah</strong></p>
<p><strong>db ‘$’</strong></p>
<p><strong>;</strong></p>
<p><strong>; String printed to report timer overflow.</strong></p>
<p><strong>;</strong></p>
<p><strong>OverflowStr label byte</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘****************************************************’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* The timer overflowed, so the interval timed was *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* too long for the precision timer to measure. *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* Please perform the timing test again with the *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* long-period timer. *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘****************************************************’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘$’</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>;* Routine called to start timing. *</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>ZTimerOn proc near</strong></p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>push ax</strong></p>
<p><strong>pushf</strong></p>
<p><strong>pop ax ;get flags so we can keep</strong></p>
<p><strong>; interrupts off when leaving</strong></p>
<p><strong>; this routine</strong></p>
<p><strong>mov cs:[OriginalFlags],ah ;remember the state of the</strong></p>
<p><strong>; Interrupt flag</strong></p>
<p><strong>and ah,0fdh ;set pushed interrupt flag</strong></p>
<p><strong>; to 0</strong></p>
<p><strong>push ax</strong></p>
<p><strong>;</strong></p>
<p><strong>; Turn on interrupts, so the timer interrupt can occur if it’s</strong></p>
<p><strong>; pending.</strong></p>
<p><strong>;</strong></p>
<p><strong>sti</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set timer 0 of the 8253 to mode 2 (divide-by-N), to cause</strong></p>
<p><strong>; linear counting rather than count-by-two counting. Also</strong></p>
<p><strong>; leaves the 8253 waiting for the initial timer 0 count to</strong></p>
<p><strong>; be loaded.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00110100b ;mode 2</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set the timer count to 0, so we know we won’t get another</strong></p>
<p><strong>; timer interrupt right away.</strong></p>
<p><strong>; Note: this introduces an inaccuracy of up to 54 ms in the system</strong></p>
<p><strong>; clock count each time it is executed.</strong></p>
<p><strong>;</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>sub al,al</strong></p>
<p><strong>out TIMER_0_8253,al ;lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>out TIMER_0_8253,al ;msb</strong></p>
<p><strong>;</strong></p>
<p><strong>; Wait before clearing interrupts to allow the interrupt generated</strong></p>
<p><strong>; when switching from mode 3 to mode 2 to be recognized. The delay</strong></p>
<p><strong>; must be at least 210 ns long to allow time for that interrupt to</strong></p>
<p><strong>; occur. Here, 10 jumps are used for the delay to ensure that the</strong></p>
<p><strong>; delay time will be more than long enough even on a very fast PC.</strong></p>
<p><strong>;</strong></p>
<p><strong>rept 10</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Disable interrupts to get an accurate count.</strong></p>
<p><strong>;</strong></p>
<p><strong>cli</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set the timer count to 0 again to start the timing interval.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00110100b ;set up to load initial</strong></p>
<p><strong>out MODE_8253,al ; timer count</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>sub al,al</strong></p>
<p><strong>out TIMER_0_8253,al ;load count lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>out TIMER_0_8253,al ;load count msb</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore the context and return.</strong></p>
<p><strong>;</strong></p>
<p><strong>MPOPF ;keeps interrupts off</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>ret</strong></p>
<p><strong>ZTimerOn endp</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>;* Routine called to stop timing and get count. *</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>ZTimerOff proc near</strong></p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>push ax</strong></p>
<p><strong>push cx</strong></p>
<p><strong>pushf</strong></p>
<p><strong>;</strong></p>
<p><strong>; Latch the count.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00000000b ;latch timer 0</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>;</strong></p>
<p><strong>; See if the timer has overflowed by checking the 8259 for a pending</strong></p>
<p><strong>; timer interrupt.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00001010b ;OCW3, set up to read</strong></p>
<p><strong>out OCW3,al ; Interrupt Request register</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>in al,IRR ;read Interrupt Request</strong></p>
<p><strong>; register</strong></p>
<p><strong>and al,1 ;set AL to 1 if IRQ0 (the</strong></p>
<p><strong>; timer interrupt) is pending</strong></p>
<p><strong>mov cs:[OverflowFlag],al ;store the timer overflow</strong></p>
<p><strong>; status</strong></p>
<p><strong>;</strong></p>
<p><strong>; Allow interrupts to happen again.</strong></p>
<p><strong>;</strong></p>
<p><strong>sti</strong></p>
<p><strong>;</strong></p>
<p><strong>; Read out the count we latched earlier.</strong></p>
<p><strong>;</strong></p>
<p><strong>in al,TIMER_0_8253 ;least significant byte</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>mov ah,al</strong></p>
<p><strong>in al,TIMER_0_8253 ;most significant byte</strong></p>
<p><strong>xchg ah,al</strong></p>
<p><strong>neg ax ;convert from countdown</strong></p>
<p><strong>; remaining to elapsed</strong></p>
<p><strong>; count</strong></p>
<p><strong>mov cs:[TimedCount],ax</strong></p>
<p><strong>; Time a zero-length code fragment, to get a reference for how</strong></p>
<p><strong>; much overhead this routine has. Time it 16 times and average it,</strong></p>
<p><strong>; for accuracy, rounding the result.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov cs:[ReferenceCount],0</strong></p>
<p><strong>mov cx,16</strong></p>
<p><strong>cli ;interrupts off to allow a</strong></p>
<p><strong>; precise reference count</strong></p>
<p><strong>RefLoop:</strong></p>
<p><strong>call ReferenceZTimerOn</strong></p>
<p><strong>call ReferenceZTimerOff</strong></p>
<p><strong>loop RefLoop</strong></p>
<p><strong>sti</strong></p>
<p><strong>add cs:[ReferenceCount],8 ;total + (0.5 * 16)</strong></p>
<p><strong>mov cl,4</strong></p>
<p><strong>shr cs:[ReferenceCount],cl ;(total) / 16 + 0.5</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore originaLinterrupt state.</strong></p>
<p><strong>;</strong></p>
<p><strong>pop ax ;retrieve flags when called</strong></p>
<p><strong>mov ch,cs:[OriginalFlags] ;get back the original upper</strong></p>
<p><strong>; byte of the FLAGS register</strong></p>
<p><strong>and ch,not 0fdh ;only care about original</strong></p>
<p><strong>; interrupt flag…</strong></p>
<p><strong>and ah,0fdh ;…keep all other flags in</strong></p>
<p><strong>; their current condition</strong></p>
<p><strong>or ah,ch ;make flags word with original</strong></p>
<p><strong>; interrupt flag</strong></p>
<p><strong>push ax ;prepare flags to be popped</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore the context of the program being timed and return to it.</strong></p>
<p><strong>;</strong></p>
<p><strong>MPOPF ;restore the flags with the</strong></p>
<p><strong>; originaLinterrupt state</strong></p>
<p><strong>pop cx</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>ret</strong></p>
<p><strong>ZTimerOff endp</strong></p>
<p><strong>;</strong></p>
<p><strong>; Called by ZTimerOff to start timer for overhead measurements.</strong></p>
<p><strong>;</strong></p>
<p><strong>ReferenceZTimerOn proc near</strong></p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>push ax</strong></p>
<p><strong>pushf ;interrupts are already off</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set timer 0 of the 8253 to mode 2 (divide-by-N), to cause</strong></p>
<p><strong>; linear counting rather than count-by-two counting.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00110100b ;set up to load</strong></p>
<p><strong>out MODE_8253,al ; initial timer count</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set the timer count to 0.</strong></p>
<p><strong>;</strong></p>
<p><strong>sub al,al</strong></p>
<p><strong>out TIMER_0_8253,al ;load count lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>out TIMER_0_8253,al ;load count msb</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore the context of the program being timed and return to it.</strong></p>
<p><strong>;</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>ret</strong></p>
<p><strong>ReferenceZTimerOn endp</strong></p>
<p><strong>;</strong></p>
<p><strong>; Called by ZTimerOff to stop timer and add result to ReferenceCount</strong></p>
<p><strong>; for overhead measurements.</strong></p>
<p><strong>;</strong></p>
<p><strong>ReferenceZTimerOff proc near</strong></p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>push ax</strong></p>
<p><strong>push cx</strong></p>
<p><strong>pushf</strong></p>
<p><strong>;</strong></p>
<p><strong>; Latch the count and read it.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00000000b ;latch timer 0</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>in al,TIMER_0_8253 ;lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>mov ah,al</strong></p>
<p><strong>in al,TIMER_0_8253 ;msb</strong></p>
<p><strong>xchg ah,al</strong></p>
<p><strong>neg ax ;convert from countdown</strong></p>
<p><strong>; remaining to amount</strong></p>
<p><strong>; counted down</strong></p>
<p><strong>add cs:[ReferenceCount],ax</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore the context of the program being timed and return to it.</strong></p>
<p><strong>;</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>pop cx</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>ret</strong></p>
<p><strong>ReferenceZTimerOff endp</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>;* Routine called to report timing results. *</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>ZTimerReport proc near</strong></p>
<p><strong>pushf</strong></p>
<p><strong>push ax</strong></p>
<p><strong>push bx</strong></p>
<p><strong>push cx</strong></p>
<p><strong>push dx</strong></p>
<p><strong>push si</strong></p>
<p><strong>push ds</strong></p>
<p><strong>;</strong></p>
<p><strong>push cs ;DOS functions require that DS point</strong></p>
<p><strong>pop ds ; to text to be displayed on the screen</strong></p>
<p><strong>assume ds:Code</strong></p>
<p><strong>;</strong></p>
<p><strong>; Check for timer 0 overflow.</strong></p>
<p><strong>;</strong></p>
<p><strong>cmp [OverflowFlag],0</strong></p>
<p><strong>jz PrintGoodCount</strong></p>
<p><strong>mov dx,offset OverflowStr</strong></p>
<p><strong>mov ah,9</strong></p>
<p><strong>int 21h</strong></p>
<p><strong>jmp short EndZTimerReport</strong></p>
<p><strong>;</strong></p>
<p><strong>; Convert net count to decimal ASCII in microseconds.</strong></p>
<p><strong>;</strong></p>
<p><strong>PrintGoodCount:</strong></p>
<p><strong>mov ax,[TimedCount]</strong></p>
<p><strong>sub ax,[ReferenceCount]</strong></p>
<p><strong>mov si,offset ASCIICountEnd -1</strong></p>
<p><strong>;</strong></p>
<p><strong>; Convert count to microseconds by multiplying by .8381.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov dx,8381</strong></p>
<p><strong>mul dx</strong></p>
<p><strong>mov bx,10000</strong></p>
<p><strong>div bx ;* .8381 = * 8381 / 10000</strong></p>
<p><strong>;</strong></p>
<p><strong>; Convert time in microseconds to 5 decimal ASCII digits.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov bx,10</strong></p>
<p><strong>mov cx,5</strong></p>
<p><strong>CTSLoop:</strong></p>
<p><strong>sub dx,dx</strong></p>
<p><strong>div bx</strong></p>
<p><strong>add dl,‘0’</strong></p>
<p><strong>mov [si],dl</strong></p>
<p><strong>dec si</strong></p>
<p><strong>loop CTSLoop</strong></p>
<p><strong>;</strong></p>
<p><strong>; Print the results.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ah,9</strong></p>
<p><strong>mov dx,offset OutputStr</strong></p>
<p><strong>int 21h</strong></p>
<p><strong>;</strong></p>
<p><strong>EndZTimerReport:</strong></p>
<p><strong>pop ds</strong></p>
<p><strong>pop si</strong></p>
<p><strong>pop dx</strong></p>
<p><strong>pop cx</strong></p>
<p><strong>pop bx</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>ret</strong></p>
<p><strong>ZTimerReport endp</strong></p>
<p><strong>Code ends</strong></p>
<p><strong>end</strong></p>
</section>
<section id="listing-2-2" class="level2">
<h2>Listing 2-2</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 2-2 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Program to measure performance of code that takes less than</strong></p>
<p><strong>; 54 ms to execute. (PZTEST.ASM)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Link with PZTIMER.ASM (Listing 2-1). PZTEST.BAT (Listing 2-4)</strong></p>
<p><strong>; can be used to assemble and link both files. Code to be</strong></p>
<p><strong>; measured must be in the file TESTCODE; Listing 2-3 shows</strong></p>
<p><strong>; a sample TESTCODE file.</strong></p>
<p><strong>;</strong></p>
<p><strong>; By Michael Abrash 4/26/89</strong></p>
<p><strong>;</strong></p>
<p><strong>mystack segment para stack ‘STACK’</strong></p>
<p><strong>db 512 dup(?)</strong></p>
<p><strong>mystack ends</strong></p>
<p><strong>;</strong></p>
<p><strong>Code segment para public ‘CODE’</strong></p>
<p><strong>assume cs:Code, ds:Code</strong></p>
<p><strong>extrn ZTimerOn:near, ZTimerOff:near, ZTimerReport:near</strong></p>
<p><strong>Start proc near</strong></p>
<p><strong>push cs</strong></p>
<p><strong>pop ds ;set DS to point to the code segment,</strong></p>
<p><strong>; so data as well as code can easily</strong></p>
<p><strong>; be included in TESTCODE</strong></p>
<p><strong>;</strong></p>
<p><strong>include TESTCODE ;code to be measured, including</strong></p>
<p><strong>; calls to ZTimerOn and ZTimerOff</strong></p>
<p><strong>;</strong></p>
<p><strong>; Display the results.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerReport</strong></p>
<p><strong>;</strong></p>
<p><strong>; Terminate the program.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ah,4ch</strong></p>
<p><strong>int 21h</strong></p>
<p><strong>Start endp</strong></p>
<p><strong>Code ends</strong></p>
<p><strong>end Start</strong></p>
</section>
<section id="listing-2-3" class="level2">
<h2>Listing 2-3</h2>
<p><strong>; *** Listing 2-3 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of 1000 loads of AL from</strong></p>
<p><strong>; memory. (Use by renaming to TESTCODE, which is</strong></p>
<p><strong>; included by PZTEST.ASM (Listing 2-2). PZTIME.BAT</strong></p>
<p><strong>; (Listing 2-4) does this, along with all assembly</strong></p>
<p><strong>; and linking.)</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip ;jump around defined data</strong></p>
<p><strong>;</strong></p>
<p><strong>MemVar db ?</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>;</strong></p>
<p><strong>; Start timing.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>;</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>mov al,[MemVar]</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Stop timing.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-2-4" class="level2">
<h2>Listing 2-4</h2>
<p><strong>echo off</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem *** Listing 2-4 ***</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem ***************************************************************</strong></p>
<p><strong>rem * Batch file PZTIME.BAT, which builds and runs the precision *</strong></p>
<p><strong>rem * Zen timer program PZTEST.EXE to time the code named as the *</strong></p>
<p><strong>rem * command-line parameter. Listing 2-1 must be named *</strong></p>
<p><strong>rem * PZTIMER.ASM, and Listing 2-2 must be named PZTEST.ASM. To *</strong></p>
<p><strong>rem * time the code in LST2-3, you’d type the DOS command: *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * pztime lst2-3 *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * Note that MASM and LINK must be in the current directory or *</strong></p>
<p><strong>rem * on the current path in order for this batch file to work. *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * This batch file can be speeded up by assembling PZTIMER.ASM *</strong></p>
<p><strong>rem * once, then removing the lines: *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * masm pztimer; *</strong></p>
<p><strong>rem * if errorlevel 1 goto errorend *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * from this file. *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * By Michael Abrash 4/26/89 *</strong></p>
<p><strong>rem ***************************************************************</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem Make sure a file to test was specified.</strong></p>
<p><strong>rem</strong></p>
<p><strong>if not x%1==x goto ckexist</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>echo * Please specify a file to test. *</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>goto end</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem Make sure the file exists.</strong></p>
<p><strong>rem</strong></p>
<p><strong>:ckexist</strong></p>
<p><strong>if exist %1 goto docopy</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>echo * The specified file, “%1,” doesn’t exist.</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>goto end</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem copy the file to measure to TESTCODE.</strong></p>
<p><strong>rem</strong></p>
<p><strong>:docopy</strong></p>
<p><strong>copy %1 testcode</strong></p>
<p><strong>masm pztest;</strong></p>
<p><strong>if errorlevel 1 goto errorend</strong></p>
<p><strong>masm pztimer;</strong></p>
<p><strong>if errorlevel 1 goto errorend</strong></p>
<p><strong>link pztest+pztimer;</strong></p>
<p><strong>if errorlevel 1 goto errorend</strong></p>
<p><strong>pztest</strong></p>
<p><strong>goto end</strong></p>
<p><strong>:errorend</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>echo * An error occurred while building the precision Zen timer. *</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>:end</strong></p>
</section>
<section id="listing-2-5" class="level2">
<h2>Listing 2-5</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 2-5 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; The long-period Zen timer. (LZTIMER.ASM)</strong></p>
<p><strong>; Uses the 8253 timer and the BIOS time-of-day count to time the</strong></p>
<p><strong>; performance of code that takes less than an hour to execute.</strong></p>
<p><strong>; Because interrupts are left on (in order to allow the timer</strong></p>
<p><strong>; interrupt to be recognized), this is less accurate than the</strong></p>
<p><strong>; precision Zen timer, so it is best used only to time code that takes</strong></p>
<p><strong>; more than about 54 milliseconds to execute (code that the precision</strong></p>
<p><strong>; Zen timer reports overflow on). Resolution is limited by the</strong></p>
<p><strong>; occurrence of timer interrupts.</strong></p>
<p><strong>;</strong></p>
<p><strong>; By Michael Abrash 4/26/89</strong></p>
<p><strong>;</strong></p>
<p><strong>; Externally callable routines:</strong></p>
<p><strong>;</strong></p>
<p><strong>; ZTimerOn: Saves the BIOS time of day count and starts the</strong></p>
<p><strong>; long-period Zen timer.</strong></p>
<p><strong>;</strong></p>
<p><strong>; ZTimerOff: Stops the long-period Zen timer and saves the timer</strong></p>
<p><strong>; count and the BIOS time-of-day count.</strong></p>
<p><strong>;</strong></p>
<p><strong>; ZTimerReport: Prints the time that passed between starting and</strong></p>
<p><strong>; stopping the timer.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: If either more than an hour passes or midnight falls between</strong></p>
<p><strong>; calls to ZTimerOn and ZTimerOff, an error is reported. For</strong></p>
<p><strong>; timing code that takes more than a few minutes to execute,</strong></p>
<p><strong>; either the DOS TIME command in a batch file before and after</strong></p>
<p><strong>; execution of the code to time or the use of the DOS</strong></p>
<p><strong>; time-of-day function in place of the long-period Zen timer is</strong></p>
<p><strong>; more than adequate.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: The PS/2 version is assembled by setting the symbol PS2 to 1.</strong></p>
<p><strong>; PS2 must be set to 1 on PS/2 computers because the PS/2’s</strong></p>
<p><strong>; timers are not compatible with an undocumented timer-stopping</strong></p>
<p><strong>; feature of the 8253; the alternative timing approach that</strong></p>
<p><strong>; must be used on PS/2 computers leaves a short window</strong></p>
<p><strong>; during which the timer 0 count and the BIOS timer count may</strong></p>
<p><strong>; not be synchronized. You should also set the PS2 symbol to</strong></p>
<p><strong>; 1 if you’re getting erratic or obviously incorrect results.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: When PS2 is 0, the code relies on an undocumented 8253</strong></p>
<p><strong>; feature to get more reliable readings. It is possible that</strong></p>
<p><strong>; the 8253 (or whatever chip is emulating the 8253) may be put</strong></p>
<p><strong>; into an undefined or incorrect state when this feature is</strong></p>
<p><strong>; used.</strong></p>
<p><strong>;</strong></p>
<p><strong>; ***************************************************************</strong></p>
<p><strong>; * If your computer displays any hint of erratic behavior *</strong></p>
<p><strong>; * after the long-period Zen timer is used, such as the floppy *</strong></p>
<p><strong>; * drive failing to operate properly, reboot the system, set *</strong></p>
<p><strong>; * PS2 to 1 and leave it that way! *</strong></p>
<p><strong>; ***************************************************************</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Each block of code being timed should ideally be run several</strong></p>
<p><strong>; times, with at least two similar readings required to</strong></p>
<p><strong>; establish a true measurement, in order to eliminate any</strong></p>
<p><strong>; variability caused by interrupts.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Interrupts must not be disabled for more than 54 ms at a</strong></p>
<p><strong>; stretch during the timing interval. Because interrupts</strong></p>
<p><strong>; are enabled, keys, mice, and other devices that generate</strong></p>
<p><strong>; interrupts should not be used during the timing interval.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Any extra code running off the timer interrupt (such as</strong></p>
<p><strong>; some memory-resident utilities) wilLincrease the time</strong></p>
<p><strong>; measured by the Zen timer.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: These routines can introduce inaccuracies of up to a few</strong></p>
<p><strong>; tenths of a second into the system clock count for each</strong></p>
<p><strong>; code section timed. Consequently, it’s a good idea to</strong></p>
<p><strong>; reboot at the conclusion of timing sessions. (The</strong></p>
<p><strong>; battery-backed clock, if any, is not affected by the Zen</strong></p>
<p><strong>; timer.)</strong></p>
<p><strong>;</strong></p>
<p><strong>; All registers and all flags are preserved by all routines.</strong></p>
<p><strong>;</strong></p>
<p><strong>Code segment word public ‘CODE’</strong></p>
<p><strong>assume cs:Code, ds:nothing</strong></p>
<p><strong>public ZTimerOn, ZTimerOff, ZTimerReport</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set PS2 to 0 to assemble for use on a fully 8253-compatible</strong></p>
<p><strong>; system; when PS2 is 0, the readings are more reliable if the</strong></p>
<p><strong>; computer supports the undocumented timer-stopping feature,</strong></p>
<p><strong>; but may be badly off if that feature is not supported. In</strong></p>
<p><strong>; fact, timer-stopping may interfere with your computer’s</strong></p>
<p><strong>; overall operation by putting the 8253 into an undefined or</strong></p>
<p><strong>; incorrect state. Use with caution!!!</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set PS2 to 1 to assemble for use on non-8253-compatible</strong></p>
<p><strong>; systems, including PS/2 computers; when PS2 is 1, readings</strong></p>
<p><strong>; may occasionally be off by 54 ms, but the code will work</strong></p>
<p><strong>; properly on all systems.</strong></p>
<p><strong>;</strong></p>
<p><strong>; A setting of 1 is safer and will work on more systems,</strong></p>
<p><strong>; while a setting of 0 produces more reliable results in systems</strong></p>
<p><strong>; which support the undocumented timer-stopping feature of the</strong></p>
<p><strong>; 8253. The choice is yours.</strong></p>
<p><strong>;</strong></p>
<p><strong>PS2 equ 1</strong></p>
<p><strong>;</strong></p>
<p><strong>; Base address of the 8253 timer chip.</strong></p>
<p><strong>;</strong></p>
<p><strong>BASE_8253 equ 40h</strong></p>
<p><strong>;</strong></p>
<p><strong>; The address of the timer 0 count registers in the 8253.</strong></p>
<p><strong>;</strong></p>
<p><strong>TIMER_0_8253 equ BASE_8253 + 0</strong></p>
<p><strong>;</strong></p>
<p><strong>; The address of the mode register in the 8253.</strong></p>
<p><strong>;</strong></p>
<p><strong>MODE_8253 equ BASE_8253 + 3</strong></p>
<p><strong>;</strong></p>
<p><strong>; The address of the BIOS timer count variable in the BIOS</strong></p>
<p><strong>; data segment.</strong></p>
<p><strong>;</strong></p>
<p><strong>TIMER_COUNT equ 46ch</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to emulate a POPF instruction in order to fix the bug in some</strong></p>
<p><strong>; 80286 chips which allows interrupts to occur during a POPF even when</strong></p>
<p><strong>; interrupts remain disabled.</strong></p>
<p><strong>;</strong></p>
<p><strong>MPOPF macro</strong></p>
<p><strong>local p1, p2</strong></p>
<p><strong>jmp short p2</strong></p>
<p><strong>p1: iret ;jump to pushed address &amp; pop flags</strong></p>
<p><strong>p2: push cs ;construct far return address to</strong></p>
<p><strong>call p1 ; the next instruction</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to delay briefly to ensure that enough time has elapsed</strong></p>
<p><strong>; between successive I/O accesses so that the device being accessed</strong></p>
<p><strong>; can respond to both accesses even on a very fast PC.</strong></p>
<p><strong>;</strong></p>
<p><strong>DELAY macro</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>endm</strong></p>
<p><strong>StartBIOSCountLow dw ? ;BIOS count low word at the</strong></p>
<p><strong>; start of the timing period</strong></p>
<p><strong>StartBIOSCountHigh dw ? ;BIOS count high word at the</strong></p>
<p><strong>; start of the timing period</strong></p>
<p><strong>EndBIOSCountLow dw ? ;BIOS count low word at the</strong></p>
<p><strong>; end of the timing period</strong></p>
<p><strong>EndBIOSCountHigh dw ? ;BIOS count high word at the</strong></p>
<p><strong>; end of the timing period</strong></p>
<p><strong>EndTimedCount dw ? ;timer 0 count at the end of</strong></p>
<p><strong>; the timing period</strong></p>
<p><strong>ReferenceCount dw ? ;number of counts required to</strong></p>
<p><strong>; execute timer overhead code</strong></p>
<p><strong>;</strong></p>
<p><strong>; String printed to report results.</strong></p>
<p><strong>;</strong></p>
<p><strong>OutputStr label byte</strong></p>
<p><strong>db 0dh, 0ah, ‘Timed count:’</strong></p>
<p><strong>TimedCountStr db 10 dup (?)</strong></p>
<p><strong>db ‘microseconds’, 0dh, 0ah</strong></p>
<p><strong>db ‘$’</strong></p>
<p><strong>;</strong></p>
<p><strong>; Temporary storage for timed count as it’s divided down by powers</strong></p>
<p><strong>; of ten when converting from doubleword binary to ASCII.</strong></p>
<p><strong>;</strong></p>
<p><strong>CurrentCountLow dw ?</strong></p>
<p><strong>CurrentCountHigh dw ?</strong></p>
<p><strong>;</strong></p>
<p><strong>; Powers of ten table used to perform division by 10 when doing</strong></p>
<p><strong>; doubleword conversion from binary to ASCII.</strong></p>
<p><strong>;</strong></p>
<p><strong>PowersOfTen label word</strong></p>
<p><strong>dd 1</strong></p>
<p><strong>dd 10</strong></p>
<p><strong>dd 100</strong></p>
<p><strong>dd 1000</strong></p>
<p><strong>dd 10000</strong></p>
<p><strong>dd 100000</strong></p>
<p><strong>dd 1000000</strong></p>
<p><strong>dd 10000000</strong></p>
<p><strong>dd 100000000</strong></p>
<p><strong>dd 1000000000</strong></p>
<p><strong>PowersOfTenEnd label word</strong></p>
<p><strong>;</strong></p>
<p><strong>; String printed to report that the high word of the BIOS count</strong></p>
<p><strong>; changed while timing (an hour elapsed or midnight was crossed),</strong></p>
<p><strong>; and so the count is invalid and the test needs to be rerun.</strong></p>
<p><strong>;</strong></p>
<p><strong>TurnOverStr label byte</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘****************************************************’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* Either midnight passed or an hour or more passed *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* while timing was in progress. If the former was *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* the case, please rerun the test; if the latter *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* was the case, the test code takes too long to *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* run to be timed by the long-period Zen timer. *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* Suggestions: use the DOS TIME command, the DOS *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* time function, or a watch. *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘****************************************************’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘$’</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>;* Routine called to start timing. *</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>ZTimerOn proc near</strong></p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>push ax</strong></p>
<p><strong>pushf</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set timer 0 of the 8253 to mode 2 (divide-by-N), to cause</strong></p>
<p><strong>; linear counting rather than count-by-two counting. Also stops</strong></p>
<p><strong>; timer 0 until the timer count is loaded, except on PS/2</strong></p>
<p><strong>; computers.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00110100b ;mode 2</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set the timer count to 0, so we know we won’t get another</strong></p>
<p><strong>; timer interrupt right away.</strong></p>
<p><strong>; Note: this introduces an inaccuracy of up to 54 ms in the system</strong></p>
<p><strong>; clock count each time it is executed.</strong></p>
<p><strong>;</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>sub al,al</strong></p>
<p><strong>out TIMER_0_8253,al ;lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>out TIMER_0_8253,al ;msb</strong></p>
<p><strong>;</strong></p>
<p><strong>; In case interrupts are disabled, enable interrupts briefly to allow</strong></p>
<p><strong>; the interrupt generated when switching from mode 3 to mode 2 to be</strong></p>
<p><strong>; recognized. Interrupts must be enabled for at least 210 ns to allow</strong></p>
<p><strong>; time for that interrupt to occur. Here, 10 jumps are used for the</strong></p>
<p><strong>; delay to ensure that the delay time will be more than long enough</strong></p>
<p><strong>; even on a very fast PC.</strong></p>
<p><strong>;</strong></p>
<p><strong>pushf</strong></p>
<p><strong>sti</strong></p>
<p><strong>rept 10</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>endm</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>;</strong></p>
<p><strong>; Store the timing start BIOS count.</strong></p>
<p><strong>; (Since the timer count was just set to 0, the BIOS count will</strong></p>
<p><strong>; stay the same for the next 54 ms, so we don’t need to disable</strong></p>
<p><strong>; interrupts in order to avoid getting a half-changed count.)</strong></p>
<p><strong>;</strong></p>
<p><strong>push ds</strong></p>
<p><strong>sub ax,ax</strong></p>
<p><strong>mov ds,ax</strong></p>
<p><strong>mov ax,ds:[TIMER_COUNT+2]</strong></p>
<p><strong>mov cs:[StartBIOSCountHigh],ax</strong></p>
<p><strong>mov ax,ds:[TIMER_COUNT]</strong></p>
<p><strong>mov cs:[StartBIOSCountLow],ax</strong></p>
<p><strong>pop ds</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set the timer count to 0 again to start the timing interval.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00110100b ;set up to load initial</strong></p>
<p><strong>out MODE_8253,al ; timer count</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>sub al,al</strong></p>
<p><strong>out TIMER_0_8253,al ;load count lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>out TIMER_0_8253,al ;load count msb</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore the context of the program being timed and return to it.</strong></p>
<p><strong>;</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>ret</strong></p>
<p><strong>ZTimerOn endp</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>;* Routine called to stop timing and get count. *</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>ZTimerOff proc near</strong></p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>pushf</strong></p>
<p><strong>push ax</strong></p>
<p><strong>push cx</strong></p>
<p><strong>;</strong></p>
<p><strong>; In case interrupts are disabled, enable interrupts briefly to allow</strong></p>
<p><strong>; any pending timer interrupt to be handled. Interrupts must be</strong></p>
<p><strong>; enabled for at least 210 ns to allow time for that interrupt to</strong></p>
<p><strong>; occur. Here, 10 jumps are used for the delay to ensure that the</strong></p>
<p><strong>; delay time will be more than long enough even on a very fast PC.</strong></p>
<p><strong>;</strong></p>
<p><strong>sti</strong></p>
<p><strong>rept 10</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Latch the timer count.</strong></p>
<p><strong>;</strong></p>
<p><strong>if PS2</strong></p>
<p><strong>mov al,00000000b</strong></p>
<p><strong>out MODE_8253,al ;latch timer 0 count</strong></p>
<p><strong>;</strong></p>
<p><strong>; This is where a one-instruction-long window exists on the PS/2.</strong></p>
<p><strong>; The timer count and the BIOS count can lose synchronization;</strong></p>
<p><strong>; since the timer keeps counting after it’s latched, it can turn</strong></p>
<p><strong>; over right after it’s latched and cause the BIOS count to turn</strong></p>
<p><strong>; over before interrupts are disabled, leaving us with the timer</strong></p>
<p><strong>; count from before the timer turned over coupled with the BIOS</strong></p>
<p><strong>; count from after the timer turned over. The result is a count</strong></p>
<p><strong>; that’s 54 ms too long.</strong></p>
<p><strong>;</strong></p>
<hr />
<p><strong>else</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set timer 0 to mode 2 (divide-by-N), waiting for a 2-byte count</strong></p>
<p><strong>; load, which stops timer 0 until the count is loaded. (Only works</strong></p>
<p><strong>; on fully 8253-compatible chips.)</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00110100b ;mode 2</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>mov al,00000000b ;latch timer 0 count</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>endif</strong></p>
<p><strong>cli ;stop the BIOS count</strong></p>
<p><strong>;</strong></p>
<p><strong>; Read the BIOS count. (Since interrupts are disabled, the BIOS</strong></p>
<p><strong>; count won’t change.)</strong></p>
<p><strong>;</strong></p>
<p><strong>push ds</strong></p>
<p><strong>sub ax,ax</strong></p>
<p><strong>mov ds,ax</strong></p>
<p><strong>mov ax,ds:[TIMER_COUNT+2]</strong></p>
<p><strong>mov cs:[EndBIOSCountHigh],ax</strong></p>
<p><strong>mov ax,ds:[TIMER_COUNT]</strong></p>
<p><strong>mov cs:[EndBIOSCountLow],ax</strong></p>
<p><strong>pop ds</strong></p>
<p><strong>;</strong></p>
<p><strong>; Read the timer count and save it.</strong></p>
<p><strong>;</strong></p>
<p><strong>in al,TIMER_0_8253 ;lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>mov ah,al</strong></p>
<p><strong>in al,TIMER_0_8253 ;msb</strong></p>
<p><strong>xchg ah,al</strong></p>
<p><strong>neg ax ;convert from countdown</strong></p>
<p><strong>; remaining to elapsed</strong></p>
<p><strong>; count</strong></p>
<p><strong>mov cs:[EndTimedCount],ax</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restart timer 0, which is still waiting for an initial count</strong></p>
<p><strong>; to be loaded.</strong></p>
<p><strong>;</strong></p>
<p><strong>ife PS2</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>mov al,00110100b ;mode 2, waiting to load a</strong></p>
<p><strong>; 2-byte count</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>sub al,al</strong></p>
<p><strong>out TIMER_0_8253,al ;lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>mov al,ah</strong></p>
<p><strong>out TIMER_0_8253,al ;msb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>endif</strong></p>
<p><strong>sti ;let the BIOS count continue</strong></p>
<p><strong>;</strong></p>
<p><strong>; Time a zero-length code fragment, to get a reference for how</strong></p>
<p><strong>; much overhead this routine has. Time it 16 times and average it,</strong></p>
<p><strong>; for accuracy, rounding the result.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov cs:[ReferenceCount],0</strong></p>
<p><strong>mov cx,16</strong></p>
<p><strong>cli ;interrupts off to allow a</strong></p>
<p><strong>; precise reference count</strong></p>
<p><strong>RefLoop:</strong></p>
<p><strong>call ReferenceZTimerOn</strong></p>
<p><strong>call ReferenceZTimerOff</strong></p>
<p><strong>loop RefLoop</strong></p>
<p><strong>sti</strong></p>
<p><strong>add cs:[ReferenceCount],8 ;total + (0.5 * 16)</strong></p>
<p><strong>mov cl,4</strong></p>
<p><strong>shr cs:[ReferenceCount],cl ;(total) / 16 + 0.5</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore the context of the program being timed and return to it.</strong></p>
<p><strong>;</strong></p>
<p><strong>pop cx</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>ret</strong></p>
<p><strong>ZTimerOff endp</strong></p>
<p><strong>;</strong></p>
<p><strong>; Called by ZTimerOff to start the timer for overhead measurements.</strong></p>
<p><strong>;</strong></p>
<p><strong>ReferenceZTimerOn proc near</strong></p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>push ax</strong></p>
<p><strong>pushf</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set timer 0 of the 8253 to mode 2 (divide-by-N), to cause</strong></p>
<p><strong>; linear counting rather than count-by-two counting.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00110100b ;mode 2</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set the timer count to 0.</strong></p>
<p><strong>;</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>sub al,al</strong></p>
<p><strong>out TIMER_0_8253,al ;lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>out TIMER_0_8253,al ;msb</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore the context of the program being timed and return to it.</strong></p>
<p><strong>;</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>ret</strong></p>
<p><strong>ReferenceZTimerOn endp</strong></p>
<p><strong>;</strong></p>
<p><strong>; Called by ZTimerOff to stop the timer and add the result to</strong></p>
<p><strong>; ReferenceCount for overhead measurements. Doesn’t need to look</strong></p>
<p><strong>; at the BIOS count because timing a zero-length code fragment</strong></p>
<p><strong>; isn’t going to take anywhere near 54 ms.</strong></p>
<p><strong>;</strong></p>
<p><strong>ReferenceZTimerOff proc near</strong></p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>pushf</strong></p>
<p><strong>push ax</strong></p>
<p><strong>push cx</strong></p>
<p><strong>;</strong></p>
<p><strong>; Match the interrupt-window delay in ZTimerOff.</strong></p>
<p><strong>;</strong></p>
<p><strong>sti</strong></p>
<p><strong>rept 10</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>endm</strong></p>
<p><strong>mov al,00000000b</strong></p>
<p><strong>out MODE_8253,al ;latch timer</strong></p>
<p><strong>;</strong></p>
<p><strong>; Read the count and save it.</strong></p>
<p><strong>;</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>in al,TIMER_0_8253 ;lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>mov ah,al</strong></p>
<p><strong>in al,TIMER_0_8253 ;msb</strong></p>
<p><strong>xchg ah,al</strong></p>
<p><strong>neg ax ;convert from countdown</strong></p>
<p><strong>; remaining to elapsed</strong></p>
<p><strong>; count</strong></p>
<p><strong>add cs:[ReferenceCount],ax</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore the context and return.</strong></p>
<p><strong>;</strong></p>
<p><strong>pop cx</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>ret</strong></p>
<p><strong>ReferenceZTimerOff endp</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>;* Routine called to report timing results. *</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>ZTimerReport proc near</strong></p>
<p><strong>pushf</strong></p>
<p><strong>push ax</strong></p>
<p><strong>push bx</strong></p>
<p><strong>push cx</strong></p>
<p><strong>push dx</strong></p>
<p><strong>push si</strong></p>
<p><strong>push di</strong></p>
<p><strong>push ds</strong></p>
<p><strong>;</strong></p>
<p><strong>push cs ;DOS functions require that DS point</strong></p>
<p><strong>pop ds ; to text to be displayed on the screen</strong></p>
<p><strong>assume ds:Code</strong></p>
<p><strong>;</strong></p>
<p><strong>; See if midnight or more than an hour passed during timing. If so,</strong></p>
<p><strong>; notify the user.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,[StartBIOSCountHigh]</strong></p>
<p><strong>cmp ax,[EndBIOSCountHigh]</strong></p>
<p><strong>jz CalcBIOSTime ;hour count didn’t change,</strong></p>
<p><strong>; so everything’s fine</strong></p>
<p><strong>inc ax</strong></p>
<p><strong>cmp ax,[EndBIOSCountHigh]</strong></p>
<p><strong>jnz TestTooLong ;midnight or two hour</strong></p>
<p><strong>; boundaries passed, so the</strong></p>
<p><strong>; results are no good</strong></p>
<p><strong>mov ax,[EndBIOSCountLow]</strong></p>
<p><strong>cmp ax,[StartBIOSCountLow]</strong></p>
<p><strong>jb CalcBIOSTime ;a single hour boundary</strong></p>
<p><strong>; passed-that’s OK, so long as</strong></p>
<p><strong>; the total time wasn’t more</strong></p>
<p><strong>; than an hour</strong></p>
<p><strong>;</strong></p>
<p><strong>; Over an hour elapsed or midnight passed during timing, which</strong></p>
<p><strong>; renders the results invalid. Notify the user. This misses the</strong></p>
<p><strong>; case where a multiple of 24 hours has passed, but we’ll rely</strong></p>
<p><strong>; on the perspicacity of the user to detect that case.</strong></p>
<p><strong>;</strong></p>
<p><strong>TestTooLong:</strong></p>
<p><strong>mov ah,9</strong></p>
<p><strong>mov dx,offset TurnOverStr</strong></p>
<p><strong>int 21h</strong></p>
<p><strong>jmp short ZTimerReportDone</strong></p>
<p><strong>;</strong></p>
<p><strong>; Convert the BIOS time to microseconds.</strong></p>
<p><strong>;</strong></p>
<p><strong>CalcBIOSTime:</strong></p>
<p><strong>mov ax,[EndBIOSCountLow]</strong></p>
<p><strong>sub ax,[StartBIOSCountLow]</strong></p>
<p><strong>mov dx,54925 ;number of microseconds each</strong></p>
<p><strong>; BIOS count represents</strong></p>
<p><strong>mul dx</strong></p>
<p><strong>mov bx,ax ;set aside BIOS count in</strong></p>
<p><strong>mov cx,dx ; microseconds</strong></p>
<p><strong>;</strong></p>
<p><strong>; Convert timer count to microseconds.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,[EndTimedCount]</strong></p>
<p><strong>mov si,8381</strong></p>
<p><strong>mul si</strong></p>
<p><strong>mov si,10000</strong></p>
<p><strong>div si ;* .8381 = * 8381 / 10000</strong></p>
<p><strong>;</strong></p>
<p><strong>; Add timer and BIOS counts together to get an overall time in</strong></p>
<p><strong>; microseconds.</strong></p>
<p><strong>;</strong></p>
<p><strong>add bx,ax</strong></p>
<p><strong>adc cx,0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Subtract the timer overhead and save the result.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,[ReferenceCount]</strong></p>
<p><strong>mov si,8381 ;convert the reference count</strong></p>
<p><strong>mul si ; to microseconds</strong></p>
<p><strong>mov si,10000</strong></p>
<p><strong>div si ;* .8381 = * 8381 / 10000</strong></p>
<p><strong>sub bx,ax</strong></p>
<p><strong>sbb cx,0</strong></p>
<p><strong>mov [CurrentCountLow],bx</strong></p>
<p><strong>mov [CurrentCountHigh],cx</strong></p>
<p><strong>;</strong></p>
<p><strong>; Convert the result to an ASCII string by trial subtractions of</strong></p>
<p><strong>; powers of 10.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov di,offset PowersOfTenEnd -offset PowersOfTen -4</strong></p>
<p><strong>mov si,offset TimedCountStr</strong></p>
<p><strong>CTSNextDigit:</strong></p>
<p><strong>mov bl,‘0’</strong></p>
<p><strong>CTSLoop:</strong></p>
<p><strong>mov ax,[CurrentCountLow]</strong></p>
<p><strong>mov dx,[CurrentCountHigh]</strong></p>
<p><strong>sub ax,PowersOfTen[di]</strong></p>
<p><strong>sbb dx,PowersOfTen[di+2]</strong></p>
<p><strong>jc CTSNextPowerDown</strong></p>
<p><strong>inc bl</strong></p>
<p><strong>mov [CurrentCountLow],ax</strong></p>
<p><strong>mov [CurrentCountHigh],dx</strong></p>
<p><strong>jmp CTSLoop</strong></p>
<p><strong>CTSNextPowerDown:</strong></p>
<p><strong>mov [si],bl</strong></p>
<p><strong>inc si</strong></p>
<p><strong>sub di,4</strong></p>
<p><strong>jns CTSNextDigit</strong></p>
<p><strong>;</strong></p>
<p><strong>;</strong></p>
<p><strong>; Print the results.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ah,9</strong></p>
<p><strong>mov dx,offset OutputStr</strong></p>
<p><strong>int 21h</strong></p>
<p><strong>;</strong></p>
<p><strong>ZTimerReportDone:</strong></p>
<p><strong>pop ds</strong></p>
<p><strong>pop di</strong></p>
<p><strong>pop si</strong></p>
<p><strong>pop dx</strong></p>
<p><strong>pop cx</strong></p>
<p><strong>pop bx</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>ret</strong></p>
<p><strong>ZTimerReport endp</strong></p>
<p><strong>Code ends</strong></p>
<p><strong>End</strong></p>
</section>
<section id="listing-2-6" class="level2">
<h2>Listing 2-6</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 2-6 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Program to measure performance of code that takes longer than</strong></p>
<p><strong>; 54 ms to execute. (LZTEST.ASM)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Link with LZTIMER.ASM (Listing 2-5). LZTEST.BAT (Listing 2-7)</strong></p>
<p><strong>; can be used to assemble and link both files. Code to be</strong></p>
<p><strong>; measured must be in the file TESTCODE; Listing 2-8 shows</strong></p>
<p><strong>; a sample TESTCODE file.</strong></p>
<p><strong>;</strong></p>
<p><strong>; By Michael Abrash 4/26/89</strong></p>
<p><strong>;</strong></p>
<p><strong>mystack segment para stack ‘STACK’</strong></p>
<p><strong>db 512 dup(?)</strong></p>
<p><strong>mystack ends</strong></p>
<p><strong>;</strong></p>
<p><strong>Code segment para public ‘CODE’</strong></p>
<p><strong>assume cs:Code, ds:Code</strong></p>
<p><strong>extrn ZTimerOn:near, ZTimerOff:near, ZTimerReport:near</strong></p>
<p><strong>Start proc near</strong></p>
<p><strong>push cs</strong></p>
<p><strong>pop ds ;point DS to the code segment,</strong></p>
<p><strong>; so data as well as code can easily</strong></p>
<p><strong>; be included in TESTCODE</strong></p>
<p><strong>;</strong></p>
<p><strong>; Delay for 6-7 seconds, to let the Enter keystroke that started the</strong></p>
<p><strong>; program come back up.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ah,2ch</strong></p>
<p><strong>int 21h ;get the current time</strong></p>
<p><strong>mov bh,dh ;set the current time aside</strong></p>
<p><strong>DelayLoop:</strong></p>
<p><strong>mov ah,2ch</strong></p>
<p><strong>push bx ;preserve start time</strong></p>
<p><strong>int 21h ;get time</strong></p>
<p><strong>pop bx ;retrieve start time</strong></p>
<p><strong>cmp dh,bh ;is the new seconds count less than</strong></p>
<p><strong>; the start seconds count?</strong></p>
<p><strong>jnb CheckDelayTime ;no</strong></p>
<p><strong>add dh,60 ;yes, a minute must have turned over,</strong></p>
<p><strong>; so add one minute</strong></p>
<p><strong>CheckDelayTime:</strong></p>
<p><strong>sub dh,bh ;get time that’s passed</strong></p>
<p><strong>cmp dh,7 ;has it been more than 6 seconds yet?</strong></p>
<p><strong>jb DelayLoop ;not yet</strong></p>
<p><strong>;</strong></p>
<p><strong>include TESTCODE ;code to be measured, including calls</strong></p>
<p><strong>; to ZTimerOn and ZTimerOff</strong></p>
<p><strong>;</strong></p>
<p><strong>; Display the results.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerReport</strong></p>
<p><strong>;</strong></p>
<p><strong>; Terminate the program.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ah,4ch</strong></p>
<p><strong>int 21h</strong></p>
<p><strong>Start endp</strong></p>
<p><strong>Code ends</strong></p>
<p><strong>end Start</strong></p>
</section>
<section id="listing-2-7" class="level2">
<h2>Listing 2-7</h2>
<p><strong>echo off</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem *** Listing 2-7 ***</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem ***************************************************************</strong></p>
<p><strong>rem * Batch file LZTIME.BAT, which builds and runs the *</strong></p>
<p><strong>rem * long-period Zen timer program LZTEST.EXE to time the code *</strong></p>
<p><strong>rem * named as the command-line parameter. Listing 2-5 must be *</strong></p>
<p><strong>rem * named LZTIMER.ASM, and Listing 2-6 must be named *</strong></p>
<p><strong>rem * LZTEST.ASM. To time the code in LST2-8, you’d type the *</strong></p>
<p><strong>rem * DOS command: *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * lztime lst2-8 *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * Note that MASM and LINK must be in the current directory or *</strong></p>
<p><strong>rem * on the current path in order for this batch file to work. *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * This batch file can be speeded up by assembling LZTIMER.ASM *</strong></p>
<p><strong>rem * once, then removing the lines: *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * masm lztimer; *</strong></p>
<p><strong>rem * if errorlevel 1 goto errorend *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * from this file. *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * By Michael Abrash 4/26/89 *</strong></p>
<p><strong>rem ***************************************************************</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem Make sure a file to test was specified.</strong></p>
<p><strong>rem</strong></p>
<p><strong>if not x%1==x goto ckexist</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>echo * Please specify a file to test. *</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>goto end</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem Make sure the file exists.</strong></p>
<p><strong>rem</strong></p>
<p><strong>:ckexist</strong></p>
<p><strong>if exist %1 goto docopy</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>echo * The specified file, “%1,” doesn’t exist.</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>goto end</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem copy the file to measure to TESTCODE.</strong></p>
<p><strong>:docopy</strong></p>
<p><strong>copy %1 testcode</strong></p>
<p><strong>masm lztest;</strong></p>
<p><strong>if errorlevel 1 goto errorend</strong></p>
<p><strong>masm lztimer;</strong></p>
<p><strong>if errorlevel 1 goto errorend</strong></p>
<p><strong>link lztest+lztimer;</strong></p>
<p><strong>if errorlevel 1 goto errorend</strong></p>
<p><strong>lztest</strong></p>
<p><strong>goto end</strong></p>
<p><strong>:errorend</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>echo * An error occurred while building the long-period Zen timer. *</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>:end</strong></p>
</section>
<section id="listing-2-8" class="level2">
<h2>Listing 2-8</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 2-8 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of 20000 loads of AL from</strong></p>
<p><strong>; memory. (Use by renaming to TESTCODE, which is</strong></p>
<p><strong>; included by LZTEST.ASM (Listing 2-6). LZTIME.BAT</strong></p>
<p><strong>; (Listing 2-7) does this, along with all assembly</strong></p>
<p><strong>; and linking.)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: takes about 10 minutes to assemble on a PC with</strong></p>
<p><strong>; MASM 5.0.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip ;jump around defined data</strong></p>
<p><strong>;</strong></p>
<p><strong>MemVar db ?</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>;</strong></p>
<p><strong>; Start timing.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>;</strong></p>
<p><strong>rept 20000</strong></p>
<p><strong>mov al,[MemVar]</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Stop timing.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-3-1" class="level2">
<h2>Listing 3-1</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 3-1 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Times speed of memory access to Enhanced Graphics</strong></p>
<p><strong>; Adapter graphics mode display memory at A000:0000.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,0010h</strong></p>
<p><strong>int 10h ;select hi-res EGA graphics</strong></p>
<p><strong>; mode 10 hex (AH=0 selects</strong></p>
<p><strong>; BIOS set mode function,</strong></p>
<p><strong>; with AL=mode to select)</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,0a000h</strong></p>
<p><strong>mov ds,ax</strong></p>
<p><strong>mov es,ax ;move to &amp; from same segment</strong></p>
<p><strong>sub si,si ;move to &amp; from same offset</strong></p>
<p><strong>mov di,si</strong></p>
<p><strong>mov cx,800h ;move 2K words</strong></p>
<p><strong>cld</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rep movsw ;simply read each of the first</strong></p>
<p><strong>; 2K words of the destination segment,</strong></p>
<p><strong>; writing each byte immediately back</strong></p>
<p><strong>; to the same address. No memory</strong></p>
<p><strong>; locations are actually altered; this</strong></p>
<p><strong>; is just to measure memory access</strong></p>
<p><strong>; times</strong></p>
<p><strong>call ZTimerOff</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,0003h</strong></p>
<p><strong>int 10h ;return to text mode</strong></p>
<p><strong>;</strong></p>
</section>
<section id="listing-3-2" class="level2">
<h2>Listing 3-2</h2>
<p><strong>; *** Listing 3-2 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Times speed of memory access to normal system</strong></p>
<p><strong>; memory.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,ds</strong></p>
<p><strong>mov es,ax ;move to &amp; from same segment</strong></p>
<p><strong>sub si,si ;move to &amp; from same offset</strong></p>
<p><strong>mov di,si</strong></p>
<p><strong>mov cx,800h ;move 2K words</strong></p>
<p><strong>cld</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rep movsw ;simply read each of the first</strong></p>
<p><strong>; 2K words of the destination segment,</strong></p>
<p><strong>; writing each byte immediately back</strong></p>
<p><strong>; to the same address. No memory</strong></p>
<p><strong>; locations are actually altered; this</strong></p>
<p><strong>; is just to measure memory access</strong></p>
<p><strong>; times</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-4-1" class="level2">
<h2>Listing 4-1</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 4-1 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of a loop which uses a</strong></p>
<p><strong>; byte-sized memory variable as the loop counter.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>Counter db 100</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>LoopTop:</strong></p>
<p><strong>dec [Counter]</strong></p>
<p><strong>jnz LoopTop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-4-2" class="level2">
<h2>Listing 4-2</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 4-2 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of a loop which uses a</strong></p>
<p><strong>; word-sized memory variable as the loop counter.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>Counter dw 100</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>LoopTop:</strong></p>
<p><strong>dec [Counter]</strong></p>
<p><strong>jnz LoopTop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-4-3" class="level2">
<h2>Listing 4-3</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 4-3 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of reading 1000 words</strong></p>
<p><strong>; from memory with 1000 word-sized accesses.</strong></p>
<p><strong>;</strong></p>
<p><strong>sub si,si</strong></p>
<p><strong>mov cx,1000</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rep lodsw</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-4-4" class="level2">
<h2>Listing 4-4</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 4-4 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of reading 1000 words</strong></p>
<p><strong>; from memory with 2000 byte-sized accesses.</strong></p>
<p><strong>;</strong></p>
<p><strong>sub si,si</strong></p>
<p><strong>mov cx,2000</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rep lodsb</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-4-5" class="level2">
<h2>Listing 4-5</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 4-5 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of 1000 SHR instructions</strong></p>
<p><strong>; in a row. Since SHR executes in 2 cycles but is</strong></p>
<p><strong>; 2 bytes long, the prefetch queue is always empty,</strong></p>
<p><strong>; and prefetching time determines the overall</strong></p>
<p><strong>; performance of the code.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>shr ax,1</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-4-6" class="level2">
<h2>Listing 4-6</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 4-6 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of 1000 MUL/SHR instruction</strong></p>
<p><strong>; pairs in a row. The lengthy execution time of MUL</strong></p>
<p><strong>; should keep the prefetch queue from ever emptying.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov cx,1000</strong></p>
<p><strong>sub ax,ax</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>mul ax</strong></p>
<p><strong>shr ax,1</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-4-7" class="level2">
<h2>Listing 4-7</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 4-7 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of repeated MOV AL,0 instructions,</strong></p>
<p><strong>; which take 4 cycles each according to Intel’s official</strong></p>
<p><strong>; specifications.</strong></p>
<p><strong>;</strong></p>
<p><strong>sub ax,ax</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>mov al,0</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-4-8" class="level2">
<h2>Listing 4-8</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 4-8 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of repeated SUB AL,ALinstructions,</strong></p>
<p><strong>; which take 3 cycles each according to Intel’s official</strong></p>
<p><strong>; specifications.</strong></p>
<p><strong>;</strong></p>
<p><strong>sub ax,ax</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>sub al,al</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-4-9" class="level2">
<h2>Listing 4-9</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 4-9 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of repeated MULinstructions,</strong></p>
<p><strong>; which allow the prefetch queue to be full at all times,</strong></p>
<p><strong>; to demonstrate a case in which DRAM refresh has no impact</strong></p>
<p><strong>; on code performance.</strong></p>
<p><strong>;</strong></p>
<p><strong>sub ax,ax</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>mul ax</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-4-10" class="level2">
<h2>Listing 4-10</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 4-10 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of repeated SHR instructions,</strong></p>
<p><strong>; which empty the prefetch queue, to demonstrate the</strong></p>
<p><strong>; worst-case impact of DRAM refresh on code performance.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>shr ax,1</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-4-11" class="level2">
<h2>Listing 4-11</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 4-11 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Times speed of memory access to Enhanced Graphics</strong></p>
<p><strong>; Adapter graphics mode display memory at A000:0000.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,0010h</strong></p>
<p><strong>int 10h ;select hi-res EGA graphics</strong></p>
<p><strong>; mode 10 hex (AH=0 selects</strong></p>
<p><strong>; BIOS set mode function,</strong></p>
<p><strong>; with AL=mode to select)</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,0a000h</strong></p>
<p><strong>mov ds,ax</strong></p>
<p><strong>mov es,ax ;move to &amp; from same segment</strong></p>
<p><strong>sub si,si ;move to &amp; from same offset</strong></p>
<p><strong>mov di,si</strong></p>
<p><strong>mov cx,800h ;move 2K words</strong></p>
<p><strong>cld</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rep movsw ;simply read each of the first</strong></p>
<p><strong>; 2K words of the destination segment,</strong></p>
<p><strong>; writing each byte immediately back</strong></p>
<p><strong>; to the same address. No memory</strong></p>
<p><strong>; locations are actually altered; this</strong></p>
<p><strong>; is just to measure memory access</strong></p>
<p><strong>; times</strong></p>
<p><strong>call ZTimerOff</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,0003h</strong></p>
<p><strong>int 10h ;return to text mode</strong></p>
</section>
<section id="listing-4-12" class="level2">
<h2>Listing 4-12</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 4-12 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Times speed of memory access to normal system</strong></p>
<p><strong>; memory.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,ds</strong></p>
<p><strong>mov es,ax ;move to &amp; from same segment</strong></p>
<p><strong>sub si,si ;move to &amp; from same offset</strong></p>
<p><strong>mov di,si</strong></p>
<p><strong>mov cx,800h ;move 2K words</strong></p>
<p><strong>cld</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rep movsw ;simply read each of the first</strong></p>
<p><strong>; 2K words of the destination segment,</strong></p>
<p><strong>; writing each byte immediately back</strong></p>
<p><strong>; to the same address. No memory</strong></p>
<p><strong>; locations are actually altered; this</strong></p>
<p><strong>; is just to measure memory access</strong></p>
<p><strong>; times</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-5-1" class="level2">
<h2>Listing 5-1</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 5-1 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a byte via AH endlessly, for the purpose of</strong></p>
<p><strong>; illustrating the complexity of a complete understanding</strong></p>
<p><strong>; of even the simplest instruction sequence on the PC.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: This program is an endless loop, and never exits!</strong></p>
<p><strong>;</strong></p>
<p><strong>; Compile and link as a standalone program; not intended</strong></p>
<p><strong>; for use with the Zen timer.</strong></p>
<p><strong>;</strong></p>
<p><strong>mystack segment para stack ‘STACK’</strong></p>
<p><strong>db 512 dup(?)</strong></p>
<p><strong>mystack ends</strong></p>
<p><strong>;</strong></p>
<p><strong>Code segment word public ‘CODE’</strong></p>
<p><strong>assume cs:Code, ds:Code</strong></p>
<p><strong>Start proc near</strong></p>
<p><strong>push cs</strong></p>
<p><strong>pop ds</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>i db 1</strong></p>
<p><strong>j db 0</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>mov ah,ds:[i]</strong></p>
<p><strong>mov ds:[j],ah</strong></p>
<p><strong>endm</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>Start endp</strong></p>
<p><strong>Code ends</strong></p>
<p><strong>end Start</strong></p>
</section>
<section id="listing-7-1" class="level2">
<h2>Listing 7-1</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-1 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Calculates the 16-bit sum of all bytes in a 64Kb block.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Time with LZTIME.BAT, since this takes more than</strong></p>
<p><strong>; 54 ms to run.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>sub bx,bx ;we’ll just sum the data segment</strong></p>
<p><strong>sub cx,cx ;count 64K bytes</strong></p>
<p><strong>mov ax,cx ;set initial sum to 0</strong></p>
<p><strong>mov dh,ah ;set DH to 0 for summing later</strong></p>
<p><strong>SumLoop:</strong></p>
<p><strong>mov dl,[bx] ;get this byte</strong></p>
<p><strong>add ax,dx ;add the byte to the sum</strong></p>
<p><strong>inc bx ;point to the next byte</strong></p>
<p><strong>loop SumLoop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-2" class="level2">
<h2>Listing 7-2</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-2 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Calculates the 16-bit sum of all bytes in a 128Kb block.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Time with LZTIME.BAT, since this takes more than</strong></p>
<p><strong>; 54 ms to run.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>sub bx,bx ;we’ll just sum the 128Kb starting</strong></p>
<p><strong>; at DS:0</strong></p>
<p><strong>sub cx,cx ;count 128K bytes with SI:CX</strong></p>
<p><strong>mov si,2</strong></p>
<p><strong>mov ax,cx ;set initial sum to 0</strong></p>
<p><strong>mov dh,ah ;set DH to 0 for summing later</strong></p>
<p><strong>SumLoop:</strong></p>
<p><strong>mov dl,[bx] ;get this byte</strong></p>
<p><strong>add ax,dx ;add the byte to the sum</strong></p>
<p><strong>inc bx ;point to the next byte</strong></p>
<p><strong>and bx,0fh ;time to advance the segment?</strong></p>
<p><strong>jnz SumLoopEnd ;not yet</strong></p>
<p><strong>mov di,ds ;advance the segment by 1; since BX</strong></p>
<p><strong>inc di ; has just gone from 15 to 0, we’ve</strong></p>
<p><strong>mov ds,di ; advanced 1 byte in all</strong></p>
<p><strong>SumLoopEnd:</strong></p>
<p><strong>loop SumLoop</strong></p>
<p><strong>dec si</strong></p>
<p><strong>jnz SumLoop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-3" class="level2">
<h2>Listing 7-3</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-3 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Calculates the 16-bit sum of all bytes in a 128Kb block</strong></p>
<p><strong>; using optimized code that takes advantage of the knowledge</strong></p>
<p><strong>; that the first byte summed is at offset 0 in its segment.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Time with LZTIME.BAT, since this takes more than</strong></p>
<p><strong>; 54 ms to run.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>sub bx,bx ;we’ll just sum the 128Kb starting</strong></p>
<p><strong>; at DS:0</strong></p>
<p><strong>mov cx,2 ;count two 64Kb blocks</strong></p>
<p><strong>mov ax,bx ;set initial sum to 0</strong></p>
<p><strong>mov dh,ah ;set DH to 0 for summing later</strong></p>
<p><strong>SumLoop:</strong></p>
<p><strong>mov dl,[bx] ;get this byte</strong></p>
<p><strong>add ax,dx ;add the byte to the sum</strong></p>
<p><strong>inc bx ;point to the next byte</strong></p>
<p><strong>jnz SumLoop ;go until we wrap at the end of a</strong></p>
<p><strong>; 64Kb block</strong></p>
<p><strong>mov si,ds</strong></p>
<p><strong>add si,1000h ;advance the segment by 64K bytes</strong></p>
<p><strong>mov ds,si</strong></p>
<p><strong>loop SumLoop ;count down 64Kb blocks</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-4" class="level2">
<h2>Listing 7-4</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-4 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Adds one far array to another far array as a high-level</strong></p>
<p><strong>; language would, loading each far pointer with LES every</strong></p>
<p><strong>; time it’s needed.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>Array1 db ARRAY_LENGTH dup (1)</strong></p>
<p><strong>Array2 db ARRAY_LENGTH dup (2)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Adds one byte-sized array to another byte-sized array.</strong></p>
<p><strong>; C-callable.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input: parameters on stack as in AddArraysParms</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, BX, CX, ES</strong></p>
<p><strong>;</strong></p>
<p><strong>AddArraysParms struc</strong></p>
<p><strong>dw ? ;pushed BP</strong></p>
<p><strong>dw ? ;return address</strong></p>
<p><strong>FarPtr1 dd ? ;pointer to array to be added to</strong></p>
<p><strong>FarPtr2 dd ? ;pointer to array to add to the</strong></p>
<p><strong>; other array</strong></p>
<p><strong>AddArraysLength dw ? ;# of bytes to add</strong></p>
<p><strong>AddArraysParms ends</strong></p>
<p><strong>;</strong></p>
<p><strong>AddArrays proc near</strong></p>
<p><strong>push bp ;save caller’s BP</strong></p>
<p><strong>mov bp,sp ;point to stack frame</strong></p>
<p><strong>mov cx,[bp+AddArraysLength]</strong></p>
<p><strong>;get the length to add</strong></p>
<p><strong>AddArraysLoop:</strong></p>
<p><strong>les bx,[bp+FarPtr2] ;point to the array to add</strong></p>
<p><strong>; from</strong></p>
<p><strong>inc word ptr [bp+FarPtr2]</strong></p>
<p><strong>;point to the next byte</strong></p>
<p><strong>; of the array to add from</strong></p>
<p><strong>mov al,es:[bx] ;get the array element to</strong></p>
<p><strong>; add</strong></p>
<p><strong>les bx,[bp+FarPtr1] ;point to the array to add</strong></p>
<p><strong>; to</strong></p>
<p><strong>inc word ptr [bp+FarPtr1]</strong></p>
<p><strong>;point to the next byte</strong></p>
<p><strong>; of the array to add to</strong></p>
<p><strong>add es:[bx],al ;add to the array</strong></p>
<p><strong>loop AddArraysLoop</strong></p>
<p><strong>pop bp ;restore caller’s BP</strong></p>
<p><strong>ret</strong></p>
<p><strong>AddArrays endp</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov ax,ARRAY_LENGTH</strong></p>
<p><strong>push ax ;pass the length to add</strong></p>
<p><strong>push ds ;pass segment of Array2</strong></p>
<p><strong>mov ax,offset Array2</strong></p>
<p><strong>push ax ;pass offset of Array2</strong></p>
<p><strong>push ds ;pass segment of Array1</strong></p>
<p><strong>mov ax,offset Array1</strong></p>
<p><strong>push ax ;pass offset of Array1</strong></p>
<p><strong>call AddArrays</strong></p>
<p><strong>add sp,10 ;clear the parameters</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-5" class="level2">
<h2>Listing 7-5</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-5 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Adds one far array to another far array as only assembler</strong></p>
<p><strong>; can, loading the two far pointers once and keeping them in</strong></p>
<p><strong>; the registers during the entire loop for speed.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>Array1 db ARRAY_LENGTH dup (1)</strong></p>
<p><strong>Array2 db ARRAY_LENGTH dup (2)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Adds one byte-sized array to another byte-sized array.</strong></p>
<p><strong>; C-callable.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input: parameters on stack as in AddArraysParms</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, BX, CX, DX, ES</strong></p>
<p><strong>;</strong></p>
<p><strong>AddArraysParms struc</strong></p>
<p><strong>dw ? ;pushed BP</strong></p>
<p><strong>dw ? ;return address</strong></p>
<p><strong>FarPtr1 dd ? ;pointer to array to be added to</strong></p>
<p><strong>FarPtr2 dd ? ;pointer to array to add to the</strong></p>
<p><strong>; other array</strong></p>
<p><strong>AddArraysLength dw ? ;# of bytes to add</strong></p>
<p><strong>AddArraysParms ends</strong></p>
<p><strong>;</strong></p>
<p><strong>AddArrays proc near</strong></p>
<p><strong>push bp ;save caller’s BP</strong></p>
<p><strong>mov bp,sp ;point to stack frame</strong></p>
<p><strong>push si ;save registers used by many</strong></p>
<p><strong>push di ; C compilers for register</strong></p>
<p><strong>; variables</strong></p>
<p><strong>mov cx,[bp+AddArraysLength]</strong></p>
<p><strong>;get the length to add</strong></p>
<p><strong>les si,[bp+FarPtr2] ;point to the array to add</strong></p>
<p><strong>; from</strong></p>
<p><strong>mov dx,es ;set aside the segment</strong></p>
<p><strong>les bx,[bp+FarPtr1] ;point to the array to add</strong></p>
<p><strong>; to</strong></p>
<p><strong>mov di,es ;set aside the segment</strong></p>
<p><strong>AddArraysLoop:</strong></p>
<p><strong>mov es,dx ;point ES:SI to the next</strong></p>
<p><strong>; byte of the array to add</strong></p>
<p><strong>; from</strong></p>
<p><strong>mov al,es:[si] ;get the array element to</strong></p>
<p><strong>; add</strong></p>
<p><strong>inc si ;point to the next byte of</strong></p>
<p><strong>; the array to add from</strong></p>
<p><strong>mov es,di ;point ES:BX to the next</strong></p>
<p><strong>; byte of the array to add</strong></p>
<p><strong>; to</strong></p>
<p><strong>add es:[bx],al ;add to the array</strong></p>
<p><strong>inc bx ;point to the next byte of</strong></p>
<p><strong>; the array to add to</strong></p>
<p><strong>loop AddArraysLoop</strong></p>
<p><strong>pop di ;restore registers used by</strong></p>
<p><strong>pop si ; many C compilers for</strong></p>
<p><strong>; register variables</strong></p>
<p><strong>pop bp ;restore caller’s BP</strong></p>
<p><strong>ret</strong></p>
<p><strong>AddArrays endp</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov ax,ARRAY_LENGTH</strong></p>
<p><strong>push ax ;pass the length to add</strong></p>
<p><strong>push ds ;pass segment of Array2</strong></p>
<p><strong>mov ax,offset Array2</strong></p>
<p><strong>push ax ;pass offset of Array2</strong></p>
<p><strong>push ds ;pass segment of Array1</strong></p>
<p><strong>mov ax,offset Array1</strong></p>
<p><strong>push ax ;pass offset of Array1</strong></p>
<p><strong>call AddArrays</strong></p>
<p><strong>add sp,10 ;clear the parameters</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-6" class="level2">
<h2>Listing 7-6</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-6 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Adds one far array to another far array by temporarily</strong></p>
<p><strong>; switching segments in order to allow the use of the most</strong></p>
<p><strong>; efficient possible instructions within the loop.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>Array1 db ARRAY_LENGTH dup (1)</strong></p>
<p><strong>Array2 db ARRAY_LENGTH dup (2)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Adds one byte-sized array to another byte-sized array.</strong></p>
<p><strong>; C-callable.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input: parameters on stack as in AddArraysParms</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, BX, CX, ES</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>AddArraysParms struc</strong></p>
<p><strong>dw ? ;pushed BP</strong></p>
<p><strong>dw ? ;return address</strong></p>
<p><strong>FarPtr1 dd ? ;pointer to array to be added to</strong></p>
<p><strong>FarPtr2 dd ? ;pointer to array to add to the</strong></p>
<p><strong>; other array</strong></p>
<p><strong>AddArraysLength dw ? ;# of bytes to add</strong></p>
<p><strong>AddArraysParms ends</strong></p>
<p><strong>;</strong></p>
<p><strong>AddArrays proc near</strong></p>
<p><strong>push bp ;save caller’s BP</strong></p>
<p><strong>mov bp,sp ;point to stack frame</strong></p>
<p><strong>push si ;save register used by many</strong></p>
<p><strong>; C compilers for register</strong></p>
<p><strong>; variables</strong></p>
<p><strong>push ds ;save normal DS, since we’re</strong></p>
<p><strong>; going to switch data</strong></p>
<p><strong>; segments for the duration</strong></p>
<p><strong>; of the loop</strong></p>
<p><strong>mov cx,[bp+AddArraysLength]</strong></p>
<p><strong>;get the length to add</strong></p>
<p><strong>les bx,[bp+FarPtr1] ;point to the array to add</strong></p>
<p><strong>; to</strong></p>
<p><strong>lds si,[bp+FarPtr2] ;point to the array to add</strong></p>
<p><strong>; from</strong></p>
<p><strong>cld ;make LODSB increment SI</strong></p>
<p><strong>AddArraysLoop:</strong></p>
<p><strong>lodsb ;get the array element to</strong></p>
<p><strong>; add</strong></p>
<p><strong>add es:[bx],al ;add to the other array</strong></p>
<p><strong>inc bx ;point to the next byte of</strong></p>
<p><strong>; the array to add to</strong></p>
<p><strong>loop AddArraysLoop</strong></p>
<p><strong>pop ds ;restore normal DS</strong></p>
<p><strong>pop si ;restore register used by</strong></p>
<p><strong>; many C compilers for</strong></p>
<p><strong>; register variables</strong></p>
<p><strong>pop bp ;restore caller’s BP</strong></p>
<p><strong>ret</strong></p>
<p><strong>AddArrays endp</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov ax,ARRAY_LENGTH</strong></p>
<p><strong>push ax ;pass the length to add</strong></p>
<p><strong>push ds ;pass segment of Array2</strong></p>
<p><strong>mov ax,offset Array2</strong></p>
<p><strong>push ax ;pass offset of Array2</strong></p>
<p><strong>push ds ;pass segment of Array1</strong></p>
<p><strong>mov ax,offset Array1</strong></p>
<p><strong>push ax ;pass offset of Array1</strong></p>
<p><strong>call AddArrays</strong></p>
<p><strong>add sp,10 ;clear the parameters</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-7" class="level2">
<h2>Listing 7-7</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-7 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Strips the high bit of every byte in a byte-sized array,</strong></p>
<p><strong>; using a segment override prefix.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>TestArray db ARRAY_LENGTH dup (0ffh)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Strips the high bit of every byte in a byte-sized array.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = length of array</strong></p>
<p><strong>; ES:BX = pointer to start of array</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, BX</strong></p>
<p><strong>;</strong></p>
<p><strong>StripHighBits proc near</strong></p>
<p><strong>mov al,not 80h ;bit pattern for stripping</strong></p>
<p><strong>; high bits, loaded into a</strong></p>
<p><strong>; register outside the loop</strong></p>
<p><strong>; so we can use fast</strong></p>
<p><strong>; register-to-memory ANDing</strong></p>
<p><strong>; inside the loop</strong></p>
<p><strong>StripHighBitsLoop:</strong></p>
<p><strong>and es:[bx],al ;strip this byte’s high bit</strong></p>
<p><strong>inc bx ;point to next byte</strong></p>
<p><strong>loop StripHighBitsLoop</strong></p>
<p><strong>ret</strong></p>
<p><strong>StripHighBits endp</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov bx,seg TestArray</strong></p>
<p><strong>mov es,bx</strong></p>
<p><strong>mov bx,offset TestArray ;point to array</strong></p>
<p><strong>; which will have</strong></p>
<p><strong>; high bits stripped</strong></p>
<p><strong>call StripHighBits ;strip the high bits</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-8" class="level2">
<h2>Listing 7-8</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-8 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Strips the high bit of every byte in a byte-sized array</strong></p>
<p><strong>; without using a segment override prefix.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>TestArray db ARRAY_LENGTH dup (0ffh)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Strips the high bit of every byte in a byte-sized array.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = length of array</strong></p>
<p><strong>; ES:BX = pointer to start of array</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, BX</strong></p>
<p><strong>;</strong></p>
<p><strong>StripHighBits proc near</strong></p>
<p><strong>push ds ;save normal DS</strong></p>
<p><strong>mov ax,es ;point DS to the array’s</strong></p>
<p><strong>mov ds,ax ; segment</strong></p>
<p><strong>mov al,not 80h ;bit pattern for stripping</strong></p>
<p><strong>; high bits, loaded into a</strong></p>
<p><strong>; register outside the loop</strong></p>
<p><strong>; so we can use fast</strong></p>
<p><strong>; register-to-memory ANDing</strong></p>
<p><strong>; inside the loop</strong></p>
<p><strong>StripHighBitsLoop:</strong></p>
<p><strong>and [bx],al ;strip this byte’s high bit</strong></p>
<p><strong>inc bx ;point to next byte</strong></p>
<p><strong>loop StripHighBitsLoop</strong></p>
<p><strong>pop ds ;restore normal DS</strong></p>
<p><strong>ret</strong></p>
<p><strong>StripHighBits endp</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov bx,seg TestArray</strong></p>
<p><strong>mov es,bx</strong></p>
<p><strong>mov bx,offset TestArray ;point to array</strong></p>
<p><strong>; which will have</strong></p>
<p><strong>; high bits stripped</strong></p>
<p><strong>call StripHighBits ;strip the high bits</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-9" class="level2">
<h2>Listing 7-9</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-9 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Adds up the elements of a byte-sized array using</strong></p>
<p><strong>; base+index+displacement addressing inside the loop.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>TestArray db ARRAY_LENGTH dup (1)</strong></p>
<p><strong>TEST_START_OFFSET equ 200 ;we’ll add elements 200-299</strong></p>
<p><strong>TEST_LENGTH equ 100 ; of TestArray</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov bx,TEST_START_OFFSET</strong></p>
<p><strong>;for base+index+displacement</strong></p>
<p><strong>sub si,si ; addressing</strong></p>
<p><strong>sub ax,ax ;initialize sum</strong></p>
<p><strong>sub dl,dl ;store 0 in DL so we can use</strong></p>
<p><strong>; it for faster register-</strong></p>
<p><strong>; register adds in the loop</strong></p>
<p><strong>mov cx,TEST_LENGTH ;# of bytes to add</strong></p>
<p><strong>SumArrayLoop:</strong></p>
<p><strong>add al,[TestArray+bx+si] ;add in the next byte</strong></p>
<p><strong>adc ah,dl ; to the 16-bit sum</strong></p>
<p><strong>inc si ;point to next byte</strong></p>
<p><strong>loop SumArrayLoop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-10" class="level2">
<h2>Listing 7-10</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-10 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Adds up the elements of a byte-sized array using</strong></p>
<p><strong>; base+index addressing inside the loop.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>TestArray db ARRAY_LENGTH dup (1)</strong></p>
<p><strong>TEST_START_OFFSET equ 200 ;we’ll add elements 200-299</strong></p>
<p><strong>TEST_LENGTH equ 100 ; of TestArray</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov bx,offset TestArray+TEST_START_OFFSET</strong></p>
<p><strong>;build the array start</strong></p>
<p><strong>; offset right into the</strong></p>
<p><strong>; base so we can use</strong></p>
<p><strong>; base+index addressing,</strong></p>
<p><strong>sub si,si ; with no displacement</strong></p>
<p><strong>sub ax,ax ;initialize sum</strong></p>
<p><strong>sub dl,dl ;store 0 in DL so we can use</strong></p>
<p><strong>; it for faster register-</strong></p>
<p><strong>; register adds in the loop</strong></p>
<p><strong>mov cx,TEST_LENGTH ;# of bytes to add</strong></p>
<p><strong>SumArrayLoop:</strong></p>
<p><strong>add al,[bx+si] ;add in the next byte</strong></p>
<p><strong>adc ah,dl ; to the 16-bit sum</strong></p>
<p><strong>inc si ;point to next byte</strong></p>
<p><strong>loop SumArrayLoop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-11" class="level2">
<h2>Listing 7-11</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-11 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Adds up the elements of a byte-sized array using</strong></p>
<p><strong>; base-only addressing inside the loop.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>TestArray db ARRAY_LENGTH dup (1)</strong></p>
<p><strong>TEST_START_OFFSET equ 200 ;we’ll add elements 200-299</strong></p>
<p><strong>TEST_LENGTH equ 100 ; of TestArray</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov bx,offset TestArray+TEST_START_OFFSET</strong></p>
<p><strong>;build the array start</strong></p>
<p><strong>; offset right into the</strong></p>
<p><strong>; base so we can use</strong></p>
<p><strong>; base addressing, with no</strong></p>
<p><strong>; displacement</strong></p>
<p><strong>sub ax,ax ;initialize sum</strong></p>
<p><strong>sub dl,dl ;store 0 in DL so we can use</strong></p>
<p><strong>; it for faster register-</strong></p>
<p><strong>; register adds in the loop</strong></p>
<p><strong>mov cx,TEST_LENGTH ;# of bytes to add</strong></p>
<p><strong>SumArrayLoop:</strong></p>
<p><strong>add al,[bx] ;add in the next byte</strong></p>
<p><strong>adc ah,dl ; to the 16-bit sum</strong></p>
<p><strong>inc bx ;point to next byte</strong></p>
<p><strong>loop SumArrayLoop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-12" class="level2">
<h2>Listing 7-12</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-12 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Adds up the elements of a byte-sized array using</strong></p>
<p><strong>; base-only addressing inside the loop, and using</strong></p>
<p><strong>; an immediate operand with ADC.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>TestArray db ARRAY_LENGTH dup (1)</strong></p>
<p><strong>TEST_START_OFFSET equ 200 ;we’ll add elements 200-299</strong></p>
<p><strong>TEST_LENGTH equ 100 ; of TestArray</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov bx,offset TestArray+TEST_START_OFFSET</strong></p>
<p><strong>;build the array start</strong></p>
<p><strong>; offset right into the</strong></p>
<p><strong>; base so we can use</strong></p>
<p><strong>; base+index addressing,</strong></p>
<p><strong>; with no displacement</strong></p>
<p><strong>sub ax,ax ;initialize sum</strong></p>
<p><strong>mov cx,TEST_LENGTH ;# of bytes to add</strong></p>
<p><strong>SumArrayLoop:</strong></p>
<p><strong>add al,[bx] ;add in the next byte</strong></p>
<p><strong>adc ah,0 ; to the 16-bit sum</strong></p>
<p><strong>inc bx ;point to next byte</strong></p>
<p><strong>loop SumArrayLoop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-13" class="level2">
<h2>Listing 7-13</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-13 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Adds up the elements of a byte-sized array using</strong></p>
<p><strong>; base-only addressing inside the loop, and using</strong></p>
<p><strong>; a memory operand with ADC.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>TestArray db ARRAY_LENGTH dup (1)</strong></p>
<p><strong>TEST_START_OFFSET equ 200 ;we’ll add elements 200-299</strong></p>
<p><strong>TEST_LENGTH equ 100 ; of TestArray</strong></p>
<p><strong>MemZero db 0 ;the constant value 0</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov bx,offset TestArray+TEST_START_OFFSET</strong></p>
<p><strong>;build the array start</strong></p>
<p><strong>; offset right into the</strong></p>
<p><strong>; base so we can use</strong></p>
<p><strong>; base+index addressing,</strong></p>
<p><strong>; with no displacement</strong></p>
<p><strong>sub ax,ax ;initialize sum</strong></p>
<p><strong>mov cx,TEST_LENGTH ;# of bytes to add</strong></p>
<p><strong>SumArrayLoop:</strong></p>
<p><strong>add al,[bx] ;add in the next byte</strong></p>
<p><strong>adc ah,[MemZero] ; to the 16-bit sum</strong></p>
<p><strong>inc bx ;point to next byte</strong></p>
<p><strong>loop SumArrayLoop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-14" class="level2">
<h2>Listing 7-14</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-14 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Performs bit-doubling of a byte in AL to a word in AX</strong></p>
<p><strong>; by using doubled shifts, one from each of two source</strong></p>
<p><strong>; registers. This approach avoids branching and is very</strong></p>
<p><strong>; fast according to officiaLinstruction timings, but is</strong></p>
<p><strong>; actually quite slow due to instruction prefetching.</strong></p>
<p><strong>;</strong></p>
<p><strong>; (Based on an approach used in “Optimizing for Speed,”</strong></p>
<p><strong>; by Michael Hoyt, Programmer’s Journal 4.2, March, 1986.)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to double each bit in a byte.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = byte to bit-double</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; AX = bit-doubled word</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, BX</strong></p>
<p><strong>;</strong></p>
<p><strong>DOUBLE_BYTE macro</strong></p>
<p><strong>mov ah,al ;put the byte to double in two</strong></p>
<p><strong>; registers</strong></p>
<p><strong>mov bx,ax</strong></p>
<p><strong>rept 8</strong></p>
<p><strong>shr bl,1 ;get the next bit to double</strong></p>
<p><strong>rcr ax,1 ;move it into the msb…</strong></p>
<p><strong>shr bh,1 ;…then get the bit again…</strong></p>
<p><strong>rcr ax,1 ;…and replicate it</strong></p>
<p><strong>endm</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>BYTE_TO_DOUBLE=0</strong></p>
<p><strong>rept 100</strong></p>
<p><strong>mov al,BYTE_TO_DOUBLE</strong></p>
<p><strong>DOUBLE_BYTE</strong></p>
<p><strong>BYTE_TO_DOUBLE=BYTE_TO_DOUBLE+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-15" class="level2">
<h2>Listing 7-15</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-15 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Performs very fast bit-doubling of a byte in AL to a</strong></p>
<p><strong>; word in AX by using a look-up table.</strong></p>
<p><strong>; This approach avoids both branching and the severe</strong></p>
<p><strong>; instruction-fetching penalty of the shift-based approach.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to double each bit in a byte.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = byte to bit-double</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; AX = bit-doubled word</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, BX</strong></p>
<p><strong>;</strong></p>
<p><strong>DOUBLE_BYTE macro</strong></p>
<p><strong>mov bl,al ;move the byte to look up to BL,</strong></p>
<p><strong>sub bh,bh ; make a word out of the value,</strong></p>
<p><strong>shl bx,1 ; and double the value so we can</strong></p>
<p><strong>; use it as a pointer into the</strong></p>
<p><strong>; table of word-sized doubled byte</strong></p>
<p><strong>; values</strong></p>
<p><strong>mov ax,[DoubledByteTable+bx]</strong></p>
<p><strong>;look up the doubled byte value</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>DOUBLED_VALUE=0</strong></p>
<p><strong>DoubledByteTable label word</strong></p>
<p><strong>dw 00000h,00003h,0000ch,0000fh,00030h,00033h,0003ch,0003fh</strong></p>
<p><strong>dw 000c0h,000c3h,000cch,000cfh,000f0h,000f3h,000fch,000ffh</strong></p>
<p><strong>dw 00300h,00303h,0030ch,0030fh,00330h,00333h,0033ch,0033fh</strong></p>
<p><strong>dw 003c0h,003c3h,003cch,003cfh,003f0h,003f3h,003fch,003ffh</strong></p>
<p><strong>dw 00c00h,00c03h,00c0ch,00c0fh,00c30h,00c33h,00c3ch,00c3fh</strong></p>
<p><strong>dw 00cc0h,00cc3h,00ccch,00ccfh,00cf0h,00cf3h,00cfch,00cffh</strong></p>
<p><strong>dw 00f00h,00f03h,00f0ch,00f0fh,00f30h,00f33h,00f3ch,00f3fh</strong></p>
<p><strong>dw 00fc0h,00fc3h,00fcch,00fcfh,00ff0h,00ff3h,00ffch,00fffh</strong></p>
<p><strong>;</strong></p>
<p><strong>dw 03000h,03003h,0300ch,0300fh,03030h,03033h,0303ch,0303fh</strong></p>
<p><strong>dw 030c0h,030c3h,030cch,030cfh,030f0h,030f3h,030fch,030ffh</strong></p>
<p><strong>dw 03300h,03303h,0330ch,0330fh,03330h,03333h,0333ch,0333fh</strong></p>
<p><strong>dw 033c0h,033c3h,033cch,033cfh,033f0h,033f3h,033fch,033ffh</strong></p>
<p><strong>dw 03c00h,03c03h,03c0ch,03c0fh,03c30h,03c33h,03c3ch,03c3fh</strong></p>
<p><strong>dw 03cc0h,03cc3h,03ccch,03ccfh,03cf0h,03cf3h,03cfch,03cffh</strong></p>
<p><strong>dw 03f00h,03f03h,03f0ch,03f0fh,03f30h,03f33h,03f3ch,03f3fh</strong></p>
<p><strong>dw 03fc0h,03fc3h,03fcch,03fcfh,03ff0h,03ff3h,03ffch,03fffh</strong></p>
<p><strong>;</strong></p>
<p><strong>dw 0c000h,0c003h,0c00ch,0c00fh,0c030h,0c033h,0c03ch,0c03fh</strong></p>
<p><strong>dw 0c0c0h,0c0c3h,0c0cch,0c0cfh,0c0f0h,0c0f3h,0c0fch,0c0ffh</strong></p>
<p><strong>dw 0c300h,0c303h,0c30ch,0c30fh,0c330h,0c333h,0c33ch,0c33fh</strong></p>
<p><strong>dw 0c3c0h,0c3c3h,0c3cch,0c3cfh,0c3f0h,0c3f3h,0c3fch,0c3ffh</strong></p>
<p><strong>dw 0cc00h,0cc03h,0cc0ch,0cc0fh,0cc30h,0cc33h,0cc3ch,0cc3fh</strong></p>
<p><strong>dw 0ccc0h,0ccc3h,0cccch,0cccfh,0ccf0h,0ccf3h,0ccfch,0ccffh</strong></p>
<p><strong>dw 0cf00h,0cf03h,0cf0ch,0cf0fh,0cf30h,0cf33h,0cf3ch,0cf3fh</strong></p>
<p><strong>dw 0cfc0h,0cfc3h,0cfcch,0cfcfh,0cff0h,0cff3h,0cffch,0cfffh</strong></p>
<p><strong>;</strong></p>
<p><strong>dw 0f000h,0f003h,0f00ch,0f00fh,0f030h,0f033h,0f03ch,0f03fh</strong></p>
<p><strong>dw 0f0c0h,0f0c3h,0f0cch,0f0cfh,0f0f0h,0f0f3h,0f0fch,0f0ffh</strong></p>
<p><strong>dw 0f300h,0f303h,0f30ch,0f30fh,0f330h,0f333h,0f33ch,0f33fh</strong></p>
<p><strong>dw 0f3c0h,0f3c3h,0f3cch,0f3cfh,0f3f0h,0f3f3h,0f3fch,0f3ffh</strong></p>
<p><strong>dw 0fc00h,0fc03h,0fc0ch,0fc0fh,0fc30h,0fc33h,0fc3ch,0fc3fh</strong></p>
<p><strong>dw 0fcc0h,0fcc3h,0fccch,0fccfh,0fcf0h,0fcf3h,0fcfch,0fcffh</strong></p>
<p><strong>dw 0ff00h,0ff03h,0ff0ch,0ff0fh,0ff30h,0ff33h,0ff3ch,0ff3fh</strong></p>
<p><strong>dw 0ffc0h,0ffc3h,0ffcch,0ffcfh,0fff0h,0fff3h,0fffch,0ffffh</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>BYTE_TO_DOUBLE=0</strong></p>
<p><strong>rept 100</strong></p>
<p><strong>mov al,BYTE_TO_DOUBLE</strong></p>
<p><strong>DOUBLE_BYTE</strong></p>
<p><strong>BYTE_TO_DOUBLE=BYTE_TO_DOUBLE+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-16" class="level2">
<h2>Listing 7-16</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-16 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Performs fast, compact bit-doubling of a byte in AL</strong></p>
<p><strong>; to a word in AX by using two nibble look-ups rather</strong></p>
<p><strong>; than a byte look-up.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to double each bit in a byte.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = byte to bit-double</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; AX = bit-doubled word</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, BX, CL</strong></p>
<p><strong>;</strong></p>
<p><strong>DOUBLE_BYTE macro</strong></p>
<p><strong>mov bl,al ;move the byte to look up to BL</strong></p>
<p><strong>sub bh,bh ; and make a word out of the value</strong></p>
<p><strong>mov cl,4 ;make a look-up pointer out of the</strong></p>
<p><strong>shr bx,cl ; upper nibble of the byte</strong></p>
<p><strong>mov ah,[DoubledNibbleTable+bx]</strong></p>
<p><strong>;look up the doubled upper nibble</strong></p>
<p><strong>mov bl,al ;get the byte to look up again,</strong></p>
<p><strong>and bl,0fh ; and make a pointer out of the</strong></p>
<p><strong>; lower nibble this time</strong></p>
<p><strong>mov al,[DoubledNibbleTable+bx]</strong></p>
<p><strong>;look up the doubled lower nibble</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>DOUBLED_VALUE=0</strong></p>
<p><strong>DoubledNibbleTable label byte</strong></p>
<p><strong>db 000h, 003h, 00ch, 00fh</strong></p>
<p><strong>db 030h, 033h, 03ch, 03fh</strong></p>
<p><strong>db 0c0h, 0c3h, 0cch, 0cfh</strong></p>
<p><strong>db 0f0h, 0f3h, 0fch, 0ffh</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>BYTE_TO_DOUBLE=0</strong></p>
<p><strong>rept 100</strong></p>
<p><strong>mov al,BYTE_TO_DOUBLE</strong></p>
<p><strong>DOUBLE_BYTE</strong></p>
<p><strong>BYTE_TO_DOUBLE=BYTE_TO_DOUBLE+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-17" class="level2">
<h2>Listing 7-17</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-17 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Performs fast, compact bit-doubling of a byte in AL</strong></p>
<p><strong>; to a word in AX by using two nibble look-ups. Overall</strong></p>
<p><strong>; code length and performance are improved by</strong></p>
<p><strong>; using base indexed addressing (bx+si) rather than base</strong></p>
<p><strong>; direct addressing (bx+DoubleNibbleTable). Even though</strong></p>
<p><strong>; an additional 3-byte MOV instruction is required to load</strong></p>
<p><strong>; SI with the offset of DoubleNibbleTable, each access to</strong></p>
<p><strong>; DoubleNibbleTable is 2 bytes shorter thanks to the</strong></p>
<p><strong>; elimination of mod-reg-rm displacements.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to double each bit in a byte.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = byte to bit-double</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; AX = bit-doubled word</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, BX, CL, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>DOUBLE_BYTE macro</strong></p>
<p><strong>mov bl,al ;move the byte to look up to BL</strong></p>
<p><strong>sub bh,bh ; and make a word out of the value</strong></p>
<p><strong>mov cl,4 ;make a look-up pointer out of the</strong></p>
<p><strong>shr bx,cl ; upper nibble of the byte</strong></p>
<p><strong>mov si,offset DoubledNibbleTable</strong></p>
<p><strong>mov ah,[si+bx]</strong></p>
<p><strong>;look up the doubled upper nibble</strong></p>
<p><strong>mov bl,al ;get the byte to look up again,</strong></p>
<p><strong>and bl,0fh ; and make a pointer out of the</strong></p>
<p><strong>; lower nibble this time</strong></p>
<p><strong>mov al,[si+bx]</strong></p>
<p><strong>;look up the doubled lower nibble</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>DOUBLED_VALUE=0</strong></p>
<p><strong>DoubledNibbleTable label byte</strong></p>
<p><strong>db 000h, 003h, 00ch, 00fh</strong></p>
<p><strong>db 030h, 033h, 03ch, 03fh</strong></p>
<p><strong>db 0c0h, 0c3h, 0cch, 0cfh</strong></p>
<p><strong>db 0f0h, 0f3h, 0fch, 0ffh</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>BYTE_TO_DOUBLE=0</strong></p>
<p><strong>rept 100</strong></p>
<p><strong>mov al,BYTE_TO_DOUBLE</strong></p>
<p><strong>DOUBLE_BYTE</strong></p>
<p><strong>BYTE_TO_DOUBLE=BYTE_TO_DOUBLE+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-18" class="level2">
<h2>Listing 7-18</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-18 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Performs fast, compact bit-doubling of a byte in AL</strong></p>
<p><strong>; to a word in AX by using two nibble look-ups. Overall</strong></p>
<p><strong>; code length and performance are improved by</strong></p>
<p><strong>; using XLAT to look up the nibbles.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to double each bit in a byte.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = byte to bit-double</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; AX = bit-doubled word</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, BX, CL</strong></p>
<p><strong>;</strong></p>
<p><strong>DOUBLE_BYTE macro</strong></p>
<p><strong>mov ah,al ;set aside the byte to look up</strong></p>
<p><strong>mov cl,4 ;make a look-up pointer out of the</strong></p>
<p><strong>shr al,cl ; upper nibble of the byte (XLAT</strong></p>
<p><strong>; uses AL as an index pointer)</strong></p>
<p><strong>mov bx,offset DoubledNibbleTable</strong></p>
<p><strong>;XLAT uses BX as a base pointer</strong></p>
<p><strong>xlat ;look up the doubled value of the</strong></p>
<p><strong>; upper nibble</strong></p>
<p><strong>xchg ah,al ;store the doubled upper nibble in AH</strong></p>
<p><strong>; and get back the value to double</strong></p>
<p><strong>and al,0fh ;make a look-up pointer out of the</strong></p>
<p><strong>; lower nibble of the byte</strong></p>
<p><strong>xlat ;look up the doubled value of the</strong></p>
<p><strong>; lower nibble of the byte</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>DOUBLED_VALUE=0</strong></p>
<p><strong>DoubledNibbleTable label byte</strong></p>
<p><strong>db 000h, 003h, 00ch, 00fh</strong></p>
<p><strong>db 030h, 033h, 03ch, 03fh</strong></p>
<p><strong>db 0c0h, 0c3h, 0cch, 0cfh</strong></p>
<p><strong>db 0f0h, 0f3h, 0fch, 0ffh</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>BYTE_TO_DOUBLE=0</strong></p>
<p><strong>rept 100</strong></p>
<p><strong>mov al,BYTE_TO_DOUBLE</strong></p>
<p><strong>DOUBLE_BYTE</strong></p>
<p><strong>BYTE_TO_DOUBLE=BYTE_TO_DOUBLE+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-19" class="level2">
<h2>Listing 7-19</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-19 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of multiplying by 80 with</strong></p>
<p><strong>; the MULinstruction</strong></p>
<p><strong>;</strong></p>
<p><strong>sub ax,ax</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>mov ax,10 ;so we have a constant value to</strong></p>
<p><strong>; multiply by</strong></p>
<p><strong>mov dx,80 ;amount to multiply by</strong></p>
<p><strong>mul dx</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-20" class="level2">
<h2>Listing 7-20</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-20 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of multiplying by 80 with</strong></p>
<p><strong>; shifts and adds.</strong></p>
<p><strong>;</strong></p>
<p><strong>sub ax,ax</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>mov ax,10 ;so we have a constant value to</strong></p>
<p><strong>; multiply by</strong></p>
<p><strong>mov cl,4</strong></p>
<p><strong>shl ax,cl ;times 16</strong></p>
<p><strong>mov cx,ax ;set aside times 16</strong></p>
<p><strong>shl ax,1 ;times 32</strong></p>
<p><strong>shl ax,1 ;times 64</strong></p>
<p><strong>add ax,cx ;times 80 (times 64 + times 16)</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-7-21" class="level2">
<h2>Listing 7-21</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 7-21 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of multiplying by 80 with</strong></p>
<p><strong>; a table look-up.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>; Table of multiples of 80, covering the range 80 times 0</strong></p>
<p><strong>; to 80 times 479.</strong></p>
<p><strong>;</strong></p>
<p><strong>Times80Table label word</strong></p>
<p><strong>TIMES_80_SUM=0</strong></p>
<p><strong>rept 480</strong></p>
<p><strong>dw TIMES_80_SUM</strong></p>
<p><strong>TIMES_80_SUM=TIMES_80_SUM+80</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>sub ax,ax</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>mov ax,10 ;so we have a constant value to</strong></p>
<p><strong>; multiply by</strong></p>
<p><strong>mov bx,ax ;put the factor where we can use it</strong></p>
<p><strong>; for a table look-up</strong></p>
<p><strong>shl bx,1 ;times 2 for use as an index in a</strong></p>
<p><strong>; word-sized look-up table</strong></p>
<p><strong>mov ax,[Times80Table+bx]</strong></p>
<p><strong>;look up the answer</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-8-1" class="level2">
<h2>Listing 8-1</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 8-1 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a byte via AH, with memory addressed with</strong></p>
<p><strong>; mod-reg-rm direct addressing.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>SourceValue db 1</strong></p>
<p><strong>DestValue db 0</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>mov ah,[SourceValue]</strong></p>
<p><strong>mov [DestValue],ah</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-8-2" class="level2">
<h2>Listing 8-2</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 8-2 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a byte via AL, with memory addressed with</strong></p>
<p><strong>; accumulator-specific direct addressing.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>SourceValue db 1</strong></p>
<p><strong>DestValue db 0</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>mov al,[SourceValue]</strong></p>
<p><strong>mov [DestValue],al</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-8-3" class="level2">
<h2>Listing 8-3</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 8-3 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Tests the zero/non-zero status of a variable via</strong></p>
<p><strong>; the direct-addressing mod-reg-rm form of CMP.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>TestValue dw ?</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>cmp [TestValue],0</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-8-4" class="level2">
<h2>Listing 8-4</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 8-4 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Tests the zero/non-zero status of a variable via</strong></p>
<p><strong>; the accumulator-specific form of MOV followed by a</strong></p>
<p><strong>; register-register AND.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>TestValue dw ?</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>mov ax,[TestValue]</strong></p>
<p><strong>and ax,ax</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-8-5" class="level2">
<h2>Listing 8-5</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 8-5 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Initializes a variable to 1 by setting AX to 1, then</strong></p>
<p><strong>; using the accumulator-specific form of MOV to store</strong></p>
<p><strong>; that value to a direct-addressed operand.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>InitialValue dw ?</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>mov ax,1</strong></p>
<p><strong>mov [InitialValue],ax</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-8-6" class="level2">
<h2>Listing 8-6</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 8-6 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Initializes a variable to 1 via the direct-addressing</strong></p>
<p><strong>; mod-reg-rm form of MOV.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>InitialValue dw ?</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>mov [InitialValue],1</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-8-7" class="level2">
<h2>Listing 8-7</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 8-7 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Initializes a variable to 0 via a register-register SUB,</strong></p>
<p><strong>; followed by the accumulator-specific form of MOV to a</strong></p>
<p><strong>; direct-addressed operand.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>InitialValue dw ?</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>sub ax,ax</strong></p>
<p><strong>mov [InitialValue],ax</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-8-8" class="level2">
<h2>Listing 8-8</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 8-8 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; The accumulator-specific immediate-addressing form of CMP.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>cmp al,1</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-8-9" class="level2">
<h2>Listing 8-9</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 8-9 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; The mod-reg-rm immediate-addressing form of CMP with a</strong></p>
<p><strong>; register as the destination operand.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>cmp bl,1</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-8-10" class="level2">
<h2>Listing 8-10</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 8-10 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Sets the BIOS equipment flag to select an 80-column</strong></p>
<p><strong>; color monitor.</strong></p>
<p><strong>; Uses mod-reg-rm AND and OR instructions.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>sub ax,ax</strong></p>
<p><strong>mov es,ax ;point ES to the segment at 0</strong></p>
<p><strong>and byte ptr es:[410h],not 30h</strong></p>
<p><strong>;mask off the adapter bits</strong></p>
<p><strong>or byte ptr es:[410h],20h</strong></p>
<p><strong>;set the adapter bits to select</strong></p>
<p><strong>; 80-column color</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-8-11" class="level2">
<h2>Listing 8-11</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 8-11 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Sets the BIOS equipment flag to select an 80-column</strong></p>
<p><strong>; color monitor.</strong></p>
<p><strong>; Uses accumulator-specific MOV, AND, and OR instructions.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>sub ax,ax</strong></p>
<p><strong>mov es,ax ;point ES to the segment at 0</strong></p>
<p><strong>mov al,es:[410h] ;get the equipment flag</strong></p>
<p><strong>and al,not 30h ;mask off the adapter bits</strong></p>
<p><strong>or al,20h ;set the adapter bits to select</strong></p>
<p><strong>; 80-column color</strong></p>
<p><strong>mov es:[410h],al ;set the new equipment flag</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-8-12" class="level2">
<h2>Listing 8-12</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 8-12 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Adds together bytes from two arrays, subtracts a byte from</strong></p>
<p><strong>; another array from the sum, and stores the result in a fourth</strong></p>
<p><strong>; array, for all elements in the arrays.</strong></p>
<p><strong>; Uses the AX-specific form of XCHG.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>Array1 db ARRAY_LENGTH dup (3)</strong></p>
<p><strong>Array2 db ARRAY_LENGTH dup (2)</strong></p>
<p><strong>Array3 db ARRAY_LENGTH dup (1)</strong></p>
<p><strong>Array4 db ARRAY_LENGTH dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>mov ax,offset Array1 ;set up array pointers</strong></p>
<p><strong>mov bx,offset Array2</strong></p>
<p><strong>mov si,offset Array3</strong></p>
<p><strong>mov di,offset Array4</strong></p>
<p><strong>mov cx,ARRAY_LENGTH</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>ProcessingLoop:</strong></p>
<p><strong>xchg ax,bx ;point BX to Array1,</strong></p>
<p><strong>; point AX to Array2</strong></p>
<p><strong>mov dl,[bx] ;get next byte from Array1</strong></p>
<p><strong>xchg ax,bx ;point BX to Array2,</strong></p>
<p><strong>; point AX to Array1</strong></p>
<p><strong>add dl,[bx] ;add Array2 element to Array1</strong></p>
<p><strong>sub dl,[si] ;subtract Array3 element</strong></p>
<p><strong>mov [di],dl ;store result in Array4</strong></p>
<p><strong>inc ax ;point to next element of each array</strong></p>
<p><strong>inc bx</strong></p>
<p><strong>inc si</strong></p>
<p><strong>inc di</strong></p>
<p><strong>loop ProcessingLoop ;do the next element</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-8-13" class="level2">
<h2>Listing 8-13</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 8-13 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Adds together bytes from two arrays, subtracts a byte from</strong></p>
<p><strong>; another array from the sum, and stores the result in a fourth</strong></p>
<p><strong>; array, for all elements in the arrays.</strong></p>
<p><strong>; Uses the mod-reg-rm form of XCHG.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>Array1 db ARRAY_LENGTH dup (3)</strong></p>
<p><strong>Array2 db ARRAY_LENGTH dup (2)</strong></p>
<p><strong>Array3 db ARRAY_LENGTH dup (1)</strong></p>
<p><strong>Array4 db ARRAY_LENGTH dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>mov dx,offset Array1</strong></p>
<p><strong>mov bx,offset Array2</strong></p>
<p><strong>mov si,offset Array3</strong></p>
<p><strong>mov di,offset Array4</strong></p>
<p><strong>mov cx,ARRAY_LENGTH</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>ProcessingLoop:</strong></p>
<p><strong>xchg dx,bx ;point BX to Array1,</strong></p>
<p><strong>; point DX to Array2</strong></p>
<p><strong>mov al,[bx] ;get next byte from Array1</strong></p>
<p><strong>xchg dx,bx ;point BX to Array2,</strong></p>
<p><strong>; point DX to Array1</strong></p>
<p><strong>add al,[bx] ;add Array2 element to Array1</strong></p>
<p><strong>sub al,[si] ;subtract Array3 element</strong></p>
<p><strong>mov [di],al ;store result in Array4</strong></p>
<p><strong>inc dx ;point to next element of each array</strong></p>
<p><strong>inc bx</strong></p>
<p><strong>inc si</strong></p>
<p><strong>inc di</strong></p>
<p><strong>loop ProcessingLoop ;do the next element</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-8-14" class="level2">
<h2>Listing 8-14</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 8-14 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Adds AL to each element in an array until the result</strong></p>
<p><strong>; of an addition exceeds 7Fh.</strong></p>
<p><strong>; Uses PUSHF and POPF.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>Data db 999 dup (0),7fh</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>mov bx,offset Data</strong></p>
<p><strong>mov al,2 ;we’ll add 2 to each array element</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>AddLoop:</strong></p>
<p><strong>add [bx],al ;add the value to this element</strong></p>
<p><strong>pushf ;save the sign flag</strong></p>
<p><strong>inc bx ;point to the next array element</strong></p>
<p><strong>popf ;get back the sign flag</strong></p>
<p><strong>jns AddLoop ;do the next element, if any</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-8-15" class="level2">
<h2>Listing 8-15</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 8-15 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Adds AL to each element in an array until the result</strong></p>
<p><strong>; of an addition exceeds 7Fh.</strong></p>
<p><strong>; Uses LAHF and SAHF.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>Data db 999 dup (0),7fh</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>mov bx,offset Data</strong></p>
<p><strong>mov al,2 ;we’ll add 2 to each array element</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>AddLoop:</strong></p>
<p><strong>add [bx],al ;add the value to this element</strong></p>
<p><strong>lahf ;save the sign flag</strong></p>
<p><strong>inc bx ;point to the next array element</strong></p>
<p><strong>sahf ;get back the sign flag</strong></p>
<p><strong>jns AddLoop ;do the next element, if any</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-8-16" class="level2">
<h2>Listing 8-16</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 8-16 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Adds AL to each element in an array until the result</strong></p>
<p><strong>; of an addition exceeds 7Fh.</strong></p>
<p><strong>; Uses two jumps in the loop, with a finaLiNC to adjust</strong></p>
<p><strong>; BX for the last addition.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>Data db 999 dup (0),7fh</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>mov bx,offset Data</strong></p>
<p><strong>mov al,2 ;we’ll add 2 to each array element</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>AddLoop:</strong></p>
<p><strong>add [bx],al ;add the value to this element</strong></p>
<p><strong>js EndAddLoop ;done if Sign flag set</strong></p>
<p><strong>inc bx ;point to the next array element</strong></p>
<p><strong>jmp AddLoop ;do the next element</strong></p>
<p><strong>EndAddLoop:</strong></p>
<p><strong>inc bx ;adjust BX for the final addition</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-8-17" class="level2">
<h2>Listing 8-17</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 8-17 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Adds AL to each element in an array until the result</strong></p>
<p><strong>; of an addition exceeds 7Fh.</strong></p>
<p><strong>; Uses one jump in the loop, with a predecrement before</strong></p>
<p><strong>; the loop, an INC before the ADD in the loop, and a final</strong></p>
<p><strong>; INC to adjust BX for the last addition.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>Data db 999 dup (0),7fh</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>mov bx,offset Data</strong></p>
<p><strong>mov al,2 ;we’ll add 2 to each array element</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>dec bx ;compensate for the initiaLiNC</strong></p>
<p><strong>AddLoop:</strong></p>
<p><strong>inc bx ;point to the next array element</strong></p>
<p><strong>add [bx],al ;add the value to this element</strong></p>
<p><strong>jns AddLoop ;do the next element, if any</strong></p>
<p><strong>EndAddLoop:</strong></p>
<p><strong>inc bx ;adjust BX for the final addition</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-1" class="level2">
<h2>Listing 9-1</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-1 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; An example of initializing multiple memory variables</strong></p>
<p><strong>; to the same value by placing the value in a register,</strong></p>
<p><strong>; then storing the register to each of the variables.</strong></p>
<p><strong>; This avoids the overhead that’s incurred when using</strong></p>
<p><strong>; immediate operands.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>MemVar1 dw ?</strong></p>
<p><strong>MemVar2 dw ?</strong></p>
<p><strong>MemVar3 dw ?</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>mov ax,0ffffh ;place the initial value in</strong></p>
<p><strong>; AX</strong></p>
<p><strong>mov [MemVar1],ax ;store AX to each memory</strong></p>
<p><strong>mov [MemVar2],ax ; variable to be initialized</strong></p>
<p><strong>mov [MemVar3],ax</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-2" class="level2">
<h2>Listing 9-2</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-2 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; An example of initializing multiple memory variables</strong></p>
<p><strong>; to the same value by making the value an immediate</strong></p>
<p><strong>; operand to each instruction. Immediate operands</strong></p>
<p><strong>; increase instruction size by 1 to 2 bytes, and preclude</strong></p>
<p><strong>; use of the accumulator-specific direct-addressing</strong></p>
<p><strong>; form of MOV.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>MemVar1 dw ?</strong></p>
<p><strong>MemVar2 dw ?</strong></p>
<p><strong>MemVar3 dw ?</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>mov [MemVar1],0ffffh ;store 0ffffh to each memory</strong></p>
<p><strong>mov [MemVar2],0ffffh ; variable as an immediate</strong></p>
<p><strong>mov [MemVar3],0ffffh ; operand</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-3" class="level2">
<h2>Listing 9-3</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-3 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; An example of using AND reg,reg to test for the</strong></p>
<p><strong>; zero/non-zero status of a register. This is faster</strong></p>
<p><strong>; (and usually shorter) than CMP reg,0.</strong></p>
<p><strong>;</strong></p>
<p><strong>sub dx,dx ;set DX to 0, so we don’t jump</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>and dx,dx ;is DX 0?</strong></p>
<p><strong>jnz $+2 ;just jumps to the next line if</strong></p>
<p><strong>; Z is not set (never jumps)</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-4" class="level2">
<h2>Listing 9-4</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-4 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; An example of using CMP reg,0 to test for the</strong></p>
<p><strong>; zero/non-zero status of a register.</strong></p>
<p><strong>;</strong></p>
<p><strong>sub dx,dx ;set DX to 0, so we don’t jump</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>cmp dx,0 ;is DX 0?</strong></p>
<p><strong>jnz $+2 ;just jumps to the next line if</strong></p>
<p><strong>; Z is not set (never jumps)</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-5" class="level2">
<h2>Listing 9-5</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-5 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; An example of performing a switch statement with just a</strong></p>
<p><strong>; few cases, all consecutive, by using CMP to test for each</strong></p>
<p><strong>; of the cases.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to perform switch statement. This must be a macro</strong></p>
<p><strong>; rather than code inside the REPT block because MASM</strong></p>
<p><strong>; doesn’t handle LOCAL declarations properly inside REPT</strong></p>
<p><strong>; blocks, but it does handle them properly inside macros.</strong></p>
<p><strong>;</strong></p>
<p><strong>HANDLE_SWITCH macro</strong></p>
<p><strong>local ValueWas1, ValueWas2, ValueWas3, ValueWas4</strong></p>
<p><strong>cmp cx,1</strong></p>
<p><strong>jz ValueWas1</strong></p>
<p><strong>cmp cx,2</strong></p>
<p><strong>jz ValueWas2</strong></p>
<p><strong>cmp cx,3</strong></p>
<p><strong>jz ValueWas3</strong></p>
<p><strong>cmp cx,4</strong></p>
<p><strong>jz ValueWas4</strong></p>
<p><strong>; <none of the above\></strong></p>
<p><strong>ValueWas1:</strong></p>
<p><strong>ValueWas2:</strong></p>
<p><strong>ValueWas3:</strong></p>
<p><strong>ValueWas4:</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>TEST_VALUE = 1</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>mov cx,TEST_VALUE ;set the test value</strong></p>
<p><strong>HANDLE_SWITCH ;perform the switch test</strong></p>
<p><strong>TEST_VALUE = (TEST_VALUE MOD 5)+1 ;cycle the test value from</strong></p>
<p><strong>; 1 to 4</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-6" class="level2">
<h2>Listing 9-6</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-6 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; An example of performing a switch statement with just a</strong></p>
<p><strong>; few cases, all consecutive, by using DEC to test for each</strong></p>
<p><strong>; of the cases.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to perform switch statement. This must be a macro</strong></p>
<p><strong>; rather than code inside the REPT block because MASM</strong></p>
<p><strong>; doesn’t handle LOCAL declarations properly inside REPT</strong></p>
<p><strong>; blocks, but it does handle them properly inside macros.</strong></p>
<p><strong>;</strong></p>
<p><strong>HANDLE_SWITCH macro</strong></p>
<p><strong>local ValueWas1, ValueWas2, ValueWas3, ValueWas4</strong></p>
<p><strong>dec cx</strong></p>
<p><strong>jz ValueWas1</strong></p>
<p><strong>dec cx</strong></p>
<p><strong>jz ValueWas2</strong></p>
<p><strong>dec cx</strong></p>
<p><strong>jz ValueWas3</strong></p>
<p><strong>dec cx</strong></p>
<p><strong>jz ValueWas4</strong></p>
<p><strong>; <none of the above\></strong></p>
<p><strong>ValueWas1:</strong></p>
<p><strong>ValueWas2:</strong></p>
<p><strong>ValueWas3:</strong></p>
<p><strong>ValueWas4:</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>TEST_VALUE = 1</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>mov cx,TEST_VALUE ;set the test value</strong></p>
<p><strong>HANDLE_SWITCH ;perform the switch test</strong></p>
<p><strong>TEST_VALUE = (TEST_VALUE MOD 5)+1 ;cycle the test value from</strong></p>
<p><strong>; 0 to 3</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-7" class="level2">
<h2>Listing 9-7</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-7 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Times the performance of a 16-bit register DEC.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov dx,1000</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>TestLoop:</strong></p>
<p><strong>dec dx ;16-bit register DEC</strong></p>
<p><strong>; (1 byte long, uses 16-bit-</strong></p>
<p><strong>; register-specific form of DEC)</strong></p>
<p><strong>jnz TestLoop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-8" class="level2">
<h2>Listing 9-8</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-8 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Times the performance of a 16-bit subtraction</strong></p>
<p><strong>; of an immediate value of 1.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov dx,1000</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>TestLoop:</strong></p>
<p><strong>sub dx,1 ;decrement DX by subtracting 1 from</strong></p>
<p><strong>; it (3 bytes long, uses sign-</strong></p>
<p><strong>; extended mod-reg-rm form of SUB)</strong></p>
<p><strong>jnz TestLoop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-9" class="level2">
<h2>Listing 9-9</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-9 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Times the performance of two 16-bit register DEC</strong></p>
<p><strong>; instructions.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov dx,2000</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>TestLoop:</strong></p>
<p><strong>dec dx ;subtract 2 from DX by decrementing</strong></p>
<p><strong>dec dx ; it twice (2 bytes long, uses</strong></p>
<p><strong>; 2 16-bit-register-specific DECs)</strong></p>
<p><strong>jnz TestLoop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-10" class="level2">
<h2>Listing 9-10</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-10 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Times the performance of an 8-bit register DEC.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov dl,100</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>TestLoop:</strong></p>
<p><strong>dec dl ;8-bit register DEC</strong></p>
<p><strong>; (2 bytes long, uses mod-reg-rm</strong></p>
<p><strong>; form of DEC)</strong></p>
<p><strong>jnz TestLoop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-11" class="level2">
<h2>Listing 9-11</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-11 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Illustrates the use of the efficient word-sized INC to</strong></p>
<p><strong>; increment a byte-sized register, taking advantage of the</strong></p>
<p><strong>; knowledge that AL never counts past 0FFh to wrap to 0 and</strong></p>
<p><strong>; so AH will never affected by the INC.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: This is a sample code fragment, and is not intended</strong></p>
<p><strong>; to either be run under the Zen timer or assembled as a</strong></p>
<p><strong>; standalone program.</strong></p>
<p><strong>;</strong></p>
<p><strong>sub al,al ;count up from 0</strong></p>
<p><strong>TestLoop:</strong></p>
<p><strong>inc ax ;AL will never turn over, so AH</strong></p>
<p><strong>; will never be affected</strong></p>
<p><strong>cmp al,8 ;count up to 8</strong></p>
<p><strong>jbe TestLoop</strong></p>
</section>
<section id="listing-9-12" class="level2">
<h2>Listing 9-12</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-12 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Illustrates the use of a word-sized DEC for the outer</strong></p>
<p><strong>; loop, taking advantage of the knowledge that the counter</strong></p>
<p><strong>; for the inner loop is always 0 when the outer loop is</strong></p>
<p><strong>; counted down. This code uses no registers other than</strong></p>
<p><strong>; CX, and would be used when registers are in such short</strong></p>
<p><strong>; supply that no other registers are available. Otherwise,</strong></p>
<p><strong>; word-sized DECs would be used for both loops. (Ideally,</strong></p>
<p><strong>; a LOOP would also be used instead of DEC CX/JNZ.)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: This is a sample code fragment, and is not intended</strong></p>
<p><strong>; to either be run under the Zen timer or assembled as a</strong></p>
<p><strong>; standalone program.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov cl,5 ;outer loop is performed 5 times</strong></p>
<p><strong>OuterLoop:</strong></p>
<p><strong>mov ch,10 ;inner loop is performed 10 times</strong></p>
<p><strong>; each time through the outer loop</strong></p>
<p><strong>InnerLoop:</strong></p>
<p><strong>;&lt;&lt;<working code goes here\>&gt;&gt;</strong></p>
<p><strong>dec ch ;count down inner loop</strong></p>
<p><strong>jnz InnerLoop</strong></p>
<p><strong>dec cx ;CH is always 0 at this point, so</strong></p>
<p><strong>; we can use the shorter &amp; faster</strong></p>
<p><strong>; word DEC to count down CL</strong></p>
<p><strong>jnz OuterLoop</strong></p>
</section>
<section id="listing-9-13" class="level2">
<h2>Listing 9-13</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-13 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Adds together two 64-bit memory variables, taking</strong></p>
<p><strong>; advantage of the fact that neither INC nor LOOP affects</strong></p>
<p><strong>; the Carry flag.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: This is a sample code fragment, and is not intended</strong></p>
<p><strong>; to either be run under the Zen timer or assembled as a</strong></p>
<p><strong>; standalone program.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>MemVar1 db 2, 0, 0, 0, 0, 0, 0, 0</strong></p>
<p><strong>MEM_VAR_LEN equ ($-MemVar1)</strong></p>
<p><strong>MemVar2 db 0feh, 0ffh, 0ffh, 0ffh, 0, 0, 0, 0</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>mov si,offset MemVar1 ;set up memory variable</strong></p>
<p><strong>mov di,offset MemVar2 ; pointers</strong></p>
<p><strong>mov ax,[si] ;add the first words</strong></p>
<p><strong>add [di],ax ; together</strong></p>
<p><strong>mov cx,(MEM_VAR_LEN/2)-1</strong></p>
<p><strong>;we’ll add together the</strong></p>
<p><strong>; remaining 3 words in</strong></p>
<p><strong>; each variable</strong></p>
<p><strong>AdditionLoop:</strong></p>
<p><strong>inc si</strong></p>
<p><strong>inc si ;point to next word</strong></p>
<p><strong>inc di ; (doesn’t affect Carry</strong></p>
<p><strong>inc di ; flag)</strong></p>
<p><strong>mov ax,[si] ;add the next words</strong></p>
<p><strong>adc [di],ax ; together-C flag still set</strong></p>
<p><strong>; from last addition</strong></p>
<p><strong>loop AdditionLoop ;add the next word of each</strong></p>
<p><strong>; variable together</strong></p>
</section>
<section id="listing-9-14" class="level2">
<h2>Listing 9-14</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-14 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; An illustration of the use of CBW to convert an</strong></p>
<p><strong>; array of unsigned byte values between 0 and 7Fh to an</strong></p>
<p><strong>; array of unsigned words. Note that this would not work</strong></p>
<p><strong>; if Array1 contained values greater than 7Fh.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>;</strong></p>
<p><strong>Array1 label byte</strong></p>
<p><strong>ARRAY_VALUE=0</strong></p>
<p><strong>rept ARRAY_LENGTH</strong></p>
<p><strong>db ARRAY_VALUE</strong></p>
<p><strong>ARRAY_VALUE=(ARRAY_VALUE+1) and 07fh</strong></p>
<p><strong>;cycle source array byte</strong></p>
<p><strong>; values from 0-7Fh</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>Array2 dw ARRAY_LENGTH dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>mov si,offset Array1 ;set up array pointers</strong></p>
<p><strong>mov di,offset Array2</strong></p>
<p><strong>mov ax,ds</strong></p>
<p><strong>mov es,ax ;copy to &amp; from same segment</strong></p>
<p><strong>cld ;make string instructions</strong></p>
<p><strong>; increment pointers</strong></p>
<p><strong>mov cx,ARRAY_LENGTH</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>ProcessingLoop:</strong></p>
<p><strong>lodsb ;get the next element</strong></p>
<p><strong>cbw ;make it a word</strong></p>
<p><strong>stosw ;save the word value</strong></p>
<p><strong>loop ProcessingLoop ;do the next element</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-15" class="level2">
<h2>Listing 9-15</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-15 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; An illustration of the use of SUB AH,AH to convert an</strong></p>
<p><strong>; array of unsigned byte values between 0 and 7Fh to an</strong></p>
<p><strong>; array of words. Note that this would work even if Array1</strong></p>
<p><strong>; contained values greater than 7Fh.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>;</strong></p>
<p><strong>Array1 label byte</strong></p>
<p><strong>ARRAY_VALUE=0</strong></p>
<p><strong>rept ARRAY_LENGTH</strong></p>
<p><strong>db ARRAY_VALUE</strong></p>
<p><strong>ARRAY_VALUE=(ARRAY_VALUE+1) and 07fh</strong></p>
<p><strong>;cycle source array byte</strong></p>
<p><strong>; values from 0-7Fh</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>Array2 dw ARRAY_LENGTH dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>mov si,offset Array1 ;set up array pointers</strong></p>
<p><strong>mov di,offset Array2</strong></p>
<p><strong>mov ax,ds</strong></p>
<p><strong>mov es,ax ;copy to &amp; from same segment</strong></p>
<p><strong>cld ;make string instructions</strong></p>
<p><strong>; increment pointers</strong></p>
<p><strong>mov cx,ARRAY_LENGTH</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>ProcessingLoop:</strong></p>
<p><strong>lodsb ;get the next element</strong></p>
<p><strong>sub ah,ah ;make it a word</strong></p>
<p><strong>stosw ;save the word value</strong></p>
<p><strong>loop ProcessingLoop ;do the next element</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-16" class="level2">
<h2>Listing 9-16</h2>
<p><strong>;</strong></p>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-16 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; An illustration of the use of SUB AH,AH outside the</strong></p>
<p><strong>; processing loop to convert an array of byte values</strong></p>
<p><strong>; between 0 and 7Fh to an array of words. AH never changes</strong></p>
<p><strong>; from one pass through the loop to the next, so there’s no</strong></p>
<p><strong>; need to continually set AH to 0.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>;</strong></p>
<p><strong>Array1 label byte</strong></p>
<p><strong>ARRAY_VALUE=0</strong></p>
<p><strong>rept ARRAY_LENGTH</strong></p>
<p><strong>db ARRAY_VALUE</strong></p>
<p><strong>ARRAY_VALUE=(ARRAY_VALUE+1) and 07fh</strong></p>
<p><strong>;cycle source array byte</strong></p>
<p><strong>; values from 0-7Fh</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>Array2 dw ARRAY_LENGTH dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>mov si,offset Array1 ;set up array pointers</strong></p>
<p><strong>mov di,offset Array2</strong></p>
<p><strong>mov ax,ds</strong></p>
<p><strong>mov es,ax ;copy to &amp; from same segment</strong></p>
<p><strong>cld ;make string instructions</strong></p>
<p><strong>; increment pointers</strong></p>
<p><strong>mov cx,ARRAY_LENGTH</strong></p>
<p><strong>sub ah,ah ;set up to make each byte</strong></p>
<p><strong>; read into AL a word in AX</strong></p>
<p><strong>; automatically</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>ProcessingLoop:</strong></p>
<p><strong>lodsb ;get the next element</strong></p>
<p><strong>stosw ;save the word value</strong></p>
<p><strong>loop ProcessingLoop ;do the next element</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-17" class="level2">
<h2>Listing 9-17</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-17 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Supports the use of CX to store a loop count and CL</strong></p>
<p><strong>; to store a shift count by pushing and popping the loop</strong></p>
<p><strong>; count around the use of the shift count.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>Array1 db ARRAY_LENGTH dup (3)</strong></p>
<p><strong>Array2 db ARRAY_LENGTH dup (2)</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>mov si,offset Array1 ;point to the source array</strong></p>
<p><strong>mov di,offset Array2 ;point to the dest array</strong></p>
<p><strong>mov ax,ds</strong></p>
<p><strong>mov es,ax ;copy to &amp; from same segment</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;the loop count</strong></p>
<p><strong>mov dl,2 ;the shift count</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>ProcessingLoop:</strong></p>
<p><strong>lodsb ;get the next byte</strong></p>
<p><strong>push cx ;save the loop count</strong></p>
<p><strong>mov cl,dl ;get the shift count into CL</strong></p>
<p><strong>shl al,cl ;shift the byte</strong></p>
<p><strong>pop cx ;get back the loop count</strong></p>
<p><strong>stosb ;save the modified byte</strong></p>
<p><strong>loop ProcessingLoop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-18" class="level2">
<h2>Listing 9-18</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-18 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Supports the use of CX to store a loop count and CL</strong></p>
<p><strong>; to store a shift count by using XCHG to swap the</strong></p>
<p><strong>; contents of CL as needed.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>Array1 db ARRAY_LENGTH dup (3)</strong></p>
<p><strong>Array2 db ARRAY_LENGTH dup (2)</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>mov si,offset Array1 ;point to the source array</strong></p>
<p><strong>mov di,offset Array2 ;point to the dest array</strong></p>
<p><strong>mov ax,ds</strong></p>
<p><strong>mov es,ax ;copy to &amp; from same segment</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;the loop count</strong></p>
<p><strong>mov dl,2 ;the shift count</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>ProcessingLoop:</strong></p>
<p><strong>lodsb ;get the next byte</strong></p>
<p><strong>xchg cl,dl ;get the shift count into CL</strong></p>
<p><strong>; and save the low byte of</strong></p>
<p><strong>; the loop count in DL</strong></p>
<p><strong>shl al,cl ;shift the byte</strong></p>
<p><strong>xchg cl,dl ;put the shift count back</strong></p>
<p><strong>; into DL and restore the</strong></p>
<p><strong>; low byte of the loop count</strong></p>
<p><strong>; to CL</strong></p>
<p><strong>stosb ;save the modified byte</strong></p>
<p><strong>loop ProcessingLoop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-19" class="level2">
<h2>Listing 9-19</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-19 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Times the performance of SUB with a register as the</strong></p>
<p><strong>; destination operand and memory as the source operand.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>Dest db 0</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>sub al,[Dest] ;subtract [Dest] from AL</strong></p>
<p><strong>; Only 1 memory access</strong></p>
<p><strong>; is performed</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-20" class="level2">
<h2>Listing 9-20</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-20 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Times the performance of SUB with memory as the</strong></p>
<p><strong>; destination operand and a register as the source operand.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>Dest db 0</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>sub [Dest],al ;subtract AL from [Dest]</strong></p>
<p><strong>; Two memory accesses are</strong></p>
<p><strong>; performed</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-21" class="level2">
<h2>Listing 9-21</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-21 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Times shifts performed by shifting CL times.</strong></p>
<p><strong>;</strong></p>
<p><strong>BITS_TO_SHIFT equ 1</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 100</strong></p>
<p><strong>mov cl,BITS_TO_SHIFT</strong></p>
<p><strong>shl ax,cl</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-22" class="level2">
<h2>Listing 9-22</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-22 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Times shifts performed by using multiple 1-bit shift</strong></p>
<p><strong>; instructions.</strong></p>
<p><strong>;</strong></p>
<p><strong>BITS_TO_SHIFT equ 1</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 100</strong></p>
<p><strong>rept BITS_TO_SHIFT</strong></p>
<p><strong>shl ax,1</strong></p>
<p><strong>endm</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-23" class="level2">
<h2>Listing 9-23</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-23 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Performs bit-doubling of a byte in AL to a word in AX</strong></p>
<p><strong>; by using SAR. This is not as fast as bit-doubling with</strong></p>
<p><strong>; a look-up table, but it is faster than any other</strong></p>
<p><strong>; shift-based approach.</strong></p>
<p><strong>; (Conceived by Dan Illowsky.)</strong></p>
<p><strong>;</strong></p>
<p><strong>DOUBLE_BYTE macro</strong></p>
<p><strong>mov bl,al</strong></p>
<p><strong>rept 8</strong></p>
<p><strong>shr bl,1 ;get the next bit to double</strong></p>
<p><strong>rcr ax,1 ;move it into the msb…</strong></p>
<p><strong>sar ax,1 ;…and replicate it</strong></p>
<p><strong>endm</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>BYTE_TO_DOUBLE=0</strong></p>
<p><strong>rept 100</strong></p>
<p><strong>mov al,BYTE_TO_DOUBLE</strong></p>
<p><strong>DOUBLE_BYTE</strong></p>
<p><strong>BYTE_TO_DOUBLE=(BYTE_TO_DOUBLE+1) and 0ffH</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-24" class="level2">
<h2>Listing 9-24</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-24 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Performs binary-to-ASCII conversion of a byte value</strong></p>
<p><strong>; by using AAM.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ResultString db 3 dup (?)</strong></p>
<p><strong>ResultStringEnd label byte</strong></p>
<p><strong>db 0 ;a zero to mark the string end</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>BYTE_VALUE=0</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 100</strong></p>
<p><strong>std ;make STOSB decrement DI</strong></p>
<p><strong>mov ax,ds</strong></p>
<p><strong>mov es,ax ;for STOSB</strong></p>
<p><strong>mov bl,‘0’ ;used for converting to ASCII</strong></p>
<p><strong>mov di,offset ResultStringEnd-1</strong></p>
<p><strong>mov al,BYTE_VALUE</strong></p>
<p><strong>aam ;put least significant decimal</strong></p>
<p><strong>; digit of BYTE_VALUE in AL,</strong></p>
<p><strong>; other digits in AH</strong></p>
<p><strong>add al,bl ;make it an ASCII digit</strong></p>
<p><strong>stosb ;save least significant digit</strong></p>
<p><strong>mov al,ah</strong></p>
<p><strong>aam ;put middle decimal digit in AL</strong></p>
<p><strong>add al,bl ;make it an ASCII digit</strong></p>
<p><strong>stosb ;save middle digit</strong></p>
<p><strong>;most significant decimal</strong></p>
<p><strong>; digit is in AH</strong></p>
<p><strong>add ah,bl ;make it an ASCII digit</strong></p>
<p><strong>mov [di],ah ;save most significant digit</strong></p>
<p><strong>BYTE_VALUE=BYTE_VALUE+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-25" class="level2">
<h2>Listing 9-25</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-25 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Performs binary-to-ASCII conversion of a byte value</strong></p>
<p><strong>; by using DIV.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ResultString db 3 dup (?)</strong></p>
<p><strong>ResultStringEnd label byte</strong></p>
<p><strong>db 0 ;a zero to mark the string end</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>BYTE_VALUE=0</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 100</strong></p>
<p><strong>mov cx,(10 shl 8)+‘0’</strong></p>
<p><strong>;CL=‘0’, used for converting to ASCII</strong></p>
<p><strong>; CH=10, used for dividing by 10</strong></p>
<p><strong>mov di,offset ResultString</strong></p>
<p><strong>mov al,BYTE_VALUE</strong></p>
<p><strong>sub ah,ah ;prepare 16-bit dividend</strong></p>
<p><strong>div ch ;put least significant decimal</strong></p>
<p><strong>; digit of BYTE_VALUE in AH,</strong></p>
<p><strong>; other digits in AL</strong></p>
<p><strong>add ah,cl ;make it an ASCII digit</strong></p>
<p><strong>mov [di+2],ah ;save least significant digit</strong></p>
<p><strong>sub ah,ah ;prepare 16-bit dividend</strong></p>
<p><strong>div ch ;put middle decimal digit in AL</strong></p>
<p><strong>add ah,cl ;make it an ASCII digit</strong></p>
<p><strong>mov [di+1],ah ;save middle ASCII decimal digit</strong></p>
<p><strong>;most significant decimal</strong></p>
<p><strong>; digit is in AL</strong></p>
<p><strong>add al,cl ;make it an ASCII digit</strong></p>
<p><strong>mov [di],al ;save most significant digit</strong></p>
<p><strong>BYTE_VALUE=BYTE_VALUE+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-9-26" class="level2">
<h2>Listing 9-26</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 9-26 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Performs addition of the ASCII decimal value “00001”</strong></p>
<p><strong>; to an ASCII decimal count variable.</strong></p>
<p><strong>;</strong></p>
<p><strong>DECIMAL_INCREMENT macro</strong></p>
<p><strong>local DigitLoop</strong></p>
<p><strong>std ;we’ll work from least-significant</strong></p>
<p><strong>; to most-significant</strong></p>
<p><strong>mov si,offset ASCIIOne+VALUE_LENGTH-1</strong></p>
<p><strong>mov di,offset Count+VALUE_LENGTH-1</strong></p>
<p><strong>mov ax,ds</strong></p>
<p><strong>mov es,ax ;ES:DI points to Count for STOSB</strong></p>
<p><strong>mov cx,VALUE_LENGTH</strong></p>
<p><strong>clc ;there’s no carry into the least-</strong></p>
<p><strong>; significant digit</strong></p>
<p><strong>DigitLoop:</strong></p>
<p><strong>lodsb ;get the next increment digit</strong></p>
<p><strong>adc al,[di] ;add it to the next Count digit</strong></p>
<p><strong>aaa ;adjust to an unpacked BCD digit</strong></p>
<p><strong>lahf ;save the carry, in case we just</strong></p>
<p><strong>; turned over 9</strong></p>
<p><strong>add al,‘0’ ;make it an ASCII digit</strong></p>
<p><strong>stosb</strong></p>
<p><strong>sahf ;get back the carry for the next adc</strong></p>
<p><strong>loop DigitLoop</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>Count db ‘00000’</strong></p>
<p><strong>VALUE_LENGTH equ $-Count</strong></p>
<p><strong>ASCIIOne db ‘00001’</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 100</strong></p>
<p><strong>DECIMAL_INCREMENT</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-10-1" class="level2">
<h2>Listing 10-1</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 10-1 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Loads each byte in a 1000-byte array into AL, using</strong></p>
<p><strong>; MOV and INC.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>ByteArray db ARRAY_LENGTH dup (0)</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset ByteArray</strong></p>
<p><strong>;point to the start of the array</strong></p>
<p><strong>rept ARRAY_LENGTH</strong></p>
<p><strong>mov al,[si] ;get this array byte</strong></p>
<p><strong>inc si ;point to the next byte in the array</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-10-2" class="level2">
<h2>Listing 10-2</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 10-2 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Loads each byte in a 1000-byte array into AL, using</strong></p>
<p><strong>; LODSB.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>ByteArray db ARRAY_LENGTH dup (0)</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset ByteArray</strong></p>
<p><strong>;point to the start of the array</strong></p>
<p><strong>cld ;make LODSB increment SI</strong></p>
<p><strong>rept ARRAY_LENGTH</strong></p>
<p><strong>lodsb ;get this array byte &amp; point to the</strong></p>
<p><strong>; next byte in the array</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-10-3" class="level2">
<h2>Listing 10-3</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 10-3 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Loads a byte into AL 1000 times via MOV, with no</strong></p>
<p><strong>; INC performed.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>ByteArray db ARRAY_LENGTH dup (0)</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset ByteArray</strong></p>
<p><strong>;point to the start of the array</strong></p>
<p><strong>rept ARRAY_LENGTH</strong></p>
<p><strong>mov al,[si] ;get this array byte but don’t point</strong></p>
<p><strong>; to the next byte in the array</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-10-4" class="level2">
<h2>Listing 10-4</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 10-4 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches a word-sized array for the first element</strong></p>
<p><strong>; greater than 10,000, using non-string instructions.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>WordArray dw 1000 dup (0), 10001</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov di,offset WordArray-2</strong></p>
<p><strong>;start 1 word early so the</strong></p>
<p><strong>; first preincrement points</strong></p>
<p><strong>; to the first element</strong></p>
<p><strong>mov ax,10000 ;value we’ll compare with</strong></p>
<p><strong>SearchLoop:</strong></p>
<p><strong>inc di ;point to the next element</strong></p>
<p><strong>inc di</strong></p>
<p><strong>cmp ax,[di] ;compare the next element</strong></p>
<p><strong>; to 10,000</strong></p>
<p><strong>jae SearchLoop ;if not greater than 10,000,</strong></p>
<p><strong>; do the next element</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-10-5" class="level2">
<h2>Listing 10-5</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 10-5 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches a word-sized array for the first element</strong></p>
<p><strong>; greater than 10,000, using SCASW.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>WordArray dw 1000 dup (0), 10001</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov di,seg WordArray</strong></p>
<p><strong>mov es,di ;SCASW always uses ES:SI as a</strong></p>
<p><strong>; memory pointer</strong></p>
<p><strong>mov di,offset WordArray</strong></p>
<p><strong>mov ax,10000 ;value we’ll compare with</strong></p>
<p><strong>cld ;make SCASW add 2 to DI after</strong></p>
<p><strong>; each execution</strong></p>
<p><strong>SearchLoop:</strong></p>
<p><strong>scasw ;compare the next element to 10,000</strong></p>
<p><strong>jae SearchLoop ;if not greater than 10,000, do</strong></p>
<p><strong>; the next element</strong></p>
<p><strong>dec di ;point back to the matching word</strong></p>
<p><strong>dec di</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-10-6" class="level2">
<h2>Listing 10-6</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 10-6 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches a word-sized array for the first element</strong></p>
<p><strong>; greater than 10,000, using LODSW &amp; CMP.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>WordArray dw 1000 dup (0), 10001</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset WordArray</strong></p>
<p><strong>;array to search</strong></p>
<p><strong>mov dx,10000 ;value we’ll compare with</strong></p>
<p><strong>cld ;make LODSW add 2 to SI after each</strong></p>
<p><strong>; execution</strong></p>
<p><strong>SearchLoop:</strong></p>
<p><strong>lodsw ;get the next element</strong></p>
<p><strong>cmp dx,ax ;compare the element to 10,000</strong></p>
<p><strong>jae SearchLoop ;if not greater than 10,000, do</strong></p>
<p><strong>; the next element</strong></p>
<p><strong>dec di ;point back to the matching word</strong></p>
<p><strong>dec di</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-10-7" class="level2">
<h2>Listing 10-7</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 10-7 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Initializes a 1000-word array using a loop and</strong></p>
<p><strong>; non-string instructions.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>WordArray dw ARRAY_LENGTH dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov di,offset WordArray</strong></p>
<p><strong>;point to array to fill</strong></p>
<p><strong>sub ax,ax ;we’ll fill with the value zero</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of words to fill</strong></p>
<p><strong>ZeroLoop:</strong></p>
<p><strong>mov [di],ax ;zero one word</strong></p>
<p><strong>inc di ;point to the next word</strong></p>
<p><strong>inc di</strong></p>
<p><strong>loop ZeroLoop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-10-8" class="level2">
<h2>Listing 10-8</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 10-8 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Initializes a 1000-word array using a single</strong></p>
<p><strong>; repeated STOSW.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>WordArray dw ARRAY_LENGTH dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov di,seg WordArray</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset WordArray</strong></p>
<p><strong>;point ES:DI to the array to</strong></p>
<p><strong>; fill, since STOSW must</strong></p>
<p><strong>; use that segment:offset combo</strong></p>
<p><strong>; as a memory pointer</strong></p>
<p><strong>sub ax,ax ;we’ll fill with the value zero</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of words to fill</strong></p>
<p><strong>cld ;make STOSW add 2 to DI after each</strong></p>
<p><strong>; execution</strong></p>
<p><strong>rep stosw ;fill the array</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-10-9" class="level2">
<h2>Listing 10-9</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 10-9 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Sets every element of a 1000-byte array to 1 by</strong></p>
<p><strong>; repeating STOSB 1000 times.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>ByteArray db ARRAY_LENGTH dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov di,seg ByteArray</strong></p>
<p><strong>mov es,di ;point ES:DI to the array to fill</strong></p>
<p><strong>mov di,offset ByteArray</strong></p>
<p><strong>mov al,1 ;we’ll fill with the value 1</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to fill</strong></p>
<p><strong>cld ;make STOSB increment DI after</strong></p>
<p><strong>; each execution</strong></p>
<p><strong>rep stosb ;initialize the array</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-10-10" class="level2">
<h2>Listing 10-10</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 10-10 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Sets every element of a 1000-byte array to 1 by</strong></p>
<p><strong>; repeating STOSW 500 times.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>WordArray db ARRAY_LENGTH dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov di,seg WordArray</strong></p>
<p><strong>mov es,di ;point ES:DI to the array to fill</strong></p>
<p><strong>mov di,offset WordArray</strong></p>
<p><strong>mov ax,(1 shl 8) + 1</strong></p>
<p><strong>;fill each byte with the value 1</strong></p>
<p><strong>mov cx,ARRAY_LENGTH/2 ;# of words to fill</strong></p>
<p><strong>cld ;make STOSW add 2 to DI on each</strong></p>
<p><strong>; execution</strong></p>
<p><strong>rep stosw ;fill a word at a time</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-10-11" class="level2">
<h2>Listing 10-11</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 10-11 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Clears a 1000-byte block of memory via BlockClear,</strong></p>
<p><strong>; which handles blocks between 0 and 64K-1 bytes in</strong></p>
<p><strong>; length.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>ByteArray db ARRAY_LENGTH dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Clears a block of memory CX bytes in length. A value</strong></p>
<p><strong>; of 0 means “clear zero bytes,” so the maximum length</strong></p>
<p><strong>; that can be cleared is 64K-1 bytes and the minimum</strong></p>
<p><strong>; length is 0 bytes.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = number of bytes to clear</strong></p>
<p><strong>; ES:DI = start of block to clear</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, CX, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>BlockClear:</strong></p>
<p><strong>sub al,al ;fill with zero</strong></p>
<p><strong>cld ;make STOSB move DI up</strong></p>
<p><strong>rep stosb ;clear the block</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov di,seg ByteArray</strong></p>
<p><strong>mov es,di ;point ES:DI to the array to clear</strong></p>
<p><strong>mov di,offset ByteArray</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to clear</strong></p>
<p><strong>call BlockClear ;clear the array</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-10-12" class="level2">
<h2>Listing 10-12</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 10-12 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Clears a 1000-byte block of memory via BlockClear64,</strong></p>
<p><strong>; which handles blocks between 1 and 64K bytes in</strong></p>
<p><strong>; length. BlockClear64 gains the ability to handle</strong></p>
<p><strong>; 64K blocks by using STOSW rather than STOSB to</strong></p>
<p><strong>; the greatest possible extent, getting a performance</strong></p>
<p><strong>; boost in the process.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>ByteArray db ARRAY_LENGTH dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Clears a block of memory CX bytes in length. A value</strong></p>
<p><strong>; of 0 means “clear 64K bytes,” so the maximum length</strong></p>
<p><strong>; that can be cleared is 64K bytes and the minimum length</strong></p>
<p><strong>; is 1 byte.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = number of bytes to clear</strong></p>
<p><strong>; ES:DI = start of block to clear</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, CX, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>BlockClear64:</strong></p>
<p><strong>sub ax,ax ;fill with zero a word at a time</strong></p>
<p><strong>stc ;assume the count is zero-setting</strong></p>
<p><strong>; the Carry flag will give us 8000h</strong></p>
<p><strong>; after the RCR</strong></p>
<p><strong>jcxz DoClear ;the count is zero</strong></p>
<p><strong>clc ;it’s not zero</strong></p>
<p><strong>DoClear:</strong></p>
<p><strong>rcr cx,1 ;divide by 2, copying the odd-byte</strong></p>
<p><strong>; status to the Carry flag and</strong></p>
<p><strong>; shifting a 1 into bit 15 if and</strong></p>
<p><strong>; only if the count is zero</strong></p>
<p><strong>cld ;make STOSW move DI up</strong></p>
<p><strong>rep stosw ;clear the block</strong></p>
<p><strong>jnc ClearDone</strong></p>
<p><strong>;the Carry status is still left over</strong></p>
<p><strong>; from the RCR. If we had an even #</strong></p>
<p><strong>; of bytes, we’re done</strong></p>
<p><strong>stosb ;clear the odd byte</strong></p>
<p><strong>ClearDone:</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov di,seg ByteArray</strong></p>
<p><strong>mov es,di ;point ES:DI to the array to clear</strong></p>
<p><strong>mov di,offset ByteArray</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to clear</strong></p>
<p><strong>call BlockClear64 ;clear the array</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-10-13" class="level2">
<h2>Listing 10-13</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 10-13 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Clears a 1000-byte block of memory via BlockClearW,</strong></p>
<p><strong>; which handles blocks between 0 and 64K-1 bytes in</strong></p>
<p><strong>; length. BlockClearW uses STOSW rather than STOSB to</strong></p>
<p><strong>; the greatest possible extent in order to improve</strong></p>
<p><strong>; performance.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>ByteArray db ARRAY_LENGTH dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Clears a block of memory CX bytes in length. A value</strong></p>
<p><strong>; of 0 means “clear zero bytes,” so the maximum length</strong></p>
<p><strong>; that can be cleared is 64K-1 bytes and the minimum</strong></p>
<p><strong>; length is 0 bytes.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = number of bytes to clear</strong></p>
<p><strong>; ES:DI = start of block to clear</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, CX, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>BlockClearW:</strong></p>
<p><strong>sub ax,ax ;we’ll fill with the value 0</strong></p>
<p><strong>shr cx,1 ;divide by 2, copying the odd-byte</strong></p>
<p><strong>; status to the Carry flag</strong></p>
<p><strong>cld ;make STOSW move DI up</strong></p>
<p><strong>rep stosw ;clear the block</strong></p>
<p><strong>jnc ClearDone</strong></p>
<p><strong>;the Carry status is still left over</strong></p>
<p><strong>; from the SHR. If we had an even #</strong></p>
<p><strong>; of bytes, we’re done</strong></p>
<p><strong>stosb ;clear the odd byte</strong></p>
<p><strong>ClearDone:</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov di,seg ByteArray</strong></p>
<p><strong>mov es,di ;point ES:DI to the array to clear</strong></p>
<p><strong>mov di,offset ByteArray</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to clear</strong></p>
<p><strong>call BlockClearW ;clear the array</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-10-14" class="level2">
<h2>Listing 10-14</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 10-14 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Generates the 8-bit checksum of a 1000-byte array</strong></p>
<p><strong>; using LODS with an ES: override.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>FarSeg segment para</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>ByteArray db ARRAY_LENGTH dup (0)</strong></p>
<p><strong>FarSeg ends</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,seg ByteArray</strong></p>
<p><strong>mov es,si ;point ES:SI to the array to</strong></p>
<p><strong>; checksum</strong></p>
<p><strong>mov si,offset ByteArray</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to checksum</strong></p>
<p><strong>sub ah,ah ;zero the checksum counter</strong></p>
<p><strong>cld ;make LODS move the pointer up</strong></p>
<p><strong>ChecksumLoop:</strong></p>
<p><strong>lods byte ptr es:[si]</strong></p>
<p><strong>;get the next byte to checksum</strong></p>
<p><strong>add ah,al ;add the byte into the checksum</strong></p>
<p><strong>loop ChecksumLoop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-10-15" class="level2">
<h2>Listing 10-15</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 10-15 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Generates the 8-bit checksum of a 1000-byte array</strong></p>
<p><strong>; using LODS without a segment override, by setting</strong></p>
<p><strong>; DS up to point to the far segment for the duration</strong></p>
<p><strong>; of the loop.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>FarSeg segment para</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>ByteArray db ARRAY_LENGTH dup (0)</strong></p>
<p><strong>FarSeg ends</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>push ds ;preserve the normal DS setting</strong></p>
<p><strong>mov si,seg ByteArray</strong></p>
<p><strong>mov ds,si ;point DS to the far segment for</strong></p>
<p><strong>; the duration of the loop-we</strong></p>
<p><strong>; won’t need the normal DS setting</strong></p>
<p><strong>; until the loop is done</strong></p>
<p><strong>mov si,offset ByteArray</strong></p>
<p><strong>mov cx,ARRAY_LENGTH</strong></p>
<p><strong>sub ah,ah ;zero the checksum counter</strong></p>
<p><strong>cld ;make LODSB move the pointer up</strong></p>
<p><strong>ChecksumLoop:</strong></p>
<p><strong>lodsb ;get the next byte to checksum</strong></p>
<p><strong>add ah,al ;add the byte into the checksum</strong></p>
<p><strong>loop ChecksumLoop</strong></p>
<p><strong>pop ds ;retrieve the normal DS setting</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-10-16" class="level2">
<h2>Listing 10-16</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 10-16 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Reads a single byte stored in a far segment by</strong></p>
<p><strong>; using a segment override prefix.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>FarSeg segment para</strong></p>
<p><strong>MemVar db 0 ;this variable resides in a</strong></p>
<p><strong>; far segment</strong></p>
<p><strong>FarSeg ends</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 100</strong></p>
<p><strong>mov si,seg MemVar</strong></p>
<p><strong>mov es,si</strong></p>
<p><strong>mov si,offset MemVar ;point ES:SI to MemVar</strong></p>
<p><strong>lods byte ptr es:[si] ;read MemVar</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-10-17" class="level2">
<h2>Listing 10-17</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 10-17 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Reads a single byte stored in a far segment by</strong></p>
<p><strong>; temporarily pointing DS to the far segment.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>FarSeg segment para</strong></p>
<p><strong>MemVar db 0 ;this variable resides in a</strong></p>
<p><strong>; far segment</strong></p>
<p><strong>FarSeg ends</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 100</strong></p>
<p><strong>push ds ;preserve the normal data segment</strong></p>
<p><strong>mov si,seg MemVar</strong></p>
<p><strong>mov ds,si</strong></p>
<p><strong>mov si,offset MemVar ;point DS:SI to MemVar</strong></p>
<p><strong>lodsb ;read MemVar</strong></p>
<p><strong>pop ds ;retrieve the normal data segment</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-10-18" class="level2">
<h2>Listing 10-18</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 10-18 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Reads a single byte stored in a far segment by</strong></p>
<p><strong>; using a segment override prefix. Loads ES just</strong></p>
<p><strong>; once and then leaves ES set to point to the far</strong></p>
<p><strong>; segment at all times.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>FarSeg segment para</strong></p>
<p><strong>MemVar db 0 ;this variable resides in a</strong></p>
<p><strong>; far segment</strong></p>
<p><strong>FarSeg ends</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,seg MemVar</strong></p>
<p><strong>mov es,si ;point ES to the far segment for</strong></p>
<p><strong>; the remainder of the test</strong></p>
<p><strong>rept 100</strong></p>
<p><strong>mov si,offset MemVar ;point ES:SI to MemVar</strong></p>
<p><strong>lods byte ptr es:[si] ;read MemVar</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-10-19" class="level2">
<h2>Listing 10-19</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 10-19 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Generates the 8-bit checksum of a 1000-byte array</strong></p>
<p><strong>; by loading both segment and offset from a far</strong></p>
<p><strong>; pointer each time through the loop and without</strong></p>
<p><strong>; using string instructions, as the code generated</strong></p>
<p><strong>; by a typical high-level language compiler would.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>FarSeg segment para</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>ByteArray db ARRAY_LENGTH dup (0)</strong></p>
<p><strong>;this array resides in a</strong></p>
<p><strong>; far segment</strong></p>
<p><strong>FarSeg ends</strong></p>
<p><strong>;</strong></p>
<p><strong>FarPtr dd ByteArray ;a far pointer to the array</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to checksum</strong></p>
<p><strong>sub ah,ah ;zero the checksum counter</strong></p>
<p><strong>ChecksumLoop:</strong></p>
<p><strong>les bx,[FarPtr] ;load both segment and</strong></p>
<p><strong>; offset from the far</strong></p>
<p><strong>; pointer</strong></p>
<p><strong>inc word ptr [FarPtr]</strong></p>
<p><strong>;advance the offset portion</strong></p>
<p><strong>; of the far pointer</strong></p>
<p><strong>add ah,es:[bx] ;add the next byte to the</strong></p>
<p><strong>; checksum</strong></p>
<p><strong>loop ChecksumLoop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-1" class="level2">
<h2>Listing 11-1</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-1 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a string to another string, converting all</strong></p>
<p><strong>; characters to uppercase in the process, using a loop</strong></p>
<p><strong>; containing LODSB and STOSB.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>SourceString label word</strong></p>
<p><strong>db ‘This space intentionally left not blank’,0</strong></p>
<p><strong>DestString db 100 dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies one zero-terminated string to another string,</strong></p>
<p><strong>; converting all characters to uppercase.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DS:SI = start of source string</strong></p>
<p><strong>; ES:DI = start of destination string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, BX, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries. Does not handle</strong></p>
<p><strong>; overlapping strings.</strong></p>
<p><strong>;</strong></p>
<p><strong>CopyStringUpper:</strong></p>
<p><strong>mov bl,‘a’ ;set up for fast register-register</strong></p>
<p><strong>mov bh,‘z’ ; comparisons</strong></p>
<p><strong>cld</strong></p>
<p><strong>StringUpperLoop:</strong></p>
<p><strong>lodsb ;get the next character and</strong></p>
<p><strong>; point to the following character</strong></p>
<p><strong>cmp al,bl ;below ‘a’?</strong></p>
<p><strong>jb IsUpper ;yes, not lowercase</strong></p>
<p><strong>cmp al,bh ;above ‘z’?</strong></p>
<p><strong>ja IsUpper ;yes, not lowercase</strong></p>
<p><strong>and al,not 20h ;is lowercase-make uppercase</strong></p>
<p><strong>IsUpper:</strong></p>
<p><strong>stosb ;put the uppercase character into</strong></p>
<p><strong>; the new string and point to the</strong></p>
<p><strong>; following character</strong></p>
<p><strong>and al,al ;is this the zero that marks the</strong></p>
<p><strong>; end of the string?</strong></p>
<p><strong>jnz StringUpperLoop ;no, do the next character</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset SourceString ;point DS:SI to the</strong></p>
<p><strong>; string to copy from</strong></p>
<p><strong>mov di,seg DestString</strong></p>
<p><strong>mov es,di ;point ES:DI to the</strong></p>
<p><strong>mov di,offset DestString ; string to copy to</strong></p>
<p><strong>call CopyStringUpper ;copy &amp; convert to</strong></p>
<p><strong>; uppercase</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-2" class="level2">
<h2>Listing 11-2</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-2 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a string to another string, converting all</strong></p>
<p><strong>; characters to uppercase in the process, using a loop</strong></p>
<p><strong>; containing non-string instructions.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>SourceString label word</strong></p>
<p><strong>db ‘This space intentionally left not blank’,0</strong></p>
<p><strong>DestString db 100 dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies one zero-terminated string to another string,</strong></p>
<p><strong>; converting all characters to uppercase.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DS:SI = start of source string</strong></p>
<p><strong>; ES:DI = start of destination string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, BX, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>CopyStringUpper:</strong></p>
<p><strong>mov bl,‘a’ ;set up for fast register-register</strong></p>
<p><strong>mov bh,‘z’ ; comparisons</strong></p>
<p><strong>StringUpperLoop:</strong></p>
<p><strong>mov al,[si] ;get the next character</strong></p>
<p><strong>inc si ;point to the following character</strong></p>
<p><strong>cmp al,bl ;below ‘a’?</strong></p>
<p><strong>jb IsUpper ;yes, not lowercase</strong></p>
<p><strong>cmp al,bh ;above ‘z’?</strong></p>
<p><strong>ja IsUpper ;yes, not lowercase</strong></p>
<p><strong>and al,not 20h ;is lowercase-make uppercase</strong></p>
<p><strong>IsUpper:</strong></p>
<p><strong>mov es:[di],al ;put the uppercase character into</strong></p>
<p><strong>; the new string</strong></p>
<p><strong>inc di ;point to the following character</strong></p>
<p><strong>and al,al ;is this the zero that marks the</strong></p>
<p><strong>; end of the string?</strong></p>
<p><strong>jnz StringUpperLoop ;no, do the next character</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset SourceString ;point DS:SI to the</strong></p>
<p><strong>; string to copy from</strong></p>
<p><strong>mov di,seg DestString</strong></p>
<p><strong>mov es,di ;point ES:DI to the</strong></p>
<p><strong>mov di,offset DestString ; string to copy to</strong></p>
<p><strong>call CopyStringUpper ;copy &amp; convert to</strong></p>
<p><strong>; uppercase</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-3" class="level2">
<h2>Listing 11-3</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-3 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Converts all characters in a string to uppercase,</strong></p>
<p><strong>; using a loop containing LODSB and STOSB and using</strong></p>
<p><strong>; two pointers.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>SourceString label word</strong></p>
<p><strong>db ‘This space intentionally left not blank’,0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies one zero-terminated string to another string,</strong></p>
<p><strong>; converting all characters to uppercase.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DS:SI = start of source string</strong></p>
<p><strong>; ES:DI = start of destination string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, BX, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>CopyStringUpper:</strong></p>
<p><strong>mov bl,‘a’ ;set up for fast register-register</strong></p>
<p><strong>mov bh,‘z’ ; comparisons</strong></p>
<p><strong>cld</strong></p>
<p><strong>StringUpperLoop:</strong></p>
<p><strong>lodsb ;get the next character and</strong></p>
<p><strong>; point to the following character</strong></p>
<p><strong>cmp al,bl ;below ‘a’?</strong></p>
<p><strong>jb IsUpper ;yes, not lowercase</strong></p>
<p><strong>cmp al,bh ;above ‘z’?</strong></p>
<p><strong>ja IsUpper ;yes, not lowercase</strong></p>
<p><strong>and al,not 20h ;is lowercase-make uppercase</strong></p>
<p><strong>IsUpper:</strong></p>
<p><strong>stosb ;put the uppercase character into</strong></p>
<p><strong>; the new string and point to the</strong></p>
<p><strong>; following character</strong></p>
<p><strong>and al,al ;is this the zero that marks the</strong></p>
<p><strong>; end of the string?</strong></p>
<p><strong>jnz StringUpperLoop ;no, do the next character</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset SourceString ;point DS:SI to the</strong></p>
<p><strong>; string to convert</strong></p>
<p><strong>mov di,ds</strong></p>
<p><strong>mov es,di ;point ES:DI to the</strong></p>
<p><strong>mov di,si ; same string</strong></p>
<p><strong>call CopyStringUpper ;convert to</strong></p>
<p><strong>; uppercase in place</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-4" class="level2">
<h2>Listing 11-4</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-4 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Converts all characters in a string to uppercase,</strong></p>
<p><strong>; using a loop containing non-string instructions</strong></p>
<p><strong>; and using only one pointer.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>SourceString label word</strong></p>
<p><strong>db ‘This space intentionally left not blank’,0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Converts a string to uppercase.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DS:SI = start of string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, BX, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>StringToUpper:</strong></p>
<p><strong>mov bl,‘a’ ;set up for fast register-register</strong></p>
<p><strong>mov bh,‘z’ ; comparisons</strong></p>
<p><strong>StringToUpperLoop:</strong></p>
<p><strong>mov al,[si] ;get the next character</strong></p>
<p><strong>cmp al,bl ;below ‘a’?</strong></p>
<p><strong>jb IsUpper ;yes, not lowercase</strong></p>
<p><strong>cmp al,bh ;above ‘z’?</strong></p>
<p><strong>ja IsUpper ;yes, not lowercase</strong></p>
<p><strong>and al,not 20h ;is lowercase-make uppercase</strong></p>
<p><strong>IsUpper:</strong></p>
<p><strong>mov [si],al ;put the uppercase character back</strong></p>
<p><strong>inc si ; into the string and point to the</strong></p>
<p><strong>; following character</strong></p>
<p><strong>and al,al ;is this the zero that marks the</strong></p>
<p><strong>; end of the string?</strong></p>
<p><strong>jnz StringToUpperLoop ;no, do the next character</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset SourceString ;point to the string</strong></p>
<p><strong>; to convert</strong></p>
<p><strong>call StringToUpper ;convert it to</strong></p>
<p><strong>; uppercase</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-5" class="level2">
<h2>Listing 11-5</h2>
<p><strong>; *** Listing 11-5 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Sets the high bit of every element in a byte</strong></p>
<p><strong>; array using LODSB and STOSB.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>ByteArray db ARRAY_LENGTH dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset ByteArray ;point to the array</strong></p>
<p><strong>mov di,ds ; as both source and</strong></p>
<p><strong>mov es,di ; destination</strong></p>
<p><strong>mov di,si</strong></p>
<p><strong>mov cx,ARRAY_LENGTH</strong></p>
<p><strong>mov ah,80h ;bit pattern to OR</strong></p>
<p><strong>cld</strong></p>
<p><strong>SetHighBitLoop:</strong></p>
<p><strong>lodsb ;get the next byte</strong></p>
<p><strong>or al,ah ;set the high bit</strong></p>
<p><strong>stosb ;save the byte</strong></p>
<p><strong>loop SetHighBitLoop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-6" class="level2">
<h2>Listing 11-6</h2>
<p><strong>; *** Listing 11-6 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Sets the high bit of every element in a byte</strong></p>
<p><strong>; array by ORing directly to memory.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 1000</strong></p>
<p><strong>ByteArray db ARRAY_LENGTH dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset ByteArray ;point to the array</strong></p>
<p><strong>mov cx,ARRAY_LENGTH</strong></p>
<p><strong>mov al,80h ;bit pattern to OR</strong></p>
<p><strong>SetHighBitLoop:</strong></p>
<p><strong>or [si],al ;set the high bit</strong></p>
<p><strong>inc si ;point to the next</strong></p>
<p><strong>; byte</strong></p>
<p><strong>loop SetHighBitLoop</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-7" class="level2">
<h2>Listing 11-7</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-7 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies overlapping blocks of memory with MOVS.</strong></p>
<p><strong>; To the greatest possible extent, the copy is</strong></p>
<p><strong>; performed a word at a time.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>TEST_LENGTH1 equ 501 ;sample copy length #1</strong></p>
<p><strong>TEST_LENGTH2 equ 1499 ;sample copy length #2</strong></p>
<p><strong>TestArray db 1500 dup (0)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a block of memory CX bytes in length. A value</strong></p>
<p><strong>; of 0 means “copy zero bytes,” since it wouldn’t make</strong></p>
<p><strong>; much sense to copy one 64K block to another 64K block</strong></p>
<p><strong>; in the same segment, so the maximum length that can</strong></p>
<p><strong>; be copied is 64K-1 bytes and the minimum length</strong></p>
<p><strong>; is 0 bytes. Note that both blocks must be in DS. Note</strong></p>
<p><strong>; also that overlap handling is not guaranteed if either</strong></p>
<p><strong>; block wraps at the end of the segment.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = number of bytes to clear</strong></p>
<p><strong>; DS:SI = start of block to copy</strong></p>
<p><strong>; DS:DI = start of destination block</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: CX, DX, SI, DI, ES</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>BlockCopyWithOverlap:</strong></p>
<p><strong>mov dx,ds ;source and destination are in the</strong></p>
<p><strong>mov es,dx ; same segment</strong></p>
<p><strong>cmp si,di ;which way do the blocks overlap, if</strong></p>
<p><strong>; they do overlap?</strong></p>
<p><strong>jae LowToHigh</strong></p>
<p><strong>;source is not below destination, so</strong></p>
<p><strong>; we can copy from low to high</strong></p>
<p><strong>;source is below destination, so we</strong></p>
<p><strong>; must copy from high to low</strong></p>
<p><strong>add si,cx ;point to the end of the source</strong></p>
<p><strong>dec si ; block</strong></p>
<p><strong>add di,cx ;point to the end of the destination</strong></p>
<p><strong>dec di ; block</strong></p>
<p><strong>std ;copy from high addresses to low</strong></p>
<p><strong>shr cx,1 ;divide by 2, copying the odd-byte</strong></p>
<p><strong>; status to the Carry flag</strong></p>
<p><strong>jnc CopyWordHighToLow ;no odd byte to copy</strong></p>
<p><strong>movsb ;copy the odd byte</strong></p>
<p><strong>CopyWordHighToLow:</strong></p>
<p><strong>dec si ;point one word lower in memory, not</strong></p>
<p><strong>dec di ; one byte</strong></p>
<p><strong>rep movsw ;move the rest of the block</strong></p>
<p><strong>cld</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>LowToHigh:</strong></p>
<p><strong>cld ;copy from low addresses to high</strong></p>
<p><strong>shr cx,1 ;divide by 2, copying the odd-byte</strong></p>
<p><strong>; status to the Carry flag</strong></p>
<p><strong>jnc CopyWordLowToHigh ;no odd byte to copy</strong></p>
<p><strong>movsb ;copy the odd byte</strong></p>
<p><strong>CopyWordLowToHigh:</strong></p>
<p><strong>rep movsw ;move the rest of the block</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>;</strong></p>
<p><strong>; First run the case where the destination overlaps &amp; is</strong></p>
<p><strong>; higher in memory.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov si,offset TestArray</strong></p>
<p><strong>mov di,offset TestArray+1</strong></p>
<p><strong>mov cx,TEST_LENGTH1</strong></p>
<p><strong>call BlockCopyWithOverlap</strong></p>
<p><strong>;</strong></p>
<p><strong>; Now run the case where the destination overlaps &amp; is</strong></p>
<p><strong>; lower in memory.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov si,offset TestArray+1</strong></p>
<p><strong>mov di,offset TestArray</strong></p>
<p><strong>mov cx,TEST_LENGTH2</strong></p>
<p><strong>call BlockCopyWithOverlap</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-8" class="level2">
<h2>Listing 11-8</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-8 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies overlapping blocks of memory with</strong></p>
<p><strong>; non-string instructions. To the greatest possible</strong></p>
<p><strong>; extent, the copy is performed a word at a time.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>TEST_LENGTH1 equ 501 ;sample copy length #1</strong></p>
<p><strong>TEST_LENGTH2 equ 1499 ;sample copy length #2</strong></p>
<p><strong>TestArray db 1500 dup (0)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a block of memory CX bytes in length. A value</strong></p>
<p><strong>; of 0 means “copy zero bytes,” since it wouldn’t make</strong></p>
<p><strong>; much sense to copy one 64K block to another 64K block</strong></p>
<p><strong>; in the same segment, so the maximum length that can</strong></p>
<p><strong>; be copied is 64K-1 bytes and the minimum length</strong></p>
<p><strong>; is 0 bytes. Note that both blocks must be in DS. Note</strong></p>
<p><strong>; also that overlap handling is not guaranteed if either</strong></p>
<p><strong>; block wraps at the end of the segment.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = number of bytes to clear</strong></p>
<p><strong>; DS:SI = start of block to copy</strong></p>
<p><strong>; DS:DI = start of destination block</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, CX, DX, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>BlockCopyWithOverlap:</strong></p>
<p><strong>jcxz BlockCopyWithOverlapDone</strong></p>
<p><strong>;guard against zero block size,</strong></p>
<p><strong>; since LOOP will execute 64K times</strong></p>
<p><strong>; when started with CX=0</strong></p>
<p><strong>mov dx,2 ;amount by which to adjust the</strong></p>
<p><strong>; pointers in the word-copy loop</strong></p>
<p><strong>cmp si,di ;which way do the blocks overlap, if</strong></p>
<p><strong>; they do overlap?</strong></p>
<p><strong>jae LowToHigh</strong></p>
<p><strong>;source is not below destination, so</strong></p>
<p><strong>; we can copy from low to high</strong></p>
<p><strong>;source is below destination, so we</strong></p>
<p><strong>; must copy from high to low</strong></p>
<p><strong>add si,cx ;point to the end of the source</strong></p>
<p><strong>dec si ; block</strong></p>
<p><strong>add di,cx ;point to the end of the destination</strong></p>
<p><strong>dec di ; block</strong></p>
<p><strong>shr cx,1 ;divide by 2, copying the odd-byte</strong></p>
<p><strong>; status to the Carry flag</strong></p>
<p><strong>jnc CopyWordHighToLow ;no odd byte to copy</strong></p>
<p><strong>mov al,[si] ;copy the odd byte</strong></p>
<p><strong>mov [di],al</strong></p>
<p><strong>dec si ;advance both pointers</strong></p>
<p><strong>dec di</strong></p>
<p><strong>CopyWordHighToLow:</strong></p>
<p><strong>dec si ;point one word lower in memory, not</strong></p>
<p><strong>dec di ; one byte</strong></p>
<p><strong>HighToLowCopyLoop:</strong></p>
<p><strong>mov ax,[si] ;copy a word</strong></p>
<p><strong>mov [di],ax</strong></p>
<p><strong>sub si,dx ;advance both pointers 1 word</strong></p>
<p><strong>sub di,dx</strong></p>
<p><strong>loop HighToLowCopyLoop</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>LowToHigh:</strong></p>
<p><strong>shr cx,1 ;divide by 2, copying the odd-byte</strong></p>
<p><strong>; status to the Carry flag</strong></p>
<p><strong>jnc LowToHighCopyLoop ;no odd byte to copy</strong></p>
<p><strong>mov al,[si] ;copy the odd byte</strong></p>
<p><strong>mov [di],al</strong></p>
<p><strong>inc si ;advance both pointers</strong></p>
<p><strong>inc di</strong></p>
<p><strong>LowToHighCopyLoop:</strong></p>
<p><strong>mov ax,[si] ;copy a word</strong></p>
<p><strong>mov [di],ax</strong></p>
<p><strong>add si,dx ;advance both pointers 1 word</strong></p>
<p><strong>add di,dx</strong></p>
<p><strong>loop LowToHighCopyLoop</strong></p>
<p><strong>BlockCopyWithOverlapDone:</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>;</strong></p>
<p><strong>; First run the case where the destination overlaps &amp; is</strong></p>
<p><strong>; higher in memory.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov si,offset TestArray</strong></p>
<p><strong>mov di,offset TestArray+1</strong></p>
<p><strong>mov cx,TEST_LENGTH1</strong></p>
<p><strong>call BlockCopyWithOverlap</strong></p>
<p><strong>;</strong></p>
<p><strong>; Now run the case where the destination overlaps &amp; is</strong></p>
<p><strong>; lower in memory.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov si,offset TestArray+1</strong></p>
<p><strong>mov di,offset TestArray</strong></p>
<p><strong>mov cx,TEST_LENGTH2</strong></p>
<p><strong>call BlockCopyWithOverlap</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-9" class="level2">
<h2>Listing 11-9</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-9 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Counts the number of times the letter ‘A’</strong></p>
<p><strong>; appears in a byte-sized array, using non-string</strong></p>
<p><strong>; instructions.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ByteArray label byte</strong></p>
<p><strong>db ‘ARRAY CONTAINING THE LETTER’‘A’‘4 TIMES’</strong></p>
<p><strong>ARRAY_LENGTH equ ($-ByteArray)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Counts the number of occurrences of the specified byte</strong></p>
<p><strong>; in the specified byte-sized array.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = byte of which to count occurrences</strong></p>
<p><strong>; CX = array length (0 means 64K)</strong></p>
<p><strong>; DS:DI = array to count byte occurrences in</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; DX = number of occurrences of the specified byte</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: CX, DX, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle arrays that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>ByteCount:</strong></p>
<p><strong>sub dx,dx ;set occurrence counter to 0</strong></p>
<p><strong>dec di ;compensate for the initial</strong></p>
<p><strong>; upcoming INC DI</strong></p>
<p><strong>and cx,cx ;64K long?</strong></p>
<p><strong>jnz ByteCountLoop ;no</strong></p>
<p><strong>dec cx ;yes, so handle first byte</strong></p>
<p><strong>; specially, since JCXZ will</strong></p>
<p><strong>; otherwise conclude that</strong></p>
<p><strong>; we’re done right away</strong></p>
<p><strong>inc di ;point to first byte</strong></p>
<p><strong>cmp [di],al ;is this byte the value</strong></p>
<p><strong>; we’re looking for?</strong></p>
<p><strong>jz ByteCountCountOccurrence</strong></p>
<p><strong>;yes, so count it</strong></p>
<p><strong>ByteCountLoop:</strong></p>
<p><strong>jcxz ByteCountDone ;done if we’ve checked all</strong></p>
<p><strong>; the bytes in the array</strong></p>
<p><strong>dec cx ;count off the byte we’re</strong></p>
<p><strong>; about to check</strong></p>
<p><strong>inc di ;point to the next byte to</strong></p>
<p><strong>; check</strong></p>
<p><strong>cmp [di],al ;see if this byte contains</strong></p>
<p><strong>; the value we’re counting</strong></p>
<p><strong>jnz ByteCountLoop ;no match</strong></p>
<p><strong>ByteCountCountOccurrence:</strong></p>
<p><strong>inc dx ;count this occurrence</strong></p>
<p><strong>jmp ByteCountLoop ;check the next byte, if any</strong></p>
<p><strong>ByteCountDone:</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov al,‘A’ ;byte of which we want a</strong></p>
<p><strong>; count of occurrences</strong></p>
<p><strong>mov di,offset ByteArray</strong></p>
<p><strong>;array we want a count for</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to check</strong></p>
<p><strong>call ByteCount ;get the count</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-10" class="level2">
<h2>Listing 11-10</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-10 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Counts the number of times the letter ‘A’</strong></p>
<p><strong>; appears in a byte-sized array, using REPNZ SCASB.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ByteArray label byte</strong></p>
<p><strong>db ‘ARRAY CONTAINING THE LETTER’‘A’‘4 TIMES’</strong></p>
<p><strong>ARRAY_LENGTH equ ($-ByteArray)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Counts the number of occurrences of the specified byte</strong></p>
<p><strong>; in the specified byte-sized array.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = byte of which to count occurrences</strong></p>
<p><strong>; CX = array length (0 means 64K)</strong></p>
<p><strong>; DS:DI = array to count byte occurrences in</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; DX = number of occurrences of the specified byte</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: CX, DX, DI, ES</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle arrays that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries. Does not handle</strong></p>
<p><strong>; overlapping strings.</strong></p>
<p><strong>;</strong></p>
<p><strong>ByteCount:</strong></p>
<p><strong>push ds</strong></p>
<p><strong>pop es ;SCAS uses ES:DI</strong></p>
<p><strong>sub dx,dx ;set occurrence counter to 0</strong></p>
<p><strong>cld</strong></p>
<p><strong>and cx,cx ;64K long?</strong></p>
<p><strong>jnz ByteCountLoop ;no</strong></p>
<p><strong>dec cx ;yes, so handle first byte</strong></p>
<p><strong>; specially, since JCXZ will</strong></p>
<p><strong>; otherwise conclude that</strong></p>
<p><strong>; we’re done right away</strong></p>
<p><strong>scasb ;is first byte a match?</strong></p>
<p><strong>jz ByteCountCountOccurrence</strong></p>
<p><strong>;yes, so count it</strong></p>
<p><strong>ByteCountLoop:</strong></p>
<p><strong>jcxz ByteCountDone ;if there’s nothing left to</strong></p>
<p><strong>; search, we’re done</strong></p>
<p><strong>repnz scasb ;search for the next byte</strong></p>
<p><strong>; occurrence or the end of</strong></p>
<p><strong>; the array</strong></p>
<p><strong>jnz ByteCountDone ;no match</strong></p>
<p><strong>ByteCountCountOccurrence:</strong></p>
<p><strong>inc dx ;count this occurrence</strong></p>
<p><strong>jmp ByteCountLoop ;check the next byte, if any</strong></p>
<p><strong>ByteCountDone:</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov al,‘A’ ;byte of which we want a</strong></p>
<p><strong>; count of occurrences</strong></p>
<p><strong>mov di,offset ByteArray</strong></p>
<p><strong>;array we want a count for</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to check</strong></p>
<p><strong>call ByteCount ;get the count</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-11" class="level2">
<h2>Listing 11-11</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-11 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the first occurrence of the letter ‘z’ in</strong></p>
<p><strong>; a zero-terminated string, using LODSB.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>TestString label byte</strong></p>
<p><strong>db ‘This is a test string that is’</strong></p>
<p><strong>db ‘z’</strong></p>
<p><strong>db ‘terminated with a zero byte…’,0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the first occurrence of the specified byte in the</strong></p>
<p><strong>; specified zero-terminated string.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = byte to find</strong></p>
<p><strong>; DS:SI = zero-terminated string to search</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; SI = pointer to first occurrence of byte in string,</strong></p>
<p><strong>; or 0 if the byte wasn’t found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Do not pass a string that starts at offset 0 (SI=0),</strong></p>
<p><strong>; since a match on the first byte and failure to find</strong></p>
<p><strong>; the byte would be indistinguishable.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>FindCharInString:</strong></p>
<p><strong>mov ah,al ;we’ll need AL since that’s the</strong></p>
<p><strong>; only register LODSB can use</strong></p>
<p><strong>cld</strong></p>
<p><strong>FindCharInStringLoop:</strong></p>
<p><strong>lodsb ;get the next string byte</strong></p>
<p><strong>cmp al,ah ;is this the byte we’re</strong></p>
<p><strong>; looking for?</strong></p>
<p><strong>jz FindCharInStringDone</strong></p>
<p><strong>;yes, so we’re done</strong></p>
<p><strong>and al,al ;is this the terminating zero?</strong></p>
<p><strong>jnz FindCharInStringLoop</strong></p>
<p><strong>;no, so check the next byte</strong></p>
<p><strong>sub si,si ;we didn’t find a match, so return</strong></p>
<p><strong>; 0 in SI</strong></p>
<p><strong>ret</strong></p>
<p><strong>FindCharInStringDone:</strong></p>
<p><strong>dec si ;point back to the matching byte</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov al,‘z’ ;byte value to find</strong></p>
<p><strong>mov si,offset TestString</strong></p>
<p><strong>;string to search</strong></p>
<p><strong>call FindCharInString ;search for the byte</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-12" class="level2">
<h2>Listing 11-12</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-12 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the first occurrence of the letter ‘z’ in</strong></p>
<p><strong>; a zero-terminated string, using REPNZ SCASB in a</strong></p>
<p><strong>; double-search approach, first finding the terminating</strong></p>
<p><strong>; zero to determine the string length, and then searching</strong></p>
<p><strong>; for the desired byte.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>TestString label byte</strong></p>
<p><strong>db ‘This is a test string that is’</strong></p>
<p><strong>db ‘z’</strong></p>
<p><strong>db ‘terminated with a zero byte…’,0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the first occurrence of the specified byte in the</strong></p>
<p><strong>; specified zero-terminated string.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = byte to find</strong></p>
<p><strong>; DS:SI = zero-terminated string to search</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; SI = pointer to first occurrence of byte in string,</strong></p>
<p><strong>; or 0 if the byte wasn’t found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AH, CX, SI, DI, ES</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Do not pass a string that starts at offset 0 (SI=0),</strong></p>
<p><strong>; since a match on the first byte and failure to find</strong></p>
<p><strong>; the byte would be indistinguishable.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: If the search value is 0, will not find the</strong></p>
<p><strong>; terminating zero in a string that is exactly 64K</strong></p>
<p><strong>; bytes long. Does not handle strings that are longer</strong></p>
<p><strong>; than 64K bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>FindCharInString:</strong></p>
<p><strong>mov ah,al ;set aside the byte to be found</strong></p>
<p><strong>sub al,al ;we’ll search for zero</strong></p>
<p><strong>push ds</strong></p>
<p><strong>pop es</strong></p>
<p><strong>mov di,si ;SCAS uses ES:DI</strong></p>
<p><strong>mov cx,0ffffh ;long enough to handle any string</strong></p>
<p><strong>; up to 64K-1 bytes in length, and</strong></p>
<p><strong>; will handle 64K case except when</strong></p>
<p><strong>; the search value is the terminating</strong></p>
<p><strong>; zero</strong></p>
<p><strong>cld</strong></p>
<p><strong>repnz scasb ;find the terminating zero</strong></p>
<p><strong>not cx ;length of string in bytes, including</strong></p>
<p><strong>; the terminating zero except in the</strong></p>
<p><strong>; case of a string that’s exactly 64K</strong></p>
<p><strong>; long including the terminating zero</strong></p>
<p><strong>mov al,ah ;get back the byte to be found</strong></p>
<p><strong>mov di,si ;point to the start of the string again</strong></p>
<p><strong>repnz scasb ;search for the byte of interest</strong></p>
<p><strong>jnz FindCharInStringNotFound</strong></p>
<p><strong>;the byte isn’t present in the string</strong></p>
<p><strong>dec di ;we’ve found the desired value. Point</strong></p>
<p><strong>; back to the matching location</strong></p>
<p><strong>mov si,di ;return the pointer in SI</strong></p>
<p><strong>ret</strong></p>
<p><strong>FindCharInStringNotFound:</strong></p>
<p><strong>sub si,si ;return a 0 pointer indicating that</strong></p>
<p><strong>; no match was found</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov al,‘z’ ;byte value to find</strong></p>
<p><strong>mov si,offset TestString</strong></p>
<p><strong>;string to search</strong></p>
<p><strong>call FindCharInString ;search for the byte</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-13" class="level2">
<h2>Listing 11-13</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-13 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the first occurrence of the letter ‘z’ in</strong></p>
<p><strong>; a zero-terminated string, using non-string instructions.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>TestString label byte</strong></p>
<p><strong>db ‘This is a test string that is’</strong></p>
<p><strong>db ‘z’</strong></p>
<p><strong>db ‘terminated with a zero byte…’,0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the first occurrence of the specified byte in the</strong></p>
<p><strong>; specified zero-terminated string.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = byte to find</strong></p>
<p><strong>; DS:SI = zero-terminated string to search</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; SI = pointer to first occurrence of byte in string,</strong></p>
<p><strong>; or 0 if the byte wasn’t found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AH, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Do not pass a string that starts at offset 0 (SI=0),</strong></p>
<p><strong>; since a match on the first byte and failure to find</strong></p>
<p><strong>; the byte would be indistinguishable.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>FindCharInString:</strong></p>
<p><strong>FindCharInStringLoop:</strong></p>
<p><strong>mov ah,[si] ;get the next string byte</strong></p>
<p><strong>cmp ah,al ;is this the byte we’re</strong></p>
<p><strong>; looking for?</strong></p>
<p><strong>jz FindCharInStringDone</strong></p>
<p><strong>;yes, so we’re done</strong></p>
<p><strong>inc si ;point to the following byte</strong></p>
<p><strong>and ah,ah ;is this the terminating zero?</strong></p>
<p><strong>jnz FindCharInStringLoop</strong></p>
<p><strong>;no, so check the next byte</strong></p>
<p><strong>sub si,si ;we didn’t find a match, so return</strong></p>
<p><strong>; 0 in SI</strong></p>
<p><strong>FindCharInStringDone:</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov al,‘z’ ;byte value to find</strong></p>
<p><strong>mov si,offset TestString</strong></p>
<p><strong>;string to search</strong></p>
<p><strong>call FindCharInString ;search for the byte</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-14" class="level2">
<h2>Listing 11-14</h2>
<p><strong>; *** Listing 11-14 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the first occurrence of the letter ‘z’ in</strong></p>
<p><strong>; a zero-terminated string, using LODSW and checking</strong></p>
<p><strong>; 2 bytes per read.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>TestString label byte</strong></p>
<p><strong>db ‘This is a test string that is’</strong></p>
<p><strong>db ‘z’</strong></p>
<p><strong>db ‘terminated with a zero byte…’,0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the first occurrence of the specified byte in the</strong></p>
<p><strong>; specified zero-terminated string.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = byte to find</strong></p>
<p><strong>; DS:SI = zero-terminated string to search</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; SI = pointer to first occurrence of byte in string,</strong></p>
<p><strong>; or 0 if the byte wasn’t found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, BL, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Do not pass a string that starts at offset 0 (SI=0),</strong></p>
<p><strong>; since a match on the first byte and failure to find</strong></p>
<p><strong>; the byte would be indistinguishable.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>FindCharInString:</strong></p>
<p><strong>mov bl,al ;we’ll need AX since that’s the</strong></p>
<p><strong>; only register LODSW can use</strong></p>
<p><strong>cld</strong></p>
<p><strong>FindCharInStringLoop:</strong></p>
<p><strong>lodsw ;get the next 2 string bytes</strong></p>
<p><strong>cmp al,bl ;is the first byte the byte we’re</strong></p>
<p><strong>; looking for?</strong></p>
<p><strong>jz FindCharInStringDoneAdjust</strong></p>
<p><strong>;yes, so we’re done after we adjust</strong></p>
<p><strong>; back to the first byte of the word</strong></p>
<p><strong>and al,al ;is the first byte the terminating</strong></p>
<p><strong>; zero?</strong></p>
<p><strong>jz FindCharInStringNoMatch ;yes, no match</strong></p>
<p><strong>cmp ah,bl ;is the second byte the byte we’re</strong></p>
<p><strong>; looking for?</strong></p>
<p><strong>jz FindCharInStringDone</strong></p>
<p><strong>;yes, so we’re done</strong></p>
<p><strong>and ah,ah ;is the second byte the terminating</strong></p>
<p><strong>; zero?</strong></p>
<p><strong>jnz FindCharInStringLoop</strong></p>
<p><strong>;no, so check the next 2 bytes</strong></p>
<p><strong>FindCharInStringNoMatch:</strong></p>
<p><strong>sub si,si ;we didn’t find a match, so return</strong></p>
<p><strong>; 0 in SI</strong></p>
<p><strong>ret</strong></p>
<p><strong>FindCharInStringDoneAdjust:</strong></p>
<p><strong>dec si ;adjust to the first byte of the</strong></p>
<p><strong>; word we just read</strong></p>
<p><strong>FindCharInStringDone:</strong></p>
<p><strong>dec si ;point back to the matching byte</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov al,‘z’ ;byte value to find</strong></p>
<p><strong>mov si,offset TestString</strong></p>
<p><strong>;string to search</strong></p>
<p><strong>call FindCharInString ;search for the byte</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-15" class="level2">
<h2>Listing 11-15</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-15 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the last non-blank character in a string, using</strong></p>
<p><strong>; LODSW and checking 2 bytes per read.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>TestString label byte</strong></p>
<p><strong>db ‘This is a test string with blanks….’</strong></p>
<p><strong>db ‘’,0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the last non-blank character in the specified</strong></p>
<p><strong>; zero-terminated string.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DS:SI = zero-terminated string to search</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; SI = pointer to last non-blank character in string,</strong></p>
<p><strong>; or 0 if there are no non-blank characters in</strong></p>
<p><strong>; the string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, BL, DX, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Do not pass a string that starts at offset 0 (SI=0),</strong></p>
<p><strong>; since a return pointer to the first byte and failure</strong></p>
<p><strong>; to find a non-blank character would be</strong></p>
<p><strong>; indistinguishable.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>FindLastNonBlankInString:</strong></p>
<p><strong>mov dx,1 ;so far we haven’t found a non-blank</strong></p>
<p><strong>; character</strong></p>
<p><strong>mov bl,‘’ ;put our search character, the space</strong></p>
<p><strong>; character, in a register for speed</strong></p>
<p><strong>cld</strong></p>
<p><strong>FindLastNonBlankInStringLoop:</strong></p>
<p><strong>lodsw ;get the next 2 string bytes</strong></p>
<p><strong>and al,al ;is the first byte the terminating</strong></p>
<p><strong>; zero?</strong></p>
<p><strong>jz FindLastNonBlankInStringDone</strong></p>
<p><strong>;yes, we’re done</strong></p>
<p><strong>cmp al,bl ;is the second byte a space?</strong></p>
<p><strong>jz FindLastNonBlankInStringNextChar</strong></p>
<p><strong>;yes, so check the next character</strong></p>
<p><strong>mov dx,si ;remember where the non-blank was</strong></p>
<p><strong>dec dx ;adjust back to first byte of word</strong></p>
<p><strong>FindLastNonBlankInStringNextChar:</strong></p>
<p><strong>and ah,ah ;is the second byte the terminating</strong></p>
<p><strong>; zero?</strong></p>
<p><strong>jz FindLastNonBlankInStringDone</strong></p>
<p><strong>;yes, we’re done</strong></p>
<p><strong>cmp ah,bl ;is the second byte a space?</strong></p>
<p><strong>jz FindLastNonBlankInStringLoop</strong></p>
<p><strong>;yes, so check the next 2 bytes</strong></p>
<p><strong>mov dx,si ;remember where the non-blank was</strong></p>
<p><strong>jmp FindLastNonBlankInStringLoop</strong></p>
<p><strong>;check the next 2 bytes</strong></p>
<p><strong>FindLastNonBlankInStringDone:</strong></p>
<p><strong>dec dx ;point back to the last non-blank</strong></p>
<p><strong>; character, correcting for the</strong></p>
<p><strong>; 1-byte overrun of LODSW</strong></p>
<p><strong>mov si,dx ;return pointer to last non-blank</strong></p>
<p><strong>; character in SI</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset TestString ;string to search</strong></p>
<p><strong>call FindLastNonBlankInString ;search for the byte</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-16" class="level2">
<h2>Listing 11-16</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-16 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the last non-blank character in a string, using</strong></p>
<p><strong>; REPNZ SCASB to find the end of the string and then using</strong></p>
<p><strong>; REPZ SCASW from the end of the string to find the last</strong></p>
<p><strong>; non-blank character.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>TestString label byte</strong></p>
<p><strong>db ‘This is a test string with blanks….’</strong></p>
<p><strong>db ‘’,0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the last non-blank character in the specified</strong></p>
<p><strong>; zero-terminated string.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DS:SI = zero-terminated string to search</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; SI = pointer to last non-blank character in string,</strong></p>
<p><strong>; or 0 if there are no non-blank characters in</strong></p>
<p><strong>; the string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, CX, SI, DI, ES</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Do not pass a string that starts at offset 0 (SI=0),</strong></p>
<p><strong>; since a return pointer to the first byte and failure</strong></p>
<p><strong>; to find a non-blank character would be</strong></p>
<p><strong>; indistinguishable.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: If there is no terminating zero in the first 64K-1</strong></p>
<p><strong>; bytes of the string, it is assumed without checking</strong></p>
<p><strong>; that byte #64K-1 (the 1 byte in the segment that</strong></p>
<p><strong>; wasn’t checked) is the terminating zero.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>FindLastNonBlankInString:</strong></p>
<p><strong>push ds</strong></p>
<p><strong>pop es</strong></p>
<p><strong>mov di,si ;SCAS uses ES:DI</strong></p>
<p><strong>sub al,al ;first we’ll search for the</strong></p>
<p><strong>; terminating zero</strong></p>
<p><strong>mov cx,0ffffh ;we’ll search the longest possible</strong></p>
<p><strong>; string</strong></p>
<p><strong>cld</strong></p>
<p><strong>repnz scasb ;find the terminating zero</strong></p>
<p><strong>dec di ;point back to the zero</strong></p>
<p><strong>cmp [di],al ;make sure this is a zero.</strong></p>
<p><strong>; (Remember, ES=DS)</strong></p>
<p><strong>jnz FindLastNonBlankInStringSearchBack</strong></p>
<p><strong>; not a zero. The string must be</strong></p>
<p><strong>; exactly 64K bytes long, so we’ve</strong></p>
<p><strong>; come up 1 byte short of the zero</strong></p>
<p><strong>; that we’re assuming is at byte</strong></p>
<p><strong>; 64K-1. That means we’re already</strong></p>
<p><strong>; pointing to the byte before the</strong></p>
<p><strong>; zero</strong></p>
<p><strong>dec di ;point to the byte before the zero</strong></p>
<p><strong>inc cx ;don’t count the terminating zero</strong></p>
<p><strong>; as one of the characters we’ve</strong></p>
<p><strong>; searched through (and have to</strong></p>
<p><strong>; search back through)</strong></p>
<p><strong>FindLastNonBlankInStringSearchBack:</strong></p>
<p><strong>std ;we’ll search backward</strong></p>
<p><strong>not cx ;length of string, not including</strong></p>
<p><strong>; the terminating zero</strong></p>
<p><strong>mov ax,2020h ;now we’re looking for a space</strong></p>
<p><strong>shr cx,1 ;divide by 2 to get a word count</strong></p>
<p><strong>jnc FindLastNonBlankInStringWord</strong></p>
<p><strong>scasb ;see if the odd byte is the last</strong></p>
<p><strong>; non-blank character</strong></p>
<p><strong>jnz FindLastNonBlankInStringFound</strong></p>
<p><strong>;it is, so we’re done</strong></p>
<p><strong>FindLastNonBlankInStringWord:</strong></p>
<p><strong>jcxz FindLastNonBlankInStringNoMatch</strong></p>
<p><strong>;if there’s nothing left to check,</strong></p>
<p><strong>; there are no non-blank characters</strong></p>
<p><strong>dec di ;point back to the start of the</strong></p>
<p><strong>; next word, not byte</strong></p>
<p><strong>repz scasw ;find the first non-blank character</strong></p>
<p><strong>jz FindLastNonBlankInStringNoMatch</strong></p>
<p><strong>;there is no non-blank character in</strong></p>
<p><strong>; this string</strong></p>
<p><strong>inc di ;undo 1 byte of SCASW’s overrun, so</strong></p>
<p><strong>; this looks like SCASB’s overrun</strong></p>
<p><strong>cmp [di+2],al ;which of the 2 bytes we just</strong></p>
<p><strong>; checked was the last non-blank</strong></p>
<p><strong>; character?</strong></p>
<p><strong>jz FindLastNonBlankInStringFound</strong></p>
<p><strong>inc di ;the byte at the higher address was</strong></p>
<p><strong>; the last non-blank character, so</strong></p>
<p><strong>; adjust by 1 byte</strong></p>
<p><strong>FindLastNonBlankInStringFound:</strong></p>
<p><strong>inc di ;point to the non-blank character</strong></p>
<p><strong>; we just found, correcting for</strong></p>
<p><strong>; overrun of SCASB running from high</strong></p>
<p><strong>; addresses to low</strong></p>
<p><strong>mov si,di ;return pointer to the last</strong></p>
<p><strong>; non-blank in SI</strong></p>
<p><strong>cld</strong></p>
<p><strong>ret</strong></p>
<p><strong>FindLastNonBlankInStringNoMatch:</strong></p>
<p><strong>sub si,si ;return that we didn’t find a</strong></p>
<p><strong>; non-blank character</strong></p>
<p><strong>cld</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset TestString ;string to search</strong></p>
<p><strong>call FindLastNonBlankInString ;search for the</strong></p>
<p><strong>; last non-blank</strong></p>
<p><strong>; character</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-17" class="level2">
<h2>Listing 11-17</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-17 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Demonstrates the calculation of the offset of the word</strong></p>
<p><strong>; matching a keystroke in a look-up table when SCASW is</strong></p>
<p><strong>; used, where the 2-byte overrun of SCASW must be</strong></p>
<p><strong>; compensated for. The offset in the look-up table is used</strong></p>
<p><strong>; to look up the corresponding address in a second table;</strong></p>
<p><strong>; that address is then jumped to in order to handle the</strong></p>
<p><strong>; keystroke.</strong></p>
<p><strong>;</strong></p>
<p><strong>; This is a standalone program, not to be used with PZTIME</strong></p>
<p><strong>; but rather assembled, linked, and run by itself.</strong></p>
<p><strong>;</strong></p>
<p><strong>stack segment para stack ‘STACK’</strong></p>
<p><strong>db 512 dup (?)</strong></p>
<p><strong>stack ends</strong></p>
<p><strong>;</strong></p>
<p><strong>code segment para public ‘CODE’</strong></p>
<p><strong>assume cs:code, ds:nothing</strong></p>
<p><strong>;</strong></p>
<p><strong>; Main loop, which simply calls VectorOnKey until one of the</strong></p>
<p><strong>; key handlers ends the program.</strong></p>
<p><strong>;</strong></p>
<p><strong>start proc near</strong></p>
<p><strong>call VectorOnKey</strong></p>
<p><strong>jmp start</strong></p>
<p><strong>start endp</strong></p>
<p><strong>;</strong></p>
<p><strong>; Gets the next 16-bit key code from the BIOS, looks it up</strong></p>
<p><strong>; in KeyLookUpTable, and jumps to the corresponding routine</strong></p>
<p><strong>; according to KeyJumpTable. When the jumped-to routine</strong></p>
<p><strong>; returns, is will return to the code that called</strong></p>
<p><strong>; VectorOnKey. Ignores the key if the key code is not in the</strong></p>
<p><strong>; look-up table.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, CX, DI, ES</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Table of 16-bit key codes this routine handles.</strong></p>
<p><strong>;</strong></p>
<p><strong>KeyLookUpTable label word</strong></p>
<p><strong>dw 0011bh ;Esc to exit</strong></p>
<p><strong>dw 01c0dh ;Enter to beep</strong></p>
<p><strong>;*** Additional key codes go here ***</strong></p>
<p><strong>KEY_LOOK_UP_TABLE_LENGTH_IN_WORDS equ (($-KeyLookUpTable)/2)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Table of addresses to jump to when corresponding key codes</strong></p>
<p><strong>; in KeyLookUpTable are found.</strong></p>
<p><strong>;</strong></p>
<p><strong>KeyJumpTable label word</strong></p>
<p><strong>dw EscHandler</strong></p>
<p><strong>dw EnterHandler</strong></p>
<p><strong>;*** Additional addresses go here ***</strong></p>
<p><strong>;</strong></p>
<p><strong>VectorOnKey proc near</strong></p>
<p><strong>WaitKeyLoop:</strong></p>
<p><strong>mov ah,1 ;BIOS key status function</strong></p>
<p><strong>int 16h ;invoke BIOS to see if</strong></p>
<p><strong>; a key is pending</strong></p>
<p><strong>jz WaitKeyLoop ;wait until key comes along</strong></p>
<p><strong>sub ah,ah ;BIOS get key function</strong></p>
<p><strong>int 16h ;invoke BIOS to get the key</strong></p>
<p><strong>push cs</strong></p>
<p><strong>pop es</strong></p>
<p><strong>mov di,offset KeyLookUpTable</strong></p>
<p><strong>;point ES:DI to the table of keys</strong></p>
<p><strong>; we handle, which is in the same</strong></p>
<p><strong>; segment as this code</strong></p>
<p><strong>mov cx,KEY_LOOK_UP_TABLE_LENGTH_IN_WORDS</strong></p>
<p><strong>;# of words to scan</strong></p>
<p><strong>cld</strong></p>
<p><strong>repnz scasw ;look up the key</strong></p>
<p><strong>jnz WaitKeyLoop ;it’s not in the table, so</strong></p>
<p><strong>; ignore it</strong></p>
<p><strong>jmp cs:[KeyJumpTable+di-2-offset KeyLookUpTable]</strong></p>
<p><strong>;jump to the routine for this key</strong></p>
<p><strong>; Note that:</strong></p>
<p><strong>; DI-2-offset KeyLookUpTable</strong></p>
<p><strong>; is the offset in KeyLookUpTable of</strong></p>
<p><strong>; the key we found, with the -2</strong></p>
<p><strong>; needed to compensate for the</strong></p>
<p><strong>; 2-byte (1-word) overrun of SCASW</strong></p>
<p><strong>VectorOnKey endp</strong></p>
<p><strong>;</strong></p>
<p><strong>; Code to handle Esc (ends the program).</strong></p>
<p><strong>;</strong></p>
<p><strong>EscHandler proc near</strong></p>
<p><strong>mov ah,4ch ;DOS terminate program function</strong></p>
<p><strong>int 21h ;exit program</strong></p>
<p><strong>EscHandler endp</strong></p>
<p><strong>;</strong></p>
<p><strong>; Code to handle Enter (beeps the speaker).</strong></p>
<p><strong>;</strong></p>
<p><strong>EnterHandler proc near</strong></p>
<p><strong>mov ax,0e07h ;AH=0E is BIOS print character</strong></p>
<p><strong>; function, AL=7 is bell (beep)</strong></p>
<p><strong>; character</strong></p>
<p><strong>int 10h ;tell BIOS to beep the speaker</strong></p>
<p><strong>ret</strong></p>
<p><strong>EnterHandler endp</strong></p>
<p><strong>;</strong></p>
<p><strong>code ends</strong></p>
<p><strong>end start</strong></p>
</section>
<section id="listing-11-18" class="level2">
<h2>Listing 11-18</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-18 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Demonstrates the calculation of the element number in a</strong></p>
<p><strong>; look-up table of a byte matching the ASCII value of a</strong></p>
<p><strong>; keystroke when SCASB is used, where the 1-count</strong></p>
<p><strong>; overrun of SCASB must be compensated for. The element</strong></p>
<p><strong>; number in the look-up table is used to look up the</strong></p>
<p><strong>; corresponding address in a second table; that address is</strong></p>
<p><strong>; then jumped to in order to handle the keystroke.</strong></p>
<p><strong>;</strong></p>
<p><strong>; This is a standalone program, not to be used with PZTIME</strong></p>
<p><strong>; but rather assembled, linked, and run by itself.</strong></p>
<p><strong>;</strong></p>
<p><strong>stack segment para stack ‘STACK’</strong></p>
<p><strong>db 512 dup (?)</strong></p>
<p><strong>stack ends</strong></p>
<p><strong>;</strong></p>
<p><strong>code segment para public ‘CODE’</strong></p>
<p><strong>assume cs:code, ds:nothing</strong></p>
<p><strong>;</strong></p>
<p><strong>; Main loop, which simply calls VectorOnASCIIKey until one</strong></p>
<p><strong>; of the key handlers ends the program.</strong></p>
<p><strong>;</strong></p>
<p><strong>start proc near</strong></p>
<p><strong>call VectorOnASCIIKey</strong></p>
<p><strong>jmp start</strong></p>
<p><strong>start endp</strong></p>
<p><strong>;</strong></p>
<p><strong>; Gets the next 16-bit key code from the BIOS, looks up just</strong></p>
<p><strong>; the 8-bit ASCII portion in ASCIIKeyLookUpTable, and jumps</strong></p>
<p><strong>; to the corresponding routine according to</strong></p>
<p><strong>; ASCIIKeyJumpTable. When the jumped-to routine returns, it</strong></p>
<p><strong>; will return directly to the code that called</strong></p>
<p><strong>; VectorOnASCIIKey. Ignores the key if the key code is not</strong></p>
<p><strong>; in the look-up table.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, CX, DI, ES</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Table of 8-bit ASCII codes this routine handles.</strong></p>
<p><strong>;</strong></p>
<p><strong>ASCIIKeyLookUpTable label word</strong></p>
<p><strong>db 02h ;Ctrl-B to beep</strong></p>
<p><strong>db 18h ;Ctrl-X to exit</strong></p>
<p><strong>;*** Additional ASCII codes go here ***</strong></p>
<p><strong>ASCII_KEY_LOOK_UP_TABLE_LENGTH equ ($-ASCIIKeyLookUpTable)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Table of addresses to jump to when corresponding key codes</strong></p>
<p><strong>; in ASCIIKeyLookUpTable are found.</strong></p>
<p><strong>;</strong></p>
<p><strong>ASCIIKeyJumpTable label word</strong></p>
<p><strong>dw Beep</strong></p>
<p><strong>dw Exit</strong></p>
<p><strong>;*** Additional addresses go here ***</strong></p>
<p><strong>;</strong></p>
<p><strong>VectorOnASCIIKey proc near</strong></p>
<p><strong>WaitASCIIKeyLoop:</strong></p>
<p><strong>mov ah,1 ;BIOS key status function</strong></p>
<p><strong>int 16h ;invoke BIOS to see if</strong></p>
<p><strong>; a key is pending</strong></p>
<p><strong>jz WaitASCIIKeyLoop ;wait until key comes along</strong></p>
<p><strong>sub ah,ah ;BIOS get key function</strong></p>
<p><strong>int 16h ;invoke BIOS to get the key</strong></p>
<p><strong>push cs</strong></p>
<p><strong>pop es</strong></p>
<p><strong>mov di,offset ASCIIKeyLookUpTable</strong></p>
<p><strong>;point ES:DI to the table of keys</strong></p>
<p><strong>; we handle, which is in the same</strong></p>
<p><strong>; segment as this code</strong></p>
<p><strong>mov cx,ASCII_KEY_LOOK_UP_TABLE_LENGTH</strong></p>
<p><strong>;# of bytes to scan</strong></p>
<p><strong>cld</strong></p>
<p><strong>repnz scasb ;look up the key</strong></p>
<p><strong>jnz WaitASCIIKeyLoop ;it’s not in the table, so</strong></p>
<p><strong>; ignore it</strong></p>
<p><strong>mov di,ASCII_KEY_LOOK_UP_TABLE_LENGTH-1</strong></p>
<p><strong>sub di,cx ;calculate the # of the element we</strong></p>
<p><strong>; found in ASCIIKeyLookUpTable.</strong></p>
<p><strong>; The -1 is needed to compensate for</strong></p>
<p><strong>; the 1-count overrun of SCAS</strong></p>
<p><strong>shl di,1 ;multiply by 2 in order to perform</strong></p>
<p><strong>; the look-up in word-sized</strong></p>
<p><strong>; ASCIIKeyJumpTable</strong></p>
<p><strong>jmp cs:[ASCIIKeyJumpTable+di]</strong></p>
<p><strong>;jump to the routine for this key</strong></p>
<p><strong>VectorOnASCIIKey endp</strong></p>
<p><strong>;</strong></p>
<p><strong>; Code to handle Ctrl-X (ends the program).</strong></p>
<p><strong>;</strong></p>
<p><strong>Exit proc near</strong></p>
<p><strong>mov ah,4ch ;DOS terminate program function</strong></p>
<p><strong>int 21h ;exit program</strong></p>
<p><strong>Exit endp</strong></p>
<p><strong>;</strong></p>
<p><strong>; Code to handle Ctrl-B (beeps the speaker).</strong></p>
<p><strong>;</strong></p>
<p><strong>Beep proc near</strong></p>
<p><strong>mov ax,0e07h ;AH=0E is BIOS print character</strong></p>
<p><strong>; function, AL=7 is bell (beep)</strong></p>
<p><strong>; character</strong></p>
<p><strong>int 10h ;tell BIOS to beep the speaker</strong></p>
<p><strong>ret</strong></p>
<p><strong>Beep endp</strong></p>
<p><strong>;</strong></p>
<p><strong>code ends</strong></p>
<p><strong>end start</strong></p>
</section>
<section id="listing-11-19" class="level2">
<h2>Listing 11-19</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-19 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Tests whether several characters are in the set</strong></p>
<p><strong>; {A,Z,3,!} by using REPNZ SCASB.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>; List of characters in the set.</strong></p>
<p><strong>;</strong></p>
<p><strong>TestSet db “AZ3!”</strong></p>
<p><strong>TEST_SET_LENGTH equ ($-TestSet)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Determines whether a given character is in TestSet.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = character to check for inclusion in TestSet</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; Z if character is in TestSet, NZ otherwise</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: DI, ES</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>CheckTestSetInclusion:</strong></p>
<p><strong>push ds</strong></p>
<p><strong>pop es</strong></p>
<p><strong>mov di,offset TestSet</strong></p>
<p><strong>;point ES:DI to the set in which to</strong></p>
<p><strong>; check inclusion</strong></p>
<p><strong>mov cx,TEST_SET_LENGTH</strong></p>
<p><strong>;# of characters in TestSet</strong></p>
<p><strong>cld</strong></p>
<p><strong>repnz scasb ;search the set for this character</strong></p>
<p><strong>ret ;the success status is already in</strong></p>
<p><strong>; the Zero flag</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov al,‘A’</strong></p>
<p><strong>call CheckTestSetInclusion ;check ‘A’</strong></p>
<p><strong>mov al,‘Z’</strong></p>
<p><strong>call CheckTestSetInclusion ;check ‘Z’</strong></p>
<p><strong>mov al,‘3’</strong></p>
<p><strong>call CheckTestSetInclusion ;check ‘3’</strong></p>
<p><strong>mov al,‘!’</strong></p>
<p><strong>call CheckTestSetInclusion ;check ‘!’</strong></p>
<p><strong>mov al,‘’</strong></p>
<p><strong>call CheckTestSetInclusion ;check space, so</strong></p>
<p><strong>; we get a failed</strong></p>
<p><strong>; search</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-20" class="level2">
<h2>Listing 11-20</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-20 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Tests whether several characters are in the set</strong></p>
<p><strong>; {A,Z,3,!} by using the compare-and-jump approach.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>; Determines whether a given character is in the set</strong></p>
<p><strong>; {A,Z,3,!}.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = character to check for inclusion in the set</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; Z if character is in TestSet, NZ otherwise</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: none</strong></p>
<p><strong>;</strong></p>
<p><strong>CheckTestSetInclusion:</strong></p>
<p><strong>cmp al,‘A’ ;is it ‘A’?</strong></p>
<p><strong>jz CheckTestSetInclusionDone ;yes, we’re done</strong></p>
<p><strong>cmp al,‘Z’ ;is it ‘Z’?</strong></p>
<p><strong>jz CheckTestSetInclusionDone ;yes, we’re done</strong></p>
<p><strong>cmp al,‘3’ ;is it ‘3’?</strong></p>
<p><strong>jz CheckTestSetInclusionDone ;yes, we’re done</strong></p>
<p><strong>cmp al,‘!’ ;is it ‘!’?</strong></p>
<p><strong>CheckTestSetInclusionDone:</strong></p>
<p><strong>ret ;the success status is already in</strong></p>
<p><strong>; the Zero flag</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov al,‘A’</strong></p>
<p><strong>call CheckTestSetInclusion ;check ‘A’</strong></p>
<p><strong>mov al,‘Z’</strong></p>
<p><strong>call CheckTestSetInclusion ;check ‘Z’</strong></p>
<p><strong>mov al,‘3’</strong></p>
<p><strong>call CheckTestSetInclusion ;check ‘3’</strong></p>
<p><strong>mov al,‘!’</strong></p>
<p><strong>call CheckTestSetInclusion ;check ‘!’</strong></p>
<p><strong>mov al,‘’</strong></p>
<p><strong>call CheckTestSetInclusion ;check space, so</strong></p>
<p><strong>; we get a failed</strong></p>
<p><strong>; search</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-21" class="level2">
<h2>Listing 11-21</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-21 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Compares two word-sized arrays of equal length to see</strong></p>
<p><strong>; whether they differ, and if so where, using REPZ CMPSW.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>WordArray1 dw 100 dup (1), 0, 99 dup (2)</strong></p>
<p><strong>ARRAY_LENGTH_IN_WORDS equ (($-WordArray1)/2)</strong></p>
<p><strong>WordArray2 dw 100 dup (1), 100 dup (2)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Returns pointers to the first locations at which two</strong></p>
<p><strong>; word-sized arrays of equal length differ, or zero if</strong></p>
<p><strong>; they’re identical.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = length of the arrays (they must be of equal</strong></p>
<p><strong>; length)</strong></p>
<p><strong>; DS:SI = the first array to compare</strong></p>
<p><strong>; ES:DI = the second array to compare</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; DS:SI = pointer to the first differing location in</strong></p>
<p><strong>; the first array if there is a difference,</strong></p>
<p><strong>; or SI=0 if the arrays are identical</strong></p>
<p><strong>; ES:DI = pointer to the first differing location in</strong></p>
<p><strong>; the second array if there is a difference,</strong></p>
<p><strong>; or DI=0 if the arrays are identical</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle arrays that are longer than 32K</strong></p>
<p><strong>; words or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>FindFirstDifference:</strong></p>
<p><strong>cld</strong></p>
<p><strong>jcxz FindFirstDifferenceSame</strong></p>
<p><strong>;if there’s nothing to</strong></p>
<p><strong>; check, we’ll consider the</strong></p>
<p><strong>; arrays to be the same.</strong></p>
<p><strong>; (If we let REPZ CMPSW</strong></p>
<p><strong>; execute with CX=0, we</strong></p>
<p><strong>; may get a false match</strong></p>
<p><strong>; because CMPSW repeated</strong></p>
<p><strong>; zero times doesn’t alter</strong></p>
<p><strong>; the flags)</strong></p>
<p><strong>repz cmpsw ;compare the arrays</strong></p>
<p><strong>jz FindFirstDifferenceSame ;they’re identical</strong></p>
<p><strong>dec si ;the arrays differ, so</strong></p>
<p><strong>dec si ; point back to first</strong></p>
<p><strong>dec di ; difference in both arrays</strong></p>
<p><strong>dec di</strong></p>
<p><strong>ret</strong></p>
<p><strong>FindFirstDifferenceSame:</strong></p>
<p><strong>sub si,si ;indicate that the strings</strong></p>
<p><strong>mov di,si ; are identical</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset WordArray1 ;point to the two</strong></p>
<p><strong>mov di,ds ; arrays to be</strong></p>
<p><strong>mov es,di ; compared</strong></p>
<p><strong>mov di,offset WordArray2</strong></p>
<p><strong>mov cx,ARRAY_LENGTH_IN_WORDS</strong></p>
<p><strong>;# of words to check</strong></p>
<p><strong>call FindFirstDifference ;see if they differ</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-22" class="level2">
<h2>Listing 11-22</h2>
<p><strong>;</strong></p>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-22 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Compares two word-sized arrays of equal length to see</strong></p>
<p><strong>; whether they differ, and if so where, using LODSW and</strong></p>
<p><strong>; SCASW.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>WordArray1 dw 100 dup (1), 0, 99 dup (2)</strong></p>
<p><strong>ARRAY_LENGTH_IN_WORDS equ (($-WordArray1)/2)</strong></p>
<p><strong>WordArray2 dw 100 dup (1), 100 dup (2)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Returns pointers to the first locations at which two</strong></p>
<p><strong>; word-sized arrays of equal length differ, or zero if</strong></p>
<p><strong>; they’re identical.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = length of the arrays (they must be of equal</strong></p>
<p><strong>; length)</strong></p>
<p><strong>; DS:SI = the first array to compare</strong></p>
<p><strong>; ES:DI = the second array to compare</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; DS:SI = pointer to the first differing location in</strong></p>
<p><strong>; the first array if there is a difference,</strong></p>
<p><strong>; or SI=0 if the arrays are identical</strong></p>
<p><strong>; ES:DI = pointer to the first differing location in</strong></p>
<p><strong>; the second array if there is a difference,</strong></p>
<p><strong>; or DI=0 if the arrays are identical</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle arrays that are longer than 32K</strong></p>
<p><strong>; words or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>FindFirstDifference:</strong></p>
<p><strong>cld</strong></p>
<p><strong>jcxz FindFirstDifferenceSame</strong></p>
<p><strong>;if there’s nothing to</strong></p>
<p><strong>; check, we’ll consider the</strong></p>
<p><strong>; arrays to be the same.</strong></p>
<p><strong>; (If we let LOOP</strong></p>
<p><strong>; execute with CX=0, we’ll</strong></p>
<p><strong>; get 64 K repetitions)</strong></p>
<p><strong>FindFirstDifferenceLoop:</strong></p>
<p><strong>lodsw</strong></p>
<p><strong>scasw ;compare the next two words</strong></p>
<p><strong>jnz FindFirstDifferenceFound</strong></p>
<p><strong>;the arrays differ</strong></p>
<p><strong>loop FindFirstDifferenceLoop</strong></p>
<p><strong>;the arrays are the</strong></p>
<p><strong>; same so far</strong></p>
<p><strong>FindFirstDifferenceSame:</strong></p>
<p><strong>sub si,si ;indicate that the strings</strong></p>
<p><strong>mov di,si ; are identical</strong></p>
<p><strong>ret</strong></p>
<p><strong>FindFirstDifferenceFound:</strong></p>
<p><strong>dec si ;the arrays differ, so</strong></p>
<p><strong>dec si ; point back to first</strong></p>
<p><strong>dec di ; difference in both arrays</strong></p>
<p><strong>dec di</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset WordArray1 ;point to the two</strong></p>
<p><strong>mov di,ds ; arrays to be</strong></p>
<p><strong>mov es,di ; compared</strong></p>
<p><strong>mov di,offset WordArray2</strong></p>
<p><strong>mov cx,ARRAY_LENGTH_IN_WORDS</strong></p>
<p><strong>;# of words to check</strong></p>
<p><strong>call FindFirstDifference ;see if they differ</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-23" class="level2">
<h2>Listing 11-23</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-23 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Compares two word-sized arrays of equal length to see</strong></p>
<p><strong>; whether they differ, and if so, where, using non-string</strong></p>
<p><strong>; instructions.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>WordArray1 dw 100 dup (1), 0, 99 dup (2)</strong></p>
<p><strong>ARRAY_LENGTH_IN_WORDS equ (($-WordArray1)/2)</strong></p>
<p><strong>WordArray2 dw 100 dup (1), 100 dup (2)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Returns pointers to the first locations at which two</strong></p>
<p><strong>; word-sized arrays of equal length differ, or zero if</strong></p>
<p><strong>; they’re identical.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = length of the arrays (they must be of equal</strong></p>
<p><strong>; length)</strong></p>
<p><strong>; DS:SI = the first array to compare</strong></p>
<p><strong>; ES:DI = the second array to compare</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; DS:SI = pointer to the first differing location in</strong></p>
<p><strong>; the first array if there is a difference,</strong></p>
<p><strong>; or SI=0 if the arrays are identical</strong></p>
<p><strong>; ES:DI = pointer to the first differing location in</strong></p>
<p><strong>; the second array if there is a difference,</strong></p>
<p><strong>; or DI=0 if the arrays are identical</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle arrays that are longer than 32K</strong></p>
<p><strong>; words or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>FindFirstDifference:</strong></p>
<p><strong>jcxz FindFirstDifferenceSame</strong></p>
<p><strong>;if there’s nothing to</strong></p>
<p><strong>; check, we’ll consider the</strong></p>
<p><strong>; arrays to be the same</strong></p>
<p><strong>FindFirstDifferenceLoop:</strong></p>
<p><strong>mov ax,[si]</strong></p>
<p><strong>cmp es:[di],ax ;compare the next two words</strong></p>
<p><strong>jnz FindFirstDifferenceFound ;the arrays differ</strong></p>
<p><strong>inc si</strong></p>
<p><strong>inc si ;point to the next words to</strong></p>
<p><strong>inc di ; compare</strong></p>
<p><strong>inc di</strong></p>
<p><strong>loop FindFirstDifferenceLoop ;the arrays are the</strong></p>
<p><strong>; same so far</strong></p>
<p><strong>FindFirstDifferenceSame:</strong></p>
<p><strong>sub si,si ;indicate that the strings</strong></p>
<p><strong>mov di,si ; are identical</strong></p>
<p><strong>FindFirstDifferenceFound:</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset WordArray1 ;point to the two</strong></p>
<p><strong>mov di,ds ; arrays to be</strong></p>
<p><strong>mov es,di ; compared</strong></p>
<p><strong>mov di,offset WordArray2</strong></p>
<p><strong>mov cx,ARRAY_LENGTH_IN_WORDS</strong></p>
<p><strong>;# of words to check</strong></p>
<p><strong>call FindFirstDifference ;see if they differ</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-24" class="level2">
<h2>Listing 11-24</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-24 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Determines whether two zero-terminated strings differ, and</strong></p>
<p><strong>; if so where, using REP SCASB to find the terminating zero</strong></p>
<p><strong>; to determine one string length, and then using REPZ CMPSW</strong></p>
<p><strong>; to compare the strings.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>TestString1 label byte</strong></p>
<p><strong>db ‘This is a test string that is’</strong></p>
<p><strong>db ‘z’</strong></p>
<p><strong>db ‘terminated with a zero byte…’,0</strong></p>
<p><strong>TestString2 label byte</strong></p>
<p><strong>db ‘This is a test string that is’</strong></p>
<p><strong>db ‘a’</strong></p>
<p><strong>db ‘terminated with a zero byte…’,0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Compares two zero-terminated strings.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DS:SI = first zero-terminated string</strong></p>
<p><strong>; ES:DI = second zero-terminated string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; DS:SI = pointer to first differing location in</strong></p>
<p><strong>; first string, or 0 if the byte wasn’t found</strong></p>
<p><strong>; ES:DI = pointer to first differing location in</strong></p>
<p><strong>; second string, or 0 if the byte wasn’t found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, CX, DX, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: If there is no terminating zero in the first 64K-1</strong></p>
<p><strong>; bytes of a string, the string is treated as if byte</strong></p>
<p><strong>; 64K is a zero without checking, since if it isn’t</strong></p>
<p><strong>; the string isn’t zero-terminated at all.</strong></p>
<p><strong>;</strong></p>
<p><strong>CompareStrings:</strong></p>
<p><strong>mov dx,di ;set aside the start of the second</strong></p>
<p><strong>; string</strong></p>
<p><strong>sub al,al ;we’ll search for zero in the second</strong></p>
<p><strong>; string to see how long it is</strong></p>
<p><strong>mov cx,0ffffh ;long enough to handle any string</strong></p>
<p><strong>; up to 64K-1 bytes in length. Any</strong></p>
<p><strong>; longer string will be treated as</strong></p>
<p><strong>; if byte 64K is zero</strong></p>
<p><strong>cld</strong></p>
<p><strong>repnz scasb ;find the terminating zero</strong></p>
<p><strong>not cx ;length of string in bytes, including</strong></p>
<p><strong>; the terminating zero except in the</strong></p>
<p><strong>; case of a string that’s exactly 64K</strong></p>
<p><strong>; long including the terminating zero</strong></p>
<p><strong>mov di,dx ;get back the start of the second</strong></p>
<p><strong>; string</strong></p>
<p><strong>shr cx,1 ;get count in words</strong></p>
<p><strong>jnc CompareStringsWord</strong></p>
<p><strong>;if there’s no odd byte, go directly</strong></p>
<p><strong>; to comparing a word at a time</strong></p>
<p><strong>cmpsb ;compare the odd bytes of the</strong></p>
<p><strong>; strings</strong></p>
<p><strong>jnz CompareStringsDifferentByte</strong></p>
<p><strong>;we’ve already found a difference</strong></p>
<p><strong>CompareStringsWord:</strong></p>
<p><strong>;there’s no need to guard against</strong></p>
<p><strong>; CX=0 here, since we know that if</strong></p>
<p><strong>; CX=0 here, the preceding CMPSB</strong></p>
<p><strong>; must have successfully compared</strong></p>
<p><strong>; the terminating zero bytes of the</strong></p>
<p><strong>; strings (which are the only bytes</strong></p>
<p><strong>; of the strings), and the Zero flag</strong></p>
<p><strong>; setting of 1 from CMPSB will be</strong></p>
<p><strong>; preserved by REPZ CMPSW if CX=0,</strong></p>
<p><strong>; resulting in the correct</strong></p>
<p><strong>; conclusion that the strings are</strong></p>
<p><strong>; identical</strong></p>
<p><strong>repz cmpsw ;compare the rest of the strings a</strong></p>
<p><strong>; word at a time for speed</strong></p>
<p><strong>jnz CompareStringsDifferent ;they’re not the same</strong></p>
<p><strong>sub si,si ;return 0 pointers indicating that</strong></p>
<p><strong>mov di,si ; the strings are identical</strong></p>
<p><strong>ret</strong></p>
<p><strong>CompareStringsDifferent:</strong></p>
<p><strong>;the strings are different, so we</strong></p>
<p><strong>; have to figure which byte in the</strong></p>
<p><strong>; word just compared was the first</strong></p>
<p><strong>; difference</strong></p>
<p><strong>dec si ;point back to the second byte of</strong></p>
<p><strong>dec di ; the differing word in each string</strong></p>
<p><strong>dec si ;point back to the differing byte in</strong></p>
<p><strong>dec di ; each string</strong></p>
<p><strong>lodsb</strong></p>
<p><strong>scasb ;compare that first byte again</strong></p>
<p><strong>jz CompareStringsDone</strong></p>
<p><strong>;if the first bytes are the same,</strong></p>
<p><strong>; then it must have been the second</strong></p>
<p><strong>; bytes that differed. That’s where</strong></p>
<p><strong>; we’re pointing, so we’re done</strong></p>
<p><strong>CompareStringsDifferentByte:</strong></p>
<p><strong>dec si ;the first bytes differed, so point</strong></p>
<p><strong>dec di ; back to them</strong></p>
<p><strong>CompareStringsDone:</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset TestString1 ;point to one string</strong></p>
<p><strong>mov di,seg TestString2</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset TestString2 ;point to other string</strong></p>
<p><strong>call CompareStrings ;and compare the strings</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-25" class="level2">
<h2>Listing 11-25</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-25 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Determines whether two zero-terminated strings differ, and</strong></p>
<p><strong>; if so where, using LODS/SCAS.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>TestString1 label byte</strong></p>
<p><strong>db ‘This is a test string that is’</strong></p>
<p><strong>db ‘z’</strong></p>
<p><strong>db ‘terminated with a zero byte…’,0</strong></p>
<p><strong>TestString2 label byte</strong></p>
<p><strong>db ‘This is a test string that is’</strong></p>
<p><strong>db ‘a’</strong></p>
<p><strong>db ‘terminated with a zero byte…’,0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Compares two zero-terminated strings.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DS:SI = first zero-terminated string</strong></p>
<p><strong>; ES:DI = second zero-terminated string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; DS:SI = pointer to first differing location in</strong></p>
<p><strong>; first string, or 0 if the byte wasn’t found</strong></p>
<p><strong>; ES:DI = pointer to first differing location in</strong></p>
<p><strong>; second string, or 0 if the byte wasn’t found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>CompareStrings:</strong></p>
<p><strong>cld</strong></p>
<p><strong>CompareStringsLoop:</strong></p>
<p><strong>lodsw ;get the next 2 bytes</strong></p>
<p><strong>and al,al ;is the first byte the terminating</strong></p>
<p><strong>; zero?</strong></p>
<p><strong>jz CompareStringsFinalByte</strong></p>
<p><strong>;yes, so there’s only one byte left</strong></p>
<p><strong>; to check</strong></p>
<p><strong>scasw ;compare this word</strong></p>
<p><strong>jnz CompareStringsDifferent ;the strings differ</strong></p>
<p><strong>and ah,ah ;is the second byte the terminating</strong></p>
<p><strong>; zero?</strong></p>
<p><strong>jnz CompareStringsLoop ;no, continue comparing</strong></p>
<p><strong>;the strings are the same</strong></p>
<p><strong>CompareStringsSame:</strong></p>
<p><strong>sub si,si ;return 0 pointers indicating that</strong></p>
<p><strong>mov di,si ; the strings are identical</strong></p>
<p><strong>ret</strong></p>
<p><strong>CompareStringsFinalByte:</strong></p>
<p><strong>scasb ;does the terminating zero match in</strong></p>
<p><strong>; the 2 strings?</strong></p>
<p><strong>jz CompareStringsSame ;yes, the strings match</strong></p>
<p><strong>dec si ;point back to the differing byte</strong></p>
<p><strong>dec di ; in each string</strong></p>
<p><strong>ret</strong></p>
<p><strong>CompareStringsDifferent:</strong></p>
<p><strong>;the strings are different, so we</strong></p>
<p><strong>; have to figure which byte in the</strong></p>
<p><strong>; word just compared was the first</strong></p>
<p><strong>; difference</strong></p>
<p><strong>dec si</strong></p>
<p><strong>dec si ;point back to the first byte of the</strong></p>
<p><strong>dec di ; differing word in each string</strong></p>
<p><strong>dec di</strong></p>
<p><strong>lodsb</strong></p>
<p><strong>scasb ;compare that first byte again</strong></p>
<p><strong>jz CompareStringsDone</strong></p>
<p><strong>;if the first bytes are the same,</strong></p>
<p><strong>; then it must have been the second</strong></p>
<p><strong>; bytes that differed. That’s where</strong></p>
<p><strong>; we’re pointing, so we’re done</strong></p>
<p><strong>dec si ;the first bytes differed, so point</strong></p>
<p><strong>dec di ; back to them</strong></p>
<p><strong>CompareStringsDone:</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset TestString1 ;point to one string</strong></p>
<p><strong>mov di,seg TestString2</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset TestString2 ;point to other string</strong></p>
<p><strong>call CompareStrings ;and compare the strings</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-26" class="level2">
<h2>Listing 11-26</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-26 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Determines whether two zero-terminated strings differ</strong></p>
<p><strong>; ignoring case-only differences, and if so where, using</strong></p>
<p><strong>; LODS.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>TestString1 label byte</strong></p>
<p><strong>db ‘THIS IS A TEST STRING THAT IS’</strong></p>
<p><strong>db ‘Z’</strong></p>
<p><strong>db ‘TERMINATED WITH A ZERO BYTE…’,0</strong></p>
<p><strong>TestString2 label byte</strong></p>
<p><strong>db ‘This is a test string that is’</strong></p>
<p><strong>db ‘a’</strong></p>
<p><strong>db ‘terminated with a zero byte…’,0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to convert the specified register to uppercase if</strong></p>
<p><strong>; it is lowercase.</strong></p>
<p><strong>;</strong></p>
<p><strong>TO_UPPER macro REGISTER</strong></p>
<p><strong>local NotLower</strong></p>
<p><strong>cmp REGISTER,ch ;below ‘a’?</strong></p>
<p><strong>jb NotLower ;yes, not lowercase</strong></p>
<p><strong>cmp REGISTER,cl ;above ‘z’?</strong></p>
<p><strong>ja NotLower ;yes, not lowercase</strong></p>
<p><strong>and REGISTER,bl ;lowercase-convert to uppercase</strong></p>
<p><strong>NotLower:</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Compares two zero-terminated strings, ignoring differences</strong></p>
<p><strong>; that are only uppercase/lowercase differences.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DS:SI = first zero-terminated string</strong></p>
<p><strong>; ES:DI = second zero-terminated string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; DS:SI = pointer to first case-insensitive differing</strong></p>
<p><strong>; location in first string, or 0 if the byte</strong></p>
<p><strong>; wasn’t found</strong></p>
<p><strong>; ES:DI = pointer to first case-insensitive differing</strong></p>
<p><strong>; location in second string, or 0 if the byte</strong></p>
<p><strong>; wasn’t found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, BL, CX, DX, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>CompareStringsNoCase:</strong></p>
<p><strong>cld</strong></p>
<p><strong>mov cx,‘az’ ;for fast register-register</strong></p>
<p><strong>; comparison in the loop</strong></p>
<p><strong>mov bl,not 20h ;for fast conversion to</strong></p>
<p><strong>; uppercase in the loop</strong></p>
<p><strong>CompareStringsLoop:</strong></p>
<p><strong>lodsw ;get the next 2 bytes</strong></p>
<p><strong>mov dx,es:[di] ; from each string</strong></p>
<p><strong>inc di ;point to the next word in the</strong></p>
<p><strong>inc di ; second string</strong></p>
<p><strong>TO_UPPER al ;convert the first byte from each</strong></p>
<p><strong>TO_UPPER dl ; string to uppercase</strong></p>
<p><strong>cmp al,dl ;do the first bytes match?</strong></p>
<p><strong>jnz CompareStringsDifferent1 ;the strings differ</strong></p>
<p><strong>and al,al ;is the first byte the terminating</strong></p>
<p><strong>; zero?</strong></p>
<p><strong>jz CompareStringsSame</strong></p>
<p><strong>;yes, we’re done with a match</strong></p>
<p><strong>TO_UPPER ah ;convert the second byte from each</strong></p>
<p><strong>TO_UPPER dh ; string to uppercase</strong></p>
<p><strong>cmp ah,dh ;do the second bytes match?</strong></p>
<p><strong>jnz CompareStringsDifferent ;the strings differ</strong></p>
<p><strong>and ah,ah ;is the second byte the terminating</strong></p>
<p><strong>; zero?</strong></p>
<p><strong>jnz CompareStringsLoop</strong></p>
<p><strong>;no, do the next 2 bytes</strong></p>
<p><strong>CompareStringsSame:</strong></p>
<p><strong>sub si,si ;return 0 pointers indicating that</strong></p>
<p><strong>mov di,si ; the strings are identical</strong></p>
<p><strong>ret</strong></p>
<p><strong>CompareStringsDifferent1:</strong></p>
<p><strong>dec si ;point back to the second byte of</strong></p>
<p><strong>dec di ; the word we just compared</strong></p>
<p><strong>CompareStringsDifferent:</strong></p>
<p><strong>dec si ;point back to the first byte of the</strong></p>
<p><strong>dec di ; word we just compared</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset TestString1 ;point to one string</strong></p>
<p><strong>mov di,seg TestString2</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset TestString2 ;point to other string</strong></p>
<p><strong>call CompareStringsNoCase ;and compare the</strong></p>
<p><strong>; strings without</strong></p>
<p><strong>; regard for case</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-27" class="level2">
<h2>Listing 11-27</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-27 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Determines whether two zero-terminated strings differ</strong></p>
<p><strong>; ignoring case-only differences, and if so where, using</strong></p>
<p><strong>; LODS, with an XLAT-based table look-up to convert to</strong></p>
<p><strong>; uppercase.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>TestString1 label byte</strong></p>
<p><strong>db ‘THIS IS A TEST STRING THAT IS’</strong></p>
<p><strong>db ‘Z’</strong></p>
<p><strong>db ‘TERMINATED WITH A ZERO BYTE…’,0</strong></p>
<p><strong>TestString2 label byte</strong></p>
<p><strong>db ‘This is a test string that is’</strong></p>
<p><strong>db ‘a’</strong></p>
<p><strong>db ‘terminated with a zero byte…’,0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Table of conversions between characters and their</strong></p>
<p><strong>; uppercase equivalents. (Could be just 128 bytes long if</strong></p>
<p><strong>; only 7-bit ASCII characters are used.)</strong></p>
<p><strong>;</strong></p>
<p><strong>ToUpperTable label word</strong></p>
<p><strong>CHAR=0</strong></p>
<p><strong>rept 256</strong></p>
<p><strong>if (CHAR lt ‘a’) or (CHAR gt ‘z’)</strong></p>
<p><strong>db CHAR ;not a lowercase character</strong></p>
<p><strong>else</strong></p>
<p><strong>db CHAR and not 20h</strong></p>
<p><strong>;convert in the range ‘a’-‘z’ to</strong></p>
<p><strong>; uppercase</strong></p>
<p><strong>endif</strong></p>
<p><strong>CHAR=CHAR+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Compares two zero-terminated strings, ignoring differences</strong></p>
<p><strong>; that are only uppercase/lowercase differences.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DS:SI = first zero-terminated string</strong></p>
<p><strong>; ES:DI = second zero-terminated string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; DS:SI = pointer to first case-insensitive differing</strong></p>
<p><strong>; location in first string, or 0 if the byte</strong></p>
<p><strong>; wasn’t found</strong></p>
<p><strong>; ES:DI = pointer to first case-insensitive differing</strong></p>
<p><strong>; location in second string, or 0 if the byte</strong></p>
<p><strong>; wasn’t found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, BX, DX, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>CompareStringsNoCase:</strong></p>
<p><strong>cld</strong></p>
<p><strong>mov bx,offset ToUpperTable</strong></p>
<p><strong>CompareStringsLoop:</strong></p>
<p><strong>lodsw ;get the next 2 bytes</strong></p>
<p><strong>mov dx,es:[di] ; from each string</strong></p>
<p><strong>inc di ;point to the next word in the</strong></p>
<p><strong>inc di ; second string</strong></p>
<p><strong>xlat ;convert the first byte in the</strong></p>
<p><strong>; first string to uppercase</strong></p>
<p><strong>xchg dl,al ;set aside the first byte &amp;</strong></p>
<p><strong>xlat ; convert the first byte in the</strong></p>
<p><strong>; second string to uppercase</strong></p>
<p><strong>cmp al,dl ;do the first bytes match?</strong></p>
<p><strong>jnz CompareStringsDifferent1 ;the strings differ</strong></p>
<p><strong>and al,al ;is this the terminating zero?</strong></p>
<p><strong>jz CompareStringsSame</strong></p>
<p><strong>;yes, we’re done, with a match</strong></p>
<p><strong>mov al,ah</strong></p>
<p><strong>xlat ;convert the second byte from the</strong></p>
<p><strong>; first string to uppercase</strong></p>
<p><strong>xchg dh,al ;set aside the second byte &amp;</strong></p>
<p><strong>xlat ; convert the second byte from the</strong></p>
<p><strong>; second string to uppercase</strong></p>
<p><strong>cmp al,dh ;do the second bytes match?</strong></p>
<p><strong>jnz CompareStringsDifferent ;the strings differ</strong></p>
<p><strong>and ah,ah ;is this the terminating zero?</strong></p>
<p><strong>jnz CompareStringsLoop</strong></p>
<p><strong>;no, do the next 2 bytes</strong></p>
<p><strong>CompareStringsSame:</strong></p>
<p><strong>sub si,si ;return 0 pointers indicating that</strong></p>
<p><strong>mov di,si ; the strings are identical</strong></p>
<p><strong>ret</strong></p>
<p><strong>CompareStringsDifferent1:</strong></p>
<p><strong>dec si ;point back to the second byte of</strong></p>
<p><strong>dec di ; the word we just compared</strong></p>
<p><strong>CompareStringsDifferent:</strong></p>
<p><strong>dec si ;point back to the first byte of the</strong></p>
<p><strong>dec di ; word we just compared</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset TestString1 ;point to one string</strong></p>
<p><strong>mov di,seg TestString2</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset TestString2 ;point to other string</strong></p>
<p><strong>call CompareStringsNoCase ;and compare the</strong></p>
<p><strong>; strings without</strong></p>
<p><strong>; regard for case</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-28" class="level2">
<h2>Listing 11-28</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-28 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches a text buffer for a sequence of bytes by checking</strong></p>
<p><strong>; for the sequence with CMPS starting at each byte of the</strong></p>
<p><strong>; buffer that potentially could start the sequence.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>; Text buffer that we’ll search.</strong></p>
<p><strong>;</strong></p>
<p><strong>TextBuffer label byte</strong></p>
<p><strong>db ‘This is a sample text buffer, suitable’</strong></p>
<p><strong>db ‘for a searching text of any sort…’</strong></p>
<p><strong>db ‘ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789’</strong></p>
<p><strong>db ‘End of text…’</strong></p>
<p><strong>TEXT_BUFFER_LENGTH equ ($-TextBuffer)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Sequence of bytes that we’ll search for.</strong></p>
<p><strong>;</strong></p>
<p><strong>SearchSequence label byte</strong></p>
<p><strong>db ‘text…’</strong></p>
<p><strong>SEARCH_SEQUENCE_LENGTH equ ($-SearchSequence)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches a buffer for the first occurrence of a specified</strong></p>
<p><strong>; sequence of bytes.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = length of sequence of bytes to search for</strong></p>
<p><strong>; DX = length of buffer to search in</strong></p>
<p><strong>; DS:SI = start of sequence of bytes to search for</strong></p>
<p><strong>; ES:DI = start of buffer to search</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; ES:DI = pointer to start of first occurrence of</strong></p>
<p><strong>; desired sequence of bytes in the buffer, or</strong></p>
<p><strong>; 0:0 if the sequence wasn’t found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, BX, CX, DX, SI, DI, BP</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle search sequences or text buffers</strong></p>
<p><strong>; that are longer than 64K bytes or cross segment</strong></p>
<p><strong>; boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Assumes non-zero length of search sequence (CX &gt; 0),</strong></p>
<p><strong>; and search sequence shorter than 64K (CX &lt;= 0ffffh).</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Assumes buffer is longer than search sequence</strong></p>
<p><strong>; (DX &gt; CX). Zero length of buffer is taken to mean</strong></p>
<p><strong>; that the buffer is 64K bytes long.</strong></p>
<p><strong>;</strong></p>
<p><strong>FindSequence:</strong></p>
<p><strong>cld</strong></p>
<p><strong>mov bp,si ;set aside the sequence start</strong></p>
<p><strong>; offset</strong></p>
<p><strong>mov ax,di ;set aside the buffer start offset</strong></p>
<p><strong>mov bx,cx ;set aside the sequence length</strong></p>
<p><strong>sub dx,cx ;difference between buffer and</strong></p>
<p><strong>; search sequence lengths</strong></p>
<p><strong>inc dx ;# of possible sequence start bytes</strong></p>
<p><strong>; to check in the buffer</strong></p>
<p><strong>FindSequenceLoop:</strong></p>
<p><strong>mov cx,bx ;sequence length</strong></p>
<p><strong>shr cx,1 ;convert to word for faster search</strong></p>
<p><strong>jnc FindSequenceWord ;do word search if no odd</strong></p>
<p><strong>; byte</strong></p>
<p><strong>cmpsb ;compare the odd byte</strong></p>
<p><strong>jnz FindSequenceNoMatch ;odd byte doesn’t match,</strong></p>
<p><strong>; so we havent’ found the</strong></p>
<p><strong>; search sequence here</strong></p>
<p><strong>FindSequenceWord:</strong></p>
<p><strong>jcxz FindSequenceFound</strong></p>
<p><strong>;since we’re guaranteed to</strong></p>
<p><strong>; have a non-zero length,</strong></p>
<p><strong>; the sequence must be 1</strong></p>
<p><strong>; byte long and we’ve</strong></p>
<p><strong>; already found that it</strong></p>
<p><strong>; matched</strong></p>
<p><strong>repz cmpsw ;check the rest of the</strong></p>
<p><strong>; sequence a word at a time</strong></p>
<p><strong>; for speed</strong></p>
<p><strong>jz FindSequenceFound ;it’s a match</strong></p>
<p><strong>FindSequenceNoMatch:</strong></p>
<p><strong>mov si,bp ;point to the start of the search</strong></p>
<p><strong>; sequence again</strong></p>
<p><strong>inc ax ;advance to the next buffer start</strong></p>
<p><strong>; search location</strong></p>
<p><strong>mov di,ax ;point DI to the next buffer start</strong></p>
<p><strong>; search location</strong></p>
<p><strong>dec dx ;count down the remaining bytes to</strong></p>
<p><strong>; search in the buffer</strong></p>
<p><strong>jnz FindSequenceLoop</strong></p>
<p><strong>sub di,di ;return 0 pointer indicating that</strong></p>
<p><strong>mov es,di ; the sequence was not found</strong></p>
<p><strong>ret</strong></p>
<p><strong>FindSequenceFound:</strong></p>
<p><strong>mov di,ax ;point to the buffer location at</strong></p>
<p><strong>; which the first occurrence of the</strong></p>
<p><strong>; sequence was found</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset SearchSequence</strong></p>
<p><strong>;point to search sequence</strong></p>
<p><strong>mov cx,SEARCH_SEQUENCE_LENGTH</strong></p>
<p><strong>;length of search sequence</strong></p>
<p><strong>mov di,seg TextBuffer</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset TextBuffer</strong></p>
<p><strong>;point to buffer to search</strong></p>
<p><strong>mov dx,TEXT_BUFFER_LENGTH</strong></p>
<p><strong>;length of buffer to search</strong></p>
<p><strong>call FindSequence ;search for the sequence</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-29" class="level2">
<h2>Listing 11-29</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-29 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches a text buffer for a sequence of bytes by using</strong></p>
<p><strong>; REPNZ SCASB to identify bytes in the buffer that</strong></p>
<p><strong>; potentially could start the sequence and then checking</strong></p>
<p><strong>; only starting at those qualified bytes for a match with</strong></p>
<p><strong>; the sequence by way of REPZ CMPS.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>; Text buffer that we’ll search.</strong></p>
<p><strong>;</strong></p>
<p><strong>TextBuffer label byte</strong></p>
<p><strong>db ‘This is a sample text buffer, suitable’</strong></p>
<p><strong>db ‘for a searching text of any sort…’</strong></p>
<p><strong>db ‘ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789’</strong></p>
<p><strong>db ‘End of text…’</strong></p>
<p><strong>TEXT_BUFFER_LENGTH equ ($-TextBuffer)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Sequence of bytes that we’ll search for.</strong></p>
<p><strong>;</strong></p>
<p><strong>SearchSequence label byte</strong></p>
<p><strong>db ‘text…’</strong></p>
<p><strong>SEARCH_SEQUENCE_LENGTH equ ($-SearchSequence)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches a buffer for the first occurrence of a specified</strong></p>
<p><strong>; sequence of bytes.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = length of sequence of bytes to search for</strong></p>
<p><strong>; DX = length of buffer to search in</strong></p>
<p><strong>; DS:SI = start of sequence of bytes to search for</strong></p>
<p><strong>; ES:DI = start of buffer to search</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; ES:DI = pointer to start of first occurrence of</strong></p>
<p><strong>; desired sequence of bytes in the buffer, or</strong></p>
<p><strong>; 0:0 if the sequence wasn’t found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, BX, CX, DX, SI, DI, BP</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle search sequences or text buffers</strong></p>
<p><strong>; that are longer than 64K bytes or cross segment</strong></p>
<p><strong>; boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Assumes non-zero length of search sequence (CX &gt; 0),</strong></p>
<p><strong>; and search sequence shorter than 64K (CX &lt;= 0ffffh).</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Assumes buffer is longer than search sequence</strong></p>
<p><strong>; (DX &gt; CX). Zero length of buffer (DX = 0) is taken</strong></p>
<p><strong>; to mean that the buffer is 64K bytes long.</strong></p>
<p><strong>;</strong></p>
<p><strong>FindSequence:</strong></p>
<p><strong>cld</strong></p>
<p><strong>lodsb ;get the first byte of the search</strong></p>
<p><strong>; sequence, which we’ll leave in AL</strong></p>
<p><strong>; for faster searching</strong></p>
<p><strong>mov bp,si ;set aside the sequence start</strong></p>
<p><strong>; offset plus one</strong></p>
<p><strong>dec cx ;we don’t need to compare the first</strong></p>
<p><strong>; byte of the sequence with CMPS,</strong></p>
<p><strong>; since we’ll do it with SCAS</strong></p>
<p><strong>mov bx,cx ;set aside the sequence length</strong></p>
<p><strong>; minus 1</strong></p>
<p><strong>sub dx,cx ;difference between buffer and</strong></p>
<p><strong>; search sequence lengths plus 1</strong></p>
<p><strong>; (# of possible sequence start</strong></p>
<p><strong>; bytes to check in the buffer)</strong></p>
<p><strong>mov cx,dx ;put buffer search length in CX</strong></p>
<p><strong>jnz FindSequenceLoop ;start normally if the</strong></p>
<p><strong>; buffer isn’t 64Kb long</strong></p>
<p><strong>dec cx ;the buffer is 64K bytes long-we</strong></p>
<p><strong>; have to check the first byte</strong></p>
<p><strong>; specially since CX = 0 means</strong></p>
<p><strong>; “do nothing” to REPNZ SCASB</strong></p>
<p><strong>scasb ;check the first byte of the buffer</strong></p>
<p><strong>jz FindSequenceCheck ;it’s a match for 1 byte,</strong></p>
<p><strong>; at least-check the rest</strong></p>
<p><strong>FindSequenceLoop:</strong></p>
<p><strong>repnz scasb ;search for the first byte of the</strong></p>
<p><strong>; search sequence</strong></p>
<p><strong>jnz FindSequenceNotFound</strong></p>
<p><strong>;it’s not found, so there are no</strong></p>
<p><strong>; possible matches</strong></p>
<p><strong>FindSequenceCheck:</strong></p>
<p><strong>;we’ve got a potential (first byte)</strong></p>
<p><strong>; match-check the rest of this</strong></p>
<p><strong>; candidate sequence</strong></p>
<p><strong>push di ;remember the address of the next</strong></p>
<p><strong>; byte to check in case it’s needed</strong></p>
<p><strong>mov dx,cx ;set aside the remaining length to</strong></p>
<p><strong>; search in the buffer</strong></p>
<p><strong>mov si,bp ;point to the rest of the search</strong></p>
<p><strong>; sequence</strong></p>
<p><strong>mov cx,bx ;sequence length (minus first byte)</strong></p>
<p><strong>shr cx,1 ;convert to word for faster search</strong></p>
<p><strong>jnc FindSequenceWord ;do word search if no odd</strong></p>
<p><strong>; byte</strong></p>
<p><strong>cmpsb ;compare the odd byte</strong></p>
<p><strong>jnz FindSequenceNoMatch</strong></p>
<p><strong>;odd byte doesn’t match,</strong></p>
<p><strong>; so we haven’t found the</strong></p>
<p><strong>; search sequence here</strong></p>
<p><strong>FindSequenceWord:</strong></p>
<p><strong>jcxz FindSequenceFound</strong></p>
<p><strong>;since we’re guaranteed to have</strong></p>
<p><strong>; a non-zero length, the</strong></p>
<p><strong>; sequence must be 1 byte long</strong></p>
<p><strong>; and we’ve already found that</strong></p>
<p><strong>; it matched</strong></p>
<p><strong>repz cmpsw ;check the rest of the sequence a</strong></p>
<p><strong>; word at a time for speed</strong></p>
<p><strong>jz FindSequenceFound ;it’s a match</strong></p>
<p><strong>FindSequenceNoMatch:</strong></p>
<p><strong>pop di ;get back the pointer to the next</strong></p>
<p><strong>; byte to check</strong></p>
<p><strong>mov cx,dx ;get back the remaining length to</strong></p>
<p><strong>; search in the buffer</strong></p>
<p><strong>and cx,cx ;see if there’s anything left to</strong></p>
<p><strong>; check</strong></p>
<p><strong>jnz FindSequenceLoop ;yes-check next byte</strong></p>
<p><strong>FindSequenceNotFound:</strong></p>
<p><strong>sub di,di ;return 0 pointer indicating that</strong></p>
<p><strong>mov es,di ; the sequence was not found</strong></p>
<p><strong>ret</strong></p>
<p><strong>FindSequenceFound:</strong></p>
<p><strong>pop di ;point to the buffer location at</strong></p>
<p><strong>dec di ; which the first occurrence of the</strong></p>
<p><strong>; sequence was found (remember that</strong></p>
<p><strong>; earlier we pushed the address of</strong></p>
<p><strong>; the byte after the potential</strong></p>
<p><strong>; sequence start)</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset SearchSequence</strong></p>
<p><strong>;point to search sequence</strong></p>
<p><strong>mov cx,SEARCH_SEQUENCE_LENGTH</strong></p>
<p><strong>;length of search sequence</strong></p>
<p><strong>mov di,seg TextBuffer</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset TextBuffer</strong></p>
<p><strong>;point to buffer to search</strong></p>
<p><strong>mov dx,TEXT_BUFFER_LENGTH</strong></p>
<p><strong>;length of buffer to search</strong></p>
<p><strong>call FindSequence ;search for the sequence</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-30" class="level2">
<h2>Listing 11-30</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-30 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches a text buffer for a sequence of bytes by checking</strong></p>
<p><strong>; for the sequence with non-string instructions starting at</strong></p>
<p><strong>; each byte of the buffer that potentially could start the</strong></p>
<p><strong>; sequence.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>; Text buffer that we’ll search.</strong></p>
<p><strong>;</strong></p>
<p><strong>TextBuffer label byte</strong></p>
<p><strong>db ‘This is a sample text buffer, suitable’</strong></p>
<p><strong>db ‘for a searching text of any sort…’</strong></p>
<p><strong>db ‘ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789’</strong></p>
<p><strong>db ‘End of text…’</strong></p>
<p><strong>TEXT_BUFFER_LENGTH equ ($-TextBuffer)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Sequence of bytes that we’ll search for.</strong></p>
<p><strong>;</strong></p>
<p><strong>SearchSequence label byte</strong></p>
<p><strong>db ‘text…’</strong></p>
<p><strong>SEARCH_SEQUENCE_LENGTH equ ($-SearchSequence)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches a buffer for the first occurrence of a specified</strong></p>
<p><strong>; sequence of bytes.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = length of sequence of bytes to search for</strong></p>
<p><strong>; DX = length of buffer to search in</strong></p>
<p><strong>; DS:SI = start of sequence of bytes to search for</strong></p>
<p><strong>; ES:DI = start of buffer to search</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; ES:DI = pointer to start of first occurrence of</strong></p>
<p><strong>; desired sequence of bytes in the buffer, or</strong></p>
<p><strong>; 0:0 if the sequence wasn’t found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, BX, CX, DX, SI, DI, BP</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle search sequences or text buffers</strong></p>
<p><strong>; that are longer than 64K bytes or cross segment</strong></p>
<p><strong>; boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Assumes non-zero length of search sequence (CX &gt; 0),</strong></p>
<p><strong>; and search sequence shorter than 64K (CX &lt;= 0ffffh).</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Assumes buffer is longer than search sequence</strong></p>
<p><strong>; (DX &gt; CX). Zero length of buffer is taken to mean</strong></p>
<p><strong>; that the buffer is 64K bytes long.</strong></p>
<p><strong>;</strong></p>
<p><strong>FindSequence:</strong></p>
<p><strong>mov bp,si ;set aside the sequence start</strong></p>
<p><strong>; offset</strong></p>
<p><strong>mov bx,cx ;set aside the sequence length</strong></p>
<p><strong>sub dx,cx ;difference between buffer and</strong></p>
<p><strong>; search sequence lengths</strong></p>
<p><strong>inc dx ;# of possible sequence start bytes</strong></p>
<p><strong>; to check in the buffer</strong></p>
<p><strong>FindSequenceLoop:</strong></p>
<p><strong>push di ;remember the address of the current</strong></p>
<p><strong>; byte in case it’s needed</strong></p>
<p><strong>mov cx,bx ;sequence length</strong></p>
<p><strong>shr cx,1 ;convert to word for faster search</strong></p>
<p><strong>jnc FindSequenceWord ;do word search if no odd</strong></p>
<p><strong>; byte</strong></p>
<p><strong>mov al,[si]</strong></p>
<p><strong>cmp es:[di],al ;compare the odd byte</strong></p>
<p><strong>jnz FindSequenceNoMatch ;odd byte doesn’t match,</strong></p>
<p><strong>; so we havent’ found the</strong></p>
<p><strong>; search sequence here</strong></p>
<p><strong>inc si ;odd byte matches, so point</strong></p>
<p><strong>inc di ; to the next byte in the</strong></p>
<p><strong>; buffer and sequence</strong></p>
<p><strong>FindSequenceWord:</strong></p>
<p><strong>jcxz FindSequenceFound</strong></p>
<p><strong>;since we’re guaranteed to</strong></p>
<p><strong>; have a non-zero length,</strong></p>
<p><strong>; the sequence must be 1</strong></p>
<p><strong>; byte long and we’ve</strong></p>
<p><strong>; already found that it</strong></p>
<p><strong>; matched</strong></p>
<p><strong>FindSequenceWordCompareLoop:</strong></p>
<p><strong>mov ax,[si] ;compare the remainder of</strong></p>
<p><strong>cmp es:[di],ax ; the search sequence to</strong></p>
<p><strong>jnz FindSequenceNoMatch ; this part of the</strong></p>
<p><strong>inc si ; buffer a word at a time</strong></p>
<p><strong>inc si ; for speed</strong></p>
<p><strong>inc di</strong></p>
<p><strong>inc di</strong></p>
<p><strong>loop FindSequenceWordCompareLoop</strong></p>
<p><strong>FindSequenceFound: ;it’s a match</strong></p>
<p><strong>pop di ;point to the buffer location at</strong></p>
<p><strong>; which the first occurrence of the</strong></p>
<p><strong>; sequence was found (remember that</strong></p>
<p><strong>; earlier we pushed the address of</strong></p>
<p><strong>; the potential sequence start)</strong></p>
<p><strong>ret</strong></p>
<p><strong>FindSequenceNoMatch:</strong></p>
<p><strong>pop di ;get back the pointer to the current</strong></p>
<p><strong>; byte</strong></p>
<p><strong>inc di ;point to the next buffer start</strong></p>
<p><strong>; search location</strong></p>
<p><strong>mov si,bp ;point to the start of the search</strong></p>
<p><strong>; sequence again</strong></p>
<p><strong>dec dx ;count down the remaining bytes to</strong></p>
<p><strong>; search in the buffer</strong></p>
<p><strong>jnz FindSequenceLoop</strong></p>
<p><strong>sub di,di ;return 0 pointer indicating that</strong></p>
<p><strong>mov es,di ; the sequence was not found</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset SearchSequence</strong></p>
<p><strong>;point to search sequence</strong></p>
<p><strong>mov cx,SEARCH_SEQUENCE_LENGTH</strong></p>
<p><strong>;length of search sequence</strong></p>
<p><strong>mov di,seg TextBuffer</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset TextBuffer</strong></p>
<p><strong>;point to buffer to search</strong></p>
<p><strong>mov dx,TEXT_BUFFER_LENGTH</strong></p>
<p><strong>;length of buffer to search</strong></p>
<p><strong>call FindSequence ;search for the sequence</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-31" class="level2">
<h2>Listing 11-31</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-31 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Compares two arrays of 16-bit signed values in order to</strong></p>
<p><strong>; find the first point at which the arrays cross, using</strong></p>
<p><strong>; non-repeated CMPSW.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>; The two arrays that we’ll compare.</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 200</strong></p>
<p><strong>;</strong></p>
<p><strong>Array1 label byte</strong></p>
<p><strong>TEMP=-100</strong></p>
<p><strong>rept ARRAY_LENGTH</strong></p>
<p><strong>dw TEMP</strong></p>
<p><strong>TEMP=TEMP+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>Array2 label byte</strong></p>
<p><strong>TEMP=100</strong></p>
<p><strong>rept ARRAY_LENGTH</strong></p>
<p><strong>dw TEMP</strong></p>
<p><strong>TEMP=TEMP-1</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Compares two buffers to find the first point at which they</strong></p>
<p><strong>; cross. Points at which the arrays become equal are</strong></p>
<p><strong>; considered to be crossing points.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = length of arrays in words (they must be of</strong></p>
<p><strong>; equal length)</strong></p>
<p><strong>; DS:SI = start of first array</strong></p>
<p><strong>; ES:DI = start of second array</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; DS:SI = pointer to crossing point in first array,</strong></p>
<p><strong>; or SI=0 if there is no crossing point</strong></p>
<p><strong>; ES:DI = pointer to crossing point in second array,</strong></p>
<p><strong>; or DI=0 if there is no crossing point</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, CX, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle arrays that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>FindCrossing:</strong></p>
<p><strong>cld</strong></p>
<p><strong>jcxz FindCrossingNotFound</strong></p>
<p><strong>;if there’s nothing to compare, we</strong></p>
<p><strong>; certainly can’t find a crossing</strong></p>
<p><strong>mov ax,[si] ;compare the first two points to</strong></p>
<p><strong>cmp ax,es:[di] ; make sure that the first array</strong></p>
<p><strong>; doesn’t start out below the second</strong></p>
<p><strong>; array</strong></p>
<p><strong>pushf ;remember the original relationship</strong></p>
<p><strong>; of the arrays, so we can put the</strong></p>
<p><strong>; pointers back at the end (can’t</strong></p>
<p><strong>; use LAHF because it doesn’t save</strong></p>
<p><strong>; the Overflow flag)</strong></p>
<p><strong>jnl FindCrossingLoop ;the first array is above</strong></p>
<p><strong>; the second array</strong></p>
<p><strong>xchg si,di ;swap the array pointers so that</strong></p>
<p><strong>; SI points to the initially-</strong></p>
<p><strong>; greater array</strong></p>
<p><strong>FindCrossingLoop:</strong></p>
<p><strong>cmpsw ;compare the next element in each</strong></p>
<p><strong>; array</strong></p>
<p><strong>jng FindCrossingFound ;if SI doesn’t point to a</strong></p>
<p><strong>; greater value, we’ve found</strong></p>
<p><strong>; the first crossing</strong></p>
<p><strong>loop FindCrossingLoop ;check the next element in</strong></p>
<p><strong>; each array</strong></p>
<p><strong>FindCrossingNotFound:</strong></p>
<p><strong>popf ;clear the flags we pushed earlier</strong></p>
<p><strong>sub si,si ;return 0 pointers to indicate that</strong></p>
<p><strong>mov di,si ; no crossing was found</strong></p>
<p><strong>ret</strong></p>
<p><strong>FindCrossingFound:</strong></p>
<p><strong>dec si</strong></p>
<p><strong>dec si ;point back to the crossing point</strong></p>
<p><strong>dec di ; in each array</strong></p>
<p><strong>dec di</strong></p>
<p><strong>popf ;get back the original relationship</strong></p>
<p><strong>; of the arrays</strong></p>
<p><strong>jnl FindCrossingDone</strong></p>
<p><strong>;SI pointed to the initially-</strong></p>
<p><strong>; greater array, so we’re all set</strong></p>
<p><strong>xchg si,di ;SI pointed to the initially-</strong></p>
<p><strong>; less array, so swap SI and DI to</strong></p>
<p><strong>; undo our earlier swap</strong></p>
<p><strong>FindCrossingDone:</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset Array1 ;point to first array</strong></p>
<p><strong>mov di,seg Array2</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset Array2 ;point to second array</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;length to compare</strong></p>
<p><strong>call FindCrossing ;find the first crossing, if</strong></p>
<p><strong>; any</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-32" class="level2">
<h2>Listing 11-32</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-32 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Compares two arrays of 16-bit signed values in order to</strong></p>
<p><strong>; find the first point at which the arrays cross, using</strong></p>
<p><strong>; non-string instructions.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>; The two arrays that we’ll compare.</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 200</strong></p>
<p><strong>;</strong></p>
<p><strong>Array1 label byte</strong></p>
<p><strong>TEMP=-100</strong></p>
<p><strong>rept ARRAY_LENGTH</strong></p>
<p><strong>dw TEMP</strong></p>
<p><strong>TEMP=TEMP+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>Array2 label byte</strong></p>
<p><strong>TEMP=100</strong></p>
<p><strong>rept ARRAY_LENGTH</strong></p>
<p><strong>dw TEMP</strong></p>
<p><strong>TEMP=TEMP-1</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Compares two buffers to find the first point at which they</strong></p>
<p><strong>; cross. Points at which the arrays become equal are</strong></p>
<p><strong>; considered to be crossing points.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = length of arrays in words (they must be of</strong></p>
<p><strong>; equal length)</strong></p>
<p><strong>; DS:SI = start of first array</strong></p>
<p><strong>; ES:DI = start of second array</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; DS:SI = pointer to crossing point in first array,</strong></p>
<p><strong>; or SI=0 if there is no crossing point</strong></p>
<p><strong>; ES:DI = pointer to crossing point in second array,</strong></p>
<p><strong>; or DI=0 if there is no crossing point</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: BX, CX, DX, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle arrays that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>FindCrossing:</strong></p>
<p><strong>jcxz FindCrossingNotFound</strong></p>
<p><strong>;if there’s nothing to compare, we</strong></p>
<p><strong>; certainly can’t find a crossing</strong></p>
<p><strong>mov dx,2 ;amount we’ll add to the pointer</strong></p>
<p><strong>; registers after each comparison,</strong></p>
<p><strong>; kept in a register for speed</strong></p>
<p><strong>mov bx,[si] ;compare the first two points to</strong></p>
<p><strong>cmp bx,es:[di] ; make sure that the first array</strong></p>
<p><strong>; doesn’t start out below the second</strong></p>
<p><strong>; array</strong></p>
<p><strong>pushf ;remember the original relationship</strong></p>
<p><strong>; of the arrays, so we can put the</strong></p>
<p><strong>; pointers back at the end (can’t</strong></p>
<p><strong>; use LAHF because it doesn’t save</strong></p>
<p><strong>; the Overflow flag)</strong></p>
<p><strong>jnl FindCrossingLoop ;the first array is above</strong></p>
<p><strong>; the second array</strong></p>
<p><strong>xchg si,di ;swap the array pointers so that</strong></p>
<p><strong>; SI points to the initially-</strong></p>
<p><strong>; greater array</strong></p>
<p><strong>FindCrossingLoop:</strong></p>
<p><strong>mov bx,[si] ;compare the next element in</strong></p>
<p><strong>cmp bx,es:[di] ; each array</strong></p>
<p><strong>jng FindCrossingFound ;if SI doesn’t point to a</strong></p>
<p><strong>; greater value, we’ve found</strong></p>
<p><strong>; the first crossing</strong></p>
<p><strong>add si,dx ;point to the next element</strong></p>
<p><strong>add di,dx ; in each array</strong></p>
<p><strong>loop FindCrossingLoop ;check the next element in</strong></p>
<p><strong>; each array</strong></p>
<p><strong>FindCrossingNotFound:</strong></p>
<p><strong>popf ;clear the flags we pushed earlier</strong></p>
<p><strong>sub si,si ;return 0 pointers to indicate that</strong></p>
<p><strong>mov di,si ; no crossing was found</strong></p>
<p><strong>ret</strong></p>
<p><strong>FindCrossingFound:</strong></p>
<p><strong>popf ;get back the original relationship</strong></p>
<p><strong>; of the arrays</strong></p>
<p><strong>jnl FindCrossingDone</strong></p>
<p><strong>;SI pointed to the initially-</strong></p>
<p><strong>; greater array, so we’re all set</strong></p>
<p><strong>xchg si,di ;SI pointed to the initially-</strong></p>
<p><strong>; less array, so swap SI and DI to</strong></p>
<p><strong>; undo our earlier swap</strong></p>
<p><strong>FindCrossingDone:</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset Array1 ;point to first array</strong></p>
<p><strong>mov di,seg Array2</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset Array2 ;point to second array</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;length to compare</strong></p>
<p><strong>call FindCrossing ;find the first crossing, if</strong></p>
<p><strong>; any</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-11-33" class="level2">
<h2>Listing 11-33</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-33 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Illustrates animation based on exclusive-oring.</strong></p>
<p><strong>; Animates 10 images at once.</strong></p>
<p><strong>; Not a general animation implementation, but rather an</strong></p>
<p><strong>; example of the strengths and weaknesses of exclusive-or</strong></p>
<p><strong>; based animation.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Make with LZTIME.BAT, since this program is too long to be</strong></p>
<p><strong>; handled by the precision Zen timer.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>DELAY equ 0 ;set to higher values to</strong></p>
<p><strong>; slow down for closer</strong></p>
<p><strong>; observation</strong></p>
<p><strong>REPETITIONS equ 500 ;# of times to move and</strong></p>
<p><strong>; redraw the images</strong></p>
<p><strong>DISPLAY_SEGMENT equ 0b800h ;display memory segment</strong></p>
<p><strong>; in 320x200 4-color</strong></p>
<p><strong>; graphics mode</strong></p>
<p><strong>SCREEN_WIDTH equ 80 ;# of bytes per scan line</strong></p>
<p><strong>BANK_OFFSET equ 2000h ;offset from the bank</strong></p>
<p><strong>; containing the even-</strong></p>
<p><strong>; numbered lines on the</strong></p>
<p><strong>; screen to the bank</strong></p>
<p><strong>; containing the odd-</strong></p>
<p><strong>; numbered lines</strong></p>
<p><strong>;</strong></p>
<p><strong>; Used to count down # of times images are moved.</strong></p>
<p><strong>;</strong></p>
<p><strong>RepCount dw REPETITIONS</strong></p>
<p><strong>;</strong></p>
<p><strong>; Complete info about one image that we’re animating.</strong></p>
<p><strong>;</strong></p>
<p><strong>Image struc</strong></p>
<p><strong>XCoord dw ? ;image X location in pixels</strong></p>
<p><strong>XInc dw ? ;# of pixels to increment</strong></p>
<p><strong>; location by in the X</strong></p>
<p><strong>; direction on each move</strong></p>
<p><strong>YCoord dw ? ;image Y location in pixels</strong></p>
<p><strong>YInc dw ? ;# of pixels to increment</strong></p>
<p><strong>; location by in the Y</strong></p>
<p><strong>; direction on each move</strong></p>
<p><strong>Image ends</strong></p>
<p><strong>;</strong></p>
<p><strong>; List of images to animate.</strong></p>
<p><strong>;</strong></p>
<p><strong>Images label Image</strong></p>
<p><strong>Image &lt;64,4,8,4&gt;</strong></p>
<p><strong>Image &lt;144,0,56,2&gt;</strong></p>
<p><strong>Image &lt;224,-4,104,0&gt;</strong></p>
<p><strong>Image &lt;64,4,152,-2&gt;</strong></p>
<p><strong>Image &lt;144,0,8,-4&gt;</strong></p>
<p><strong>Image &lt;224,-4,56,-2&gt;</strong></p>
<p><strong>Image &lt;64,4,104,0&gt;</strong></p>
<p><strong>Image &lt;144,0,152,2&gt;</strong></p>
<p><strong>Image &lt;224,-4,8,4&gt;</strong></p>
<p><strong>Image &lt;64,4,56,2&gt;</strong></p>
<p><strong>ImagesEnd label Image</strong></p>
<p><strong>;</strong></p>
<p><strong>; Pixel pattern for the one image this program draws,</strong></p>
<p><strong>; a 32x32 3-color square.</strong></p>
<p><strong>;</strong></p>
<p><strong>TheImage label byte</strong></p>
<p><strong>rept 32</strong></p>
<p><strong>dw 0ffffh, 05555h, 0aaaah, 0ffffh</strong></p>
<p><strong>endm</strong></p>
<p><strong>IMAGE_HEIGHT equ 32 ;# of rows in the image</strong></p>
<p><strong>IMAGE_WIDTH equ 8 ;# of bytes across the image</strong></p>
<p><strong>;</strong></p>
<p><strong>; Exclusive-ors the image of a 3-color square at the</strong></p>
<p><strong>; specified screen location. Assumes images start on</strong></p>
<p><strong>; even-numbered scan lines and are an even number of</strong></p>
<p><strong>; scan lines high. Always draws images byte-aligned in</strong></p>
<p><strong>; display memory.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = X coordinate of upper left corner at which to</strong></p>
<p><strong>; draw image (will be adjusted to nearest</strong></p>
<p><strong>; less-than or equal-to multiple of 4 in order</strong></p>
<p><strong>; to byte-align)</strong></p>
<p><strong>; DX = Y coordinate of upper left corner at which to</strong></p>
<p><strong>; draw image</strong></p>
<p><strong>; ES = display memory segment</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, CX, DX, SI, DI, BP</strong></p>
<p><strong>;</strong></p>
<p><strong>XorImage:</strong></p>
<p><strong>push bx ;preserve the main loop’s pointer</strong></p>
<p><strong>shr dx,1 ;divide the row # by 2 to compensate</strong></p>
<p><strong>; for the 2-bank nature of 320x200</strong></p>
<p><strong>; 4-color mode</strong></p>
<p><strong>mov ax,SCREEN_WIDTH</strong></p>
<p><strong>mul dx ;start offset of top row of image in</strong></p>
<p><strong>; display memory</strong></p>
<p><strong>shr cx,1 ;divide the X coordinate by 4</strong></p>
<p><strong>shr cx,1 ; because there are 4 pixels per</strong></p>
<p><strong>; byte</strong></p>
<p><strong>add ax,cx ;point to the offset at which the</strong></p>
<p><strong>; upper left byte of the image will</strong></p>
<p><strong>; go</strong></p>
<p><strong>mov di,ax</strong></p>
<p><strong>mov si,offset TheImage</strong></p>
<p><strong>;point to the start of the one image</strong></p>
<p><strong>; we always draw</strong></p>
<p><strong>mov bx,BANK_OFFSET-IMAGE_WIDTH</strong></p>
<p><strong>;offset from the end of an even line</strong></p>
<p><strong>; of the image in display memory to</strong></p>
<p><strong>; the start of the next odd line of</strong></p>
<p><strong>; the image</strong></p>
<p><strong>mov dx,IMAGE_HEIGHT/2</strong></p>
<p><strong>;# of even/odd numbered row pairs to</strong></p>
<p><strong>; draw in the image</strong></p>
<p><strong>mov bp,IMAGE_WIDTH/2</strong></p>
<p><strong>;# of words to draw per row of the</strong></p>
<p><strong>; image. Note that IMAGE_WIDTH must</strong></p>
<p><strong>; be an even number since we XOR</strong></p>
<p><strong>; the image a word at a time</strong></p>
<p><strong>XorRowLoop:</strong></p>
<p><strong>mov cx,bp ;# of words to draw per row of the</strong></p>
<p><strong>; image</strong></p>
<p><strong>XorColumnLoopEvenRows:</strong></p>
<p><strong>lodsw ;next word of the image pattern</strong></p>
<p><strong>xor es:[di],ax ;XOR the next word of the</strong></p>
<p><strong>; image into the screen</strong></p>
<p><strong>inc di ;point to the next word in display</strong></p>
<p><strong>inc di ; memory</strong></p>
<p><strong>loop XorColumnLoopEvenRows</strong></p>
<p><strong>add di,bx ;point to the start of the next</strong></p>
<p><strong>; (odd) row of the image, which is</strong></p>
<p><strong>; in the second bank of display</strong></p>
<p><strong>; memory</strong></p>
<p><strong>mov cx,bp ;# of words to draw per row of the</strong></p>
<p><strong>; image</strong></p>
<p><strong>XorColumnLoopOddRows:</strong></p>
<p><strong>lodsw ;next word of the image pattern</strong></p>
<p><strong>xor es:[di],ax ;XOR the next word of the</strong></p>
<p><strong>; image into the screen</strong></p>
<p><strong>inc di ;point to the next word in display</strong></p>
<p><strong>inc di ; memory</strong></p>
<p><strong>loop XorColumnLoopOddRows</strong></p>
<p><strong>sub di,BANK_OFFSET-SCREEN_WIDTH+IMAGE_WIDTH</strong></p>
<p><strong>;point to the start of the next</strong></p>
<p><strong>; (even) row of the image, which is</strong></p>
<p><strong>; in the first bank of display</strong></p>
<p><strong>; memory</strong></p>
<p><strong>dec dx ;count down the row pairs</strong></p>
<p><strong>jnz XorRowLoop</strong></p>
<p><strong>pop bx ;restore the main loop’s pointer</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>; Main animation program.</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set the mode to 320x200 4-color graphics mode.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,0004h ;AH=0 is mode select fn</strong></p>
<p><strong>;AL=4 selects mode 4,</strong></p>
<p><strong>; 320x200 4-color mode</strong></p>
<p><strong>int 10h ;invoke the BIOS video</strong></p>
<p><strong>; interrupt to set the mode</strong></p>
<p><strong>;</strong></p>
<p><strong>; Point ES to display memory for the rest of the program.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,DISPLAY_SEGMENT</strong></p>
<p><strong>mov es,ax</strong></p>
<p><strong>;</strong></p>
<p><strong>; We’ll always want to count up.</strong></p>
<p><strong>;</strong></p>
<p><strong>cld</strong></p>
<p><strong>;</strong></p>
<p><strong>; Start timing.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>;</strong></p>
<p><strong>; Draw all the images initially.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov bx,offset Images ;list of images</strong></p>
<p><strong>InitialDrawLoop:</strong></p>
<p><strong>mov cx,[bx+XCoord] ;X coordinate</strong></p>
<p><strong>mov dx,[bx+YCoord] ;Y coordinate</strong></p>
<p><strong>call XorImage ;draw this image</strong></p>
<p><strong>add bx,size Image ;point to next image</strong></p>
<p><strong>cmp bx,offset ImagesEnd</strong></p>
<p><strong>jb InitialDrawLoop ;draw next image, if</strong></p>
<p><strong>; there is one</strong></p>
<p><strong>;</strong></p>
<p><strong>; Erase, move, and redraw each image in turn REPETITIONS</strong></p>
<p><strong>; times.</strong></p>
<p><strong>;</strong></p>
<p><strong>MainMoveAndDrawLoop:</strong></p>
<p><strong>mov bx,offset Images ;list of images</strong></p>
<p><strong>ImageMoveLoop:</strong></p>
<p><strong>mov cx,[bx+XCoord] ;X coordinate</strong></p>
<p><strong>mov dx,[bx+YCoord] ;Y coordinate</strong></p>
<p><strong>call XorImage ;erase this image (it’s</strong></p>
<p><strong>; already drawn at this</strong></p>
<p><strong>; location, so this XOR</strong></p>
<p><strong>; erases it)</strong></p>
<p><strong>mov cx,[bx+XCoord] ;X coordinate</strong></p>
<p><strong>cmp cx,4 ;at left edge?</strong></p>
<p><strong>ja CheckRightMargin ;no</strong></p>
<p><strong>neg [bx+XInc] ;yes, so bounce</strong></p>
<p><strong>CheckRightMargin:</strong></p>
<p><strong>cmp cx,284 ;at right edge?</strong></p>
<p><strong>jb MoveX ;no</strong></p>
<p><strong>neg [bx+XInc] ;yes, so bounce</strong></p>
<p><strong>MoveX:</strong></p>
<p><strong>add cx,[bx+XInc] ;move horizontally</strong></p>
<p><strong>mov [bx+XCoord],cx ;save the new location</strong></p>
<p><strong>mov dx,[bx+YCoord] ;Y coordinate</strong></p>
<p><strong>cmp dx,4 ;at top edge?</strong></p>
<p><strong>ja CheckBottomMargin ;no</strong></p>
<p><strong>neg [bx+YInc] ;yes, so bounce</strong></p>
<p><strong>CheckBottomMargin:</strong></p>
<p><strong>cmp dx,164 ;at bottom edge?</strong></p>
<p><strong>jb MoveY ;no</strong></p>
<p><strong>neg [bx+YInc] ;yes, so bounce</strong></p>
<p><strong>MoveY:</strong></p>
<p><strong>add dx,[bx+YInc] ;move horizontally</strong></p>
<p><strong>mov [bx+YCoord],dx ;save the new location</strong></p>
<p><strong>call XorImage ;draw the image at its</strong></p>
<p><strong>; new location</strong></p>
<p><strong>add bx,size Image ;point to the next image</strong></p>
<p><strong>cmp bx,offset ImagesEnd</strong></p>
<p><strong>jb ImageMoveLoop ;move next image, if there</strong></p>
<p><strong>; is one</strong></p>
<p><strong>if DELAY</strong></p>
<p><strong>mov cx,DELAY ;slow down as specified</strong></p>
<p><strong>loop $</strong></p>
<p><strong>endif</strong></p>
<p><strong>dec [RepCount] ;animate again?</strong></p>
<p><strong>jnz MainMoveAndDrawLoop ;yes</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOff ;done timing</strong></p>
<p><strong>;</strong></p>
<p><strong>; Return to text mode.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,0003h ;AH=0 is mode select fn</strong></p>
<p><strong>;AL=3 selects mode 3,</strong></p>
<p><strong>; 80x25 text mode</strong></p>
<p><strong>int 10h ;invoke the BIOS video</strong></p>
<p><strong>; interrupt to set the mode</strong></p>
</section>
<section id="listing-11-34" class="level2">
<h2>Listing 11-34</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 11-34 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Illustrates animation based on block moves.</strong></p>
<p><strong>; Animates 10 images at once.</strong></p>
<p><strong>; Not a general animation implementation, but rather an</strong></p>
<p><strong>; example of the strengths and weaknesses of block-move</strong></p>
<p><strong>; based animation.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Make with LZTIME.BAT, since this program is too long to be</strong></p>
<p><strong>; handled by the precision Zen timer.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>DELAY equ 0 ;set to higher values to</strong></p>
<p><strong>; slow down for closer</strong></p>
<p><strong>; observation</strong></p>
<p><strong>REPETITIONS equ 500 ;# of times to move and</strong></p>
<p><strong>; redraw the images</strong></p>
<p><strong>DISPLAY_SEGMENT equ 0b800h ;display memory segment</strong></p>
<p><strong>; in 320x200 4-color</strong></p>
<p><strong>; graphics mode</strong></p>
<p><strong>SCREEN_WIDTH equ 80 ;# of bytes per scan line</strong></p>
<p><strong>BANK_OFFSET equ 2000h ;offset from the bank</strong></p>
<p><strong>; containing the even-</strong></p>
<p><strong>; numbered lines on the</strong></p>
<p><strong>; screen to the bank</strong></p>
<p><strong>; containing the odd-</strong></p>
<p><strong>; numbered lines</strong></p>
<p><strong>;</strong></p>
<p><strong>; Used to count down # of times images are moved.</strong></p>
<p><strong>;</strong></p>
<p><strong>RepCount dw REPETITIONS</strong></p>
<p><strong>;</strong></p>
<p><strong>; Complete info about one image that we’re animating.</strong></p>
<p><strong>;</strong></p>
<p><strong>Image struc</strong></p>
<p><strong>XCoord dw ? ;image X location in pixels</strong></p>
<p><strong>XInc dw ? ;# of pixels to increment</strong></p>
<p><strong>; location by in the X</strong></p>
<p><strong>; direction on each move</strong></p>
<p><strong>YCoord dw ? ;image Y location in pixels</strong></p>
<p><strong>YInc dw ? ;# of pixels to increment</strong></p>
<p><strong>; location by in the Y</strong></p>
<p><strong>; direction on each move</strong></p>
<p><strong>Image ends</strong></p>
<p><strong>;</strong></p>
<p><strong>; List of images to animate.</strong></p>
<p><strong>;</strong></p>
<p><strong>Images label Image</strong></p>
<p><strong>Image &lt;60,4,4,4&gt;</strong></p>
<p><strong>Image &lt;140,0,52,2&gt;</strong></p>
<p><strong>Image &lt;220,-4,100,0&gt;</strong></p>
<p><strong>Image &lt;60,4,148,-2&gt;</strong></p>
<p><strong>Image &lt;140,0,4,-4&gt;</strong></p>
<p><strong>Image &lt;220,-4,52,-2&gt;</strong></p>
<p><strong>Image &lt;60,4,100,0&gt;</strong></p>
<p><strong>Image &lt;140,0,148,2&gt;</strong></p>
<p><strong>Image &lt;220,-4,4,4&gt;</strong></p>
<p><strong>Image &lt;60,4,52,2&gt;</strong></p>
<p><strong>ImagesEnd label Image</strong></p>
<p><strong>;</strong></p>
<p><strong>; Pixel pattern for the one image this program draws,</strong></p>
<p><strong>; a 32x32 3-color square. There’s a 4-pixel-wide blank</strong></p>
<p><strong>; fringe around each image, which makes sure the image at</strong></p>
<p><strong>; the old location is erased by the drawing of the image at</strong></p>
<p><strong>; the new location.</strong></p>
<p><strong>;</strong></p>
<p><strong>TheImage label byte</strong></p>
<p><strong>rept 4</strong></p>
<p><strong>dw 5 dup (0) ;top blank fringe</strong></p>
<p><strong>endm</strong></p>
<p><strong>rept 32</strong></p>
<p><strong>db 00h ;left blank fringe</strong></p>
<p><strong>dw 0ffffh, 05555h, 0aaaah, 0ffffh</strong></p>
<p><strong>db 00h ;right blank fringe</strong></p>
<p><strong>endm</strong></p>
<p><strong>rept 4</strong></p>
<p><strong>dw 5 dup (0) ;bottom blank fringe</strong></p>
<p><strong>endm</strong></p>
<p><strong>IMAGE_HEIGHT equ 40 ;# of rows in the image</strong></p>
<p><strong>; (including blank fringe)</strong></p>
<p><strong>IMAGE_WIDTH equ 10 ;# of bytes across the image</strong></p>
<p><strong>; (including blank fringe)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Block-move draws the image of a 3-color square at the</strong></p>
<p><strong>; specified screen location. Assumes images start on</strong></p>
<p><strong>; even-numbered scan lines and are an even number of</strong></p>
<p><strong>; scan lines high. Always draws images byte-aligned in</strong></p>
<p><strong>; display memory.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = X coordinate of upper left corner at which to</strong></p>
<p><strong>; draw image (will be adjusted to nearest</strong></p>
<p><strong>; less-than or equal-to multiple of 4 in order</strong></p>
<p><strong>; to byte-align)</strong></p>
<p><strong>; DX = Y coordinate of upper left corner at which to</strong></p>
<p><strong>; draw image</strong></p>
<p><strong>; ES = display memory segment</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, CX, DX, SI, DI, BP</strong></p>
<p><strong>;</strong></p>
<p><strong>BlockDrawImage:</strong></p>
<p><strong>push bx ;preserve the main loop’s pointer</strong></p>
<p><strong>shr dx,1 ;divide the row # by 2 to compensate</strong></p>
<p><strong>; for the 2-bank nature of 320x200</strong></p>
<p><strong>; 4-color mode</strong></p>
<p><strong>mov ax,SCREEN_WIDTH</strong></p>
<p><strong>mul dx ;start offset of top row of image in</strong></p>
<p><strong>; display memory</strong></p>
<p><strong>shr cx,1 ;divide the X coordinate by 4</strong></p>
<p><strong>shr cx,1 ; because there are 4 pixels per</strong></p>
<p><strong>; byte</strong></p>
<p><strong>add ax,cx ;point to the offset at which the</strong></p>
<p><strong>; upper left byte of the image will</strong></p>
<p><strong>; go</strong></p>
<p><strong>mov di,ax</strong></p>
<p><strong>mov si,offset TheImage</strong></p>
<p><strong>;point to the start of the one image</strong></p>
<p><strong>; we always draw</strong></p>
<p><strong>mov ax,BANK_OFFSET-SCREEN_WIDTH+IMAGE_WIDTH</strong></p>
<p><strong>;offset from the end of an odd line</strong></p>
<p><strong>; of the image in display memory to</strong></p>
<p><strong>; the start of the next even line of</strong></p>
<p><strong>; the image</strong></p>
<p><strong>mov bx,BANK_OFFSET-IMAGE_WIDTH</strong></p>
<p><strong>;offset from the end of an even line</strong></p>
<p><strong>; of the image in display memory to</strong></p>
<p><strong>; the start of the next odd line of</strong></p>
<p><strong>; the image</strong></p>
<p><strong>mov dx,IMAGE_HEIGHT/2</strong></p>
<p><strong>;# of even/odd numbered row pairs to</strong></p>
<p><strong>; draw in the image</strong></p>
<p><strong>mov bp,IMAGE_WIDTH/2</strong></p>
<p><strong>;# of words to draw per row of the</strong></p>
<p><strong>; image. Note that IMAGE_WIDTH must</strong></p>
<p><strong>; be an even number since we draw</strong></p>
<p><strong>; the image a word at a time</strong></p>
<p><strong>BlockDrawRowLoop:</strong></p>
<p><strong>mov cx,bp ;# of words to draw per row of the</strong></p>
<p><strong>; image</strong></p>
<p><strong>rep movsw ;draw a whole even row with this one</strong></p>
<p><strong>; repeated instruction</strong></p>
<p><strong>add di,bx ;point to the start of the next</strong></p>
<p><strong>; (odd) row of the image, which is</strong></p>
<p><strong>; in the second bank of display</strong></p>
<p><strong>; memory</strong></p>
<p><strong>mov cx,bp ;# of words to draw per row of the</strong></p>
<p><strong>; image</strong></p>
<p><strong>rep movsw ;draw a whole odd row with this one</strong></p>
<p><strong>; repeated instruction</strong></p>
<p><strong>sub di,ax</strong></p>
<p><strong>;point to the start of the next</strong></p>
<p><strong>; (even) row of the image, which is</strong></p>
<p><strong>; in the first bank of display</strong></p>
<p><strong>; memory</strong></p>
<p><strong>dec dx ;count down the row pairs</strong></p>
<p><strong>jnz BlockDrawRowLoop</strong></p>
<p><strong>pop bx ;restore the main loop’s pointer</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>; Main animation program.</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set the mode to 320x200 4-color graphics mode.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,0004h ;AH=0 is mode select fn</strong></p>
<p><strong>;AL=4 selects mode 4,</strong></p>
<p><strong>; 320x200 4-color mode</strong></p>
<p><strong>int 10h ;invoke the BIOS video</strong></p>
<p><strong>; interrupt to set the mode</strong></p>
<p><strong>;</strong></p>
<p><strong>; Point ES to display memory for the rest of the program.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,DISPLAY_SEGMENT</strong></p>
<p><strong>mov es,ax</strong></p>
<p><strong>;</strong></p>
<p><strong>; We’ll always want to count up.</strong></p>
<p><strong>;</strong></p>
<p><strong>cld</strong></p>
<p><strong>;</strong></p>
<p><strong>; Start timing.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>;</strong></p>
<p><strong>; There’s no need to draw all the images initially with</strong></p>
<p><strong>; block-move animation.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Move and redraw each image in turn REPETITIONS times.</strong></p>
<p><strong>; Redrawing automatically erases the image at the old</strong></p>
<p><strong>; location, thanks to the blank fringe.</strong></p>
<p><strong>;</strong></p>
<p><strong>MainMoveAndDrawLoop:</strong></p>
<p><strong>mov bx,offset Images ;list of images</strong></p>
<p><strong>ImageMoveLoop:</strong></p>
<p><strong>mov cx,[bx+XCoord] ;X coordinate</strong></p>
<p><strong>cmp cx,0 ;at left edge?</strong></p>
<p><strong>ja CheckRightMargin ;no</strong></p>
<p><strong>neg [bx+XInc] ;yes, so bounce</strong></p>
<p><strong>CheckRightMargin:</strong></p>
<p><strong>cmp cx,280 ;at right edge?</strong></p>
<p><strong>jb MoveX ;no</strong></p>
<p><strong>neg [bx+XInc] ;yes, so bounce</strong></p>
<p><strong>MoveX:</strong></p>
<p><strong>add cx,[bx+XInc] ;move horizontally</strong></p>
<p><strong>mov [bx+XCoord],cx ;save the new location</strong></p>
<p><strong>mov dx,[bx+YCoord] ;Y coordinate</strong></p>
<p><strong>cmp dx,0 ;at top edge?</strong></p>
<p><strong>ja CheckBottomMargin ;no</strong></p>
<p><strong>neg [bx+YInc] ;yes, so bounce</strong></p>
<p><strong>CheckBottomMargin:</strong></p>
<p><strong>cmp dx,160 ;at bottom edge?</strong></p>
<p><strong>jb MoveY ;no</strong></p>
<p><strong>neg [bx+YInc] ;yes, so bounce</strong></p>
<p><strong>MoveY:</strong></p>
<p><strong>add dx,[bx+YInc] ;move horizontally</strong></p>
<p><strong>mov [bx+YCoord],dx ;save the new location</strong></p>
<p><strong>call BlockDrawImage ;draw the image at its</strong></p>
<p><strong>; new location</strong></p>
<p><strong>add bx,size Image ;point to the next image</strong></p>
<p><strong>cmp bx,offset ImagesEnd</strong></p>
<p><strong>jb ImageMoveLoop ;move next image, if there</strong></p>
<p><strong>; is one</strong></p>
<p><strong>if DELAY</strong></p>
<p><strong>mov cx,DELAY ;slow down as specified</strong></p>
<p><strong>loop $</strong></p>
<p><strong>endif</strong></p>
<p><strong>dec [RepCount] ;animate again?</strong></p>
<p><strong>jnz MainMoveAndDrawLoop ;yes</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOff ;done timing</strong></p>
<p><strong>;</strong></p>
<p><strong>; Return to text mode.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,0003h ;AH=0 is mode select fn</strong></p>
<p><strong>;AL=3 selects mode 3,</strong></p>
<p><strong>; 80x25 text mode</strong></p>
<p><strong>int 10h ;invoke the BIOS video</strong></p>
<p><strong>; interrupt to set the mode</strong></p>
</section>
<section id="listing-12-1" class="level2">
<h2>Listing 12-1</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 12-1 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of JMP.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>jmp short $+2 ;we’ll do a short jump,</strong></p>
<p><strong>; since the next instruction</strong></p>
<p><strong>; can be reached with a</strong></p>
<p><strong>; 1-byte displacement</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-12-2" class="level2">
<h2>Listing 12-2</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 12-2 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of IMUL when used to calculate</strong></p>
<p><strong>; the 32-bit product of two 16-bit factors each with a value</strong></p>
<p><strong>; of zero.</strong></p>
<p><strong>;</strong></p>
<p><strong>sub ax,ax ;we’ll multiply zero times zero</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>imul ax</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-12-3" class="level2">
<h2>Listing 12-3</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 12-3 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of JMP when the prefetch queue</strong></p>
<p><strong>; is full when it comes time for each JMP to run.</strong></p>
<p><strong>;</strong></p>
<p><strong>sub ax,ax ;we’ll multiply zero times zero</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>imul ax ;let the prefetch queue fill</strong></p>
<p><strong>jmp short $+2 ;we’ll do a short jump,</strong></p>
<p><strong>; since the next instruction</strong></p>
<p><strong>; is less than 127 bytes</strong></p>
<p><strong>; away</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-12-4" class="level2">
<h2>Listing 12-4</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 12-4 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of JMP when 1) the prefetch queue</strong></p>
<p><strong>; is full when it comes time for each JMP to run and 2) the</strong></p>
<p><strong>; prefetch queue is allowed to fill faster than the</strong></p>
<p><strong>; instruction bytes after the JMP are requested by the EU,</strong></p>
<p><strong>; so the EU doesn’t have to wait for instruction bytes.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>push ax ;let the prefetch queue fill while</strong></p>
<p><strong>; the first instruction byte after</strong></p>
<p><strong>; each branch executes</strong></p>
<p><strong>jmp short $+2 ;we’ll do a short jump,</strong></p>
<p><strong>; since the next instruction</strong></p>
<p><strong>; is less than 127 bytes</strong></p>
<p><strong>; away</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-12-5" class="level2">
<h2>Listing 12-5</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 12-5 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of PUSH AX.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>push ax</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-1" class="level2">
<h2>Listing 13-1</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-1 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Generates the cumulative exclusive-or of all bytes in a</strong></p>
<p><strong>; 64-byte block of memory by using the LOOP instruction to</strong></p>
<p><strong>; repeat the same code 64 times.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>; The 64-byte block for which to generate the cumulative</strong></p>
<p><strong>; exclusive-or.</strong></p>
<p><strong>;</strong></p>
<p><strong>X=1</strong></p>
<p><strong>ByteArray label byte</strong></p>
<p><strong>rept 64</strong></p>
<p><strong>db X</strong></p>
<p><strong>X=X+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Generates the cumulative exclusive-or of all bytes in a</strong></p>
<p><strong>; 64-byte memory block.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; SI = pointer to start of 64-byte block for which to</strong></p>
<p><strong>; calculate cumulative exclusive-or</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; AH = cumulative exclusive-or of all bytes in the</strong></p>
<p><strong>; 64-byte block</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, CX, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>CumulativeXor:</strong></p>
<p><strong>cld</strong></p>
<p><strong>sub ah,ah ;initialize our cumulative XOR to 0</strong></p>
<p><strong>mov cx,64 ;number of bytes to XOR together</strong></p>
<p><strong>XorLoop:</strong></p>
<p><strong>lodsb ;get the next byte and</strong></p>
<p><strong>xor ah,al ; XOR it into the cumulative result</strong></p>
<p><strong>loop XorLoop</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset ByteArray</strong></p>
<p><strong>;point to the 64-byte block</strong></p>
<p><strong>call CumulativeXor ;get the cumulative XOR</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-2" class="level2">
<h2>Listing 13-2</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-2 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Generates the cumulative exclusive-or of all bytes in a</strong></p>
<p><strong>; 64-byte block of memory by replicating the exclusive-or</strong></p>
<p><strong>; code 64 times and then executing all 64 instances in a</strong></p>
<p><strong>; row without branching.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>; The 64-byte block for which to generate the cumulative</strong></p>
<p><strong>; exclusive-or.</strong></p>
<p><strong>;</strong></p>
<p><strong>X=1</strong></p>
<p><strong>ByteArray label byte</strong></p>
<p><strong>rept 64</strong></p>
<p><strong>db X</strong></p>
<p><strong>X=X+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Generates the cumulative exclusive-or of all bytes in a</strong></p>
<p><strong>; 64-byte memory block.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; SI = pointer to start of 64-byte block for which to</strong></p>
<p><strong>; calculate cumulative exclusive-or</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; AH = cumulative exclusive-or of all bytes in the</strong></p>
<p><strong>; 64-byte block</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>CumulativeXor:</strong></p>
<p><strong>sub ah,ah ;initialize our cumulative XOR to 0</strong></p>
<p><strong>rept 64</strong></p>
<p><strong>lodsb ;get the next byte and</strong></p>
<p><strong>xor ah,al ; XOR it into the cumulative result</strong></p>
<p><strong>endm</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>cld</strong></p>
<p><strong>mov si,offset ByteArray</strong></p>
<p><strong>;point to the 64-byte block</strong></p>
<p><strong>call CumulativeXor ;get the cumulative XOR</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-3" class="level2">
<h2>Listing 13-3</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-3 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Tests whether several characters are in the set</strong></p>
<p><strong>; {A,Z,3,!} by using the compare-and-jump approach,</strong></p>
<p><strong>; branching each time a match isn’t found.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>; Determines whether a given character is in the set</strong></p>
<p><strong>; {A,Z,3,!}.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = character to check for inclusion in the set</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; Z if character is in TestSet, NZ otherwise</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: none</strong></p>
<p><strong>;</strong></p>
<p><strong>CheckTestSetInclusion:</strong></p>
<p><strong>cmp al,‘A’ ;is it ‘A’?</strong></p>
<p><strong>jnz CheckTestSetZ</strong></p>
<p><strong>ret ;yes, we’re done</strong></p>
<p><strong>CheckTestSetZ:</strong></p>
<p><strong>cmp al,‘Z’ ;is it ‘Z’?</strong></p>
<p><strong>jnz CheckTestSet3</strong></p>
<p><strong>ret ;yes, we’re done</strong></p>
<p><strong>CheckTestSet3:</strong></p>
<p><strong>cmp al,‘3’ ;is it ‘3’?</strong></p>
<p><strong>jnz CheckTestSetEx</strong></p>
<p><strong>ret ;yes, we’re done</strong></p>
<p><strong>CheckTestSetEx:</strong></p>
<p><strong>cmp al,‘!’ ;is it ‘!’?</strong></p>
<p><strong>ret ;the success status is already in</strong></p>
<p><strong>; the Zero flag</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov al,‘A’</strong></p>
<p><strong>call CheckTestSetInclusion ;check ‘A’</strong></p>
<p><strong>mov al,‘Z’</strong></p>
<p><strong>call CheckTestSetInclusion ;check ‘Z’</strong></p>
<p><strong>mov al,‘3’</strong></p>
<p><strong>call CheckTestSetInclusion ;check ‘3’</strong></p>
<p><strong>mov al,‘!’</strong></p>
<p><strong>call CheckTestSetInclusion ;check ‘!’</strong></p>
<p><strong>mov al,‘’</strong></p>
<p><strong>call CheckTestSetInclusion ;check space, so</strong></p>
<p><strong>; we’ve got a failed</strong></p>
<p><strong>; search</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-4" class="level2">
<h2>Listing 13-4</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-4 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Negates several 32-bit values with non-branching code.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>; Negates a 32-bit value.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DX:AX = 32-bit value to negate</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; DX:AX = negated 32-bit value</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, DX</strong></p>
<p><strong>;</strong></p>
<p><strong>Negate32Bits:</strong></p>
<p><strong>neg dx</strong></p>
<p><strong>neg ax</strong></p>
<p><strong>sbb dx,0</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>; First, negate zero.</strong></p>
<p><strong>sub dx,dx</strong></p>
<p><strong>mov ax,dx ;0</strong></p>
<p><strong>call Negate32Bits</strong></p>
<p><strong>; Next, negate 1 through 50.</strong></p>
<p><strong>X=1</strong></p>
<p><strong>rept 50</strong></p>
<p><strong>sub dx,dx</strong></p>
<p><strong>mov ax,X</strong></p>
<p><strong>call Negate32Bits</strong></p>
<p><strong>X=X+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>; Finally, negate -1 through -50.</strong></p>
<p><strong>X=-1</strong></p>
<p><strong>rept 50</strong></p>
<p><strong>mov dx,0ffffh</strong></p>
<p><strong>mov ax,X</strong></p>
<p><strong>call Negate32Bits</strong></p>
<p><strong>X=X-1</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-5" class="level2">
<h2>Listing 13-5</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-5 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Negates several 32-bit values using the branch-on-zero-AX</strong></p>
<p><strong>; approach.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>; Negates a 32-bit value.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DX:AX = 32-bit value to negate</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; DX:AX = negated 32-bit value</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, DX</strong></p>
<p><strong>;</strong></p>
<p><strong>; ————————————————————————————————-</strong></p>
<p><strong>; Branching-out exit for Negate32Bits when AX negates to</strong></p>
<p><strong>; zero, necessitating an increment of DX.</strong></p>
<p><strong>;</strong></p>
<p><strong>Negate32BitsIncDX:</strong></p>
<p><strong>inc dx</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Negate32Bits:</strong></p>
<p><strong>not dx</strong></p>
<p><strong>neg ax</strong></p>
<p><strong>jnc Negate32BitsIncDX</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>; First, negate zero.</strong></p>
<p><strong>sub dx,dx</strong></p>
<p><strong>mov ax,dx ;0</strong></p>
<p><strong>call Negate32Bits</strong></p>
<p><strong>; Next, negate 1 through 50.</strong></p>
<p><strong>X=1</strong></p>
<p><strong>rept 50</strong></p>
<p><strong>sub dx,dx</strong></p>
<p><strong>mov ax,X</strong></p>
<p><strong>call Negate32Bits</strong></p>
<p><strong>X=X+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>; Finally, negate -1 through -50.</strong></p>
<p><strong>X=-1</strong></p>
<p><strong>rept 50</strong></p>
<p><strong>mov dx,0ffffh</strong></p>
<p><strong>mov ax,X</strong></p>
<p><strong>call Negate32Bits</strong></p>
<p><strong>X=X-1</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-6" class="level2">
<h2>Listing 13-6</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-6 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the time needed to set AL, based on the contents</strong></p>
<p><strong>; of DL, with test-and-branch code (a branch is required no</strong></p>
<p><strong>; matter what value DL contains).</strong></p>
<p><strong>;</strong></p>
<p><strong>; ———————————————————————————————————</strong></p>
<p><strong>; Macro to perform the test of DL and setting of AL.</strong></p>
<p><strong>; It’s necessary to use a macro because the LOCAL directive</strong></p>
<p><strong>; doesn’t work properly inside REPT blocks with MASM.</strong></p>
<p><strong>;</strong></p>
<p><strong>TEST_DL_AND_SET_AL macro</strong></p>
<p><strong>local DLGreaterThan10, DLCheckDone</strong></p>
<p><strong>cmp dl,10 ;is DL greater than 10?</strong></p>
<p><strong>ja DLGreaterThan10 ;yes, so set AL to 1</strong></p>
<p><strong>sub al,al ;DLis &lt;= 10</strong></p>
<p><strong>jmp short DLCheckDone</strong></p>
<p><strong>DLGreaterThan10:</strong></p>
<p><strong>mov al,1 ;DLis greater than 10</strong></p>
<p><strong>DLCheckDone:</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>mov dl,10 ;AL will always be set to 0</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>TEST_DL_AND_SET_AL</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-7" class="level2">
<h2>Listing 13-7</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-7 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the time needed to set AL, based on the contents</strong></p>
<p><strong>; of DL, with preload code (a branch is required in only one</strong></p>
<p><strong>; of the two possible cases).</strong></p>
<p><strong>;</strong></p>
<p><strong>; ——————————————————————————————————</strong></p>
<p><strong>; Macro to perform the test of DL and setting of AL.</strong></p>
<p><strong>; It’s necessary to use a macro because the LOCAL directive</strong></p>
<p><strong>; doesn’t work properly inside REPT blocks with MASM.</strong></p>
<p><strong>;</strong></p>
<p><strong>TEST_DL_AND_SET_AL macro</strong></p>
<p><strong>local DLCheckDone</strong></p>
<p><strong>sub al,al ;assume DL &lt;= 10</strong></p>
<p><strong>cmp dl,10 ;is DL greater than 10?</strong></p>
<p><strong>jbe DLCheckDone ;no, so ALis already set</strong></p>
<p><strong>mov al,1 ;DLis greater than 10</strong></p>
<p><strong>DLCheckDone:</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>mov dl,10 ;AL will always be set to 0</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>TEST_DL_AND_SET_AL</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-8" class="level2">
<h2>Listing 13-8</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-8 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Counts the number of negative values in a 1000-word array,</strong></p>
<p><strong>; by comparing each element to 0 and branching accordingly.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>WordArray label word</strong></p>
<p><strong>X=-500</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>dw X</strong></p>
<p><strong>X=X+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>WORD_ARRAY_LENGTH equ ($-WordArray)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Counts the number of negative values in a word-sized</strong></p>
<p><strong>; array.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = length of array in words</strong></p>
<p><strong>; DS:SI = pointer to start of array</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; DX = count of negative values in array</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, CX, DX, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle arrays that are longer than 32K</strong></p>
<p><strong>; words or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>CountNegativeWords:</strong></p>
<p><strong>cld</strong></p>
<p><strong>sub dx,dx ;initialize the count to 0</strong></p>
<p><strong>CountNegativeWordsLoop:</strong></p>
<p><strong>lodsw ;get the next word from the array</strong></p>
<p><strong>and ax,ax ;is the word negative?</strong></p>
<p><strong>jns CountNegativeWordsLoopBottom</strong></p>
<p><strong>;not negative-do the next element</strong></p>
<p><strong>inc dx ;word is negative, so increment the</strong></p>
<p><strong>; negative-word counter</strong></p>
<p><strong>CountNegativeWordsLoopBottom:</strong></p>
<p><strong>loop CountNegativeWordsLoop</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset WordArray</strong></p>
<p><strong>;point to the array to count</strong></p>
<p><strong>; the # of negative words in…</strong></p>
<p><strong>mov cx,WORD_ARRAY_LENGTH/2</strong></p>
<p><strong>;…set the # of words to check…</strong></p>
<p><strong>call CountNegativeWords</strong></p>
<p><strong>;…and count the negative words</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-9" class="level2">
<h2>Listing 13-9</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-9 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Counts the number of negative values in a 1000-word array,</strong></p>
<p><strong>; by adding the Sign bit of each array element directly to</strong></p>
<p><strong>; the register used for counting.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>WordArray label word</strong></p>
<p><strong>X=-500</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>dw X</strong></p>
<p><strong>X=X+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>WORD_ARRAY_LENGTH equ ($-WordArray)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Counts the number of negative values in a word-sized</strong></p>
<p><strong>; array.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = length of array in words</strong></p>
<p><strong>; DS:SI = pointer to start of array</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; DX = count of negative values in array</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, BX, CX, DX, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle arrays that are longer than 32K</strong></p>
<p><strong>; words or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>CountNegativeWords:</strong></p>
<p><strong>cld</strong></p>
<p><strong>sub dx,dx ;initialize the count to 0</strong></p>
<p><strong>mov bx,dx ;store the constant 0 in BX to speed</strong></p>
<p><strong>; up ADC in the loop</strong></p>
<p><strong>CountNegativeWordsLoop:</strong></p>
<p><strong>lodsw ;get the next word from the array</strong></p>
<p><strong>shl ax,1 ;put the sign bit in the Carry flag</strong></p>
<p><strong>adc dx,bx ;add the sign bit (via the Carry</strong></p>
<p><strong>; flag) to DX, since BX is 0</strong></p>
<p><strong>CountNegativeWordsLoopBottom:</strong></p>
<p><strong>loop CountNegativeWordsLoop</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset WordArray</strong></p>
<p><strong>;point to the array to count</strong></p>
<p><strong>; the # of negative words in…</strong></p>
<p><strong>mov cx,WORD_ARRAY_LENGTH/2</strong></p>
<p><strong>;…set the # of words to check…</strong></p>
<p><strong>call CountNegativeWords</strong></p>
<p><strong>;…and count the negative words</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-10" class="level2">
<h2>Listing 13-10</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-10 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the first occurrence of the letter ‘z’ in</strong></p>
<p><strong>; a zero-terminated string, with a less-than-ideal</strong></p>
<p><strong>; conditional jump followed by an unconditional jump at</strong></p>
<p><strong>; the end of the loop.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>TestString label byte</strong></p>
<p><strong>db ‘This is a test string that is’</strong></p>
<p><strong>db ‘z’</strong></p>
<p><strong>db ‘terminated with a zero byte…’,0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the first occurrence of the specified byte in the</strong></p>
<p><strong>; specified zero-terminated string.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = byte to find</strong></p>
<p><strong>; DS:SI = zero-terminated string to search</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; SI = pointer to first occurrence of byte in string,</strong></p>
<p><strong>; or 0 if the byte wasn’t found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Do not pass a string that starts at offset 0 (SI=0),</strong></p>
<p><strong>; since a match on the first byte and failure to find</strong></p>
<p><strong>; the byte would be indistinguishable.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>FindCharInString:</strong></p>
<p><strong>mov ah,al ;we’ll need AL since that’s the</strong></p>
<p><strong>; only register LODSB can use</strong></p>
<p><strong>cld</strong></p>
<p><strong>FindCharInStringLoop:</strong></p>
<p><strong>lodsb ;get the next string byte</strong></p>
<p><strong>cmp al,ah ;is this the byte we’re</strong></p>
<p><strong>; looking for?</strong></p>
<p><strong>jz FindCharInStringFound</strong></p>
<p><strong>;yes, so we’re done with a match</strong></p>
<p><strong>and al,al ;is this the terminating zero?</strong></p>
<p><strong>jz FindCharInStringNotFound</strong></p>
<p><strong>;yes, so we’re done with no match</strong></p>
<p><strong>jmp FindCharInStringLoop</strong></p>
<p><strong>;check the next byte</strong></p>
<p><strong>FindCharInStringFound:</strong></p>
<p><strong>dec si ;point back to the matching byte</strong></p>
<p><strong>ret</strong></p>
<p><strong>FindCharInStringNotFound:</strong></p>
<p><strong>sub si,si ;we didn’t find a match, so return</strong></p>
<p><strong>; 0 in SI</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov al,‘z’ ;byte value to find</strong></p>
<p><strong>mov si,offset TestString</strong></p>
<p><strong>;string to search</strong></p>
<p><strong>call FindCharInString ;search for the byte</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-11" class="level2">
<h2>Listing 13-11</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-11 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Determines whether there are more non-negative or negative</strong></p>
<p><strong>; elements in an array of 8-bit signed values, using a</strong></p>
<p><strong>; standard test-and-branch approach and a single LOOP</strong></p>
<p><strong>; instruction.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 256</strong></p>
<p><strong>ByteArray label byte</strong></p>
<p><strong>X=0</strong></p>
<p><strong>rept ARRAY_LENGTH</strong></p>
<p><strong>db X</strong></p>
<p><strong>X=X+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Determines whether there are more non-negative or</strong></p>
<p><strong>; negative elements in the specified array of 8-bit</strong></p>
<p><strong>; signed values.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = length of array</strong></p>
<p><strong>; DS:SI = array to check</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; DX = signed count of the number of non-negative</strong></p>
<p><strong>; elements found in the array minus the number</strong></p>
<p><strong>; of negative elements found. (Zero if there</strong></p>
<p><strong>; are the same number of each type of element.</strong></p>
<p><strong>; Otherwise, sign bit set if there are more</strong></p>
<p><strong>; negative elements than non-negative</strong></p>
<p><strong>; elements, cleared if there are more</strong></p>
<p><strong>; non-negative elements than negative</strong></p>
<p><strong>; elements)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, CX, DX, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Only usefuLif the surplus of non-negative</strong></p>
<p><strong>; elements over negative elements is less than</strong></p>
<p><strong>; 32K, or if the surplus of negative elements</strong></p>
<p><strong>; over non-negative elements is less than or</strong></p>
<p><strong>; equal to 32K. Otherwise, the signed count</strong></p>
<p><strong>; returned in DX overflows.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle arrays that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>CountNegPos:</strong></p>
<p><strong>cld</strong></p>
<p><strong>sub dx,dx ;initialize the count to zero</strong></p>
<p><strong>CountNegPosLoop:</strong></p>
<p><strong>lodsb ;get the next byte to check</strong></p>
<p><strong>and al,al ;see if it’s negative or</strong></p>
<p><strong>; non-negative</strong></p>
<p><strong>js CountNeg ;it’s negative</strong></p>
<p><strong>inc dx ;count off one non-negative element</strong></p>
<p><strong>jmp short CountNegPosLoopBottom</strong></p>
<p><strong>CountNeg:</strong></p>
<p><strong>dec dx ;count off one negative element</strong></p>
<p><strong>CountNegPosLoopBottom:</strong></p>
<p><strong>loop CountNegPosLoop</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset ByteArray ;array to check</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to check</strong></p>
<p><strong>call CountNegPos ;see whether there</strong></p>
<p><strong>; are more negative</strong></p>
<p><strong>; or non-negative</strong></p>
<p><strong>; elements</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-12" class="level2">
<h2>Listing 13-12</h2>
<p><strong>; *** Listing 13-12 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Determines whether there are more non-negative or negative</strong></p>
<p><strong>; elements in an array of 8-bit signed values, using</strong></p>
<p><strong>; duplicated code with two LOOP instructions and two RET</strong></p>
<p><strong>; instructions.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 256</strong></p>
<p><strong>ByteArray label byte</strong></p>
<p><strong>X=0</strong></p>
<p><strong>rept ARRAY_LENGTH</strong></p>
<p><strong>db X</strong></p>
<p><strong>X=X+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Determines whether there are more non-negative or</strong></p>
<p><strong>; negative elements in the specified array of 8-bit</strong></p>
<p><strong>; signed values.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = length of array</strong></p>
<p><strong>; DS:SI = array to check</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; DX = signed count of the number of non-negative</strong></p>
<p><strong>; elements found in the array minus the number</strong></p>
<p><strong>; of negative elements found. (Zero if there</strong></p>
<p><strong>; are the same number of each type of element.</strong></p>
<p><strong>; Otherwise, sign bit set if there are more</strong></p>
<p><strong>; negative elements than non-negative</strong></p>
<p><strong>; elements, cleared if there are more</strong></p>
<p><strong>; non-negative elements than negative</strong></p>
<p><strong>; elements)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, CX, DX, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Only usefuLif the surplus of non-negative</strong></p>
<p><strong>; elements over negative elements is less than</strong></p>
<p><strong>; 32K, or if the surplus of negative elements</strong></p>
<p><strong>; over non-negative elements is less than or</strong></p>
<p><strong>; equal to 32K. Otherwise, the signed count</strong></p>
<p><strong>; returned in DX overflows.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle arrays that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>CountNegPos:</strong></p>
<p><strong>cld</strong></p>
<p><strong>sub dx,dx ;initialize the count to zero</strong></p>
<p><strong>CountNegPosLoop:</strong></p>
<p><strong>lodsb ;get the next byte to check</strong></p>
<p><strong>and al,al ;see if it’s negative or</strong></p>
<p><strong>; non-negative</strong></p>
<p><strong>js CountNeg ;it’s negative</strong></p>
<p><strong>inc dx ;count off one non-negative element</strong></p>
<p><strong>loop CountNegPosLoop</strong></p>
<p><strong>ret</strong></p>
<p><strong>CountNeg:</strong></p>
<p><strong>dec dx ;count off one negative element</strong></p>
<p><strong>loop CountNegPosLoop</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset ByteArray ;array to check</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to check</strong></p>
<p><strong>call CountNegPos ;see whether there</strong></p>
<p><strong>; are more negative</strong></p>
<p><strong>; or non-negative</strong></p>
<p><strong>; elements</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-13" class="level2">
<h2>Listing 13-13</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-13 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a zero-terminated string to another string,</strong></p>
<p><strong>; optionally converting characters to uppercase. The</strong></p>
<p><strong>; decision as to whether to convert to uppercase is made</strong></p>
<p><strong>; once for each character.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>SourceString label byte</strong></p>
<p><strong>db ‘This is a sample string, consisting of’</strong></p>
<p><strong>db ‘both uppercase and lowercase characters.’</strong></p>
<p><strong>db 0</strong></p>
<p><strong>DestinationString label byte</strong></p>
<p><strong>db 100 dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a zero-terminated string to another string,</strong></p>
<p><strong>; optionally converting characters to uppercase.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DL = 1 if conversion to uppercase during copying is</strong></p>
<p><strong>; desired, 0 otherwise</strong></p>
<p><strong>; DS:SI = source string</strong></p>
<p><strong>; ES:DI = destination string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>CopyAndConvert:</strong></p>
<p><strong>cld</strong></p>
<p><strong>CopyAndConvertLoop:</strong></p>
<p><strong>lodsb ;get the next byte</strong></p>
<p><strong>; to check</strong></p>
<p><strong>and dl,dl ;conversion to</strong></p>
<p><strong>; uppercase desired?</strong></p>
<p><strong>jz CopyAndConvertUC ;no</strong></p>
<p><strong>cmp al,‘a’ ;less than ‘a’?</strong></p>
<p><strong>jb CopyAndConvertUC ;yes, not lowercase</strong></p>
<p><strong>cmp al,‘z’ ;greater than ‘z’?</strong></p>
<p><strong>ja CopyAndConvertUC ;yes, not lowercase</strong></p>
<p><strong>and al,not 20h ;make it uppercase</strong></p>
<p><strong>CopyAndConvertUC:</strong></p>
<p><strong>stosb ;put the byte in the</strong></p>
<p><strong>; destination string</strong></p>
<p><strong>and al,al ;was that the</strong></p>
<p><strong>; terminating zero?</strong></p>
<p><strong>jnz CopyAndConvertLoop ;no, do next byte</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>;</strong></p>
<p><strong>; First, copy without converting to uppercase.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov di,seg DestinationString</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset DestinationString</strong></p>
<p><strong>;ES:DI points to the destination</strong></p>
<p><strong>mov si,offset SourceString</strong></p>
<p><strong>;DS:SI points to the source</strong></p>
<p><strong>sub dl,dl ;don’t convert to uppercase</strong></p>
<p><strong>call CopyAndConvert ;copy without converting</strong></p>
<p><strong>; to uppercase</strong></p>
<p><strong>;</strong></p>
<p><strong>; Now copy and convert to uppercase.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov di,offset DestinationString</strong></p>
<p><strong>;ES:DI points to the destination</strong></p>
<p><strong>mov si,offset SourceString</strong></p>
<p><strong>;DS:SI points to the source</strong></p>
<p><strong>mov dl,1 ;convert to uppercase this time</strong></p>
<p><strong>call CopyAndConvert ;copy and convert to</strong></p>
<p><strong>; uppercase</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-14" class="level2">
<h2>Listing 13-14</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-14 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a zero-terminated string to another string,</strong></p>
<p><strong>; optionally converting characters to uppercase. The</strong></p>
<p><strong>; decision as to whether to convert to uppercase is made</strong></p>
<p><strong>; once at the beginning of the subroutine; if conversion</strong></p>
<p><strong>; is not desired, the register containing the value of the</strong></p>
<p><strong>; start of the lowercase range is simply set to cause all</strong></p>
<p><strong>; tests for lowercase to fail. This avoids one test in the</strong></p>
<p><strong>; case where conversion to uppercase is desired, since the</strong></p>
<p><strong>; single test for the start of the lowercase range is able</strong></p>
<p><strong>; to perform both that test and the test for whether</strong></p>
<p><strong>; conversion is desired.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>SourceString label byte</strong></p>
<p><strong>db ‘This is a sample string, consisting of’</strong></p>
<p><strong>db ‘both uppercase and lowercase characters.’</strong></p>
<p><strong>db 0</strong></p>
<p><strong>DestinationString label byte</strong></p>
<p><strong>db 100 dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a zero-terminated string to another string,</strong></p>
<p><strong>; optionally converting characters to uppercase.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DL = 1 if conversion to uppercase during copying is</strong></p>
<p><strong>; desired, 0 otherwise</strong></p>
<p><strong>; DS:SI = source string</strong></p>
<p><strong>; ES:DI = destination string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>CopyAndConvert:</strong></p>
<p><strong>cld</strong></p>
<p><strong>mov ah,0ffh ;assume conversion to uppercase is</strong></p>
<p><strong>; not desired. In that case, this</strong></p>
<p><strong>; value will cause the initial</strong></p>
<p><strong>; lowercase test to fail (except</strong></p>
<p><strong>; when the character is 0FFh, but</strong></p>
<p><strong>; that’s rare and will be rejected</strong></p>
<p><strong>; by the second lowercase test</strong></p>
<p><strong>and dl,dl ;is conversion to uppercase desired?</strong></p>
<p><strong>jz CopyAndConvertLoop ;no, AH is all set</strong></p>
<p><strong>mov ah,‘a’ ;set the proper lower limit of the</strong></p>
<p><strong>; lowercase range</strong></p>
<p><strong>CopyAndConvertLoop:</strong></p>
<p><strong>lodsb ;get the next byte</strong></p>
<p><strong>; to check</strong></p>
<p><strong>cmp al,ah ;less than ‘a’?</strong></p>
<p><strong>; (If conversion</strong></p>
<p><strong>; isn’t desired,</strong></p>
<p><strong>; AH is 0FFh, and</strong></p>
<p><strong>; this fails)</strong></p>
<p><strong>jb CopyAndConvertUC ;yes, not lowercase</strong></p>
<p><strong>cmp al,‘z’ ;greater than ‘z’?</strong></p>
<p><strong>ja CopyAndConvertUC ;yes, not lowercase</strong></p>
<p><strong>and al,not 20h ;make it uppercase</strong></p>
<p><strong>CopyAndConvertUC:</strong></p>
<p><strong>stosb ;put the byte in the</strong></p>
<p><strong>; destination string</strong></p>
<p><strong>and al,al ;was that the</strong></p>
<p><strong>; terminating zero?</strong></p>
<p><strong>jnz CopyAndConvertLoop ;no, do next byte</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>;</strong></p>
<p><strong>; First, copy without converting to uppercase.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov di,seg DestinationString</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset DestinationString</strong></p>
<p><strong>;ES:DI points to the destination</strong></p>
<p><strong>mov si,offset SourceString</strong></p>
<p><strong>;DS:SI points to the source</strong></p>
<p><strong>sub dl,dl ;don’t convert to uppercase</strong></p>
<p><strong>call CopyAndConvert ;copy without converting</strong></p>
<p><strong>; to uppercase</strong></p>
<p><strong>;</strong></p>
<p><strong>; Now copy and convert to uppercase.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov di,offset DestinationString</strong></p>
<p><strong>;ES:DI points to the destination</strong></p>
<p><strong>mov si,offset SourceString</strong></p>
<p><strong>;DS:SI points to the source</strong></p>
<p><strong>mov dl,1 ;convert to uppercase this time</strong></p>
<p><strong>call CopyAndConvert ;copy and convert to</strong></p>
<p><strong>; uppercase</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-15" class="level2">
<h2>Listing 13-15</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-15 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a zero-terminated string to another string,</strong></p>
<p><strong>; optionally converting characters to uppercase. The</strong></p>
<p><strong>; decision as to whether to convert to uppercase is made</strong></p>
<p><strong>; once at the beginning of the subroutine, with separate</strong></p>
<p><strong>; code executed depending on whether conversion is desired</strong></p>
<p><strong>; or not.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>SourceString label byte</strong></p>
<p><strong>db ‘This is a sample string, consisting of’</strong></p>
<p><strong>db ‘both uppercase and lowercase characters.’</strong></p>
<p><strong>db 0</strong></p>
<p><strong>DestinationString label byte</strong></p>
<p><strong>db 100 dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a zero-terminated string to another string,</strong></p>
<p><strong>; optionally converting characters to uppercase.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DL = 1 if conversion to uppercase during copying is</strong></p>
<p><strong>; desired, 0 otherwise</strong></p>
<p><strong>; DS:SI = source string</strong></p>
<p><strong>; ES:DI = destination string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>CopyAndConvert:</strong></p>
<p><strong>cld</strong></p>
<p><strong>and dl,dl ;is conversion desired?</strong></p>
<p><strong>jz CopyLoop ;no, so just copy the string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copy the string, converting to uppercase.</strong></p>
<p><strong>;</strong></p>
<p><strong>CopyAndConvertLoop:</strong></p>
<p><strong>lodsb ;get the next byte</strong></p>
<p><strong>; to check</strong></p>
<p><strong>cmp al,‘a’ ;less than ‘a’?</strong></p>
<p><strong>jb CopyAndConvertUC ;yes, not lowercase</strong></p>
<p><strong>cmp al,‘z’ ;greater than ‘z’?</strong></p>
<p><strong>ja CopyAndConvertUC ;yes, not lowercase</strong></p>
<p><strong>and al,not 20h ;make it uppercase</strong></p>
<p><strong>CopyAndConvertUC:</strong></p>
<p><strong>stosb ;put the byte in the</strong></p>
<p><strong>; destination string</strong></p>
<p><strong>and al,al ;was that the</strong></p>
<p><strong>; terminating zero?</strong></p>
<p><strong>jnz CopyAndConvertLoop ;no, do next byte</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copy the string without conversion to uppercase.</strong></p>
<p><strong>;</strong></p>
<p><strong>CopyLoop:</strong></p>
<p><strong>lodsb ;get the next byte to check</strong></p>
<p><strong>stosb ;copy the byte</strong></p>
<p><strong>and al,al ;was that the terminating 0?</strong></p>
<p><strong>jnz CopyLoop ;no, do next byte</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>;</strong></p>
<p><strong>; First, copy without converting to uppercase.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov di,seg DestinationString</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset DestinationString</strong></p>
<p><strong>;ES:DI points to the destination</strong></p>
<p><strong>mov si,offset SourceString</strong></p>
<p><strong>;DS:SI points to the source</strong></p>
<p><strong>sub dl,dl ;don’t convert to uppercase</strong></p>
<p><strong>call CopyAndConvert ;copy without converting</strong></p>
<p><strong>; to uppercase</strong></p>
<p><strong>;</strong></p>
<p><strong>; Now copy and convert to uppercase.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov di,offset DestinationString</strong></p>
<p><strong>;ES:DI points to the destination</strong></p>
<p><strong>mov si,offset SourceString</strong></p>
<p><strong>;DS:SI points to the source</strong></p>
<p><strong>mov dl,1 ;convert to uppercase this time</strong></p>
<p><strong>call CopyAndConvert ;copy and convert to</strong></p>
<p><strong>; uppercase</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-16" class="level2">
<h2>Listing 13-16</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-16 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a zero-terminated string to another string,</strong></p>
<p><strong>; filtering out non-printable characters by means of a</strong></p>
<p><strong>; subroutine that performs the test.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>SourceString label byte</strong></p>
<p><strong>db ‘This is a sample string, consisting of’</strong></p>
<p><strong>X=1</strong></p>
<p><strong>rept 31</strong></p>
<p><strong>db X</strong></p>
<p><strong>X=X+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>db 7fh</strong></p>
<p><strong>db ‘both printable and non-printable’</strong></p>
<p><strong>db ‘characters’, 0</strong></p>
<p><strong>DestinationString label byte</strong></p>
<p><strong>db 200 dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Determines whether a character is printable (in the range</strong></p>
<p><strong>; 20h through 7Eh).</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = character to check</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; Zero flag set to 1 if character is printable,</strong></p>
<p><strong>; set to 0 otherwise</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: none</strong></p>
<p><strong>;</strong></p>
<p><strong>IsPrintable:</strong></p>
<p><strong>cmp al,20h</strong></p>
<p><strong>jb IsPrintableDone ;not printable</strong></p>
<p><strong>cmp al,7eh</strong></p>
<p><strong>ja IsPrintableDone ;not printable</strong></p>
<p><strong>cmp al,al ;set the Zero flag to 1, since the</strong></p>
<p><strong>; character is printable</strong></p>
<p><strong>IsPrintableDone:</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a zero-terminated string to another string,</strong></p>
<p><strong>; filtering out non-printable characters.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DS:SI = source string</strong></p>
<p><strong>; ES:DI = destination string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>CopyPrintable:</strong></p>
<p><strong>cld</strong></p>
<p><strong>CopyPrintableLoop:</strong></p>
<p><strong>lodsb ;get the next byte to copy</strong></p>
<p><strong>call IsPrintable ;is it printable?</strong></p>
<p><strong>jnz NotPrintable ;nope, don’t copy it</strong></p>
<p><strong>stosb ;put the byte in the</strong></p>
<p><strong>; destination string</strong></p>
<p><strong>jmp CopyPrintableLoop ;the character was</strong></p>
<p><strong>; printable, so it couldn’t</strong></p>
<p><strong>; possibly have been 0. No</strong></p>
<p><strong>; need to check whether it</strong></p>
<p><strong>; terminated the string</strong></p>
<p><strong>NotPrintable:</strong></p>
<p><strong>and al,al ;was that the</strong></p>
<p><strong>; terminating zero?</strong></p>
<p><strong>jnz CopyPrintableLoop ;no, do next byte</strong></p>
<p><strong>stosb ;copy the terminating zero</strong></p>
<p><strong>ret ;done</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov di,seg DestinationString</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset DestinationString</strong></p>
<p><strong>;ES:DI points to the destination</strong></p>
<p><strong>mov si,offset SourceString</strong></p>
<p><strong>;DS:SI points to the source</strong></p>
<p><strong>call CopyPrintable ;copy the printable</strong></p>
<p><strong>; characters</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-17" class="level2">
<h2>Listing 13-17</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-17 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a zero-terminated string to another string,</strong></p>
<p><strong>; filtering out non-printable characters by means of a</strong></p>
<p><strong>; macro that performs the test.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>SourceString label byte</strong></p>
<p><strong>db ‘This is a sample string, consisting of’</strong></p>
<p><strong>X=1</strong></p>
<p><strong>rept 31</strong></p>
<p><strong>db X</strong></p>
<p><strong>X=X+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>db 7fh</strong></p>
<p><strong>db ‘both printable and non-printable’</strong></p>
<p><strong>db ‘characters’, 0</strong></p>
<p><strong>DestinationString label byte</strong></p>
<p><strong>db 200 dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro that determines whether a character is printable (in</strong></p>
<p><strong>; the range 20h through 7Eh).</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = character to check</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; Zero flag set to 1 if character is printable,</strong></p>
<p><strong>; set to 0 otherwise</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: none</strong></p>
<p><strong>;</strong></p>
<p><strong>IS_PRINTABLE macro</strong></p>
<p><strong>local IsPrintableDone</strong></p>
<p><strong>cmp al,20h</strong></p>
<p><strong>jb IsPrintableDone ;not printable</strong></p>
<p><strong>cmp al,7eh</strong></p>
<p><strong>ja IsPrintableDone ;not printable</strong></p>
<p><strong>cmp al,al ;set the Zero flag to 1, since the</strong></p>
<p><strong>; character is printable</strong></p>
<p><strong>IsPrintableDone:</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a zero-terminated string to another string,</strong></p>
<p><strong>; filtering out non-printable characters.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DS:SI = source string</strong></p>
<p><strong>; ES:DI = destination string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>CopyPrintable:</strong></p>
<p><strong>cld</strong></p>
<p><strong>CopyPrintableLoop:</strong></p>
<p><strong>lodsb ;get the next byte to copy</strong></p>
<p><strong>IS_PRINTABLE ;is it printable?</strong></p>
<p><strong>jnz NotPrintable ;nope, don’t copy it</strong></p>
<p><strong>stosb ;put the byte in the</strong></p>
<p><strong>; destination string</strong></p>
<p><strong>jmp CopyPrintableLoop ;the character was</strong></p>
<p><strong>; printable, so it couldn’t</strong></p>
<p><strong>; possibly have been 0. No</strong></p>
<p><strong>; need to check whether it</strong></p>
<p><strong>; terminated the string</strong></p>
<p><strong>NotPrintable:</strong></p>
<p><strong>and al,al ;was that the</strong></p>
<p><strong>; terminating zero?</strong></p>
<p><strong>jnz CopyPrintableLoop ;no, do next byte</strong></p>
<p><strong>stosb ;copy the terminating zero</strong></p>
<p><strong>ret ;done</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov di,seg DestinationString</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset DestinationString</strong></p>
<p><strong>;ES:DI points to the destination</strong></p>
<p><strong>mov si,offset SourceString</strong></p>
<p><strong>;DS:SI points to the source</strong></p>
<p><strong>call CopyPrintable ;copy the printable</strong></p>
<p><strong>; characters</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-18" class="level2">
<h2>Listing 13-18</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-18 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a zero-terminated string to another string,</strong></p>
<p><strong>; filtering out non-printable characters by means of</strong></p>
<p><strong>; carefully customized code that performs the test</strong></p>
<p><strong>; directly in the loop.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>SourceString label byte</strong></p>
<p><strong>db ‘This is a sample string, consisting of’</strong></p>
<p><strong>X=1</strong></p>
<p><strong>rept 31</strong></p>
<p><strong>db X</strong></p>
<p><strong>X=X+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>db 7fh</strong></p>
<p><strong>db ‘both printable and non-printable’</strong></p>
<p><strong>db ‘characters’, 0</strong></p>
<p><strong>DestinationString label byte</strong></p>
<p><strong>db 200 dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a zero-terminated string to another string,</strong></p>
<p><strong>; filtering out non-printable characters.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DS:SI = source string</strong></p>
<p><strong>; ES:DI = destination string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>CopyPrintable:</strong></p>
<p><strong>cld</strong></p>
<p><strong>CopyPrintableLoop:</strong></p>
<p><strong>lodsb ;get the next byte to copy</strong></p>
<p><strong>cmp al,20h</strong></p>
<p><strong>jb NotPrintable ;not printable</strong></p>
<p><strong>cmp al,7eh</strong></p>
<p><strong>ja CopyPrintableLoop ;not printable</strong></p>
<p><strong>stosb ;put the byte in the</strong></p>
<p><strong>; destination string</strong></p>
<p><strong>jmp CopyPrintableLoop ;the character was</strong></p>
<p><strong>; printable, so it couldn’t</strong></p>
<p><strong>; possibly have been 0. No</strong></p>
<p><strong>; need to check whether it</strong></p>
<p><strong>; terminated the string</strong></p>
<p><strong>NotPrintable:</strong></p>
<p><strong>and al,al ;was that the</strong></p>
<p><strong>; terminating zero?</strong></p>
<p><strong>jnz CopyPrintableLoop ;no, do next byte</strong></p>
<p><strong>stosb ;copy the terminating zero</strong></p>
<p><strong>ret ;done</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov di,seg DestinationString</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset DestinationString</strong></p>
<p><strong>;ES:DI points to the destination</strong></p>
<p><strong>mov si,offset SourceString</strong></p>
<p><strong>;DS:SI points to the source</strong></p>
<p><strong>call CopyPrintable ;copy the printable</strong></p>
<p><strong>; characters</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-19" class="level2">
<h2>Listing 13-19</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-19 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Zeros the high-bit of each byte in a 100-byte array,</strong></p>
<p><strong>; using the LOOP instruction.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 100</strong></p>
<p><strong>ByteArray label byte</strong></p>
<p><strong>db ARRAY_LENGTH dup (80h)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Clears the high bit of each byte in an array of</strong></p>
<p><strong>; length ARRAY_LENGTH.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; BX = pointer to the start of the array to clear</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, BX, CX</strong></p>
<p><strong>;</strong></p>
<p><strong>ClearHighBits:</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to clear</strong></p>
<p><strong>mov al,not 80h ;pattern to clear</strong></p>
<p><strong>; high bits with</strong></p>
<p><strong>ClearHighBitsLoop:</strong></p>
<p><strong>and [bx],al ;clear the high bit</strong></p>
<p><strong>; of this byte</strong></p>
<p><strong>inc bx ;point to the next</strong></p>
<p><strong>; byte</strong></p>
<p><strong>loop ClearHighBitsLoop ;repeat until we’re</strong></p>
<p><strong>; out of bytes</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov bx,offset ByteArray</strong></p>
<p><strong>;array in which to clear</strong></p>
<p><strong>; high bits</strong></p>
<p><strong>call ClearHighBits ;clear the high bits of the</strong></p>
<p><strong>; bytes</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-20" class="level2">
<h2>Listing 13-20</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-20 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Zeros the high-bit of each byte in a 100-byte array,</strong></p>
<p><strong>; using in-line code.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 100</strong></p>
<p><strong>ByteArray label byte</strong></p>
<p><strong>db ARRAY_LENGTH dup (80h)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Clears the high bit of each byte in an array of</strong></p>
<p><strong>; length ARRAY_LENGTH.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; BX = pointer to the start of the array to clear</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, BX</strong></p>
<p><strong>;</strong></p>
<p><strong>ClearHighBits:</strong></p>
<p><strong>mov al,not 80h ;pattern to clear</strong></p>
<p><strong>; high bits with</strong></p>
<p><strong>rept ARRAY_LENGTH ;# of bytes to clear</strong></p>
<p><strong>and [bx],al ;clear the high bit</strong></p>
<p><strong>; of this byte</strong></p>
<p><strong>inc bx ;point to the next</strong></p>
<p><strong>; byte</strong></p>
<p><strong>endm</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov bx,offset ByteArray</strong></p>
<p><strong>;array in which to clear</strong></p>
<p><strong>; high bits</strong></p>
<p><strong>call ClearHighBits ;clear the high bits of the</strong></p>
<p><strong>; bytes</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-21" class="level2">
<h2>Listing 13-21</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-21 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Replacement code for XorImage in Listing 11-33.</strong></p>
<p><strong>; This version uses in-line code to eliminate branching</strong></p>
<p><strong>; during the drawing of each image line.</strong></p>
<p><strong>;—————————–</strong></p>
<p><strong>; Exclusive-ors the image of a 3-color square at the</strong></p>
<p><strong>; specified screen location. Assumes images start on</strong></p>
<p><strong>; even-numbered scan lines and are an even number of</strong></p>
<p><strong>; scan lines high. Always draws images byte-aligned in</strong></p>
<p><strong>; display memory.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = X coordinate of upper left corner at which to</strong></p>
<p><strong>; draw image (will be adjusted to nearest</strong></p>
<p><strong>; less-than or equal-to multiple of 4 in order</strong></p>
<p><strong>; to byte-align)</strong></p>
<p><strong>; DX = Y coordinate of upper left corner at which to</strong></p>
<p><strong>; draw image</strong></p>
<p><strong>; ES = display memory segment</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, CX, DX, SI, DI, BP</strong></p>
<p><strong>;</strong></p>
<p><strong>XorImage:</strong></p>
<p><strong>shr dx,1 ;divide the row # by 2 to compensate</strong></p>
<p><strong>; for the 2-bank nature of 320x200</strong></p>
<p><strong>; 4-color mode</strong></p>
<p><strong>mov ax,SCREEN_WIDTH</strong></p>
<p><strong>mul dx ;start offset of top row of image in</strong></p>
<p><strong>; display memory</strong></p>
<p><strong>shr cx,1 ;divide the X coordinate by 4</strong></p>
<p><strong>shr cx,1 ; because there are 4 pixels per</strong></p>
<p><strong>; byte</strong></p>
<p><strong>add ax,cx ;point to the offset at which the</strong></p>
<p><strong>; upper left byte of the image will</strong></p>
<p><strong>; go</strong></p>
<p><strong>mov di,ax</strong></p>
<p><strong>mov si,offset TheImage</strong></p>
<p><strong>;point to the start of the one image</strong></p>
<p><strong>; we always draw</strong></p>
<p><strong>mov dx,BANK_OFFSET-IMAGE_WIDTH</strong></p>
<p><strong>;offset from the end of an even line</strong></p>
<p><strong>; of the image in display memory to</strong></p>
<p><strong>; the start of the next odd line of</strong></p>
<p><strong>; the image</strong></p>
<p><strong>mov bp,BANK_OFFSET-SCREEN_WIDTH+IMAGE_WIDTH</strong></p>
<p><strong>;offset from the end of an odd line</strong></p>
<p><strong>; of the image in display memory to</strong></p>
<p><strong>; the start of the next even line of</strong></p>
<p><strong>; the image</strong></p>
<p><strong>mov cx,IMAGE_HEIGHT/2</strong></p>
<p><strong>;# of even/odd numbered row pairs to</strong></p>
<p><strong>; draw in the image</strong></p>
<p><strong>XorRowLoop:</strong></p>
<p><strong>rept IMAGE_WIDTH/2</strong></p>
<p><strong>lodsw ;next word of the image pattern</strong></p>
<p><strong>xor es:[di],ax ;XOR the next word of the</strong></p>
<p><strong>; image into the screen</strong></p>
<p><strong>inc di ;point to the next word in display</strong></p>
<p><strong>inc di ; memory</strong></p>
<p><strong>endm</strong></p>
<p><strong>add di,dx ;point to the start of the next</strong></p>
<p><strong>; (odd) row of the image, which is</strong></p>
<p><strong>; in the second bank of display</strong></p>
<p><strong>; memory</strong></p>
<p><strong>rept IMAGE_WIDTH/2</strong></p>
<p><strong>lodsw ;next word of the image pattern</strong></p>
<p><strong>xor es:[di],ax ;XOR the next word of the</strong></p>
<p><strong>; image into the screen</strong></p>
<p><strong>inc di ;point to the next word in display</strong></p>
<p><strong>inc di ; memory</strong></p>
<p><strong>endm</strong></p>
<p><strong>sub di,bp ;point to the start of the next</strong></p>
<p><strong>; (even) row of the image, which is</strong></p>
<p><strong>; in the first bank of display</strong></p>
<p><strong>; memory</strong></p>
<p><strong>loop XorRowLoop ;count down the row pairs</strong></p>
<p><strong>ret</strong></p>
</section>
<section id="listing-13-22" class="level2">
<h2>Listing 13-22</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-22 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Replacement code for BlockDrawImage in Listing 11-34.</strong></p>
<p><strong>; This version uses in-line code to eliminate branching</strong></p>
<p><strong>; entirely during the drawing of each image (eliminates</strong></p>
<p><strong>; the branching between the drawing of each pair of lines.)</strong></p>
<p><strong>;—————————–</strong></p>
<p><strong>; Block-move draws the image of a 3-color square at the</strong></p>
<p><strong>; specified screen location. Assumes images start on</strong></p>
<p><strong>; even-numbered scan lines and are an even number of</strong></p>
<p><strong>; scan lines high. Always draws images byte-aligned in</strong></p>
<p><strong>; display memory.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; CX = X coordinate of upper left corner at which to</strong></p>
<p><strong>; draw image (will be adjusted to nearest</strong></p>
<p><strong>; less-than or equal-to multiple of 4 in order</strong></p>
<p><strong>; to byte-align)</strong></p>
<p><strong>; DX = Y coordinate of upper left corner at which to</strong></p>
<p><strong>; draw image</strong></p>
<p><strong>; ES = display memory segment</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, CX, DX, SI, DI, BP</strong></p>
<p><strong>;</strong></p>
<p><strong>BlockDrawImage:</strong></p>
<p><strong>shr dx,1 ;divide the row # by 2 to compensate</strong></p>
<p><strong>; for the 2-bank nature of 320x200</strong></p>
<p><strong>; 4-color mode</strong></p>
<p><strong>mov ax,SCREEN_WIDTH</strong></p>
<p><strong>mul dx ;start offset of top row of image in</strong></p>
<p><strong>; display memory</strong></p>
<p><strong>shr cx,1 ;divide the X coordinate by 4</strong></p>
<p><strong>shr cx,1 ; because there are 4 pixels per</strong></p>
<p><strong>; byte</strong></p>
<p><strong>add ax,cx ;point to the offset at which the</strong></p>
<p><strong>; upper left byte of the image will</strong></p>
<p><strong>; go</strong></p>
<p><strong>mov di,ax</strong></p>
<p><strong>mov si,offset TheImage</strong></p>
<p><strong>;point to the start of the one image</strong></p>
<p><strong>; we always draw</strong></p>
<p><strong>mov ax,BANK_OFFSET-SCREEN_WIDTH+IMAGE_WIDTH</strong></p>
<p><strong>;offset from the end of an odd line</strong></p>
<p><strong>; of the image in display memory to</strong></p>
<p><strong>; the start of the next even line of</strong></p>
<p><strong>; the image</strong></p>
<p><strong>mov dx,BANK_OFFSET-IMAGE_WIDTH</strong></p>
<p><strong>;offset from the end of an even line</strong></p>
<p><strong>; of the image in display memory to</strong></p>
<p><strong>; the start of the next odd line of</strong></p>
<p><strong>; the image</strong></p>
<p><strong>mov bp,IMAGE_WIDTH/2</strong></p>
<p><strong>;# of words to draw per row of the</strong></p>
<p><strong>; image. Note that IMAGE_WIDTH must</strong></p>
<p><strong>; be an even number since we XOR</strong></p>
<p><strong>; the image a word at a time</strong></p>
<p><strong>rept IMAGE_HEIGHT/2</strong></p>
<p><strong>mov cx,bp ;# of words to draw per row of the</strong></p>
<p><strong>; image</strong></p>
<p><strong>rep movsw ;draw a whole even row with this one</strong></p>
<p><strong>; repeated instruction</strong></p>
<p><strong>add di,dx ;point to the start of the next</strong></p>
<p><strong>; (odd) row of the image, which is</strong></p>
<p><strong>; in the second bank of display</strong></p>
<p><strong>; memory</strong></p>
<p><strong>mov cx,bp ;# of words to draw per row of the</strong></p>
<p><strong>; image</strong></p>
<p><strong>rep movsw ;draw a whole odd row with this one</strong></p>
<p><strong>; repeated instruction</strong></p>
<p><strong>sub di,ax</strong></p>
<p><strong>;point to the start of the next</strong></p>
<p><strong>; (even) row of the image, which is</strong></p>
<p><strong>; in the first bank of display</strong></p>
<p><strong>; memory</strong></p>
<p><strong>endm</strong></p>
<p><strong>ret</strong></p>
</section>
<section id="listing-13-23" class="level2">
<h2>Listing 13-23</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-23 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Zeros the high-bit of each byte in a 100-byte array,</strong></p>
<p><strong>; using branched-to in-line code.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>MAXIMUM_ARRAY_LENGTH equ 200</strong></p>
<p><strong>ARRAY_LENGTH equ 100</strong></p>
<p><strong>ByteArray label byte</strong></p>
<p><strong>db ARRAY_LENGTH dup (80h)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Clears the high bit of each byte in an array.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; BX = pointer to the start of the array to clear</strong></p>
<p><strong>; CX = number of bytes to clear (no greater than</strong></p>
<p><strong>; MAXIMUM_ARRAY_LENGTH)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, BX, CX</strong></p>
<p><strong>;</strong></p>
<p><strong>ClearHighBits:</strong></p>
<p><strong>;</strong></p>
<p><strong>; Calculate the offset in the in-line code to which to jump</strong></p>
<p><strong>; in order to get the desired number of repetitions.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,InLineBitClearEnd-SingleRepetitionStart</strong></p>
<p><strong>;# of bytes per single</strong></p>
<p><strong>; repetition of</strong></p>
<p><strong>; AND [BX],AL/INC BX</strong></p>
<p><strong>mul cl ;# of code bytes in the # of</strong></p>
<p><strong>; repetitions desired</strong></p>
<p><strong>mov cx,offset InLineBitClearEnd</strong></p>
<p><strong>sub cx,ax ;point back just enough</strong></p>
<p><strong>; instruction bytes from</strong></p>
<p><strong>; the end of the in-line</strong></p>
<p><strong>; code to perform the</strong></p>
<p><strong>; desired # of repetitions</strong></p>
<p><strong>mov al,not 80h ;pattern to clear high bits</strong></p>
<p><strong>; with</strong></p>
<p><strong>jmp cx ;finally, branch to perform</strong></p>
<p><strong>; the desired # of</strong></p>
<p><strong>; repetitions</strong></p>
<p><strong>;</strong></p>
<p><strong>; In-line code to clear the high bits of up to the maximum #</strong></p>
<p><strong>; of bytes.</strong></p>
<p><strong>;</strong></p>
<p><strong>rept MAXIMUM_ARRAY_LENGTH-1</strong></p>
<p><strong>;maximum # of bytes to clear</strong></p>
<p><strong>; less 1</strong></p>
<p><strong>and [bx],al ;clear the high bit of this</strong></p>
<p><strong>; byte</strong></p>
<p><strong>inc bx ;point to the next byte</strong></p>
<p><strong>endm</strong></p>
<p><strong>SingleRepetitionStart: ;a single repetition of the</strong></p>
<p><strong>; loop code, so we can</strong></p>
<p><strong>; calculate the length of</strong></p>
<p><strong>; a single repetition</strong></p>
<p><strong>and [bx],dl ;clear the high bit of this</strong></p>
<p><strong>; byte</strong></p>
<p><strong>inc bx ;point to the next byte</strong></p>
<p><strong>InLineBitClearEnd:</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov bx,offset ByteArray</strong></p>
<p><strong>;array in which to clear</strong></p>
<p><strong>; high bits</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to clear</strong></p>
<p><strong>; (always less than</strong></p>
<p><strong>; MAXIMUM_ARRAY_LENGTH)</strong></p>
<p><strong>call ClearHighBits ;clear the high bits of the</strong></p>
<p><strong>; bytes</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-24" class="level2">
<h2>Listing 13-24</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-24 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Zeros the high-bit of each byte in a 100-byte array,</strong></p>
<p><strong>; using partiaLin-line code.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 100</strong></p>
<p><strong>ByteArray label byte</strong></p>
<p><strong>db ARRAY_LENGTH dup (80h)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Clears the high bit of each byte in an array.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; BX = pointer to the start of the array to clear</strong></p>
<p><strong>; CX = number of bytes to clear (must be a multiple</strong></p>
<p><strong>; of 4)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, BX, CX</strong></p>
<p><strong>;</strong></p>
<p><strong>ClearHighBits:</strong></p>
<p><strong>mov al,not 80h ;pattern to clear</strong></p>
<p><strong>; high bits with</strong></p>
<p><strong>shr cx,1 ;# of passes through</strong></p>
<p><strong>shr cx,1 ; partiaLin-line</strong></p>
<p><strong>; loop, which does</strong></p>
<p><strong>; 4 bytes at a pop</strong></p>
<p><strong>ClearHighBitsLoop:</strong></p>
<p><strong>rept 4 ;we’ll put 4 bit-</strong></p>
<p><strong>; clears back to</strong></p>
<p><strong>; back, then loop</strong></p>
<p><strong>and [bx],al ;clear the high bit</strong></p>
<p><strong>; of this byte</strong></p>
<p><strong>inc bx ;point to the next</strong></p>
<p><strong>; byte</strong></p>
<p><strong>endm</strong></p>
<p><strong>loop ClearHighBitsLoop</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov bx,offset ByteArray</strong></p>
<p><strong>;array in which to clear</strong></p>
<p><strong>; high bits</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to clear</strong></p>
<p><strong>; (always a multiple of 4)</strong></p>
<p><strong>call ClearHighBits ;clear the high bits of the</strong></p>
<p><strong>; bytes</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-25" class="level2">
<h2>Listing 13-25</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-25 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Zeros the high-bit of each byte in a 100-byte array,</strong></p>
<p><strong>; using branched-to partiaLin-line code.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ARRAY_LENGTH equ 100</strong></p>
<p><strong>ByteArray label byte</strong></p>
<p><strong>db ARRAY_LENGTH dup (80h)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Clears the high bit of each byte in an array.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; BX = pointer to the start of the array to clear</strong></p>
<p><strong>; CX = number of bytes to clear (0 means 0)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, BX, CX, DX</strong></p>
<p><strong>;</strong></p>
<p><strong>ClearHighBits:</strong></p>
<p><strong>;</strong></p>
<p><strong>; Calculate the offset in the partiaLin-line code to which</strong></p>
<p><strong>; to jump in order to perform CX modulo 4 repetitions (the</strong></p>
<p><strong>; remaining repetitions will be handled by full passes</strong></p>
<p><strong>; through the loop).</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,cx</strong></p>
<p><strong>and ax,3 ;# of repetitions modulo 4</strong></p>
<p><strong>mov dx,ax</strong></p>
<p><strong>shl ax,1</strong></p>
<p><strong>add ax,dx ;(# of reps modulo 4) * 3</strong></p>
<p><strong>; is the # of bytes from the</strong></p>
<p><strong>; the end of the partial</strong></p>
<p><strong>; in-line code to branch to</strong></p>
<p><strong>; in order to handle the</strong></p>
<p><strong>; # of repetitions that</strong></p>
<p><strong>; can’t be handled in a full</strong></p>
<p><strong>; loop</strong></p>
<p><strong>mov dx,offset InLineBitClearEnd</strong></p>
<p><strong>sub dx,ax ;point back just enough</strong></p>
<p><strong>; instruction bytes from</strong></p>
<p><strong>; the end of the in-line</strong></p>
<p><strong>; code to perform the</strong></p>
<p><strong>; desired # of repetitions</strong></p>
<p><strong>shr cx,1 ;divide by 4, since we’ll do</strong></p>
<p><strong>shr cx,1 ; 4 repetitions per loop</strong></p>
<p><strong>inc cx ;account for the first,</strong></p>
<p><strong>; partial pass through the</strong></p>
<p><strong>; loop</strong></p>
<p><strong>mov al,not 80h ;pattern to clear high bits</strong></p>
<p><strong>; with</strong></p>
<p><strong>jmp dx ;finally, branch to perform</strong></p>
<p><strong>; the desired # of</strong></p>
<p><strong>; repetitions</strong></p>
<p><strong>;</strong></p>
<p><strong>; PartiaLin-line code to clear the high bits of 4 bytes per</strong></p>
<p><strong>; pass through the loop.</strong></p>
<p><strong>;</strong></p>
<p><strong>ClearHighBitsLoop:</strong></p>
<p><strong>rept 4</strong></p>
<p><strong>and [bx],al ;clear the high bit of this</strong></p>
<p><strong>; byte</strong></p>
<p><strong>inc bx ;point to the next byte</strong></p>
<p><strong>endm</strong></p>
<p><strong>InLineBitClearEnd:</strong></p>
<p><strong>loop ClearHighBitsLoop</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov bx,offset ByteArray</strong></p>
<p><strong>;array in which to clear</strong></p>
<p><strong>; high bits</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to clear</strong></p>
<p><strong>; (always less than</strong></p>
<p><strong>; MAXIMUM_ARRAY_LENGTH)</strong></p>
<p><strong>call ClearHighBits ;clear the high bits of the</strong></p>
<p><strong>; bytes</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-13-26" class="level2">
<h2>Listing 13-26</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-26 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Replacement code for ClearHighBits in Listing 13-25.</strong></p>
<p><strong>; This version performs 64K rather than 0 repetitions</strong></p>
<p><strong>; when CX is 0.</strong></p>
<p><strong>;—————————–</strong></p>
<p><strong>; Clears the high bit of each byte in an array.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; BX = pointer to the start of the array to clear</strong></p>
<p><strong>; CX = number of bytes to clear (0 means 64K)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, BX, CX, DX</strong></p>
<p><strong>;</strong></p>
<p><strong>ClearHighBits:</strong></p>
<p><strong>;</strong></p>
<p><strong>; Calculate the offset in the partiaLin-line code to which</strong></p>
<p><strong>; to jump in order to perform CX modulo 4 repetitions (the</strong></p>
<p><strong>; remaining repetitions will be handled by full passes</strong></p>
<p><strong>; through the loop).</strong></p>
<p><strong>;</strong></p>
<p><strong>dec cx ;# of reps -1, since 1 to 4</strong></p>
<p><strong>; (rather than 0 to 3) repetitions</strong></p>
<p><strong>; are performed on the first,</strong></p>
<p><strong>; possibly partial pass through</strong></p>
<p><strong>; the loop</strong></p>
<hr />
<p><strong>mov ax,cx</strong></p>
<p><strong>and ax,3 ;# of repetitions modulo 4</strong></p>
<p><strong>inc ax ;(# of reps modulo 4)+1 in order to</strong></p>
<p><strong>; perform 1 to 4 repetitions on the</strong></p>
<p><strong>; first, possibly partial pass</strong></p>
<p><strong>; through the loop</strong></p>
<p><strong>mov dx,ax</strong></p>
<p><strong>shl ax,1</strong></p>
<p><strong>add ax,dx ;(((# of reps -1) modulo 4)+1)*3</strong></p>
<p><strong>; is the # of bytes from the</strong></p>
<p><strong>; the end of the partial</strong></p>
<p><strong>; in-line code to branch to</strong></p>
<p><strong>; in order to handle the</strong></p>
<p><strong>; # of repetitions that</strong></p>
<p><strong>; must be handled in the</strong></p>
<p><strong>; first, possibly partial</strong></p>
<p><strong>; loop</strong></p>
<p><strong>mov dx,offset InLineBitClearEnd</strong></p>
<p><strong>sub dx,ax ;point back just enough</strong></p>
<p><strong>; instruction bytes from</strong></p>
<p><strong>; the end of the in-line</strong></p>
<p><strong>; code to perform the</strong></p>
<p><strong>; desired # of repetitions</strong></p>
<p><strong>shr cx,1 ;divide by 4, since we’ll do</strong></p>
<p><strong>shr cx,1 ; 4 repetitions per loop</strong></p>
<p><strong>inc cx ;account for the first,</strong></p>
<p><strong>; possibly partial pass</strong></p>
<p><strong>; through the loop</strong></p>
<p><strong>mov al,not 80h</strong></p>
<p><strong>;pattern with which to clear</strong></p>
<p><strong>; high bits</strong></p>
<p><strong>jmp dx ;finally, branch to perform</strong></p>
<p><strong>; the desired # of repetitions</strong></p>
<p><strong>;</strong></p>
<p><strong>; PartiaLin-line code to clear the high bits of 4 bytes per</strong></p>
<p><strong>; pass through the loop.</strong></p>
<p><strong>;</strong></p>
<p><strong>ClearHighBitsLoop:</strong></p>
<p><strong>rept 4</strong></p>
<p><strong>and [bx],al ;clear the high bit of this</strong></p>
<p><strong>; byte</strong></p>
<p><strong>inc bx ;point to the next byte</strong></p>
<p><strong>endm</strong></p>
<p><strong>InLineBitClearEnd:</strong></p>
<p><strong>loop ClearHighBitsLoop</strong></p>
<p><strong>ret</strong></p>
</section>
<section id="listing-13-27" class="level2">
<h2>Listing 13-27</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 13-27 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Determines whether two zero-terminated strings differ, and</strong></p>
<p><strong>; if so where, using LODS/SCAS and partiaLin-line code.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>TestString1 label byte</strong></p>
<p><strong>db ‘This is a test string that is’</strong></p>
<p><strong>db ‘z’</strong></p>
<p><strong>db ‘terminated with a zero byte…’,0</strong></p>
<p><strong>TestString2 label byte</strong></p>
<p><strong>db ‘This is a test string that is’</strong></p>
<p><strong>db ‘a’</strong></p>
<p><strong>db ‘terminated with a zero byte…’,0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Compares two zero-terminated strings.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DS:SI = first zero-terminated string</strong></p>
<p><strong>; ES:DI = second zero-terminated string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; DS:SI = pointer to first differing location in</strong></p>
<p><strong>; first string, or 0 if the byte wasn’t found</strong></p>
<p><strong>; ES:DI = pointer to first differing location in</strong></p>
<p><strong>; second string, or 0 if the byte wasn’t found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>CompareStrings:</strong></p>
<p><strong>cld</strong></p>
<p><strong>CompareStringsLoop:</strong></p>
<p><strong>;</strong></p>
<p><strong>; First 7 repetitions of partiaLin-line code.</strong></p>
<p><strong>;</strong></p>
<p><strong>rept 7</strong></p>
<p><strong>lodsw ;get the next 2 bytes</strong></p>
<p><strong>and al,al ;is the first byte the terminating</strong></p>
<p><strong>; zero?</strong></p>
<p><strong>jz CompareStringsFinalByte</strong></p>
<p><strong>;yes, so there’s only one byte left</strong></p>
<p><strong>; to check</strong></p>
<p><strong>scasw ;compare this word</strong></p>
<p><strong>jnz CompareStringsDifferent ;the strings differ</strong></p>
<p><strong>and ah,ah ;is the second byte the terminating</strong></p>
<p><strong>; zero?</strong></p>
<p><strong>jz CompareStringsSame</strong></p>
<p><strong>;yes, we’ve got a match</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Final repetition of partiaLin-line code.</strong></p>
<p><strong>;</strong></p>
<p><strong>lodsw ;get the next 2 bytes</strong></p>
<p><strong>and al,al ;is the first byte the terminating</strong></p>
<p><strong>; zero?</strong></p>
<p><strong>jz CompareStringsFinalByte</strong></p>
<p><strong>;yes, so there’s only one byte left</strong></p>
<p><strong>; to check</strong></p>
<p><strong>scasw ;compare this word</strong></p>
<p><strong>jnz CompareStringsDifferent ;the strings differ</strong></p>
<p><strong>and ah,ah ;is the second byte the terminating</strong></p>
<p><strong>; zero?</strong></p>
<p><strong>jnz CompareStringsLoop ;no, continue comparing</strong></p>
<p><strong>;the strings are the same</strong></p>
<p><strong>CompareStringsSame:</strong></p>
<p><strong>sub si,si ;return 0 pointers indicating that</strong></p>
<p><strong>mov di,si ; the strings are identical</strong></p>
<p><strong>ret</strong></p>
<p><strong>CompareStringsFinalByte:</strong></p>
<p><strong>scasb ;does the terminating zero match in</strong></p>
<p><strong>; the 2 strings?</strong></p>
<p><strong>jz CompareStringsSame ;yes, the strings match</strong></p>
<p><strong>dec si ;point back to the differing byte</strong></p>
<p><strong>dec di ; in each string</strong></p>
<p><strong>ret</strong></p>
<p><strong>CompareStringsDifferent:</strong></p>
<p><strong>;the strings are different, so we</strong></p>
<p><strong>; have to figure which byte in the</strong></p>
<p><strong>; word just compared was the first</strong></p>
<p><strong>; difference</strong></p>
<p><strong>dec si</strong></p>
<p><strong>dec si ;point back to the first byte of the</strong></p>
<p><strong>dec di ; differing word in each string</strong></p>
<p><strong>dec di</strong></p>
<p><strong>lodsb</strong></p>
<p><strong>scasb ;compare that first byte again</strong></p>
<p><strong>jz CompareStringsDone</strong></p>
<p><strong>;if the first bytes are the same,</strong></p>
<p><strong>; then it must have been the second</strong></p>
<p><strong>; bytes that differed. That’s where</strong></p>
<p><strong>; we’re pointing, so we’re done</strong></p>
<p><strong>dec si ;the first bytes differed, so point</strong></p>
<p><strong>dec di ; back to them</strong></p>
<p><strong>CompareStringsDone:</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov si,offset TestString1 ;point to one string</strong></p>
<p><strong>mov di,seg TestString2</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset TestString2 ;point to other string</strong></p>
<p><strong>call CompareStrings ;and compare the strings</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-14-1" class="level2">
<h2>Listing 14-1</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 14-1 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a zero-terminated string to another string,</strong></p>
<p><strong>; filtering out non-printable characters by means of a</strong></p>
<p><strong>; subroutine that performs the test. The subroutine is</strong></p>
<p><strong>; called with a far call and returns with a far return.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>SourceString label byte</strong></p>
<p><strong>db ‘This is a sample string, consisting of’</strong></p>
<p><strong>X=1</strong></p>
<p><strong>rept 31</strong></p>
<p><strong>db X</strong></p>
<p><strong>X=X+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>db 7fh</strong></p>
<p><strong>db ‘both printable and non-printable’</strong></p>
<p><strong>db ‘characters’, 0</strong></p>
<p><strong>DestinationString label byte</strong></p>
<p><strong>db 200 dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Determines whether a character is printable (in the range</strong></p>
<p><strong>; 20h through 7Eh).</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = character to check</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; Zero flag set to 1 if character is printable,</strong></p>
<p><strong>; set to 0 otherwise</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: none</strong></p>
<p><strong>;</strong></p>
<p><strong>IsPrintable proc far</strong></p>
<p><strong>cmp al,20h</strong></p>
<p><strong>jb IsPrintableDone ;not printable</strong></p>
<p><strong>cmp al,7eh</strong></p>
<p><strong>ja IsPrintableDone ;not printable</strong></p>
<p><strong>cmp al,al ;set the Zero flag to 1, since the</strong></p>
<p><strong>; character is printable</strong></p>
<p><strong>IsPrintableDone:</strong></p>
<p><strong>ret</strong></p>
<p><strong>IsPrintable endp</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a zero-terminated string to another string,</strong></p>
<p><strong>; filtering out non-printable characters.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DS:SI = source string</strong></p>
<p><strong>; ES:DI = destination string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>CopyPrintable:</strong></p>
<p><strong>cld</strong></p>
<p><strong>CopyPrintableLoop:</strong></p>
<p><strong>lodsb ;get the next byte to copy</strong></p>
<p><strong>call IsPrintable ;is it printable?</strong></p>
<p><strong>jnz NotPrintable ;nope, don’t copy it</strong></p>
<p><strong>stosb ;put the byte in the</strong></p>
<p><strong>; destination string</strong></p>
<p><strong>jmp CopyPrintableLoop ;the character was</strong></p>
<p><strong>; printable, so it couldn’t</strong></p>
<p><strong>; possibly have been 0. No</strong></p>
<p><strong>; need to check whether it</strong></p>
<p><strong>; terminated the string</strong></p>
<p><strong>NotPrintable:</strong></p>
<p><strong>and al,al ;was that the</strong></p>
<p><strong>; terminating zero?</strong></p>
<p><strong>jnz CopyPrintableLoop ;no, do next byte</strong></p>
<p><strong>stosb ;copy the terminating zero</strong></p>
<p><strong>ret ;done</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov di,seg DestinationString</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset DestinationString</strong></p>
<p><strong>;ES:DI points to the destination</strong></p>
<p><strong>mov si,offset SourceString</strong></p>
<p><strong>;DS:SI points to the source</strong></p>
<p><strong>call CopyPrintable ;copy the printable</strong></p>
<p><strong>; characters</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-14-2" class="level2">
<h2>Listing 14-2</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 14-2 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a zero-terminated string to another string,</strong></p>
<p><strong>; filtering out non-printable characters by means of a</strong></p>
<p><strong>; subroutine that performs the test. The subroutine is</strong></p>
<p><strong>; invoked with a JMP and returns with another JMP.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>SourceString label byte</strong></p>
<p><strong>db ‘This is a sample string, consisting of’</strong></p>
<p><strong>X=1</strong></p>
<p><strong>rept 31</strong></p>
<p><strong>db X</strong></p>
<p><strong>X=X+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>db 7fh</strong></p>
<p><strong>db ‘both printable and non-printable’</strong></p>
<p><strong>db ‘characters’, 0</strong></p>
<p><strong>DestinationString label byte</strong></p>
<p><strong>db 200 dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Determines whether a character is printable (in the range</strong></p>
<p><strong>; 20h through 7Eh).</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = character to check</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; Zero flag set to 1 if character is printable,</strong></p>
<p><strong>; set to 0 otherwise</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: none</strong></p>
<p><strong>;</strong></p>
<p><strong>IsPrintable:</strong></p>
<p><strong>cmp al,20h</strong></p>
<p><strong>jb IsPrintableDone ;not printable</strong></p>
<p><strong>cmp al,7eh</strong></p>
<p><strong>ja IsPrintableDone ;not printable</strong></p>
<p><strong>cmp al,al ;set the Zero flag to 1, since the</strong></p>
<p><strong>; character is printable</strong></p>
<p><strong>IsPrintableDone:</strong></p>
<p><strong>jmp short IsPrintableReturn</strong></p>
<p><strong>;this hardwires IsPrintable to</strong></p>
<p><strong>; return to just one place</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a zero-terminated string to another string,</strong></p>
<p><strong>; filtering out non-printable characters.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DS:SI = source string</strong></p>
<p><strong>; ES:DI = destination string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, SI, DI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>CopyPrintable:</strong></p>
<p><strong>cld</strong></p>
<p><strong>CopyPrintableLoop:</strong></p>
<p><strong>lodsb ;get the next byte to copy</strong></p>
<p><strong>jmp IsPrintable ;is it printable?</strong></p>
<p><strong>IsPrintableReturn:</strong></p>
<p><strong>jnz NotPrintable ;nope, don’t copy it</strong></p>
<p><strong>stosb ;put the byte in the</strong></p>
<p><strong>; destination string</strong></p>
<p><strong>jmp CopyPrintableLoop ;the character was</strong></p>
<p><strong>; printable, so it couldn’t</strong></p>
<p><strong>; possibly have been 0. No</strong></p>
<p><strong>; need to check whether it</strong></p>
<p><strong>; terminated the string</strong></p>
<p><strong>NotPrintable:</strong></p>
<p><strong>and al,al ;was that the</strong></p>
<p><strong>; terminating zero?</strong></p>
<p><strong>jnz CopyPrintableLoop ;no, do next byte</strong></p>
<p><strong>stosb ;copy the terminating zero</strong></p>
<p><strong>ret ;done</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov di,seg DestinationString</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset DestinationString</strong></p>
<p><strong>;ES:DI points to the destination</strong></p>
<p><strong>mov si,offset SourceString</strong></p>
<p><strong>;DS:SI points to the source</strong></p>
<p><strong>call CopyPrintable ;copy the printable</strong></p>
<p><strong>; characters</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-14-3" class="level2">
<h2>Listing 14-3</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 14-3 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a zero-terminated string to another string,</strong></p>
<p><strong>; filtering out non-printable characters by means of a</strong></p>
<p><strong>; subroutine that performs the test. The subroutine is</strong></p>
<p><strong>; invoked with a JMP and returns with a JMP through a</strong></p>
<p><strong>; register.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>SourceString label byte</strong></p>
<p><strong>db ‘This is a sample string, consisting of’</strong></p>
<p><strong>X=1</strong></p>
<p><strong>rept 31</strong></p>
<p><strong>db X</strong></p>
<p><strong>X=X+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>db 7fh</strong></p>
<p><strong>db ‘both printable and non-printable’</strong></p>
<p><strong>db ‘characters’, 0</strong></p>
<p><strong>DestinationString label byte</strong></p>
<p><strong>db 200 dup (?)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Determines whether a character is printable (in the range</strong></p>
<p><strong>; 20h through 7Eh).</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = character to check</strong></p>
<p><strong>; BP = return address</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; Zero flag set to 1 if character is printable,</strong></p>
<p><strong>; set to 0 otherwise</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: none</strong></p>
<p><strong>;</strong></p>
<p><strong>IsPrintable:</strong></p>
<p><strong>cmp al,20h</strong></p>
<p><strong>jb IsPrintableDone ;not printable</strong></p>
<p><strong>cmp al,7eh</strong></p>
<p><strong>ja IsPrintableDone ;not printable</strong></p>
<p><strong>cmp al,al ;set the Zero flag to 1, since the</strong></p>
<p><strong>; character is printable</strong></p>
<p><strong>IsPrintableDone:</strong></p>
<p><strong>jmp bp ;return to the address in BP</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies a zero-terminated string to another string,</strong></p>
<p><strong>; filtering out non-printable characters.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; DS:SI = source string</strong></p>
<p><strong>; ES:DI = destination string</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AL, SI, DI, BP</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle strings that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>CopyPrintable:</strong></p>
<p><strong>cld</strong></p>
<p><strong>mov bp,offset IsPrintableReturn</strong></p>
<p><strong>;set the return address for</strong></p>
<p><strong>; IsPrintable. Note that</strong></p>
<p><strong>; this is done outside the</strong></p>
<p><strong>; loop for speed</strong></p>
<p><strong>CopyPrintableLoop:</strong></p>
<p><strong>lodsb ;get the next byte to copy</strong></p>
<p><strong>jmp IsPrintable ;is it printable?</strong></p>
<p><strong>IsPrintableReturn:</strong></p>
<p><strong>jnz NotPrintable ;nope, don’t copy it</strong></p>
<p><strong>stosb ;put the byte in the</strong></p>
<p><strong>; destination string</strong></p>
<p><strong>jmp CopyPrintableLoop ;the character was</strong></p>
<p><strong>; printable, so it couldn’t</strong></p>
<p><strong>; possibly have been 0. No</strong></p>
<p><strong>; need to check whether it</strong></p>
<p><strong>; terminated the string</strong></p>
<p><strong>NotPrintable:</strong></p>
<p><strong>and al,al ;was that the</strong></p>
<p><strong>; terminating zero?</strong></p>
<p><strong>jnz CopyPrintableLoop ;no, do next byte</strong></p>
<p><strong>stosb ;copy the terminating zero</strong></p>
<p><strong>ret ;done</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov di,seg DestinationString</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset DestinationString</strong></p>
<p><strong>;ES:DI points to the destination</strong></p>
<p><strong>mov si,offset SourceString</strong></p>
<p><strong>;DS:SI points to the source</strong></p>
<p><strong>call CopyPrintable ;copy the printable</strong></p>
<p><strong>; characters</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-14-4" class="level2">
<h2>Listing 14-4</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 14-4 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies the standard input to the standard output,</strong></p>
<p><strong>; converting all characters to uppercase. Does so</strong></p>
<p><strong>; one character at a time.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>; Storage for the character we’re processing.</strong></p>
<p><strong>Character db ?</strong></p>
<p><strong>ErrorMsg db ‘An error occurred’, 0dh, 0ah</strong></p>
<p><strong>ERROR_MSG_LENGTH equ $-ErrorMsg</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>CopyLoop:</strong></p>
<p><strong>mov ah,3fh ;DOS read fn</strong></p>
<p><strong>sub bx,bx ;handle 0 is the standard input</strong></p>
<p><strong>mov cx,1 ;we want to get 1 character</strong></p>
<p><strong>mov dx,offset Character ;the character goes here</strong></p>
<p><strong>int 21h ;get the character</strong></p>
<p><strong>jc Error ;check for an error</strong></p>
<p><strong>and ax,ax ;did we read any characters?</strong></p>
<p><strong>jz Done ;no, we’ve hit the end of the file</strong></p>
<p><strong>mov al,[Character] ;get the character and</strong></p>
<p><strong>cmp al,‘a’ ; convert it to uppercase</strong></p>
<p><strong>jb WriteCharacter ; if it’s lowercase</strong></p>
<p><strong>cmp al,‘z’</strong></p>
<p><strong>ja WriteCharacter</strong></p>
<p><strong>and al,not 20h ;it’s uppercase-convert to</strong></p>
<p><strong>mov [Character],al ; uppercase and save</strong></p>
<p><strong>WriteCharacter:</strong></p>
<p><strong>mov ah,40h ;DOS write fn</strong></p>
<p><strong>mov bx,1 ;handle 1 is the standard output</strong></p>
<p><strong>mov cx,1 ;we want to write 1 character</strong></p>
<p><strong>mov dx,offset Character ;the character to write</strong></p>
<p><strong>int 21h ;write the character</strong></p>
<p><strong>jnc CopyLoop ;if no error, do the next character</strong></p>
<p><strong>Error:</strong></p>
<p><strong>mov ah,40h ;DOS write fn</strong></p>
<p><strong>mov bx,2 ;handle 2 is standard error</strong></p>
<p><strong>mov cx,ERROR_MSG_LENGTH ;# of chars to display</strong></p>
<p><strong>mov dx,offset ErrorMsg ;error msg to display</strong></p>
<p><strong>int 21h ;notify of error</strong></p>
<p><strong>Done:</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-14-5" class="level2">
<h2>Listing 14-5</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 14-5 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Copies the standard input to the standard output,</strong></p>
<p><strong>; converting all characters to uppercase. Does so in</strong></p>
<p><strong>; blocks of 256 characters.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>; Storage for the characters we’re processing.</strong></p>
<p><strong>CHARACTER_BLOCK_SIZE equ 256</strong></p>
<p><strong>CharacterBlock db CHARACTER_BLOCK_SIZE dup (?)</strong></p>
<p><strong>ErrorMsg db ‘An error occurred’, 0dh, 0ah</strong></p>
<p><strong>ERROR_MSG_LENGTH equ $-ErrorMsg</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>CopyLoop:</strong></p>
<p><strong>mov ah,3fh ;DOS read fn</strong></p>
<p><strong>sub bx,bx ;handle 0 is the standard input</strong></p>
<p><strong>mov cx,CHARACTER_BLOCK_SIZE</strong></p>
<p><strong>;we want to get a block</strong></p>
<p><strong>mov dx,offset CharacterBlock</strong></p>
<p><strong>;the characters go here</strong></p>
<p><strong>int 21h ;get the characters</strong></p>
<p><strong>jc Error ;check for an error</strong></p>
<p><strong>mov cx,ax ;get the count where it does us the</strong></p>
<p><strong>; most good</strong></p>
<p><strong>jcxz Done ;if we didn’t read anything, we’ve</strong></p>
<p><strong>; hit the end of the file</strong></p>
<p><strong>mov dx,cx ;remember how many characters we read</strong></p>
<p><strong>mov bx,offset CharacterBlock</strong></p>
<p><strong>;point to the first character to</strong></p>
<p><strong>; convert</strong></p>
<p><strong>ConvertLoop:</strong></p>
<p><strong>mov al,[bx] ;get the next character and</strong></p>
<p><strong>cmp al,‘a’ ; convert it to uppercase</strong></p>
<p><strong>jb ConvertLoopBottom ; if it’s lowercase</strong></p>
<p><strong>cmp al,‘z’</strong></p>
<p><strong>ja ConvertLoopBottom</strong></p>
<p><strong>and al,not 20h ;it’s uppercase-convert to</strong></p>
<p><strong>mov [bx],al ; uppercase and save</strong></p>
<p><strong>ConvertLoopBottom:</strong></p>
<p><strong>inc bx ;point to the next character</strong></p>
<p><strong>loop ConvertLoop</strong></p>
<p><strong>mov cx,dx ;get back the character count in</strong></p>
<p><strong>; this block, to serve as a count of</strong></p>
<p><strong>; bytes for DOS to write</strong></p>
<p><strong>mov ah,40h ;DOS write fn</strong></p>
<p><strong>mov bx,1 ;handle 1 is the standard output</strong></p>
<p><strong>mov dx,offset CharacterBlock</strong></p>
<p><strong>;point to the characters to write</strong></p>
<p><strong>push cx ;remember # of characters read</strong></p>
<p><strong>int 21h ;write the character</strong></p>
<p><strong>pop ax ;get back the # of characters in</strong></p>
<p><strong>; this block</strong></p>
<p><strong>jc Error ;check for an error</strong></p>
<p><strong>cmp ax,CHARACTER_BLOCK_SIZE</strong></p>
<p><strong>;was it a partial block?</strong></p>
<p><strong>jz CopyLoop ;no, so we’re not done yet</strong></p>
<p><strong>jmp short Done ;it was a partial block, so that</strong></p>
<p><strong>; was the end of the file</strong></p>
<p><strong>Error:</strong></p>
<p><strong>mov ah,40h ;DOS write fn</strong></p>
<p><strong>mov bx,2 ;handle 2 is standard error</strong></p>
<p><strong>mov cx,ERROR_MSG_LENGTH ;# of chars to display</strong></p>
<p><strong>mov dx,offset ErrorMsg ;error msg to display</strong></p>
<p><strong>int 21h ;notify of error</strong></p>
<p><strong>Done:</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-14-6" class="level2">
<h2>Listing 14-6</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 14-6 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches for the first appearance of a character, in any</strong></p>
<p><strong>; case, in a byte-sized array by using JZ and LOOP.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ByteArray label byte</strong></p>
<p><strong>db ‘Array Containing Both Upper and Lowercase’</strong></p>
<p><strong>db ‘Characters And Blanks’</strong></p>
<p><strong>ARRAY_LENGTH equ ($-ByteArray)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the first occurrence of the specified character, in</strong></p>
<p><strong>; any case, in the specified byte-sized array.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = character for which to perform a</strong></p>
<p><strong>; case-insensitive search</strong></p>
<p><strong>; CX = array length (0 means 64K long)</strong></p>
<p><strong>; DS:SI = array to search</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; SI = pointer to first case-insensitive match, or 0</strong></p>
<p><strong>; if no match is found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, CX, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle arrays that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Do not pass an array that starts at offset 0 (SI=0),</strong></p>
<p><strong>; since a match on the first byte and failure to find</strong></p>
<p><strong>; the byte would be indistinguishable.</strong></p>
<p><strong>;</strong></p>
<p><strong>CaseInsensitiveSearch:</strong></p>
<p><strong>cld</strong></p>
<p><strong>cmp al,‘a’</strong></p>
<p><strong>jb CaseInsensitiveSearchBegin</strong></p>
<p><strong>cmp al,‘z’</strong></p>
<p><strong>ja CaseInsensitiveSearchBegin</strong></p>
<p><strong>and al,not 20h ;make sure the search byte</strong></p>
<p><strong>; is uppercase</strong></p>
<p><strong>CaseInsensitiveSearchBegin:</strong></p>
<p><strong>mov ah,al ;put the search byte in AH</strong></p>
<p><strong>; so we can use AL to hold</strong></p>
<p><strong>; the bytes we’re checking</strong></p>
<p><strong>CaseInsensitiveSearchLoop:</strong></p>
<p><strong>lodsb ;get the next byte from the</strong></p>
<p><strong>; array being searched</strong></p>
<p><strong>cmp al,‘a’</strong></p>
<p><strong>jb CaseInsensitiveSearchIsUpper</strong></p>
<p><strong>cmp al,‘z’</strong></p>
<p><strong>ja CaseInsensitiveSearchIsUpper</strong></p>
<p><strong>and al,not 20h ;make sure the array byte is</strong></p>
<p><strong>; uppercase</strong></p>
<p><strong>CaseInsensitiveSearchIsUpper:</strong></p>
<p><strong>cmp al,ah ;do we have a</strong></p>
<p><strong>; case-insensitive match?</strong></p>
<p><strong>jz CaseInsensitiveSearchMatchFound ;yes</strong></p>
<p><strong>loop CaseInsensitiveSearchLoop</strong></p>
<p><strong>;check the next byte, if any</strong></p>
<p><strong>sub si,si ;no match found</strong></p>
<p><strong>ret</strong></p>
<p><strong>CaseInsensitiveSearchMatchFound:</strong></p>
<p><strong>dec si ;point back to the matching</strong></p>
<p><strong>; array byte</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov al,‘K’ ;character to search for</strong></p>
<p><strong>mov si,offset ByteArray ;array to search</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to search</strong></p>
<p><strong>; through</strong></p>
<p><strong>call CaseInsensitiveSearch</strong></p>
<p><strong>;perform a case-insensitive</strong></p>
<p><strong>; search for ‘K’</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-14-7" class="level2">
<h2>Listing 14-7</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 14-7 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches for the first appearance of a character, in any</strong></p>
<p><strong>; case, in a byte-sized array by using LOOPNZ.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ByteArray label byte</strong></p>
<p><strong>db ‘Array Containing Both Upper and Lowercase’</strong></p>
<p><strong>db ‘Characters And Blanks’</strong></p>
<p><strong>ARRAY_LENGTH equ ($-ByteArray)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the first occurrence of the specified character, in</strong></p>
<p><strong>; any case, in the specified byte-sized array.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = character for which to perform a</strong></p>
<p><strong>; case-insensitive search</strong></p>
<p><strong>; CX = array length (0 means 64K long)</strong></p>
<p><strong>; DS:SI = array to search</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; SI = pointer to first case-insensitive match, or 0</strong></p>
<p><strong>; if no match is found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, CX, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle arrays that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Do not pass an array that starts at offset 0 (SI=0),</strong></p>
<p><strong>; since a match on the first byte and failure to find</strong></p>
<p><strong>; the byte would be indistinguishable.</strong></p>
<p><strong>;</strong></p>
<p><strong>CaseInsensitiveSearch:</strong></p>
<p><strong>cld</strong></p>
<p><strong>cmp al,‘a’</strong></p>
<p><strong>jb CaseInsensitiveSearchBegin</strong></p>
<p><strong>cmp al,‘z’</strong></p>
<p><strong>ja CaseInsensitiveSearchBegin</strong></p>
<p><strong>and al,not 20h ;make sure the search byte</strong></p>
<p><strong>; is uppercase</strong></p>
<p><strong>CaseInsensitiveSearchBegin:</strong></p>
<p><strong>mov ah,al ;put the search byte in AH</strong></p>
<p><strong>; so we can use AL to hold</strong></p>
<p><strong>; the bytes we’re checking</strong></p>
<p><strong>CaseInsensitiveSearchLoop:</strong></p>
<p><strong>lodsb ;get the next byte from the</strong></p>
<p><strong>; array being searched</strong></p>
<p><strong>cmp al,‘a’</strong></p>
<p><strong>jb CaseInsensitiveSearchIsUpper</strong></p>
<p><strong>cmp al,‘z’</strong></p>
<p><strong>ja CaseInsensitiveSearchIsUpper</strong></p>
<p><strong>and al,not 20h ;make sure the array byte is</strong></p>
<p><strong>; uppercase</strong></p>
<p><strong>CaseInsensitiveSearchIsUpper:</strong></p>
<p><strong>cmp al,ah ;do we have a</strong></p>
<p><strong>; case-insensitive match?</strong></p>
<p><strong>loopnz CaseInsensitiveSearchLoop</strong></p>
<p><strong>;fall through if we have a</strong></p>
<p><strong>; match, or if we’ve run out</strong></p>
<p><strong>; of bytes. Otherwise, check</strong></p>
<p><strong>; the next byte</strong></p>
<p><strong>jz CaseInsensitiveSearchMatchFound</strong></p>
<p><strong>;we did find a match</strong></p>
<p><strong>sub si,si ;no match found</strong></p>
<p><strong>ret</strong></p>
<p><strong>CaseInsensitiveSearchMatchFound:</strong></p>
<p><strong>dec si ;point back to the matching</strong></p>
<p><strong>; array byte</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov al,‘K’ ;character to search for</strong></p>
<p><strong>mov si,offset ByteArray ;array to search</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to search</strong></p>
<p><strong>; through</strong></p>
<p><strong>call CaseInsensitiveSearch</strong></p>
<p><strong>;perform a case-insensitive</strong></p>
<p><strong>; search for ‘K’</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-14-8" class="level2">
<h2>Listing 14-8</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 14-8 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches for the first appearance of a character, in any</strong></p>
<p><strong>; case, in a byte-sized array by using JZ, DEC REG16, and</strong></p>
<p><strong>; JNZ.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ByteArray label byte</strong></p>
<p><strong>db ‘Array Containing Both Upper and Lowercase’</strong></p>
<p><strong>db ‘Characters And Blanks’</strong></p>
<p><strong>ARRAY_LENGTH equ ($-ByteArray)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the first occurrence of the specified character, in</strong></p>
<p><strong>; any case, in the specified byte-sized array.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = character for which to perform a</strong></p>
<p><strong>; case-insensitive search</strong></p>
<p><strong>; CX = array length (0 means 64K long)</strong></p>
<p><strong>; DS:SI = array to search</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; SI = pointer to first case-insensitive match, or 0</strong></p>
<p><strong>; if no match is found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, CX, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle arrays that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Do not pass an array that starts at offset 0 (SI=0),</strong></p>
<p><strong>; since a match on the first byte and failure to find</strong></p>
<p><strong>; the byte would be indistinguishable.</strong></p>
<p><strong>;</strong></p>
<p><strong>CaseInsensitiveSearch:</strong></p>
<p><strong>cld</strong></p>
<p><strong>cmp al,‘a’</strong></p>
<p><strong>jb CaseInsensitiveSearchBegin</strong></p>
<p><strong>cmp al,‘z’</strong></p>
<p><strong>ja CaseInsensitiveSearchBegin</strong></p>
<p><strong>and al,not 20h ;make sure the search byte</strong></p>
<p><strong>; is uppercase</strong></p>
<p><strong>CaseInsensitiveSearchBegin:</strong></p>
<p><strong>mov ah,al ;put the search byte in AH</strong></p>
<p><strong>; so we can use AL to hold</strong></p>
<p><strong>; the bytes we’re checking</strong></p>
<p><strong>CaseInsensitiveSearchLoop:</strong></p>
<p><strong>lodsb ;get the next byte from the</strong></p>
<p><strong>; array being searched</strong></p>
<p><strong>cmp al,‘a’</strong></p>
<p><strong>jb CaseInsensitiveSearchIsUpper</strong></p>
<p><strong>cmp al,‘z’</strong></p>
<p><strong>ja CaseInsensitiveSearchIsUpper</strong></p>
<p><strong>and al,not 20h ;make sure the array byte is</strong></p>
<p><strong>; uppercase</strong></p>
<p><strong>CaseInsensitiveSearchIsUpper:</strong></p>
<p><strong>cmp al,ah ;do we have a</strong></p>
<p><strong>; case-insensitive match?</strong></p>
<p><strong>jz CaseInsensitiveSearchMatchFound ;yes</strong></p>
<p><strong>dec cx ;count down bytes remaining</strong></p>
<p><strong>; in array being searched</strong></p>
<p><strong>jnz CaseInsensitiveSearchLoop</strong></p>
<p><strong>;check the next byte, if any</strong></p>
<p><strong>sub si,si ;no match found</strong></p>
<p><strong>ret</strong></p>
<p><strong>CaseInsensitiveSearchMatchFound:</strong></p>
<p><strong>dec si ;point back to the matching</strong></p>
<p><strong>; array byte</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov al,‘K’ ;character to search for</strong></p>
<p><strong>mov si,offset ByteArray ;array to search</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to search</strong></p>
<p><strong>; through</strong></p>
<p><strong>call CaseInsensitiveSearch</strong></p>
<p><strong>;perform a case-insensitive</strong></p>
<p><strong>; search for ‘K’</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-14-9" class="level2">
<h2>Listing 14-9</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 14-9 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches for the first appearance of a character, in any</strong></p>
<p><strong>; case, in a byte-sized array by using JZ, DEC REG8, and</strong></p>
<p><strong>; JNZ.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ByteArray label byte</strong></p>
<p><strong>db ‘Array Containing Both Upper and Lowercase’</strong></p>
<p><strong>db ‘Characters And Blanks’</strong></p>
<p><strong>ARRAY_LENGTH equ ($-ByteArray)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the first occurrence of the specified character, in</strong></p>
<p><strong>; any case, in the specified byte-sized array.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = character for which to perform a</strong></p>
<p><strong>; case-insensitive search</strong></p>
<p><strong>; CL = array length (0 means 256 long)</strong></p>
<p><strong>; DS:SI = array to search</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; SI = pointer to first case-insensitive match, or 0</strong></p>
<p><strong>; if no match is found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, CL, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle arrays that are longer than 256</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Do not pass an array that starts at offset 0 (SI=0),</strong></p>
<p><strong>; since a match on the first byte and failure to find</strong></p>
<p><strong>; the byte would be indistinguishable.</strong></p>
<p><strong>;</strong></p>
<p><strong>CaseInsensitiveSearch:</strong></p>
<p><strong>cld</strong></p>
<p><strong>cmp al,‘a’</strong></p>
<p><strong>jb CaseInsensitiveSearchBegin</strong></p>
<p><strong>cmp al,‘z’</strong></p>
<p><strong>ja CaseInsensitiveSearchBegin</strong></p>
<p><strong>and al,not 20h ;make sure the search byte</strong></p>
<p><strong>; is uppercase</strong></p>
<p><strong>CaseInsensitiveSearchBegin:</strong></p>
<p><strong>mov ah,al ;put the search byte in AH</strong></p>
<p><strong>; so we can use AL to hold</strong></p>
<p><strong>; the bytes we’re checking</strong></p>
<p><strong>CaseInsensitiveSearchLoop:</strong></p>
<p><strong>lodsb ;get the next byte from the</strong></p>
<p><strong>; array being searched</strong></p>
<p><strong>cmp al,‘a’</strong></p>
<p><strong>jb CaseInsensitiveSearchIsUpper</strong></p>
<p><strong>cmp al,‘z’</strong></p>
<p><strong>ja CaseInsensitiveSearchIsUpper</strong></p>
<p><strong>and al,not 20h ;make sure the array byte is</strong></p>
<p><strong>; uppercase</strong></p>
<p><strong>CaseInsensitiveSearchIsUpper:</strong></p>
<p><strong>cmp al,ah ;do we have a</strong></p>
<p><strong>; case-insensitive match?</strong></p>
<p><strong>jz CaseInsensitiveSearchMatchFound ;yes</strong></p>
<p><strong>dec cl ;count down bytes remaining</strong></p>
<p><strong>; in array being searched</strong></p>
<p><strong>jnz CaseInsensitiveSearchLoop</strong></p>
<p><strong>;check the next byte, if any</strong></p>
<p><strong>sub si,si ;no match found</strong></p>
<p><strong>ret</strong></p>
<p><strong>CaseInsensitiveSearchMatchFound:</strong></p>
<p><strong>dec si ;point back to the matching</strong></p>
<p><strong>; array byte</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov al,‘K’ ;character to search for</strong></p>
<p><strong>mov si,offset ByteArray ;array to search</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to search</strong></p>
<p><strong>; through</strong></p>
<p><strong>call CaseInsensitiveSearch</strong></p>
<p><strong>;perform a case-insensitive</strong></p>
<p><strong>; search for ‘K’</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-14-10" class="level2">
<h2>Listing 14-10</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 14-10 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches for the first appearance of a character, in any</strong></p>
<p><strong>; case, in a byte-sized array by using JZ, DEC MEM8, and</strong></p>
<p><strong>; JNZ.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ByteArray label byte</strong></p>
<p><strong>db ‘Array Containing Both Upper and Lowercase’</strong></p>
<p><strong>db ‘Characters And Blanks’</strong></p>
<p><strong>ARRAY_LENGTH equ ($-ByteArray)</strong></p>
<p><strong>BCount db ? ;used to count down the # of bytes</strong></p>
<p><strong>; remaining in the array being</strong></p>
<p><strong>; searched (counter is byte-sized)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the first occurrence of the specified character, in</strong></p>
<p><strong>; any case, in the specified byte-sized array.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = character for which to perform a</strong></p>
<p><strong>; case-insensitive search</strong></p>
<p><strong>; CL = array length (0 means 256 long)</strong></p>
<p><strong>; DS:SI = array to search</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; SI = pointer to first case-insensitive match, or 0</strong></p>
<p><strong>; if no match is found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle arrays that are longer than 256</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Do not pass an array that starts at offset 0 (SI=0),</strong></p>
<p><strong>; since a match on the first byte and failure to find</strong></p>
<p><strong>; the byte would be indistinguishable.</strong></p>
<p><strong>;</strong></p>
<p><strong>CaseInsensitiveSearch:</strong></p>
<p><strong>cld</strong></p>
<p><strong>mov [BCount],cl ;set the count variable</strong></p>
<p><strong>cmp al,‘a’</strong></p>
<p><strong>jb CaseInsensitiveSearchBegin</strong></p>
<p><strong>cmp al,‘z’</strong></p>
<p><strong>ja CaseInsensitiveSearchBegin</strong></p>
<p><strong>and al,not 20h ;make sure the search byte</strong></p>
<p><strong>; is uppercase</strong></p>
<p><strong>CaseInsensitiveSearchBegin:</strong></p>
<p><strong>mov ah,al ;put the search byte in AH</strong></p>
<p><strong>; so we can use AL to hold</strong></p>
<p><strong>; the bytes we’re checking</strong></p>
<p><strong>CaseInsensitiveSearchLoop:</strong></p>
<p><strong>lodsb ;get the next byte from the</strong></p>
<p><strong>; array being searched</strong></p>
<p><strong>cmp al,‘a’</strong></p>
<p><strong>jb CaseInsensitiveSearchIsUpper</strong></p>
<p><strong>cmp al,‘z’</strong></p>
<p><strong>ja CaseInsensitiveSearchIsUpper</strong></p>
<p><strong>and al,not 20h ;make sure the array byte is</strong></p>
<p><strong>; uppercase</strong></p>
<p><strong>CaseInsensitiveSearchIsUpper:</strong></p>
<p><strong>cmp al,ah ;do we have a</strong></p>
<p><strong>; case-insensitive match?</strong></p>
<p><strong>jz CaseInsensitiveSearchMatchFound ;yes</strong></p>
<p><strong>dec [BCount] ;count down bytes remaining</strong></p>
<p><strong>; in array being searched</strong></p>
<p><strong>; (counter is byte-sized)</strong></p>
<p><strong>jnz CaseInsensitiveSearchLoop</strong></p>
<p><strong>;check the next byte, if any</strong></p>
<p><strong>sub si,si ;no match found</strong></p>
<p><strong>ret</strong></p>
<p><strong>CaseInsensitiveSearchMatchFound:</strong></p>
<p><strong>dec si ;point back to the matching</strong></p>
<p><strong>; array byte</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov al,‘K’ ;character to search for</strong></p>
<p><strong>mov si,offset ByteArray ;array to search</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to search</strong></p>
<p><strong>; through</strong></p>
<p><strong>call CaseInsensitiveSearch</strong></p>
<p><strong>;perform a case-insensitive</strong></p>
<p><strong>; search for ‘K’</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-14-11" class="level2">
<h2>Listing 14-11</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 14-11 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches for the first appearance of a character, in any</strong></p>
<p><strong>; case, in a byte-sized array by using JZ, DEC MEM16, and</strong></p>
<p><strong>; JNZ.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>ByteArray label byte</strong></p>
<p><strong>db ‘Array Containing Both Upper and Lowercase’</strong></p>
<p><strong>db ‘Characters And Blanks’</strong></p>
<p><strong>ARRAY_LENGTH equ ($-ByteArray)</strong></p>
<p><strong>WCount dw ? ;used to count down the # of bytes</strong></p>
<p><strong>; remaining in the array being</strong></p>
<p><strong>; searched (counter is word-sized)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Finds the first occurrence of the specified character, in</strong></p>
<p><strong>; any case, in the specified byte-sized array.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = character for which to perform a</strong></p>
<p><strong>; case-insensitive search</strong></p>
<p><strong>; CX = array length (0 means 64K long)</strong></p>
<p><strong>; DS:SI = array to search</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; SI = pointer to first case-insensitive match, or 0</strong></p>
<p><strong>; if no match is found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Does not handle arrays that are longer than 64K</strong></p>
<p><strong>; bytes or cross segment boundaries.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Do not pass an array that starts at offset 0 (SI=0),</strong></p>
<p><strong>; since a match on the first byte and failure to find</strong></p>
<p><strong>; the byte would be indistinguishable.</strong></p>
<p><strong>;</strong></p>
<p><strong>CaseInsensitiveSearch:</strong></p>
<p><strong>cld</strong></p>
<p><strong>mov [WCount],cx ;set the count variable</strong></p>
<p><strong>cmp al,‘a’</strong></p>
<p><strong>jb CaseInsensitiveSearchBegin</strong></p>
<p><strong>cmp al,‘z’</strong></p>
<p><strong>ja CaseInsensitiveSearchBegin</strong></p>
<p><strong>and al,not 20h ;make sure the search byte</strong></p>
<p><strong>; is uppercase</strong></p>
<p><strong>CaseInsensitiveSearchBegin:</strong></p>
<p><strong>mov ah,al ;put the search byte in AH</strong></p>
<p><strong>; so we can use AL to hold</strong></p>
<p><strong>; the bytes we’re checking</strong></p>
<p><strong>CaseInsensitiveSearchLoop:</strong></p>
<p><strong>lodsb ;get the next byte from the</strong></p>
<p><strong>; array being searched</strong></p>
<p><strong>cmp al,‘a’</strong></p>
<p><strong>jb CaseInsensitiveSearchIsUpper</strong></p>
<p><strong>cmp al,‘z’</strong></p>
<p><strong>ja CaseInsensitiveSearchIsUpper</strong></p>
<p><strong>and al,not 20h ;make sure the array byte is</strong></p>
<p><strong>; uppercase</strong></p>
<p><strong>CaseInsensitiveSearchIsUpper:</strong></p>
<p><strong>cmp al,ah ;do we have a</strong></p>
<p><strong>; case-insensitive match?</strong></p>
<p><strong>jz CaseInsensitiveSearchMatchFound ;yes</strong></p>
<p><strong>dec [WCount] ;count down bytes remaining</strong></p>
<p><strong>; in array being searched</strong></p>
<p><strong>; (counter is word-sized)</strong></p>
<p><strong>jnz CaseInsensitiveSearchLoop</strong></p>
<p><strong>;check the next byte, if any</strong></p>
<p><strong>sub si,si ;no match found</strong></p>
<p><strong>ret</strong></p>
<p><strong>CaseInsensitiveSearchMatchFound:</strong></p>
<p><strong>dec si ;point back to the matching</strong></p>
<p><strong>; array byte</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov al,‘K’ ;character to search for</strong></p>
<p><strong>mov si,offset ByteArray ;array to search</strong></p>
<p><strong>mov cx,ARRAY_LENGTH ;# of bytes to search</strong></p>
<p><strong>; through</strong></p>
<p><strong>call CaseInsensitiveSearch</strong></p>
<p><strong>;perform a case-insensitive</strong></p>
<p><strong>; search for ‘K’</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-14-12" class="level2">
<h2>Listing 14-12</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 14-12 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Demonstrates scanning a table with REPNZ SCASW in</strong></p>
<p><strong>; order to generate an index to be used with a jump table.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>; Branches to the routine corresponding to the key code in</strong></p>
<p><strong>; AX. Simply returns if no match is found.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AX = 16-bit key code, as returned by the BIOS</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: CX, DI, ES</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Table of 16-bit key codes this routine handles.</strong></p>
<p><strong>;</strong></p>
<p><strong>KeyLookUpTable label word</strong></p>
<p><strong>dw 1e41h, 3042h, 2e43h, 2044h ;A-D</strong></p>
<p><strong>dw 1245h, 2146h, 2247h, 2347h ;E-H</strong></p>
<p><strong>dw 1749h, 244ah, 254bh, 264ch ;I-L</strong></p>
<p><strong>dw 324dh, 314eh, 184fh, 1950h ;M-P</strong></p>
<p><strong>dw 1051h, 1352h, 1f53h, 1454h ;Q-T</strong></p>
<p><strong>dw 1655h, 2f56h, 1157h, 2d58h ;U-X</strong></p>
<p><strong>dw 1559h, 2c5ah ;Y-Z</strong></p>
<p><strong>KEY_LOOK_UP_TABLE_LENGTH_IN_WORDS equ (($-KeyLookUpTable)/2)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Table of addresses to which to jump when the corresponding</strong></p>
<p><strong>; key codes in KeyLookUpTable are found. All the entries</strong></p>
<p><strong>; point to the same routine, since this is for illustrative</strong></p>
<p><strong>; purposes only, but they could easily be changed to point</strong></p>
<p><strong>; to any labeLin the code segment.</strong></p>
<p><strong>;</strong></p>
<p><strong>KeyJumpTable label word</strong></p>
<p><strong>dw HandleA_Z, HandleA_Z, HandleA_Z, HandleA_Z</strong></p>
<p><strong>dw HandleA_Z, HandleA_Z, HandleA_Z, HandleA_Z</strong></p>
<p><strong>dw HandleA_Z, HandleA_Z, HandleA_Z, HandleA_Z</strong></p>
<p><strong>dw HandleA_Z, HandleA_Z, HandleA_Z, HandleA_Z</strong></p>
<p><strong>dw HandleA_Z, HandleA_Z, HandleA_Z, HandleA_Z</strong></p>
<p><strong>dw HandleA_Z, HandleA_Z, HandleA_Z, HandleA_Z</strong></p>
<p><strong>dw HandleA_Z, HandleA_Z</strong></p>
<p><strong>;</strong></p>
<p><strong>VectorOnKey proc near</strong></p>
<p><strong>mov di,cs</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset KeyLookUpTable</strong></p>
<p><strong>;point ES:DI to the table of keys</strong></p>
<p><strong>; we handle, which is in the same</strong></p>
<p><strong>; code segment as this routine</strong></p>
<p><strong>mov cx,KEY_LOOK_UP_TABLE_LENGTH_IN_WORDS</strong></p>
<p><strong>;# of words to scan</strong></p>
<p><strong>cld</strong></p>
<p><strong>repnz scasw ;look up the key</strong></p>
<p><strong>jnz VectorOnKeyDone ;it’s not in the table, so</strong></p>
<p><strong>; we’re done</strong></p>
<p><strong>jmp cs:[KeyJumpTable+di-2-offset KeyLookUpTable]</strong></p>
<p><strong>;jump to the routine for this key</strong></p>
<p><strong>; Note that:</strong></p>
<p><strong>; DI-2-offset KeyLookUpTable</strong></p>
<p><strong>; is the offset in KeyLookUpTable of</strong></p>
<p><strong>; the key we found, with the -2</strong></p>
<p><strong>; needed to compensate for the</strong></p>
<p><strong>; 2-byte (1-word) overrun of SCASW</strong></p>
<p><strong>HandleA_Z:</strong></p>
<p><strong>VectorOnKeyDone:</strong></p>
<p><strong>ret</strong></p>
<p><strong>VectorOnKey endp</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov ax,1e41h</strong></p>
<p><strong>call VectorOnKey ;look up ‘A’</strong></p>
<p><strong>mov ax,1749h</strong></p>
<p><strong>call VectorOnKey ;look up ‘I’</strong></p>
<p><strong>mov ax,1f53h</strong></p>
<p><strong>call VectorOnKey ;look up ‘S’</strong></p>
<p><strong>mov ax,2c5ah</strong></p>
<p><strong>call VectorOnKey ;look up ‘Z’</strong></p>
<p><strong>mov ax,0</strong></p>
<p><strong>call VectorOnKey ;finally, look up a key</strong></p>
<p><strong>; code that’s not in the</strong></p>
<p><strong>; table</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-14-13" class="level2">
<h2>Listing 14-13</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 14-13 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Demonstrates that it’s much slower to scan a table</strong></p>
<p><strong>; in a loop than to use REP SCASW; look-up tables should</strong></p>
<p><strong>; be designed so that repeated string instructions can be</strong></p>
<p><strong>; used.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>; Branches to the routine corresponding to the key code in</strong></p>
<p><strong>; AX. Simply returns if no match is found.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AX = 16-bit key code, as returned by the BIOS</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output: none</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: CX, DI, ES</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Table of 16-bit key codes this routine handles, each</strong></p>
<p><strong>; paired with the address to jump to if that key code is</strong></p>
<p><strong>; found.</strong></p>
<p><strong>;</strong></p>
<p><strong>KeyLookUpTable label word</strong></p>
<p><strong>dw 1e41h, HandleA_Z, 3042h, HandleA_Z ;A-B</strong></p>
<p><strong>dw 2e43h, HandleA_Z, 2044h, HandleA_Z ;C-D</strong></p>
<p><strong>dw 1245h, HandleA_Z, 2146h, HandleA_Z ;E-F</strong></p>
<p><strong>dw 2247h, HandleA_Z, 2347h, HandleA_Z ;G-H</strong></p>
<p><strong>dw 1749h, HandleA_Z, 244ah, HandleA_Z ;I-J</strong></p>
<p><strong>dw 254bh, HandleA_Z, 264ch, HandleA_Z ;K-L</strong></p>
<p><strong>dw 324dh, HandleA_Z, 314eh, HandleA_Z ;M-N</strong></p>
<p><strong>dw 184fh, HandleA_Z, 1950h, HandleA_Z ;O-P</strong></p>
<p><strong>dw 1051h, HandleA_Z, 1352h, HandleA_Z ;Q-R</strong></p>
<p><strong>dw 1f53h, HandleA_Z, 1454h, HandleA_Z ;S-T</strong></p>
<p><strong>dw 1655h, HandleA_Z, 2f56h, HandleA_Z ;U-V</strong></p>
<p><strong>dw 1157h, HandleA_Z, 2d58h, HandleA_Z ;W-X</strong></p>
<p><strong>dw 1559h, HandleA_Z, 2c5ah, HandleA_Z ;Y-Z</strong></p>
<p><strong>KEY_LOOK_UP_TABLE_LEN_IN_ENTRIES equ (($-KeyLookUpTable)/4)</strong></p>
<p><strong>;</strong></p>
<p><strong>VectorOnKey proc near</strong></p>
<p><strong>mov di,cs</strong></p>
<p><strong>mov es,di</strong></p>
<p><strong>mov di,offset KeyLookUpTable</strong></p>
<p><strong>;point ES:DI to the table of keys</strong></p>
<p><strong>; we handle, which is in the same</strong></p>
<p><strong>; code segment as this routine</strong></p>
<p><strong>mov cx,KEY_LOOK_UP_TABLE_LEN_IN_ENTRIES</strong></p>
<p><strong>;# of entries to scan</strong></p>
<p><strong>cld</strong></p>
<p><strong>VectorOnKeyLoop:</strong></p>
<p><strong>scasw</strong></p>
<p><strong>jz VectorOnKeyJump ;we’ve found the key code</strong></p>
<p><strong>inc di ;point to the next entry</strong></p>
<p><strong>inc di</strong></p>
<p><strong>loop VectorOnKeyLoop</strong></p>
<p><strong>ret ;the key code is not in the</strong></p>
<p><strong>; table, so we’re done</strong></p>
<p><strong>VectorOnKeyJump:</strong></p>
<p><strong>jmp word ptr cs:[di]</strong></p>
<p><strong>;jump to the routine for this key</strong></p>
<p><strong>HandleA_Z:</strong></p>
<p><strong>ret</strong></p>
<p><strong>VectorOnKey endp</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov ax,1e41h</strong></p>
<p><strong>call VectorOnKey ;look up ‘A’</strong></p>
<p><strong>mov ax,1749h</strong></p>
<p><strong>call VectorOnKey ;look up ‘I’</strong></p>
<p><strong>mov ax,1f53h</strong></p>
<p><strong>call VectorOnKey ;look up ‘S’</strong></p>
<p><strong>mov ax,2c5ah</strong></p>
<p><strong>call VectorOnKey ;look up ‘Z’</strong></p>
<p><strong>mov ax,0</strong></p>
<p><strong>call VectorOnKey ;finally, look up a key</strong></p>
<p><strong>; code that’s not in the</strong></p>
<p><strong>; table</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-14-14" class="level2">
<h2>Listing 14-14</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 14-14 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Demonstrates the use of a jump table to branch into</strong></p>
<p><strong>; in-line code consisting of repeated code blocks of</strong></p>
<p><strong>; varying lengths. The approach of using a jump table to</strong></p>
<p><strong>; branch into in-line code is speedy enough that</strong></p>
<p><strong>; it’s often preferable even when all the repeated code</strong></p>
<p><strong>; blocks are the same size, although the jump table does</strong></p>
<p><strong>; take extra space.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches up to N bytes of a zero-terminated string for</strong></p>
<p><strong>; a character.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>TestString label byte</strong></p>
<p><strong>db ‘This is a string containing the letter’</strong></p>
<p><strong>db ‘z but not containing capital q’, 0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches a zero-terminated string for a character.</strong></p>
<p><strong>; Searches until a match is found, the terminating zero</strong></p>
<p><strong>; is found, or the specified number of characters have been</strong></p>
<p><strong>; checked.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = character to search for</strong></p>
<p><strong>; BX = maximum # of characters to search. Must be</strong></p>
<p><strong>; less than or equal to 80</strong></p>
<p><strong>; DS:SI = string to search</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; SI = pointer to character, or 0 if character not</strong></p>
<p><strong>; found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, BX, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Don’t pass a string starting at offset 0, since a</strong></p>
<p><strong>; match there couldn’t be distinguished from a failure</strong></p>
<p><strong>; to match.</strong></p>
<p><strong>;</strong></p>
<p><strong>MAX_SEARCH_LENGTH equ 80 ;longest supported search</strong></p>
<p><strong>; length</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to create SearchTable entries.</strong></p>
<p><strong>;</strong></p>
<p><strong>MAKE_CHECK_CHAR_LABEL macro NUMBER</strong></p>
<p><strong>dw CheckChar&amp;NUMBER&amp;</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to create in-line code to search 1 character.</strong></p>
<p><strong>; Gives the code block a unique label according to NUMBER.</strong></p>
<p><strong>; Each conditional branch uses the shortest possible jump</strong></p>
<p><strong>; sequence to reach NoMatch and MatchFound.</strong></p>
<p><strong>;</strong></p>
<p><strong>CHECK_CHAR macro NUMBER</strong></p>
<p><strong>local CheckMatch, Continue</strong></p>
<p><strong>CheckChar&amp;NUMBER&amp;:</strong></p>
<p><strong>lodsb ;get the character</strong></p>
<p><strong>and al,al ;done if terminating zero</strong></p>
<p><strong>;</strong></p>
<p><strong>; Assemble a single conditional jump if it’ll reach, or</strong></p>
<p><strong>; a conditional jump around an unconditional jump if the</strong></p>
<p><strong>; 1-byte displacement of a conditional jump won’t reach.</strong></p>
<p><strong>;</strong></p>
<p><strong>if ($+2-NoMatch) le 128</strong></p>
<p><strong>jz NoMatch</strong></p>
<p><strong>else</strong></p>
<p><strong>jnz CheckMatch</strong></p>
<p><strong>jmp NoMatch</strong></p>
<p><strong>endif</strong></p>
<p><strong>CheckMatch:</strong></p>
<p><strong>cmp ah,al ;done if matches search character</strong></p>
<p><strong>;</strong></p>
<p><strong>; Again, assemble shortest possible jump sequence.</strong></p>
<p><strong>;</strong></p>
<p><strong>if ($+2-MatchFound) le 128</strong></p>
<p><strong>jz MatchFound</strong></p>
<p><strong>else</strong></p>
<p><strong>jnz Continue</strong></p>
<p><strong>jmp MatchFound</strong></p>
<p><strong>endif</strong></p>
<p><strong>Continue:</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Table of in-line code entry points for maximum search</strong></p>
<p><strong>; lengths of 0 through 80.</strong></p>
<p><strong>;</strong></p>
<p><strong>SearchTable label word</strong></p>
<p><strong>dw NoMatch ;we never match on a</strong></p>
<p><strong>; maximum length of 0</strong></p>
<p><strong>BLOCK_NUMBER=MAX_SEARCH_LENGTH-1</strong></p>
<p><strong>rept MAX_SEARCH_LENGTH</strong></p>
<p><strong>MAKE_CHECK_CHAR_LABEL %BLOCK_NUMBER</strong></p>
<p><strong>BLOCK_NUMBER=BLOCK_NUMBER-1</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>SearchNBytes proc near</strong></p>
<p><strong>mov ah,al ;we’ll need AL for LODSB</strong></p>
<p><strong>cmp bx,MAX_SEARCH_LENGTH</strong></p>
<p><strong>ja NoMatch ;if the maximum length’s</strong></p>
<p><strong>; too long for the in-line</strong></p>
<p><strong>; code, return a no-match</strong></p>
<p><strong>; status</strong></p>
<p><strong>shl bx,1 ;*2 to look up in word-sized</strong></p>
<p><strong>; table</strong></p>
<p><strong>jmp [SearchTable+bx] ;branch into the in-line</strong></p>
<p><strong>; code to do the search</strong></p>
<p><strong>;</strong></p>
<p><strong>; No match was found.</strong></p>
<p><strong>;</strong></p>
<p><strong>NoMatch:</strong></p>
<p><strong>sub si,si ;return no-match status</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>; A match was found.</strong></p>
<p><strong>;</strong></p>
<p><strong>MatchFound:</strong></p>
<p><strong>dec si ;point back to matching</strong></p>
<p><strong>; location</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>; This is the in-line code that actually does the search.</strong></p>
<p><strong>; Each repetition is uniquely labelled, with the labels</strong></p>
<p><strong>; running from CheckChar0 through CheckChar79.</strong></p>
<p><strong>;</strong></p>
<p><strong>BLOCK_NUMBER=0</strong></p>
<p><strong>;</strong></p>
<p><strong>; These in-line blocks use 1-byte displacements whenever</strong></p>
<p><strong>; possible to branch backward; otherwise 2-byte</strong></p>
<p><strong>; displacements are used to branch backward, with</strong></p>
<p><strong>; conditional jumps around unconditional jumps.</strong></p>
<p><strong>;</strong></p>
<p><strong>rept MAX_SEARCH_LENGTH</strong></p>
<p><strong>CHECK_CHAR %BLOCK_NUMBER</strong></p>
<p><strong>BLOCK_NUMBER=BLOCK_NUMBER+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; If we make it here, we haven’t found the character.</strong></p>
<p><strong>;</strong></p>
<p><strong>sub si,si ;return no-match status</strong></p>
<p><strong>ret</strong></p>
<p><strong>SearchNBytes endp</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov al,‘Q’</strong></p>
<p><strong>mov bx,20 ;search up to the</strong></p>
<p><strong>mov si,offset TestString ; first 20 bytes of</strong></p>
<p><strong>call SearchNBytes ; TestString for ‘Q’</strong></p>
<p><strong>mov al,‘z’</strong></p>
<p><strong>mov bx,80 ;search up to the</strong></p>
<p><strong>mov si,offset TestString ; first 80 bytes of</strong></p>
<p><strong>call SearchNBytes ; TestString for ‘z’</strong></p>
<p><strong>mov al,‘a’</strong></p>
<p><strong>mov bx,10 ;search up to the</strong></p>
<p><strong>mov si,offset TestString ; first 10 bytes of</strong></p>
<p><strong>call SearchNBytes ; TestString for ‘a’</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-14-15" class="level2">
<h2>Listing 14-15</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 14-15 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; For comparison with the in-line-code-branched-to-via-a-</strong></p>
<p><strong>; jump-table approach of Listing 14-14, this is a loop-based</strong></p>
<p><strong>; string-search routine that searches at most the specified</strong></p>
<p><strong>; number of bytes of a zero-terminated string for the</strong></p>
<p><strong>; specified character.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>TestString label byte</strong></p>
<p><strong>db ‘This is a string containing the letter’</strong></p>
<p><strong>db ‘z but not containing capital q’, 0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches a zero-terminated string for a character.</strong></p>
<p><strong>; Searches until a match is found, the terminating zero</strong></p>
<p><strong>; is found, or the specified number of characters have been</strong></p>
<p><strong>; checked.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = character to search for</strong></p>
<p><strong>; BX = maximum # of characters to search</strong></p>
<p><strong>; DS:SI = string to search</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; SI = pointer to character, or 0 if character not</strong></p>
<p><strong>; found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, CX, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Don’t pass a string starting at offset 0, since a</strong></p>
<p><strong>; match there couldn’t be distinguished from a failure</strong></p>
<p><strong>; to match.</strong></p>
<p><strong>;</strong></p>
<p><strong>SearchNBytes proc near</strong></p>
<p><strong>mov ah,al ;we’ll need AL for LODSB</strong></p>
<p><strong>mov cx,bx ;for LOOP</strong></p>
<p><strong>SearchNBytesLoop:</strong></p>
<p><strong>lodsb</strong></p>
<p><strong>and al,al</strong></p>
<p><strong>jz NoMatch ;terminating 0, so no match</strong></p>
<p><strong>cmp ah,al</strong></p>
<p><strong>jz MatchFound ;match, so we’re done</strong></p>
<p><strong>loop SearchNBytesLoop</strong></p>
<p><strong>;</strong></p>
<p><strong>; No match was found.</strong></p>
<p><strong>;</strong></p>
<p><strong>NoMatch:</strong></p>
<p><strong>sub si,si ;return no-match status</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>; A match was found.</strong></p>
<p><strong>;</strong></p>
<p><strong>MatchFound:</strong></p>
<p><strong>dec si ;point back to matching</strong></p>
<p><strong>; location</strong></p>
<p><strong>ret</strong></p>
<p><strong>SearchNBytes endp</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov al,‘Q’</strong></p>
<p><strong>mov bx,20 ;search up to the</strong></p>
<p><strong>mov si,offset TestString ; first 20 bytes of</strong></p>
<p><strong>call SearchNBytes ; TestString for ‘Q’</strong></p>
<p><strong>mov al,‘z’</strong></p>
<p><strong>mov bx,80 ;search up to the</strong></p>
<p><strong>mov si,offset TestString ; first 80 bytes of</strong></p>
<p><strong>call SearchNBytes ; TestString for ‘z’</strong></p>
<p><strong>mov al,‘a’</strong></p>
<p><strong>mov bx,10 ;search up to the</strong></p>
<p><strong>mov si,offset TestString ; first 10 bytes of</strong></p>
<p><strong>call SearchNBytes ; TestString for ‘a’</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-14-16" class="level2">
<h2>Listing 14-16</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 14-16 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Demonstrates the use of a jump table to branch into</strong></p>
<p><strong>; in-line code consisting of repeated code blocks of</strong></p>
<p><strong>; varying lengths. Branches out of the in-line code with</strong></p>
<p><strong>; 1-byte displacements at both ends of the in-line code,</strong></p>
<p><strong>; for improved speed.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches up to N bytes of a zero-terminated string for</strong></p>
<p><strong>; a character.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>TestString label byte</strong></p>
<p><strong>db ‘This is a string containing the letter’</strong></p>
<p><strong>db ‘z but not containing capital q’, 0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Searches a zero-terminated string for a character.</strong></p>
<p><strong>; Searches until a match is found, the terminating zero</strong></p>
<p><strong>; is found, or the specified number of characters has been</strong></p>
<p><strong>; checked.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Input:</strong></p>
<p><strong>; AL = character to search for</strong></p>
<p><strong>; BX = maximum # of characters to search. Must be</strong></p>
<p><strong>; less than or equal to MAX_SEARCH_LENGTH</strong></p>
<p><strong>; DS:SI = string to search</strong></p>
<p><strong>;</strong></p>
<p><strong>; Output:</strong></p>
<p><strong>; SI = pointer to character, or 0 if character not</strong></p>
<p><strong>; found</strong></p>
<p><strong>;</strong></p>
<p><strong>; Registers altered: AX, BX, SI</strong></p>
<p><strong>;</strong></p>
<p><strong>; Direction flag cleared</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Don’t pass a string starting at offset 0, since a</strong></p>
<p><strong>; match there couldn’t be distinguished from a failure</strong></p>
<p><strong>; to match.</strong></p>
<p><strong>;</strong></p>
<p><strong>MAX_SEARCH_LENGTH equ 80 ;longest supported search</strong></p>
<p><strong>; length</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to create SearchTable entries.</strong></p>
<p><strong>;</strong></p>
<p><strong>MAKE_CHECK_CHAR_LABEL macro NUMBER</strong></p>
<p><strong>dw CheckChar&amp;NUMBER&amp;</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to create in-line code to search 1 character.</strong></p>
<p><strong>; Gives the code block a unique label according to NUMBER.</strong></p>
<p><strong>; Each conditional branch uses the shortest possible jump</strong></p>
<p><strong>; sequence to reach NoMatch and MatchFound.</strong></p>
<p><strong>;</strong></p>
<p><strong>CHECK_CHAR macro NUMBER</strong></p>
<p><strong>local CheckMatch, Continue</strong></p>
<p><strong>CheckChar&amp;NUMBER&amp;:</strong></p>
<p><strong>lodsb ;get the character</strong></p>
<p><strong>and al,al ;done if terminating zero</strong></p>
<p><strong>;</strong></p>
<p><strong>; Assemble a single conditional jump if it’ll reach, or</strong></p>
<p><strong>; a conditional jump around an unconditional jump if the</strong></p>
<p><strong>; 1-byte displacement of a conditional jump won’t reach.</strong></p>
<p><strong>;</strong></p>
<p><strong>if ($+2-NoMatch) le 128</strong></p>
<p><strong>jz NoMatch</strong></p>
<p><strong>else</strong></p>
<p><strong>jnz CheckMatch</strong></p>
<p><strong>jmp NoMatch</strong></p>
<p><strong>endif</strong></p>
<p><strong>CheckMatch:</strong></p>
<p><strong>cmp ah,al ;done if matches search character</strong></p>
<p><strong>;</strong></p>
<p><strong>; Again, assemble shortest possible jump sequence.</strong></p>
<p><strong>;</strong></p>
<p><strong>if ($+2-MatchFound) le 128</strong></p>
<p><strong>jz MatchFound</strong></p>
<p><strong>else</strong></p>
<p><strong>jnz Continue</strong></p>
<p><strong>jmp MatchFound</strong></p>
<p><strong>endif</strong></p>
<p><strong>Continue:</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to create in-line code to search 1 character.</strong></p>
<p><strong>; Gives the code block a unique label according to NUMBER.</strong></p>
<p><strong>; All branches use a 1-byte displacement to branch to</strong></p>
<p><strong>; NoMatch2 and MatchFound2.</strong></p>
<p><strong>;</strong></p>
<p><strong>CHECK_CHAR2 macro NUMBER</strong></p>
<p><strong>CheckChar&amp;NUMBER&amp;:</strong></p>
<p><strong>lodsb ;get the character</strong></p>
<p><strong>and al,al ;done if terminating zero</strong></p>
<p><strong>jz NoMatch2</strong></p>
<p><strong>cmp ah,al ;done if matches search character</strong></p>
<p><strong>jz MatchFound2</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Table of in-line code entry points for maximum search</strong></p>
<p><strong>; lengths of 0 through 80.</strong></p>
<p><strong>;</strong></p>
<p><strong>SearchTable label word</strong></p>
<p><strong>dw NoMatch ;we never match on a</strong></p>
<p><strong>; maximum length of 0</strong></p>
<p><strong>BLOCK_NUMBER=MAX_SEARCH_LENGTH-1</strong></p>
<p><strong>rept MAX_SEARCH_LENGTH</strong></p>
<p><strong>MAKE_CHECK_CHAR_LABEL %BLOCK_NUMBER</strong></p>
<p><strong>BLOCK_NUMBER=BLOCK_NUMBER-1</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>SearchNBytes proc near</strong></p>
<p><strong>mov ah,al ;we’ll need AL for LODSB</strong></p>
<p><strong>cmp bx,MAX_SEARCH_LENGTH</strong></p>
<p><strong>ja NoMatch ;if the maximum length’s</strong></p>
<p><strong>; too long for the in-line</strong></p>
<p><strong>; code, return a no-match</strong></p>
<p><strong>; status</strong></p>
<p><strong>shl bx,1 ;*2 to look up in word-sized</strong></p>
<p><strong>; table</strong></p>
<p><strong>jmp [SearchTable+bx] ;branch into the in-line</strong></p>
<p><strong>; code to do the search</strong></p>
<p><strong>;</strong></p>
<p><strong>; No match was found.</strong></p>
<p><strong>;</strong></p>
<p><strong>NoMatch:</strong></p>
<p><strong>sub si,si ;return no-match status</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>; A match was found.</strong></p>
<p><strong>;</strong></p>
<p><strong>MatchFound:</strong></p>
<p><strong>dec si ;point back to matching</strong></p>
<p><strong>; location</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>; This is the in-line code that actually does the search.</strong></p>
<p><strong>; Each repetition is uniquely labelled, with labels</strong></p>
<p><strong>; CheckChar0 through CheckChar79.</strong></p>
<p><strong>;</strong></p>
<p><strong>BLOCK_NUMBER=0</strong></p>
<p><strong>;</strong></p>
<p><strong>; These in-line code blocks use 1-byte displacements</strong></p>
<p><strong>; whenever possible to branch backward; otherwise 2-byte</strong></p>
<p><strong>; displacements are used to branch backwards, with</strong></p>
<p><strong>; conditional jumps around unconditional jumps.</strong></p>
<p><strong>;</strong></p>
<p><strong>rept MAX_SEARCH_LENGTH-14</strong></p>
<p><strong>CHECK_CHAR %BLOCK_NUMBER</strong></p>
<p><strong>BLOCK_NUMBER=BLOCK_NUMBER+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; These in-line code blocks use 1-byte displacements to</strong></p>
<p><strong>; branch forward.</strong></p>
<p><strong>;</strong></p>
<p><strong>rept 14</strong></p>
<p><strong>CHECK_CHAR2 %BLOCK_NUMBER</strong></p>
<p><strong>BLOCK_NUMBER=BLOCK_NUMBER+1</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; If we make it here, we haven’t found the character.</strong></p>
<p><strong>;</strong></p>
<p><strong>NoMatch2:</strong></p>
<p><strong>sub si,si ;return no-match status</strong></p>
<p><strong>ret</strong></p>
<p><strong>;</strong></p>
<p><strong>; A match was found.</strong></p>
<p><strong>;</strong></p>
<p><strong>MatchFound2:</strong></p>
<p><strong>dec si ;point back to matching</strong></p>
<p><strong>; location</strong></p>
<p><strong>ret</strong></p>
<p><strong>SearchNBytes endp</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>mov al,‘Q’</strong></p>
<p><strong>mov bx,20 ;search up to the</strong></p>
<p><strong>mov si,offset TestString ; first 20 bytes of</strong></p>
<p><strong>call SearchNBytes ; TestString for ‘Q’</strong></p>
<p><strong>mov al,‘z’</strong></p>
<p><strong>mov bx,80 ;search up to the</strong></p>
<p><strong>mov si,offset TestString ; first 80 bytes of</strong></p>
<p><strong>call SearchNBytes ; TestString for ‘z’</strong></p>
<p><strong>mov al,‘a’</strong></p>
<p><strong>mov bx,10 ;search up to the</strong></p>
<p><strong>mov si,offset TestString ; first 10 bytes of</strong></p>
<p><strong>call SearchNBytes ; TestString for ‘a’</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-15-1" class="level2">
<h2>Listing 15-1</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 15-1 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>;</strong></p>
<p><strong>;</strong></p>
<p><strong>;</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>even ;always make sure word-sized memory</strong></p>
<p><strong>; variables are word-aLigned!</strong></p>
<p><strong>WordVar dw 0</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>mov [WordVar],1</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-15-2" class="level2">
<h2>Listing 15-2</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 15-2 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of accesses to word-sized</strong></p>
<p><strong>; variables that start at odd addresses (are not</strong></p>
<p><strong>; Word-aLigned).</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>push ds</strong></p>
<p><strong>pop es</strong></p>
<p><strong>mov si,1 ;source and destination are the same</strong></p>
<p><strong>mov di,si ; and both are not word-aLigned</strong></p>
<p><strong>mov cx,1000 ;move 1000 words</strong></p>
<p><strong>cld</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rep movsw</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-15-3" class="level2">
<h2>Listing 15-3</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 15-3 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of accesses to word-sized</strong></p>
<p><strong>; variables that start at even addresses (are word-aLigned).</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip</strong></p>
<p><strong>push ds</strong></p>
<p><strong>pop es</strong></p>
<p><strong>mov si,si ;source and destination are the same</strong></p>
<p><strong>mov di,si ; and both are word-aLigned</strong></p>
<p><strong>mov cx,1000 ;move 1000 words</strong></p>
<p><strong>cld</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rep movsw</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-15-4" class="level2">
<h2>Listing 15-4</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 15-4 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of adding an immediate value</strong></p>
<p><strong>; to a register, for comparison with Listing 15-5, which</strong></p>
<p><strong>; adds an immediate value to a memory variable.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>add dx,100h</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="listing-15-5" class="level2">
<h2>Listing 15-5</h2>
<p><strong>;</strong></p>
<p><strong>; *** Listing 15-5 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Measures the performance of adding an immediate value</strong></p>
<p><strong>; to a memory variable, for comparison with listing 15-4,</strong></p>
<p><strong>; which adds an immediate value to a register.</strong></p>
<p><strong>;</strong></p>
<p><strong>jmp Skip</strong></p>
<p><strong>;</strong></p>
<p><strong>even ;always make sure word-sized memory</strong></p>
<p><strong>; Variables are word-aLigned!</strong></p>
<p><strong>WordVar dw 0</strong></p>
<p><strong>;</strong></p>
<p><strong>Skip:</strong></p>
<p><strong>call ZTimerOn</strong></p>
<p><strong>rept 1000</strong></p>
<p><strong>add [WordVar],100h</strong></p>
<p><strong>endm</strong></p>
<p><strong>call ZTimerOff</strong></p>
</section>
<section id="lztest" class="level2">
<h2>LZTEST</h2>
<p><strong>; LZTEST</strong></p>
<p><strong>;</strong></p>
<p><strong>; *** Listing 2-6 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Program to measure performance of code that takes longer than</strong></p>
<p><strong>; 54 ms to execute. (LZTEST.ASM)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Link with LZTIMER.ASM (Listing 2-5). LZTEST.BAT (Listing 2-7)</strong></p>
<p><strong>; can be used to assemble and link both files. Code to be</strong></p>
<p><strong>; measured must be in the file TESTCODE; Listing 2-8 shows</strong></p>
<p><strong>; a sample TESTCODE file.</strong></p>
<p><strong>;</strong></p>
<p><strong>; By Michael Abrash 4/26/89</strong></p>
<p><strong>;</strong></p>
<p><strong>mystack segment para stack ‘STACK’</strong></p>
<p><strong>db 512 dup(?)</strong></p>
<p><strong>mystack ends</strong></p>
<p><strong>;</strong></p>
<p><strong>Code segment para public ‘CODE’</strong></p>
<p><strong>assume cs:Code, ds:Code</strong></p>
<p><strong>extrn ZTimerOn:near, ZTimerOff:near, ZTimerReport:near</strong></p>
<p><strong>Start proc near</strong></p>
<p><strong>push cs</strong></p>
<p><strong>pop ds ;point DS to the code segment,</strong></p>
<p><strong>; so data as well as code can easily</strong></p>
<p><strong>; be included in TESTCODE</strong></p>
<p><strong>;</strong></p>
<p><strong>; Delay for 6-7 seconds, to let the Enter keystroke that started the</strong></p>
<p><strong>; program come back up.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ah,2ch</strong></p>
<p><strong>int 21h ;get the current time</strong></p>
<p><strong>mov bh,dh ;set the current time aside</strong></p>
<p><strong>DelayLoop:</strong></p>
<p><strong>mov ah,2ch</strong></p>
<p><strong>push bx ;preserve start time</strong></p>
<p><strong>int 21h ;get time</strong></p>
<p><strong>pop bx ;retrieve start time</strong></p>
<p><strong>cmp dh,bh ;is the new seconds count less than</strong></p>
<p><strong>; the start seconds count?</strong></p>
<p><strong>jnb CheckDelayTime ;no</strong></p>
<p><strong>add dh,60 ;yes, a minute must have turned over,</strong></p>
<p><strong>; so add one minute</strong></p>
<p><strong>CheckDelayTime:</strong></p>
<p><strong>sub dh,bh ;get time that’s passed</strong></p>
<p><strong>cmp dh,7 ;has it been more than 6 seconds yet?</strong></p>
<p><strong>jb DelayLoop ;not yet</strong></p>
<p><strong>;</strong></p>
<p><strong>include TESTCODE ;code to be measured, including calls</strong></p>
<p><strong>; to ZTimerOn and ZTimerOff</strong></p>
<p><strong>;</strong></p>
<p><strong>; Display the results.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerReport</strong></p>
<p><strong>;</strong></p>
<p><strong>; Terminate the program.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ah,4ch</strong></p>
<p><strong>int 21h</strong></p>
<p><strong>Start endp</strong></p>
<p><strong>Code ends</strong></p>
<p><strong>end Start</strong></p>
</section>
<section id="lztime.bat" class="level2">
<h2>LZTIME.BAT</h2>
<p><strong>LZTIME.BAT</strong></p>
<p><strong>echo off</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem *** Listing 2-7 ***</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem ***************************************************************</strong></p>
<p><strong>rem * Batch file LZTIME.BAT, which builds and runs the *</strong></p>
<p><strong>rem * long-period Zen timer program LZTEST.EXE to time the code *</strong></p>
<p><strong>rem * named as the command-line parameter. Listing 2-5 must be *</strong></p>
<p><strong>rem * named LZTIMER.ASM, and Listing 2-6 must be named *</strong></p>
<p><strong>rem * LZTEST.ASM. To time the code in LST2-8, you’d type the *</strong></p>
<p><strong>rem * DOS command: *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * lztime lst2-8 *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * Note that MASM and LINK must be in the current directory or *</strong></p>
<p><strong>rem * on the current path in order for this batch file to work. *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * This batch file can be speeded up by assembling LZTIMER.ASM *</strong></p>
<p><strong>rem * once, then removing the lines: *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * masm lztimer; *</strong></p>
<p><strong>rem * if errorlevel 1 goto errorend *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * from this file. *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * By Michael Abrash 4/26/89 *</strong></p>
<p><strong>rem ***************************************************************</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem Make sure a file to test was specified.</strong></p>
<p><strong>rem</strong></p>
<p><strong>if not x%1==x goto ckexist</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>echo * Please specify a file to test. *</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>goto end</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem Make sure the file exists.</strong></p>
<p><strong>rem</strong></p>
<p><strong>:ckexist</strong></p>
<p><strong>if exist %1 goto docopy</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>echo * The specified file, “%1,” doesn’t exist.</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>goto end</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem copy the file to measure to TESTCODE.</strong></p>
<p><strong>:docopy</strong></p>
<p><strong>copy %1 testcode</strong></p>
<p><strong>masm lztest;</strong></p>
<p><strong>if errorlevel 1 goto errorend</strong></p>
<p><strong>masm lztimer;</strong></p>
<p><strong>if errorlevel 1 goto errorend</strong></p>
<p><strong>link lztest+lztimer;</strong></p>
<p><strong>if errorlevel 1 goto errorend</strong></p>
<p><strong>lztest</strong></p>
<p><strong>goto end</strong></p>
<p><strong>:errorend</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>echo * An error occurred while building the long-period Zen timer. *</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>:end</strong></p>
</section>
<section id="lztime" class="level2">
<h2>LZTIME</h2>
<p><strong>; LZTIME</strong> <strong>;</strong> <strong>; *** Listing 2-5 ***</strong> <strong>;</strong></p>
<p><strong>; The long-period Zen timer. (LZTIMER.ASM)</strong></p>
<p><strong>; Uses the 8253 timer and the BIOS time-of-day count to time the</strong></p>
<p><strong>; performance of code that takes less than an hour to execute.</strong></p>
<p><strong>; Because interrupts are left on (in order to allow the timer</strong></p>
<p><strong>; interrupt to be recognized), this is less accurate than the</strong></p>
<p><strong>; precision Zen timer, so it is best used only to time code that takes</strong></p>
<p><strong>; more than about 54 milliseconds to execute (code that the precision</strong></p>
<p><strong>; Zen timer reports overflow on). Resolution is limited by the</strong></p>
<p><strong>; occurrence of timer interrupts.</strong></p>
<p><strong>;</strong></p>
<p><strong>; By Michael Abrash 4/26/89</strong></p>
<p><strong>;</strong></p>
<p><strong>; Externally callable routines:</strong></p>
<p><strong>;</strong></p>
<p><strong>; ZTimerOn: Saves the BIOS time of day count and starts the</strong></p>
<p><strong>; long-period Zen timer.</strong></p>
<p><strong>;</strong></p>
<p><strong>; ZTimerOff: Stops the long-period Zen timer and saves the timer</strong></p>
<p><strong>; count and the BIOS time-of-day count.</strong></p>
<p><strong>;</strong></p>
<p><strong>; ZTimerReport: Prints the time that passed between starting and</strong></p>
<p><strong>; stopping the timer.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: If either more than an hour passes or midnight falls between</strong></p>
<p><strong>; calls to ZTimerOn and ZTimerOff, an error is reported. For</strong></p>
<p><strong>; timing code that takes more than a few minutes to execute,</strong></p>
<p><strong>; either the DOS TIME command in a batch file before and after</strong></p>
<p><strong>; execution of the code to time or the use of the DOS</strong></p>
<p><strong>; time-of-day function in place of the long-period Zen timer is</strong></p>
<p><strong>; more than adequate.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: The PS/2 version is assembled by setting the symbol PS2 to 1.</strong></p>
<p><strong>; PS2 must be set to 1 on PS/2 computers because the PS/2’s</strong></p>
<p><strong>; timers are not compatible with an undocumented timer-stopping</strong></p>
<p><strong>; feature of the 8253; the alternative timing approach that</strong></p>
<p><strong>; must be used on PS/2 computers leaves a short window</strong></p>
<p><strong>; during which the timer 0 count and the BIOS timer count may</strong></p>
<p><strong>; not be synchronized. You should also set the PS2 symbol to</strong></p>
<p><strong>; 1 if you’re getting erratic or obviously incorrect results.</strong></p>
<p><strong>; When the PS/2 version is used, each block of code being timed</strong></p>
<p><strong>; should be run several times, with at least two similar</strong></p>
<p><strong>; readings required to establish a true measurement.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: When PS2 is 0, the code relies on an undocumented 8253</strong></p>
<p><strong>; feature. It is possible that the 8253 (or whatever chip</strong></p>
<p><strong>; is emulating the 8253) may be put into an undefined or</strong></p>
<p><strong>; incorrect state when this feature is used. If your computer</strong></p>
<p><strong>; displays any hint of erratic behavior after the long-period</strong></p>
<p><strong>; Zen timer is used, such as the floppy drive failing to</strong></p>
<p><strong>; operate properly, reboot the system, set PS2 to 1 and</strong></p>
<p><strong>; leave it that way.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Interrupts must not be disabled for more than 54 ms at a</strong></p>
<p><strong>; stretch during the timing interval. Because interrupts</strong></p>
<p><strong>; are enabled, keys, mice, and other devices that generate</strong></p>
<p><strong>; interrupts should not be used during the timing interval.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Any extra code running off the timer interrupt (such as</strong></p>
<p><strong>; some memory-resident utilities) wilLincrease the time</strong></p>
<p><strong>; measured by the Zen timer.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: These routines can introduce inaccuracies of up to a few</strong></p>
<p><strong>; tenths of a second into the system clock count for each</strong></p>
<p><strong>; code section timed. Consequently, it’s a good idea to</strong></p>
<p><strong>; reboot at the conclusion of timing sessions. (The</strong></p>
<p><strong>; battery-backed clock, if any, is not affected by the Zen</strong></p>
<p><strong>; timer.)</strong></p>
<p><strong>;</strong></p>
<p><strong>; All registers and all flags are preserved by all routines.</strong></p>
<p><strong>;</strong></p>
<p> </p>
<p><strong>Code segment word public ‘CODE’</strong></p>
<p><strong>assume cs:Code, ds:nothing</strong></p>
<p><strong>public ZTimerOn, ZTimerOff, ZTimerReport</strong></p>
<p> </p>
<p><strong>;</strong></p>
<p><strong>; Set to 0 to assemble for use on a fully 8253-compatible</strong></p>
<p><strong>; system. Set to 1 to assemble for use on non-8253-compatible</strong></p>
<p><strong>; systems, including PS/2 computers. In general, leave this</strong></p>
<p><strong>; set to 0 on non-PS/2 computers unless you get inconsistent</strong></p>
<p><strong>; or inaccurate readings.</strong></p>
<p><strong>;</strong></p>
<p><strong>PS2 equ 0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Base address of the 8253 timer chip.</strong></p>
<p><strong>;</strong></p>
<p><strong>BASE_8253 equ 40h</strong></p>
<p><strong>;</strong></p>
<p><strong>; The address of the timer 0 count registers in the 8253.</strong></p>
<p><strong>;</strong></p>
<p><strong>TIMER_0_8253 equ BASE_8253 + 0</strong></p>
<p><strong>;</strong></p>
<p><strong>; The address of the mode register in the 8253.</strong></p>
<p><strong>;</strong></p>
<p><strong>MODE_8253 equ BASE_8253 + 3</strong></p>
<p><strong>;</strong></p>
<p><strong>; The address of the BIOS timer count variable in the BIOS</strong></p>
<p><strong>; data segment.</strong></p>
<p><strong>;</strong></p>
<p><strong>TIMER_COUNT equ 46ch</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to emulate a POPF instruction in order to fix the bug in some</strong></p>
<p><strong>; 80286 chips which allows interrupts to occur during a POPF even when</strong></p>
<p><strong>; interrupts remain disabled.</strong></p>
<p><strong>;</strong></p>
<p><strong>MPOPF macro</strong></p>
<p><strong>local p1, p2</strong></p>
<p><strong>jmp short p2</strong></p>
<p><strong>p1: iret ;jump to pushed address &amp; pop flags</strong></p>
<p><strong>p2: push cs ;construct far return address to</strong></p>
<p><strong>call p1 ; the next instruction</strong></p>
<p><strong>endm</strong></p>
<p> </p>
<p><strong>;</strong></p>
<p><strong>; Macro to delay briefly to ensure that enough time has elapsed</strong></p>
<p><strong>; between successive I/O accesses so that the device being accessed</strong></p>
<p><strong>; can respond to both accesses even on a very fast PC.</strong></p>
<p><strong>;</strong></p>
<p><strong>DELAY macro</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>endm</strong></p>
<p> </p>
<p><strong>StartBIOSCountLow dw ? ;BIOS count low word at the</strong></p>
<p><strong>; start of the timing period</strong></p>
<p><strong>StartBIOSCountHigh dw ? ;BIOS count high word at the</strong></p>
<p><strong>; start of the timing period</strong></p>
<p><strong>EndBIOSCountLow dw ? ;BIOS count low word at the</strong></p>
<p><strong>; end of the timing period</strong></p>
<p><strong>EndBIOSCountHigh dw ? ;BIOS count high word at the</strong></p>
<p><strong>; end of the timing period</strong></p>
<p><strong>EndTimedCount dw ? ;timer 0 count at the end of</strong></p>
<p><strong>; the timing period</strong></p>
<p><strong>ReferenceCount dw ? ;number of counts required to</strong></p>
<p><strong>; execute timer overhead code</strong></p>
<p><strong>;</strong></p>
<p><strong>; String printed to report results.</strong></p>
<p><strong>;</strong></p>
<p><strong>OutputStr label byte</strong></p>
<p><strong>db 0dh, 0ah, ‘Timed count:’</strong></p>
<p><strong>TimedCountStr db 10 dup (?)</strong></p>
<p><strong>db ‘microseconds’, 0dh, 0ah</strong></p>
<p><strong>db ‘$’</strong></p>
<p><strong>;</strong></p>
<p><strong>; Temporary storage for timed count as it’s divided down by powers</strong></p>
<p><strong>; of ten when converting from doubleword binary to ASCII.</strong></p>
<p><strong>;</strong></p>
<p><strong>CurrentCountLow dw ?</strong></p>
<p><strong>CurrentCountHigh dw ?</strong></p>
<p><strong>;</strong></p>
<p><strong>; Powers of ten table used to perform division by 10 when doing</strong></p>
<p><strong>; doubleword conversion from binary to ASCII.</strong></p>
<p><strong>;</strong></p>
<p><strong>PowersOfTen label word</strong></p>
<p><strong>dd 1</strong></p>
<p><strong>dd 10</strong></p>
<p><strong>dd 100</strong></p>
<p><strong>dd 1000</strong></p>
<p><strong>dd 10000</strong></p>
<p><strong>dd 100000</strong></p>
<p><strong>dd 1000000</strong></p>
<p><strong>dd 10000000</strong></p>
<p><strong>dd 100000000</strong></p>
<p><strong>dd 1000000000</strong></p>
<p><strong>PowersOfTenEnd label word</strong></p>
<p><strong>;</strong></p>
<p><strong>; String printed to report that the high word of the BIOS count</strong></p>
<p><strong>; changed while timing (an hour elapsed or midnight was crossed),</strong></p>
<p><strong>; and so the count is invalid and the test needs to be rerun.</strong></p>
<p><strong>;</strong></p>
<p><strong>TurnOverStr label byte</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘****************************************************’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* Either midnight passed or an hour or more passed *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* while timing was in progress. If the former was *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* the case, please rerun the test; if the latter *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* was the case, the test code takes too long to *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* run to be timed by the long-period Zen timer. *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* Suggestions: use the DOS TIME command, the DOS *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* time function, or a watch. *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘****************************************************’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘$’</strong></p>
<p> </p>
<p><strong>;********************************************************************</strong></p>
<p><strong>;* Routine called to start timing. *</strong></p>
<p><strong>;********************************************************************</strong></p>
<p> </p>
<p><strong>ZTimerOn proc near</strong></p>
<p> </p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>push ax</strong></p>
<p><strong>pushf</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set timer 0 of the 8253 to mode 2 (divide-by-N), to cause</strong></p>
<p><strong>; linear counting rather than count-by-two counting. Also stops</strong></p>
<p><strong>; timer 0 until the timer count is loaded, except on PS/2</strong></p>
<p><strong>; computers.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00110100b ;mode 2</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set the timer count to 0, so we know we won’t get another</strong></p>
<p><strong>; timer interrupt right away.</strong></p>
<p><strong>; Note: this introduces an inaccuracy of up to 54 ms in the system</strong></p>
<p><strong>; clock count each time it is executed.</strong></p>
<p><strong>;</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>sub al,al</strong></p>
<p><strong>out TIMER_0_8253,al ;lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>out TIMER_0_8253,al ;msb</strong></p>
<p><strong>;</strong></p>
<p><strong>; In case interrupts are disabled, enable interrupts briefly to allow</strong></p>
<p><strong>; the interrupt generated when switching from mode 3 to mode 2 to be</strong></p>
<p><strong>; recognized. Interrupts must be enabled for at least 210 ns to allow</strong></p>
<p><strong>; time for that interrupt to occur. Here, 10 jumps are used for the</strong></p>
<p><strong>; delay to ensure that the delay time will be more than long enough</strong></p>
<p><strong>; even on a very fast PC.</strong></p>
<p><strong>;</strong></p>
<p><strong>pushf</strong></p>
<p><strong>sti</strong></p>
<p><strong>rept 10</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>endm</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>;</strong></p>
<p><strong>; Store the timing start BIOS count.</strong></p>
<p><strong>; (Since the timer count was just set to 0, the BIOS count will</strong></p>
<p><strong>; stay the same for the next 54 ms, so we don’t need to disable</strong></p>
<p><strong>; interrupts in order to avoid getting a half-changed count.)</strong></p>
<p><strong>;</strong></p>
<p><strong>push ds</strong></p>
<p><strong>sub ax,ax</strong></p>
<p><strong>mov ds,ax</strong></p>
<p>[**mov ax,ds:TIMER_COUNT+2]**</p>
<p>[**mov cs:StartBIOSCountHigh],ax**</p>
<p>[**mov ax,ds:TIMER_COUNT]**</p>
<p>[**mov cs:StartBIOSCountLow],ax**</p>
<p><strong>pop ds</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set the timer count to 0 again to start the timing interval.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00110100b ;set up to load initial</strong></p>
<p><strong>out MODE_8253,al ; timer count</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>sub al,al</strong></p>
<p><strong>out TIMER_0_8253,al ;load count lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>out TIMER_0_8253,al ;load count msb</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore the context of the program being timed and return to it.</strong></p>
<p><strong>;</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>ret</strong></p>
<p> </p>
<p><strong>ZTimerOn endp</strong></p>
<p> </p>
<p><strong>;********************************************************************</strong></p>
<p><strong>;* Routine called to stop timing and get count. *</strong></p>
<p><strong>;********************************************************************</strong></p>
<p> </p>
<p><strong>ZTimerOff proc near</strong></p>
<p> </p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>pushf</strong></p>
<p><strong>push ax</strong></p>
<p><strong>push cx</strong></p>
<p><strong>;</strong></p>
<p><strong>; In case interrupts are disabled, enable interrupts briefly to allow</strong></p>
<p><strong>; any pending timer interrupt to be handled. Interrupts must be</strong></p>
<p><strong>; enabled for at least 210 ns to allow time for that interrupt to</strong></p>
<p><strong>; occur. Here, 10 jumps are used for the delay to ensure that the</strong></p>
<p><strong>; delay time will be more than long enough even on a very fast PC.</strong></p>
<p><strong>;</strong></p>
<p><strong>sti</strong></p>
<p><strong>rept 10</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>endm</strong></p>
<p> </p>
<p><strong>;</strong></p>
<p><strong>; Latch the timer count.</strong></p>
<p><strong>;</strong></p>
<p> </p>
<p><strong>if PS2</strong></p>
<p> </p>
<p><strong>mov al,00000000b</strong></p>
<p><strong>out MODE_8253,al ;latch timer 0 count</strong></p>
<p><strong>;</strong></p>
<p><strong>; This is where a one-instruction-long window exists on the PS/2.</strong></p>
<p><strong>; The timer count and the BIOS count can lose synchronization;</strong></p>
<p><strong>; since the timer keeps counting after it’s latched, it can turn</strong></p>
<p><strong>; over right after it’s latched and cause the BIOS count to turn</strong></p>
<p><strong>; over before interrupts are disabled, leaving us with the timer</strong></p>
<p><strong>; count from before the timer turned over coupled with the BIOS</strong></p>
<p><strong>; count from after the timer turned over. The result is a count</strong></p>
<p><strong>; that’s 54 ms too long.</strong></p>
<p><strong>;</strong></p>
<p><strong> </strong></p>
<p><strong>else</strong></p>
<p> </p>
<p><strong>;</strong></p>
<p><strong>; Set timer 0 to mode 2 (divide-by-N), waiting for a 2-byte count</strong></p>
<p><strong>; load, which stops timer 0 until the count is loaded. (Only works</strong></p>
<p><strong>; on fully 8253-compatible chips.)</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00110100b ;mode 2</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>mov al,00000000b ;latch timer 0 count</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p> </p>
<p><strong>endif</strong></p>
<p> </p>
<p><strong>cli ;stop the BIOS count</strong></p>
<p><strong>;</strong></p>
<p><strong>; Read the BIOS count. (Since interrupts are disabled, the BIOS</strong></p>
<p><strong>; count won’t change.)</strong></p>
<p><strong>;</strong></p>
<p><strong>push ds</strong></p>
<p><strong>sub ax,ax</strong></p>
<p><strong>mov ds,ax</strong></p>
<p>[**mov ax,ds:TIMER_COUNT+2]**</p>
<p>[**mov cs:EndBIOSCountHigh],ax**</p>
<p>[**mov ax,ds:TIMER_COUNT]**</p>
<p>[**mov cs:EndBIOSCountLow],ax**</p>
<p><strong>pop ds</strong></p>
<p><strong>;</strong></p>
<p><strong>; Read the timer count and save it.</strong></p>
<p><strong>;</strong></p>
<p><strong>in al,TIMER_0_8253 ;lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>mov ah,al</strong></p>
<p><strong>in al,TIMER_0_8253 ;msb</strong></p>
<p><strong>xchg ah,al</strong></p>
<p><strong>neg ax ;convert from countdown</strong></p>
<p><strong>; remaining to elapsed</strong></p>
<p><strong>; count</strong></p>
<p>[**mov cs:EndTimedCount],ax**</p>
<p><strong>;</strong></p>
<p><strong>; Restart timer 0, which is still waiting for an initial count</strong></p>
<p><strong>; to be loaded.</strong></p>
<p><strong>;</strong></p>
<p> </p>
<p><strong>ife PS2</strong></p>
<p> </p>
<p><strong>DELAY</strong></p>
<p><strong>mov al,00110100b ;mode 2, waiting to load a</strong></p>
<p><strong>; 2-byte count</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>sub al,al</strong></p>
<p><strong>out TIMER_0_8253,al ;lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>mov al,ah</strong></p>
<p><strong>out TIMER_0_8253,al ;msb</strong></p>
<p><strong>DELAY</strong></p>
<p> </p>
<p><strong>endif</strong></p>
<p> </p>
<p><strong>sti ;let the BIOS count continue</strong></p>
<p><strong>;</strong></p>
<p><strong>; Time a zero-length code fragment, to get a reference for how</strong></p>
<p><strong>; much overhead this routine has. Time it 16 times and average it,</strong></p>
<p><strong>; for accuracy, rounding the result.</strong></p>
<p><strong>;</strong></p>
<p>[**mov cs:ReferenceCount],0**</p>
<p><strong>mov cx,16</strong></p>
<p><strong>cli ;interrupts off to allow a</strong></p>
<p><strong>; precise reference count</strong></p>
<p><strong>RefLoop:</strong></p>
<p><strong>call ReferenceZTimerOn</strong></p>
<p><strong>call ReferenceZTimerOff</strong></p>
<p><strong>loop RefLoop</strong></p>
<p><strong>sti</strong></p>
<p><strong>add cs:[ReferenceCount],8 ;total + (0.5 * 16)</strong></p>
<p><strong>mov cl,4</strong></p>
<p><strong>shr cs:[ReferenceCount],cl ;(total) / 16 + 0.5</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore the context of the program being timed and return to it.</strong></p>
<p><strong>;</strong></p>
<p><strong>pop cx</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>ret</strong></p>
<p> </p>
<p><strong>ZTimerOff endp</strong></p>
<p> </p>
<p><strong>;</strong></p>
<p><strong>; Called by ZTimerOff to start the timer for overhead measurements.</strong></p>
<p><strong>;</strong></p>
<p> </p>
<p><strong>ReferenceZTimerOn proc near</strong></p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>push ax</strong></p>
<p><strong>pushf</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set timer 0 of the 8253 to mode 2 (divide-by-N), to cause</strong></p>
<p><strong>; linear counting rather than count-by-two counting.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00110100b ;mode 2</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set the timer count to 0.</strong></p>
<p><strong>;</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>sub al,al</strong></p>
<p><strong>out TIMER_0_8253,al ;lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>out TIMER_0_8253,al ;msb</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore the context of the program being timed and return to it.</strong></p>
<p><strong>;</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>ret</strong></p>
<p> </p>
<p><strong>ReferenceZTimerOn endp</strong></p>
<p> </p>
<p><strong>;</strong></p>
<p><strong>; Called by ZTimerOff to stop the timer and add the result to</strong></p>
<p><strong>; ReferenceCount for overhead measurements. Doesn’t need to look</strong></p>
<p><strong>; at the BIOS count because timing a zero-length code fragment</strong></p>
<p><strong>; isn’t going to take anywhere near 54 ms.</strong></p>
<p><strong>;</strong></p>
<p> </p>
<p><strong>ReferenceZTimerOff proc near</strong></p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>pushf</strong></p>
<p><strong>push ax</strong></p>
<p><strong>push cx</strong></p>
<p> </p>
<p><strong>;</strong></p>
<p><strong>; Match the interrupt-window delay in ZTimerOff.</strong></p>
<p><strong>;</strong></p>
<p><strong>sti</strong></p>
<p><strong>rept 10</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>endm</strong></p>
<p> </p>
<p><strong>mov al,00000000b</strong></p>
<p><strong>out MODE_8253,al ;latch timer</strong></p>
<p><strong>;</strong></p>
<p><strong>; Read the count and save it.</strong></p>
<p><strong>;</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>in al,TIMER_0_8253 ;lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>mov ah,al</strong></p>
<p><strong>in al,TIMER_0_8253 ;msb</strong></p>
<p><strong>xchg ah,al</strong></p>
<p><strong>neg ax ;convert from countdown</strong></p>
<p><strong>; remaining to elapsed</strong></p>
<p><strong>; count</strong></p>
<p>[**add cs:ReferenceCount],ax**</p>
<p><strong>;</strong></p>
<p><strong>; Restore the context and return.</strong></p>
<p><strong>;</strong></p>
<p><strong>pop cx</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>ret</strong></p>
<p> </p>
<p><strong>ReferenceZTimerOff endp</strong></p>
<p> </p>
<p><strong>;********************************************************************</strong></p>
<p><strong>;* Routine called to report timing results. *</strong></p>
<p><strong>;********************************************************************</strong></p>
<p> </p>
<p><strong>ZTimerReport proc near</strong></p>
<p> </p>
<p><strong>pushf</strong></p>
<p><strong>push ax</strong></p>
<p><strong>push bx</strong></p>
<p><strong>push cx</strong></p>
<p><strong>push dx</strong></p>
<p><strong>push si</strong></p>
<p><strong>push di</strong></p>
<p><strong>push ds</strong></p>
<p><strong>;</strong></p>
<p><strong>push cs ;DOS functions require that DS point</strong></p>
<p><strong>pop ds ; to text to be displayed on the screen</strong></p>
<p><strong>assume ds:Code</strong></p>
<p><strong>;</strong></p>
<p><strong>; See if midnight or more than an hour passed during timing. If so,</strong></p>
<p><strong>; notify the user.</strong></p>
<p><strong>;</strong></p>
<p>[**mov ax,StartBIOSCountHigh]**</p>
<p>[**cmp ax,EndBIOSCountHigh]**</p>
<p><strong>jz CalcBIOSTime ;hour count didn’t change,</strong></p>
<p><strong>; so everything’s fine</strong></p>
<p><strong>inc ax</strong></p>
<p>[**cmp ax,EndBIOSCountHigh]**</p>
<p><strong>jnz TestTooLong ;midnight or two hour</strong></p>
<p><strong>; boundaries passed, so the</strong></p>
<p><strong>; results are no good</strong></p>
<p>[**mov ax,EndBIOSCountLow]**</p>
<p>[**cmp ax,StartBIOSCountLow]**</p>
<p><strong>jb CalcBIOSTime ;a single hour boundary</strong></p>
<p><strong>; passed-that’s OK, so long as</strong></p>
<p><strong>; the total time wasn’t more</strong></p>
<p><strong>; than an hour</strong></p>
<p> </p>
<p><strong>;</strong></p>
<p><strong>; Over an hour elapsed or midnight passed during timing, which</strong></p>
<p><strong>; renders the results invalid. Notify the user. This misses the</strong></p>
<p><strong>; case where a multiple of 24 hours has passed, but we’ll rely</strong></p>
<p><strong>; on the perspicacity of the user to detect that case.</strong></p>
<p><strong>;</strong></p>
<p><strong>TestTooLong:</strong></p>
<p><strong>mov ah,9</strong></p>
<p><strong>mov dx,offset TurnOverStr</strong></p>
<p><strong>int 21h</strong></p>
<p><strong>jmp short ZTimerReportDone</strong></p>
<p><strong>;</strong></p>
<p><strong>; Convert the BIOS time to microseconds.</strong></p>
<p><strong>;</strong></p>
<p><strong>CalcBIOSTime:</strong></p>
<p>[**mov ax,EndBIOSCountLow]**</p>
<p>[**sub ax,StartBIOSCountLow]**</p>
<p><strong>mov dx,54925 ;number of microseconds each</strong></p>
<p><strong>; BIOS count represents</strong></p>
<p><strong>mul dx</strong></p>
<p><strong>mov bx,ax ;set aside BIOS count in</strong></p>
<p><strong>mov cx,dx ; microseconds</strong></p>
<p><strong>;</strong></p>
<p><strong>; Convert timer count to microseconds.</strong></p>
<p><strong>;</strong></p>
<p>[**mov ax,EndTimedCount]**</p>
<p><strong>mov si,8381</strong></p>
<p><strong>mul si</strong></p>
<p><strong>mov si,10000</strong></p>
<p><strong>div si ;* .8381 = * 8381 / 10000</strong></p>
<p><strong>;</strong></p>
<p><strong>; Add timer and BIOS counts together to get an overall time in</strong></p>
<p><strong>; microseconds.</strong></p>
<p><strong>;</strong></p>
<p><strong>add bx,ax</strong></p>
<p><strong>adc cx,0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Subtract the timer overhead and save the result.</strong></p>
<p><strong>;</strong></p>
<p>[**mov ax,ReferenceCount]**</p>
<p><strong>mov si,8381 ;convert the reference count</strong></p>
<p><strong>mul si ; to microseconds</strong></p>
<p><strong>mov si,10000</strong></p>
<p><strong>div si ;* .8381 = * 8381 / 10000</strong></p>
<p><strong>sub bx,ax</strong></p>
<p><strong>sbb cx,0</strong></p>
<p>[**mov CurrentCountLow],bx**</p>
<p>[**mov CurrentCountHigh],cx**</p>
<p><strong>;</strong></p>
<p><strong>; Convert the result to an ASCII string by trial subtractions of</strong></p>
<p><strong>; powers of 10.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov di,offset PowersOfTenEnd -offset PowersOfTen -4</strong></p>
<p><strong>mov si,offset TimedCountStr</strong></p>
<p><strong>CTSNextDigit:</strong></p>
<p><strong>mov bl,‘0’</strong></p>
<p><strong>CTSLoop:</strong></p>
<p>[**mov ax,CurrentCountLow]**</p>
<p>[**mov dx,CurrentCountHigh]**</p>
<p>[**sub ax,PowersOfTendi]**</p>
<p>[**sbb dx,PowersOfTendi+2]**</p>
<p><strong>jc CTSNextPowerDown</strong></p>
<p><strong>inc bl</strong></p>
<p>[**mov CurrentCountLow],ax**</p>
<p>[**mov CurrentCountHigh],dx**</p>
<p><strong>jmp CTSLoop</strong></p>
<p><strong>CTSNextPowerDown:</strong></p>
<p><strong>mov [si],bl</strong></p>
<p><strong>inc si</strong></p>
<p><strong>sub di,4</strong></p>
<p><strong>jns CTSNextDigit</strong></p>
<p><strong>;</strong></p>
<p><strong>;</strong></p>
<p><strong>; Print the results.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ah,9</strong></p>
<p><strong>mov dx,offset OutputStr</strong></p>
<p><strong>int 21h</strong></p>
<p><strong>;</strong></p>
<p><strong>ZTimerReportDone:</strong></p>
<p><strong>pop ds</strong></p>
<p><strong>pop di</strong></p>
<p><strong>pop si</strong></p>
<p><strong>pop dx</strong></p>
<p><strong>pop cx</strong></p>
<p><strong>pop bx</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>ret</strong></p>
<p> </p>
<p><strong>ZTimerReport endp</strong></p>
<p> </p>
<p><strong>Code ends</strong></p>
<p><strong>end</strong></p>
<p> </p>
<p> </p>
</section>
<section id="lztimer" class="level2">
<h2>LZTIMER</h2>
<p><strong>; LZTIMER</strong></p>
<p><strong>;</strong></p>
<p><strong>; *** Listing 2-5 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; The long-period Zen timer. (LZTIMER.ASM)</strong></p>
<p><strong>; Uses the 8253 timer and the BIOS time-of-day count to time the</strong></p>
<p><strong>; performance of code that takes less than an hour to execute.</strong></p>
<p><strong>; Because interrupts are left on (in order to allow the timer</strong></p>
<p><strong>; interrupt to be recognized), this is less accurate than the</strong></p>
<p><strong>; precision Zen timer, so it is best used only to time code that takes</strong></p>
<p><strong>; more than about 54 milliseconds to execute (code that the precision</strong></p>
<p><strong>; Zen timer reports overflow on). Resolution is limited by the</strong></p>
<p><strong>; occurrence of timer interrupts.</strong></p>
<p><strong>;</strong></p>
<p><strong>; By Michael Abrash 4/26/89</strong></p>
<p><strong>;</strong></p>
<p><strong>; Externally callable routines:</strong></p>
<p><strong>;</strong></p>
<p><strong>; ZTimerOn: Saves the BIOS time of day count and starts the</strong></p>
<p><strong>; long-period Zen timer.</strong></p>
<p><strong>;</strong></p>
<p><strong>; ZTimerOff: Stops the long-period Zen timer and saves the timer</strong></p>
<p><strong>; count and the BIOS time-of-day count.</strong></p>
<p><strong>;</strong></p>
<p><strong>; ZTimerReport: Prints the time that passed between starting and</strong></p>
<p><strong>; stopping the timer.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: If either more than an hour passes or midnight falls between</strong></p>
<p><strong>; calls to ZTimerOn and ZTimerOff, an error is reported. For</strong></p>
<p><strong>; timing code that takes more than a few minutes to execute,</strong></p>
<p><strong>; either the DOS TIME command in a batch file before and after</strong></p>
<p><strong>; execution of the code to time or the use of the DOS</strong></p>
<p><strong>; time-of-day function in place of the long-period Zen timer is</strong></p>
<p><strong>; more than adequate.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: The PS/2 version is assembled by setting the symbol PS2 to 1.</strong></p>
<p><strong>; PS2 must be set to 1 on PS/2 computers because the PS/2’s</strong></p>
<p><strong>; timers are not compatible with an undocumented timer-stopping</strong></p>
<p><strong>; feature of the 8253; the alternative timing approach that</strong></p>
<p><strong>; must be used on PS/2 computers leaves a short window</strong></p>
<p><strong>; during which the timer 0 count and the BIOS timer count may</strong></p>
<p><strong>; not be synchronized. You should also set the PS2 symbol to</strong></p>
<p><strong>; 1 if you’re getting erratic or obviously incorrect results.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: When PS2 is 0, the code relies on an undocumented 8253</strong></p>
<p><strong>; feature to get more reliable readings. It is possible that</strong></p>
<p><strong>; the 8253 (or whatever chip is emulating the 8253) may be put</strong></p>
<p><strong>; into an undefined or incorrect state when this feature is</strong></p>
<p><strong>; used.</strong></p>
<p><strong>;</strong></p>
<p><strong>; ***************************************************************</strong></p>
<p><strong>; * If your computer displays any hint of erratic behavior *</strong></p>
<p><strong>; * after the long-period Zen timer is used, such as the floppy *</strong></p>
<p><strong>; * drive failing to operate properly, reboot the system, set *</strong></p>
<p><strong>; * PS2 to 1 and leave it that way! *</strong></p>
<p><strong>; ***************************************************************</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Each block of code being timed should ideally be run several</strong></p>
<p><strong>; times, with at least two similar readings required to</strong></p>
<p><strong>; establish a true measurement, in order to eliminate any</strong></p>
<p><strong>; variability caused by interrupts.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Interrupts must not be disabled for more than 54 ms at a</strong></p>
<p><strong>; stretch during the timing interval. Because interrupts</strong></p>
<p><strong>; are enabled, keys, mice, and other devices that generate</strong></p>
<p><strong>; interrupts should not be used during the timing interval.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Any extra code running off the timer interrupt (such as</strong></p>
<p><strong>; some memory-resident utilities) wilLincrease the time</strong></p>
<p><strong>; measured by the Zen timer.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: These routines can introduce inaccuracies of up to a few</strong></p>
<p><strong>; tenths of a second into the system clock count for each</strong></p>
<p><strong>; code section timed. Consequently, it’s a good idea to</strong></p>
<p><strong>; reboot at the conclusion of timing sessions. (The</strong></p>
<p><strong>; battery-backed clock, if any, is not affected by the Zen</strong></p>
<p><strong>; timer.)</strong></p>
<p><strong>;</strong></p>
<p><strong>; All registers and all flags are preserved by all routines.</strong></p>
<p><strong>;</strong></p>
<p><strong>Code segment word public ‘CODE’</strong></p>
<p><strong>assume cs:Code, ds:nothing</strong></p>
<p><strong>public ZTimerOn, ZTimerOff, ZTimerReport</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set PS2 to 0 to assemble for use on a fully 8253-compatible</strong></p>
<p><strong>; system; when PS2 is 0, the readings are more reliable if the</strong></p>
<p><strong>; computer supports the undocumented timer-stopping feature,</strong></p>
<p><strong>; but may be badly off if that feature is not supported. In</strong></p>
<p><strong>; fact, timer-stopping may interfere with your computer’s</strong></p>
<p><strong>; overall operation by putting the 8253 into an undefined or</strong></p>
<p><strong>; incorrect state. Use with caution!!!</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set PS2 to 1 to assemble for use on non-8253-compatible</strong></p>
<p><strong>; systems, including PS/2 computers; when PS2 is 1, readings</strong></p>
<p><strong>; may occasionally be off by 54 ms, but the code will work</strong></p>
<p><strong>; properly on all systems.</strong></p>
<p><strong>;</strong></p>
<p><strong>; A setting of 1 is safer and will work on more systems,</strong></p>
<p><strong>; while a setting of 0 produces more reliable results in systems</strong></p>
<p><strong>; which support the undocumented timer-stopping feature of the</strong></p>
<p><strong>; 8253. The choice is yours.</strong></p>
<p><strong>;</strong></p>
<p><strong>PS2 equ 1</strong></p>
<p><strong>;</strong></p>
<p><strong>; Base address of the 8253 timer chip.</strong></p>
<p><strong>;</strong></p>
<p><strong>BASE_8253 equ 40h</strong></p>
<p><strong>;</strong></p>
<p><strong>; The address of the timer 0 count registers in the 8253.</strong></p>
<p><strong>;</strong></p>
<p><strong>TIMER_0_8253 equ BASE_8253 + 0</strong></p>
<p><strong>;</strong></p>
<p><strong>; The address of the mode register in the 8253.</strong></p>
<p><strong>;</strong></p>
<p><strong>MODE_8253 equ BASE_8253 + 3</strong></p>
<p><strong>;</strong></p>
<p><strong>; The address of the BIOS timer count variable in the BIOS</strong></p>
<p><strong>; data segment.</strong></p>
<p><strong>;</strong></p>
<p><strong>TIMER_COUNT equ 46ch</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to emulate a POPF instruction in order to fix the bug in some</strong></p>
<p><strong>; 80286 chips which allows interrupts to occur during a POPF even when</strong></p>
<p><strong>; interrupts remain disabled.</strong></p>
<p><strong>;</strong></p>
<p><strong>MPOPF macro</strong></p>
<p><strong>local p1, p2</strong></p>
<p><strong>jmp short p2</strong></p>
<p><strong>p1: iret ;jump to pushed address &amp; pop flags</strong></p>
<p><strong>p2: push cs ;construct far return address to</strong></p>
<p><strong>call p1 ; the next instruction</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to delay briefly to ensure that enough time has elapsed</strong></p>
<p><strong>; between successive I/O accesses so that the device being accessed</strong></p>
<p><strong>; can respond to both accesses even on a very fast PC.</strong></p>
<p><strong>;</strong></p>
<p><strong>DELAY macro</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>endm</strong></p>
<p><strong>StartBIOSCountLow dw ? ;BIOS count low word at the</strong></p>
<p><strong>; start of the timing period</strong></p>
<p><strong>StartBIOSCountHigh dw ? ;BIOS count high word at the</strong></p>
<p><strong>; start of the timing period</strong></p>
<p><strong>EndBIOSCountLow dw ? ;BIOS count low word at the</strong></p>
<p><strong>; end of the timing period</strong></p>
<p><strong>EndBIOSCountHigh dw ? ;BIOS count high word at the</strong></p>
<p><strong>; end of the timing period</strong></p>
<p><strong>EndTimedCount dw ? ;timer 0 count at the end of</strong></p>
<p><strong>; the timing period</strong></p>
<p><strong>ReferenceCount dw ? ;number of counts required to</strong></p>
<p><strong>; execute timer overhead code</strong></p>
<p><strong>;</strong></p>
<p><strong>; String printed to report results.</strong></p>
<p><strong>;</strong></p>
<p><strong>OutputStr label byte</strong></p>
<p><strong>db 0dh, 0ah, ‘Timed count:’</strong></p>
<p><strong>TimedCountStr db 10 dup (?)</strong></p>
<p><strong>db ‘microseconds’, 0dh, 0ah</strong></p>
<p><strong>db ‘$’</strong></p>
<p><strong>;</strong></p>
<p><strong>; Temporary storage for timed count as it’s divided down by powers</strong></p>
<p><strong>; of ten when converting from doubleword binary to ASCII.</strong></p>
<p><strong>;</strong></p>
<p><strong>CurrentCountLow dw ?</strong></p>
<p><strong>CurrentCountHigh dw ?</strong></p>
<p><strong>;</strong></p>
<p><strong>; Powers of ten table used to perform division by 10 when doing</strong></p>
<p><strong>; doubleword conversion from binary to ASCII.</strong></p>
<p><strong>;</strong></p>
<p><strong>PowersOfTen label word</strong></p>
<p><strong>dd 1</strong></p>
<p><strong>dd 10</strong></p>
<p><strong>dd 100</strong></p>
<p><strong>dd 1000</strong></p>
<p><strong>dd 10000</strong></p>
<p><strong>dd 100000</strong></p>
<p><strong>dd 1000000</strong></p>
<p><strong>dd 10000000</strong></p>
<p><strong>dd 100000000</strong></p>
<p><strong>dd 1000000000</strong></p>
<p><strong>PowersOfTenEnd label word</strong></p>
<p><strong>;</strong></p>
<p><strong>; String printed to report that the high word of the BIOS count</strong></p>
<p><strong>; changed while timing (an hour elapsed or midnight was crossed),</strong></p>
<p><strong>; and so the count is invalid and the test needs to be rerun.</strong></p>
<p><strong>;</strong></p>
<p><strong>TurnOverStr label byte</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘****************************************************’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* Either midnight passed or an hour or more passed *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* while timing was in progress. If the former was *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* the case, please rerun the test; if the latter *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* was the case, the test code takes too long to *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* run to be timed by the long-period Zen timer. *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* Suggestions: use the DOS TIME command, the DOS *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* time function, or a watch. *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘****************************************************’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘$’</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>;* Routine called to start timing. *</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>ZTimerOn proc near</strong></p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>push ax</strong></p>
<p><strong>pushf</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set timer 0 of the 8253 to mode 2 (divide-by-N), to cause</strong></p>
<p><strong>; linear counting rather than count-by-two counting. Also stops</strong></p>
<p><strong>; timer 0 until the timer count is loaded, except on PS/2</strong></p>
<p><strong>; computers.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00110100b ;mode 2</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set the timer count to 0, so we know we won’t get another</strong></p>
<p><strong>; timer interrupt right away.</strong></p>
<p><strong>; Note: this introduces an inaccuracy of up to 54 ms in the system</strong></p>
<p><strong>; clock count each time it is executed.</strong></p>
<p><strong>;</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>sub al,al</strong></p>
<p><strong>out TIMER_0_8253,al ;lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>out TIMER_0_8253,al ;msb</strong></p>
<p><strong>;</strong></p>
<p><strong>; In case interrupts are disabled, enable interrupts briefly to allow</strong></p>
<p><strong>; the interrupt generated when switching from mode 3 to mode 2 to be</strong></p>
<p><strong>; recognized. Interrupts must be enabled for at least 210 ns to allow</strong></p>
<p><strong>; time for that interrupt to occur. Here, 10 jumps are used for the</strong></p>
<p><strong>; delay to ensure that the delay time will be more than long enough</strong></p>
<p><strong>; even on a very fast PC.</strong></p>
<p><strong>;</strong></p>
<p><strong>pushf</strong></p>
<p><strong>sti</strong></p>
<p><strong>rept 10</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>endm</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>;</strong></p>
<p><strong>; Store the timing start BIOS count.</strong></p>
<p><strong>; (Since the timer count was just set to 0, the BIOS count will</strong></p>
<p><strong>; stay the same for the next 54 ms, so we don’t need to disable</strong></p>
<p><strong>; interrupts in order to avoid getting a half-changed count.)</strong></p>
<p><strong>;</strong></p>
<p><strong>push ds</strong></p>
<p><strong>sub ax,ax</strong></p>
<p><strong>mov ds,ax</strong></p>
<p><strong>mov ax,ds:[TIMER_COUNT+2]</strong></p>
<p><strong>mov cs:[StartBIOSCountHigh],ax</strong></p>
<p><strong>mov ax,ds:[TIMER_COUNT]</strong></p>
<p><strong>mov cs:[StartBIOSCountLow],ax</strong></p>
<p><strong>pop ds</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set the timer count to 0 again to start the timing interval.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00110100b ;set up to load initial</strong></p>
<p><strong>out MODE_8253,al ; timer count</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>sub al,al</strong></p>
<p><strong>out TIMER_0_8253,al ;load count lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>out TIMER_0_8253,al ;load count msb</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore the context of the program being timed and return to it.</strong></p>
<p><strong>;</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>ret</strong></p>
<p><strong>ZTimerOn endp</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>;* Routine called to stop timing and get count. *</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>ZTimerOff proc near</strong></p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>pushf</strong></p>
<p><strong>push ax</strong></p>
<p><strong>push cx</strong></p>
<p><strong>;</strong></p>
<p><strong>; In case interrupts are disabled, enable interrupts briefly to allow</strong></p>
<p><strong>; any pending timer interrupt to be handled. Interrupts must be</strong></p>
<p><strong>; enabled for at least 210 ns to allow time for that interrupt to</strong></p>
<p><strong>; occur. Here, 10 jumps are used for the delay to ensure that the</strong></p>
<p><strong>; delay time will be more than long enough even on a very fast PC.</strong></p>
<p><strong>;</strong></p>
<p><strong>sti</strong></p>
<p><strong>rept 10</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Latch the timer count.</strong></p>
<p><strong>;</strong></p>
<p><strong>if PS2</strong></p>
<p><strong>mov al,00000000b</strong></p>
<p><strong>out MODE_8253,al ;latch timer 0 count</strong></p>
<p><strong>;</strong></p>
<p><strong>; This is where a one-instruction-long window exists on the PS/2.</strong></p>
<p><strong>; The timer count and the BIOS count can lose synchronization;</strong></p>
<p><strong>; since the timer keeps counting after it’s latched, it can turn</strong></p>
<p><strong>; over right after it’s latched and cause the BIOS count to turn</strong></p>
<p><strong>; over before interrupts are disabled, leaving us with the timer</strong></p>
<p><strong>; count from before the timer turned over coupled with the BIOS</strong></p>
<p><strong>; count from after the timer turned over. The result is a count</strong></p>
<p><strong>; that’s 54 ms too long.</strong></p>
<p><strong>;</strong></p>
<hr />
<p><strong>else</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set timer 0 to mode 2 (divide-by-N), waiting for a 2-byte count</strong></p>
<p><strong>; load, which stops timer 0 until the count is loaded. (Only works</strong></p>
<p><strong>; on fully 8253-compatible chips.)</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00110100b ;mode 2</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>mov al,00000000b ;latch timer 0 count</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>endif</strong></p>
<p><strong>cli ;stop the BIOS count</strong></p>
<p><strong>;</strong></p>
<p><strong>; Read the BIOS count. (Since interrupts are disabled, the BIOS</strong></p>
<p><strong>; count won’t change.)</strong></p>
<p><strong>;</strong></p>
<p><strong>push ds</strong></p>
<p><strong>sub ax,ax</strong></p>
<p><strong>mov ds,ax</strong></p>
<p><strong>mov ax,ds:[TIMER_COUNT+2]</strong></p>
<p><strong>mov cs:[EndBIOSCountHigh],ax</strong></p>
<p><strong>mov ax,ds:[TIMER_COUNT]</strong></p>
<p><strong>mov cs:[EndBIOSCountLow],ax</strong></p>
<p><strong>pop ds</strong></p>
<p><strong>;</strong></p>
<p><strong>; Read the timer count and save it.</strong></p>
<p><strong>;</strong></p>
<p><strong>in al,TIMER_0_8253 ;lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>mov ah,al</strong></p>
<p><strong>in al,TIMER_0_8253 ;msb</strong></p>
<p><strong>xchg ah,al</strong></p>
<p><strong>neg ax ;convert from countdown</strong></p>
<p><strong>; remaining to elapsed</strong></p>
<p><strong>; count</strong></p>
<p><strong>mov cs:[EndTimedCount],ax</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restart timer 0, which is still waiting for an initial count</strong></p>
<p><strong>; to be loaded.</strong></p>
<p><strong>;</strong></p>
<p><strong>ife PS2</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>mov al,00110100b ;mode 2, waiting to load a</strong></p>
<p><strong>; 2-byte count</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>sub al,al</strong></p>
<p><strong>out TIMER_0_8253,al ;lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>mov al,ah</strong></p>
<p><strong>out TIMER_0_8253,al ;msb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>endif</strong></p>
<p><strong>sti ;let the BIOS count continue</strong></p>
<p><strong>;</strong></p>
<p><strong>; Time a zero-length code fragment, to get a reference for how</strong></p>
<p><strong>; much overhead this routine has. Time it 16 times and average it,</strong></p>
<p><strong>; for accuracy, rounding the result.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov cs:[ReferenceCount],0</strong></p>
<p><strong>mov cx,16</strong></p>
<p><strong>cli ;interrupts off to allow a</strong></p>
<p><strong>; precise reference count</strong></p>
<p><strong>RefLoop:</strong></p>
<p><strong>call ReferenceZTimerOn</strong></p>
<p><strong>call ReferenceZTimerOff</strong></p>
<p><strong>loop RefLoop</strong></p>
<p><strong>sti</strong></p>
<p><strong>add cs:[ReferenceCount],8 ;total + (0.5 * 16)</strong></p>
<p><strong>mov cl,4</strong></p>
<p><strong>shr cs:[ReferenceCount],cl ;(total) / 16 + 0.5</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore the context of the program being timed and return to it.</strong></p>
<p><strong>;</strong></p>
<p><strong>pop cx</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>ret</strong></p>
<p><strong>ZTimerOff endp</strong></p>
<p><strong>;</strong></p>
<p><strong>; Called by ZTimerOff to start the timer for overhead measurements.</strong></p>
<p><strong>;</strong></p>
<p><strong>ReferenceZTimerOn proc near</strong></p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>push ax</strong></p>
<p><strong>pushf</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set timer 0 of the 8253 to mode 2 (divide-by-N), to cause</strong></p>
<p><strong>; linear counting rather than count-by-two counting.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00110100b ;mode 2</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set the timer count to 0.</strong></p>
<p><strong>;</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>sub al,al</strong></p>
<p><strong>out TIMER_0_8253,al ;lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>out TIMER_0_8253,al ;msb</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore the context of the program being timed and return to it.</strong></p>
<p><strong>;</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>ret</strong></p>
<p><strong>ReferenceZTimerOn endp</strong></p>
<p><strong>;</strong></p>
<p><strong>; Called by ZTimerOff to stop the timer and add the result to</strong></p>
<p><strong>; ReferenceCount for overhead measurements. Doesn’t need to look</strong></p>
<p><strong>; at the BIOS count because timing a zero-length code fragment</strong></p>
<p><strong>; isn’t going to take anywhere near 54 ms.</strong></p>
<p><strong>;</strong></p>
<p><strong>ReferenceZTimerOff proc near</strong></p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>pushf</strong></p>
<p><strong>push ax</strong></p>
<p><strong>push cx</strong></p>
<p><strong>;</strong></p>
<p><strong>; Match the interrupt-window delay in ZTimerOff.</strong></p>
<p><strong>;</strong></p>
<p><strong>sti</strong></p>
<p><strong>rept 10</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>endm</strong></p>
<p><strong>mov al,00000000b</strong></p>
<p><strong>out MODE_8253,al ;latch timer</strong></p>
<p><strong>;</strong></p>
<p><strong>; Read the count and save it.</strong></p>
<p><strong>;</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>in al,TIMER_0_8253 ;lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>mov ah,al</strong></p>
<p><strong>in al,TIMER_0_8253 ;msb</strong></p>
<p><strong>xchg ah,al</strong></p>
<p><strong>neg ax ;convert from countdown</strong></p>
<p><strong>; remaining to elapsed</strong></p>
<p><strong>; count</strong></p>
<p><strong>add cs:[ReferenceCount],ax</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore the context and return.</strong></p>
<p><strong>;</strong></p>
<p><strong>pop cx</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>ret</strong></p>
<p><strong>ReferenceZTimerOff endp</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>;* Routine called to report timing results. *</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>ZTimerReport proc near</strong></p>
<p><strong>pushf</strong></p>
<p><strong>push ax</strong></p>
<p><strong>push bx</strong></p>
<p><strong>push cx</strong></p>
<p><strong>push dx</strong></p>
<p><strong>push si</strong></p>
<p><strong>push di</strong></p>
<p><strong>push ds</strong></p>
<p><strong>;</strong></p>
<p><strong>push cs ;DOS functions require that DS point</strong></p>
<p><strong>pop ds ; to text to be displayed on the screen</strong></p>
<p><strong>assume ds:Code</strong></p>
<p><strong>;</strong></p>
<p><strong>; See if midnight or more than an hour passed during timing. If so,</strong></p>
<p><strong>; notify the user.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,[StartBIOSCountHigh]</strong></p>
<p><strong>cmp ax,[EndBIOSCountHigh]</strong></p>
<p><strong>jz CalcBIOSTime ;hour count didn’t change,</strong></p>
<p><strong>; so everything’s fine</strong></p>
<p><strong>inc ax</strong></p>
<p><strong>cmp ax,[EndBIOSCountHigh]</strong></p>
<p><strong>jnz TestTooLong ;midnight or two hour</strong></p>
<p><strong>; boundaries passed, so the</strong></p>
<p><strong>; results are no good</strong></p>
<p><strong>mov ax,[EndBIOSCountLow]</strong></p>
<p><strong>cmp ax,[StartBIOSCountLow]</strong></p>
<p><strong>jb CalcBIOSTime ;a single hour boundary</strong></p>
<p><strong>; passed-that’s OK, so long as</strong></p>
<p><strong>; the total time wasn’t more</strong></p>
<p><strong>; than an hour</strong></p>
<p><strong>;</strong></p>
<p><strong>; Over an hour elapsed or midnight passed during timing, which</strong></p>
<p><strong>; renders the results invalid. Notify the user. This misses the</strong></p>
<p><strong>; case where a multiple of 24 hours has passed, but we’ll rely</strong></p>
<p><strong>; on the perspicacity of the user to detect that case.</strong></p>
<p><strong>;</strong></p>
<p><strong>TestTooLong:</strong></p>
<p><strong>mov ah,9</strong></p>
<p><strong>mov dx,offset TurnOverStr</strong></p>
<p><strong>int 21h</strong></p>
<p><strong>jmp short ZTimerReportDone</strong></p>
<p><strong>;</strong></p>
<p><strong>; Convert the BIOS time to microseconds.</strong></p>
<p><strong>;</strong></p>
<p><strong>CalcBIOSTime:</strong></p>
<p><strong>mov ax,[EndBIOSCountLow]</strong></p>
<p><strong>sub ax,[StartBIOSCountLow]</strong></p>
<p><strong>mov dx,54925 ;number of microseconds each</strong></p>
<p><strong>; BIOS count represents</strong></p>
<p><strong>mul dx</strong></p>
<p><strong>mov bx,ax ;set aside BIOS count in</strong></p>
<p><strong>mov cx,dx ; microseconds</strong></p>
<p><strong>;</strong></p>
<p><strong>; Convert timer count to microseconds.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,[EndTimedCount]</strong></p>
<p><strong>mov si,8381</strong></p>
<p><strong>mul si</strong></p>
<p><strong>mov si,10000</strong></p>
<p><strong>div si ;* .8381 = * 8381 / 10000</strong></p>
<p><strong>;</strong></p>
<p><strong>; Add timer and BIOS counts together to get an overall time in</strong></p>
<p><strong>; microseconds.</strong></p>
<p><strong>;</strong></p>
<p><strong>add bx,ax</strong></p>
<p><strong>adc cx,0</strong></p>
<p><strong>;</strong></p>
<p><strong>; Subtract the timer overhead and save the result.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ax,[ReferenceCount]</strong></p>
<p><strong>mov si,8381 ;convert the reference count</strong></p>
<p><strong>mul si ; to microseconds</strong></p>
<p><strong>mov si,10000</strong></p>
<p><strong>div si ;* .8381 = * 8381 / 10000</strong></p>
<p><strong>sub bx,ax</strong></p>
<p><strong>sbb cx,0</strong></p>
<p><strong>mov [CurrentCountLow],bx</strong></p>
<p><strong>mov [CurrentCountHigh],cx</strong></p>
<p><strong>;</strong></p>
<p><strong>; Convert the result to an ASCII string by trial subtractions of</strong></p>
<p><strong>; powers of 10.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov di,offset PowersOfTenEnd -offset PowersOfTen -4</strong></p>
<p><strong>mov si,offset TimedCountStr</strong></p>
<p><strong>CTSNextDigit:</strong></p>
<p><strong>mov bl,‘0’</strong></p>
<p><strong>CTSLoop:</strong></p>
<p><strong>mov ax,[CurrentCountLow]</strong></p>
<p><strong>mov dx,[CurrentCountHigh]</strong></p>
<p><strong>sub ax,PowersOfTen[di]</strong></p>
<p><strong>sbb dx,PowersOfTen[di+2]</strong></p>
<p><strong>jc CTSNextPowerDown</strong></p>
<p><strong>inc bl</strong></p>
<p><strong>mov [CurrentCountLow],ax</strong></p>
<p><strong>mov [CurrentCountHigh],dx</strong></p>
<p><strong>jmp CTSLoop</strong></p>
<p><strong>CTSNextPowerDown:</strong></p>
<p><strong>mov [si],bl</strong></p>
<p><strong>inc si</strong></p>
<p><strong>sub di,4</strong></p>
<p><strong>jns CTSNextDigit</strong></p>
<p><strong>;</strong></p>
<p><strong>;</strong></p>
<p><strong>; Print the results.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ah,9</strong></p>
<p><strong>mov dx,offset OutputStr</strong></p>
<p><strong>int 21h</strong></p>
<p><strong>;</strong></p>
<p><strong>ZTimerReportDone:</strong></p>
<p><strong>pop ds</strong></p>
<p><strong>pop di</strong></p>
<p><strong>pop si</strong></p>
<p><strong>pop dx</strong></p>
<p><strong>pop cx</strong></p>
<p><strong>pop bx</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>ret</strong></p>
<p><strong>ZTimerReport endp</strong></p>
<p><strong>Code ends</strong></p>
<p><strong>end</strong></p>
</section>
<section id="pztest" class="level2">
<h2>PZTEST</h2>
<p><strong>; PZTEST</strong></p>
<p><strong>;</strong></p>
<p><strong>; *** Listing 2-2 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; Program to measure performance of code that takes less than</strong></p>
<p><strong>; 54 ms to execute. (PZTEST.ASM)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Link with PZTIMER.ASM (Listing 2-1). PZTEST.BAT (Listing 2-4)</strong></p>
<p><strong>; can be used to assemble and link both files. Code to be</strong></p>
<p><strong>; measured must be in the file TESTCODE; Listing 2-3 shows</strong></p>
<p><strong>; a sample TESTCODE file.</strong></p>
<p><strong>;</strong></p>
<p><strong>; By Michael Abrash 4/26/89</strong></p>
<p><strong>;</strong></p>
<p><strong>mystack segment para stack ‘STACK’</strong></p>
<p><strong>db 512 dup(?)</strong></p>
<p><strong>mystack ends</strong></p>
<p><strong>;</strong></p>
<p><strong>Code segment para public ‘CODE’</strong></p>
<p><strong>assume cs:Code, ds:Code</strong></p>
<p><strong>extrn ZTimerOn:near, ZTimerOff:near, ZTimerReport:near</strong></p>
<p><strong>Start proc near</strong></p>
<p><strong>push cs</strong></p>
<p><strong>pop ds ;set DS to point to the code segment,</strong></p>
<p><strong>; so data as well as code can easily</strong></p>
<p><strong>; be included in TESTCODE</strong></p>
<p><strong>;</strong></p>
<p><strong>include TESTCODE ;code to be measured, including</strong></p>
<p><strong>; calls to ZTimerOn and ZTimerOff</strong></p>
<p><strong>;</strong></p>
<p><strong>; Display the results.</strong></p>
<p><strong>;</strong></p>
<p><strong>call ZTimerReport</strong></p>
<p><strong>;</strong></p>
<p><strong>; Terminate the program.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ah,4ch</strong></p>
<p><strong>int 21h</strong></p>
<p><strong>Start endp</strong></p>
<p><strong>Code ends</strong></p>
<p><strong>end Start</strong></p>
</section>
<section id="pztime.bat" class="level2">
<h2>PZTIME.BAT</h2>
<p><strong>PZTIME.BAT</strong></p>
<p><strong>echo off</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem *** Listing 2-4 ***</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem ***************************************************************</strong></p>
<p><strong>rem * Batch file PZTIME.BAT, which builds and runs the precision *</strong></p>
<p><strong>rem * Zen timer program PZTEST.EXE to time the code named as the *</strong></p>
<p><strong>rem * command-line parameter. Listing 2-1 must be named *</strong></p>
<p><strong>rem * PZTIMER.ASM, and Listing 2-2 must be named PZTEST.ASM. To *</strong></p>
<p><strong>rem * time the code in LST2-3, you’d type the DOS command: *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * pztime lst2-3 *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * Note that MASM and LINK must be in the current directory or *</strong></p>
<p><strong>rem * on the current path in order for this batch file to work. *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * This batch file can be speeded up by assembling PZTIMER.ASM *</strong></p>
<p><strong>rem * once, then removing the lines: *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * masm pztimer; *</strong></p>
<p><strong>rem * if errorlevel 1 goto errorend *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * from this file. *</strong></p>
<p><strong>rem * *</strong></p>
<p><strong>rem * By Michael Abrash 4/26/89 *</strong></p>
<p><strong>rem ***************************************************************</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem Make sure a file to test was specified.</strong></p>
<p><strong>rem</strong></p>
<p><strong>if not x%1==x goto ckexist</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>echo * Please specify a file to test. *</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>goto end</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem Make sure the file exists.</strong></p>
<p><strong>rem</strong></p>
<p><strong>:ckexist</strong></p>
<p><strong>if exist %1 goto docopy</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>echo * The specified file, “%1,” doesn’t exist.</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>goto end</strong></p>
<p><strong>rem</strong></p>
<p><strong>rem copy the file to measure to TESTCODE.</strong></p>
<p><strong>rem</strong></p>
<p><strong>:docopy</strong></p>
<p><strong>copy %1 testcode</strong></p>
<p><strong>masm pztest;</strong></p>
<p><strong>if errorlevel 1 goto errorend</strong></p>
<p><strong>masm pztimer;</strong></p>
<p><strong>if errorlevel 1 goto errorend</strong></p>
<p><strong>link pztest+pztimer;</strong></p>
<p><strong>if errorlevel 1 goto errorend</strong></p>
<p><strong>pztest</strong></p>
<p><strong>goto end</strong></p>
<p><strong>:errorend</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>echo * An error occurred while building the precision Zen timer. *</strong></p>
<p><strong>echo ***************************************************************</strong></p>
<p><strong>:end</strong></p>
</section>
<section id="pztimer" class="level2">
<h2>PZTIMER</h2>
<p><strong>; PZTIMER</strong></p>
<p><strong>;</strong></p>
<p><strong>; *** Listing 2-1 ***</strong></p>
<p><strong>;</strong></p>
<p><strong>; The precision Zen timer (PZTIMER.ASM)</strong></p>
<p><strong>;</strong></p>
<p><strong>; Uses the 8253 timer to time the performance of code that takes</strong></p>
<p><strong>; less than about 54 milliseconds to execute, with a resolution</strong></p>
<p><strong>; of better than 10 microseconds.</strong></p>
<p><strong>;</strong></p>
<p><strong>; By Michael Abrash 4/26/89</strong></p>
<p><strong>;</strong></p>
<p><strong>; Externally callable routines:</strong></p>
<p><strong>;</strong></p>
<p><strong>; ZTimerOn: Starts the Zen timer, with interrupts disabled.</strong></p>
<p><strong>;</strong></p>
<p><strong>; ZTimerOff: Stops the Zen timer, saves the timer count,</strong></p>
<p><strong>; times the overhead code, and restores interrupts to the</strong></p>
<p><strong>; state they were in when ZTimerOn was called.</strong></p>
<p><strong>;</strong></p>
<p><strong>; ZTimerReport: Prints the net time that passed between starting</strong></p>
<p><strong>; and stopping the timer.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: If longer than about 54 ms passes between ZTimerOn and</strong></p>
<p><strong>; ZTimerOff calls, the timer turns over and the count is</strong></p>
<p><strong>; inaccurate. When this happens, an error message is displayed</strong></p>
<p><strong>; instead of a count. The long-period Zen timer should be used</strong></p>
<p><strong>; in such cases.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: Interrupts *MUST* be left off between calls to ZTimerOn</strong></p>
<p><strong>; and ZTimerOff for accurate timing and for detection of</strong></p>
<p><strong>; timer overflow.</strong></p>
<p><strong>;</strong></p>
<p><strong>; Note: These routines can introduce slight inaccuracies into the</strong></p>
<p><strong>; system clock count for each code section timed even if</strong></p>
<p><strong>; timer 0 doesn’t overflow. If timer 0 does overflow, the</strong></p>
<p><strong>; system clock can become slow by virtually any amount of</strong></p>
<p><strong>; time, since the system clock can’t advance while the</strong></p>
<p><strong>; precison timer is timing. Consequently, it’s a good idea</strong></p>
<p><strong>; to reboot at the end of each timing session. (The</strong></p>
<p><strong>; battery-backed clock, if any, is not affected by the Zen</strong></p>
<p><strong>; timer.)</strong></p>
<p><strong>;</strong></p>
<p><strong>; All registers, and all flags except the interrupt flag, are</strong></p>
<p><strong>; preserved by all routines. Interrupts are enabled and then disabled</strong></p>
<p><strong>; by ZTimerOn, and are restored by ZTimerOff to the state they were</strong></p>
<p><strong>; in when ZTimerOn was called.</strong></p>
<p><strong>;</strong></p>
<p><strong>Code segment word public ‘CODE’</strong></p>
<p><strong>assume cs:Code, ds:nothing</strong></p>
<p><strong>public ZTimerOn, ZTimerOff, ZTimerReport</strong></p>
<p><strong>;</strong></p>
<p><strong>; Base address of the 8253 timer chip.</strong></p>
<p><strong>;</strong></p>
<p><strong>BASE_8253 equ 40h</strong></p>
<p><strong>;</strong></p>
<p><strong>; The address of the timer 0 count registers in the 8253.</strong></p>
<p><strong>;</strong></p>
<p><strong>TIMER_0_8253 equ BASE_8253 + 0</strong></p>
<p><strong>;</strong></p>
<p><strong>; The address of the mode register in the 8253.</strong></p>
<p><strong>;</strong></p>
<p><strong>MODE_8253 equ BASE_8253 + 3</strong></p>
<p><strong>;</strong></p>
<p><strong>; The address of Operation Command Word 3 in the 8259 Programmable</strong></p>
<p><strong>; Interrupt Controller (PIC) (write only, and writable only when</strong></p>
<p><strong>; bit 4 of the byte written to this address is 0 and bit 3 is 1).</strong></p>
<p><strong>;</strong></p>
<p><strong>OCW3 equ 20h</strong></p>
<p><strong>;</strong></p>
<p><strong>; The address of the Interrupt Request register in the 8259 PIC</strong></p>
<p><strong>; (read only, and readable only when bit 1 of OCW3 = 1 and bit 0</strong></p>
<p><strong>; of OCW3 = 0).</strong></p>
<p><strong>;</strong></p>
<p><strong>IRR equ 20h</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to emulate a POPF instruction in order to fix the bug in some</strong></p>
<p><strong>; 80286 chips which allows interrupts to occur during a POPF even when</strong></p>
<p><strong>; interrupts remain disabled.</strong></p>
<p><strong>;</strong></p>
<p><strong>MPOPF macro</strong></p>
<p><strong>local p1, p2</strong></p>
<p><strong>jmp short p2</strong></p>
<p><strong>p1: iret ;jump to pushed address &amp; pop flags</strong></p>
<p><strong>p2: push cs ;construct far return address to</strong></p>
<p><strong>call p1 ; the next instruction</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Macro to delay briefly to ensure that enough time has elapsed</strong></p>
<p><strong>; between successive I/O accesses so that the device being accessed</strong></p>
<p><strong>; can respond to both accesses even on a very fast PC.</strong></p>
<p><strong>;</strong></p>
<p><strong>DELAY macro</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>endm</strong></p>
<p><strong>OriginalFlags db ? ;storage for upper byte of</strong></p>
<p><strong>; FLAGS register when</strong></p>
<p><strong>; ZTimerOn called</strong></p>
<p><strong>TimedCount dw ? ;timer 0 count when the timer</strong></p>
<p><strong>; is stopped</strong></p>
<p><strong>ReferenceCount dw ? ;number of counts required to</strong></p>
<p><strong>; execute timer overhead code</strong></p>
<p><strong>OverflowFlag db ? ;used to indicate whether the</strong></p>
<p><strong>; timer overflowed during the</strong></p>
<p><strong>; timing interval</strong></p>
<p><strong>;</strong></p>
<p><strong>; String printed to report results.</strong></p>
<p><strong>;</strong></p>
<p><strong>OutputStr label byte</strong></p>
<p><strong>db 0dh, 0ah, ‘Timed count:’, 5 dup (?)</strong></p>
<p><strong>ASCIICountEnd label byte</strong></p>
<p><strong>db ‘microseconds’, 0dh, 0ah</strong></p>
<p><strong>db ‘$’</strong></p>
<p><strong>;</strong></p>
<p><strong>; String printed to report timer overflow.</strong></p>
<p><strong>;</strong></p>
<p><strong>OverflowStr label byte</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘****************************************************’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* The timer overflowed, so the interval timed was *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* too long for the precision timer to measure. *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* Please perform the timing test again with the *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘* long-period timer. *’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘****************************************************’</strong></p>
<p><strong>db 0dh, 0ah</strong></p>
<p><strong>db ‘$’</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>;* Routine called to start timing. *</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>ZTimerOn proc near</strong></p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>push ax</strong></p>
<p><strong>pushf</strong></p>
<p><strong>pop ax ;get flags so we can keep</strong></p>
<p><strong>; interrupts off when leaving</strong></p>
<p><strong>; this routine</strong></p>
<p><strong>mov cs:[OriginalFlags],ah ;remember the state of the</strong></p>
<p><strong>; Interrupt flag</strong></p>
<p><strong>and ah,0fdh ;set pushed interrupt flag</strong></p>
<p><strong>; to 0</strong></p>
<p><strong>push ax</strong></p>
<p><strong>;</strong></p>
<p><strong>; Turn on interrupts, so the timer interrupt can occur if it’s</strong></p>
<p><strong>; pending.</strong></p>
<p><strong>;</strong></p>
<p><strong>sti</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set timer 0 of the 8253 to mode 2 (divide-by-N), to cause</strong></p>
<p><strong>; linear counting rather than count-by-two counting. Also</strong></p>
<p><strong>; leaves the 8253 waiting for the initial timer 0 count to</strong></p>
<p><strong>; be loaded.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00110100b ;mode 2</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set the timer count to 0, so we know we won’t get another</strong></p>
<p><strong>; timer interrupt right away.</strong></p>
<p><strong>; Note: this introduces an inaccuracy of up to 54 ms in the system</strong></p>
<p><strong>; clock count each time it is executed.</strong></p>
<p><strong>;</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>sub al,al</strong></p>
<p><strong>out TIMER_0_8253,al ;lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>out TIMER_0_8253,al ;msb</strong></p>
<p><strong>;</strong></p>
<p><strong>; Wait before clearing interrupts to allow the interrupt generated</strong></p>
<p><strong>; when switching from mode 3 to mode 2 to be recognized. The delay</strong></p>
<p><strong>; must be at least 210 ns long to allow time for that interrupt to</strong></p>
<p><strong>; occur. Here, 10 jumps are used for the delay to ensure that the</strong></p>
<p><strong>; delay time will be more than long enough even on a very fast PC.</strong></p>
<p><strong>;</strong></p>
<p><strong>rept 10</strong></p>
<p><strong>jmp $+2</strong></p>
<p><strong>endm</strong></p>
<p><strong>;</strong></p>
<p><strong>; Disable interrupts to get an accurate count.</strong></p>
<p><strong>;</strong></p>
<p><strong>cli</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set the timer count to 0 again to start the timing interval.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00110100b ;set up to load initial</strong></p>
<p><strong>out MODE_8253,al ; timer count</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>sub al,al</strong></p>
<p><strong>out TIMER_0_8253,al ;load count lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>out TIMER_0_8253,al ;load count msb</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore the context and return.</strong></p>
<p><strong>;</strong></p>
<p><strong>MPOPF ;keeps interrupts off</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>ret</strong></p>
<p><strong>ZTimerOn endp</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>;* Routine called to stop timing and get count. *</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>ZTimerOff proc near</strong></p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>push ax</strong></p>
<p><strong>push cx</strong></p>
<p><strong>pushf</strong></p>
<p><strong>;</strong></p>
<p><strong>; Latch the count.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00000000b ;latch timer 0</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>;</strong></p>
<p><strong>; See if the timer has overflowed by checking the 8259 for a pending</strong></p>
<p><strong>; timer interrupt.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00001010b ;OCW3, set up to read</strong></p>
<p><strong>out OCW3,al ; Interrupt Request register</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>in al,IRR ;read Interrupt Request</strong></p>
<p><strong>; register</strong></p>
<p><strong>and al,1 ;set AL to 1 if IRQ0 (the</strong></p>
<p><strong>; timer interrupt) is pending</strong></p>
<p><strong>mov cs:[OverflowFlag],al ;store the timer overflow</strong></p>
<p><strong>; status</strong></p>
<p><strong>;</strong></p>
<p><strong>; Allow interrupts to happen again.</strong></p>
<p><strong>;</strong></p>
<p><strong>sti</strong></p>
<p><strong>;</strong></p>
<p><strong>; Read out the count we latched earlier.</strong></p>
<p><strong>;</strong></p>
<p><strong>in al,TIMER_0_8253 ;least significant byte</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>mov ah,al</strong></p>
<p><strong>in al,TIMER_0_8253 ;most significant byte</strong></p>
<p><strong>xchg ah,al</strong></p>
<p><strong>neg ax ;convert from countdown</strong></p>
<p><strong>; remaining to elapsed</strong></p>
<p><strong>; count</strong></p>
<p><strong>mov cs:[TimedCount],ax</strong></p>
<p><strong>; Time a zero-length code fragment, to get a reference for how</strong></p>
<p><strong>; much overhead this routine has. Time it 16 times and average it,</strong></p>
<p><strong>; for accuracy, rounding the result.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov cs:[ReferenceCount],0</strong></p>
<p><strong>mov cx,16</strong></p>
<p><strong>cli ;interrupts off to allow a</strong></p>
<p><strong>; precise reference count</strong></p>
<p><strong>RefLoop:</strong></p>
<p><strong>call ReferenceZTimerOn</strong></p>
<p><strong>call ReferenceZTimerOff</strong></p>
<p><strong>loop RefLoop</strong></p>
<p><strong>sti</strong></p>
<p><strong>add cs:[ReferenceCount],8 ;total + (0.5 * 16)</strong></p>
<p><strong>mov cl,4</strong></p>
<p><strong>shr cs:[ReferenceCount],cl ;(total) / 16 + 0.5</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore originaLinterrupt state.</strong></p>
<p><strong>;</strong></p>
<p><strong>pop ax ;retrieve flags when called</strong></p>
<p><strong>mov ch,cs:[OriginalFlags] ;get back the original upper</strong></p>
<p><strong>; byte of the FLAGS register</strong></p>
<p><strong>and ch,not 0fdh ;only care about original</strong></p>
<p><strong>; interrupt flag…</strong></p>
<p><strong>and ah,0fdh ;…keep all other flags in</strong></p>
<p><strong>; their current condition</strong></p>
<p><strong>or ah,ch ;make flags word with original</strong></p>
<p><strong>; interrupt flag</strong></p>
<p><strong>push ax ;prepare flags to be popped</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore the context of the program being timed and return to it.</strong></p>
<p><strong>;</strong></p>
<p><strong>MPOPF ;restore the flags with the</strong></p>
<p><strong>; originaLinterrupt state</strong></p>
<p><strong>pop cx</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>ret</strong></p>
<p><strong>ZTimerOff endp</strong></p>
<p><strong>;</strong></p>
<p><strong>; Called by ZTimerOff to start timer for overhead measurements.</strong></p>
<p><strong>;</strong></p>
<p><strong>ReferenceZTimerOn proc near</strong></p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>push ax</strong></p>
<p><strong>pushf ;interrupts are already off</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set timer 0 of the 8253 to mode 2 (divide-by-N), to cause</strong></p>
<p><strong>; linear counting rather than count-by-two counting.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00110100b ;set up to load</strong></p>
<p><strong>out MODE_8253,al ; initial timer count</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>;</strong></p>
<p><strong>; Set the timer count to 0.</strong></p>
<p><strong>;</strong></p>
<p><strong>sub al,al</strong></p>
<p><strong>out TIMER_0_8253,al ;load count lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>out TIMER_0_8253,al ;load count msb</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore the context of the program being timed and return to it.</strong></p>
<p><strong>;</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>ret</strong></p>
<p><strong>ReferenceZTimerOn endp</strong></p>
<p><strong>;</strong></p>
<p><strong>; Called by ZTimerOff to stop timer and add result to ReferenceCount</strong></p>
<p><strong>; for overhead measurements.</strong></p>
<p><strong>;</strong></p>
<p><strong>ReferenceZTimerOff proc near</strong></p>
<p><strong>;</strong></p>
<p><strong>; Save the context of the program being timed.</strong></p>
<p><strong>;</strong></p>
<p><strong>push ax</strong></p>
<p><strong>push cx</strong></p>
<p><strong>pushf</strong></p>
<p><strong>;</strong></p>
<p><strong>; Latch the count and read it.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov al,00000000b ;latch timer 0</strong></p>
<p><strong>out MODE_8253,al</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>in al,TIMER_0_8253 ;lsb</strong></p>
<p><strong>DELAY</strong></p>
<p><strong>mov ah,al</strong></p>
<p><strong>in al,TIMER_0_8253 ;msb</strong></p>
<p><strong>xchg ah,al</strong></p>
<p><strong>neg ax ;convert from countdown</strong></p>
<p><strong>; remaining to amount</strong></p>
<p><strong>; counted down</strong></p>
<p><strong>add cs:[ReferenceCount],ax</strong></p>
<p><strong>;</strong></p>
<p><strong>; Restore the context of the program being timed and return to it.</strong></p>
<p><strong>;</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>pop cx</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>ret</strong></p>
<p><strong>ReferenceZTimerOff endp</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>;* Routine called to report timing results. *</strong></p>
<p><strong>;********************************************************************</strong></p>
<p><strong>ZTimerReport proc near</strong></p>
<p><strong>pushf</strong></p>
<p><strong>push ax</strong></p>
<p><strong>push bx</strong></p>
<p><strong>push cx</strong></p>
<p><strong>push dx</strong></p>
<p><strong>push si</strong></p>
<p><strong>push ds</strong></p>
<p><strong>;</strong></p>
<p><strong>push cs ;DOS functions require that DS point</strong></p>
<p><strong>pop ds ; to text to be displayed on the screen</strong></p>
<p><strong>assume ds:Code</strong></p>
<p><strong>;</strong></p>
<p><strong>; Check for timer 0 overflow.</strong></p>
<p><strong>;</strong></p>
<p><strong>cmp [OverflowFlag],0</strong></p>
<p><strong>jz PrintGoodCount</strong></p>
<p><strong>mov dx,offset OverflowStr</strong></p>
<p><strong>mov ah,9</strong></p>
<p><strong>int 21h</strong></p>
<p><strong>jmp short EndZTimerReport</strong></p>
<p><strong>;</strong></p>
<p><strong>; Convert net count to decimal ASCII in microseconds.</strong></p>
<p><strong>;</strong></p>
<p><strong>PrintGoodCount:</strong></p>
<p><strong>mov ax,[TimedCount]</strong></p>
<p><strong>sub ax,[ReferenceCount]</strong></p>
<p><strong>mov si,offset ASCIICountEnd -1</strong></p>
<p><strong>;</strong></p>
<p><strong>; Convert count to microseconds by multiplying by .8381.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov dx,8381</strong></p>
<p><strong>mul dx</strong></p>
<p><strong>mov bx,10000</strong></p>
<p><strong>div bx ;* .8381 = * 8381 / 10000</strong></p>
<p><strong>;</strong></p>
<p><strong>; Convert time in microseconds to 5 decimal ASCII digits.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov bx,10</strong></p>
<p><strong>mov cx,5</strong></p>
<p><strong>CTSLoop:</strong></p>
<p><strong>sub dx,dx</strong></p>
<p><strong>div bx</strong></p>
<p><strong>add dl,‘0’</strong></p>
<p><strong>mov [si],dl</strong></p>
<p><strong>dec si</strong></p>
<p><strong>loop CTSLoop</strong></p>
<p><strong>;</strong></p>
<p><strong>; Print the results.</strong></p>
<p><strong>;</strong></p>
<p><strong>mov ah,9</strong></p>
<p><strong>mov dx,offset OutputStr</strong></p>
<p><strong>int 21h</strong></p>
<p><strong>;</strong></p>
<p><strong>EndZTimerReport:</strong></p>
<p><strong>pop ds</strong></p>
<p><strong>pop si</strong></p>
<p><strong>pop dx</strong></p>
<p><strong>pop cx</strong></p>
<p><strong>pop bx</strong></p>
<p><strong>pop ax</strong></p>
<p><strong>MPOPF</strong></p>
<p><strong>ret</strong></p>
<p><strong>ZTimerReport endp</strong></p>
<p><strong>Code ends</strong></p>
<p><strong>end</strong></p>
</section>
</section>
<section id="appendix-a-80868088-instruction-set-reference" class="level1">
<h1>Appendix A: 8086/8088 Instruction Set Reference</h1>
<p><em>Adapted from “Assembly Language from Square One,” by Jeff Duntemann (Scott, Foresman and Company, 1989), by permission of the author.</em></p>
<p>The following is a summary of the 8088’s instruction set, with valid instruction forms, execution times, sizes, and examples given for each instruction. A short summary of each instruction is provided as well. This is not a complete reference on the 8088’s instruction set; rather, it is a quick reference summary that is particularly useful for calculating Execution Unit execution time and/or code size. This reference is also handy in that it lists all forms of each instruction, including the special, shorter forms that many instructions have.</p>
<p>References that provide more comprehensive information about the 8088’s instruction set are listed below.</p>
<section id="notes-on-the-instruction-set-reference" class="level2">
<h2>Notes on the Instruction Set Reference</h2>
<section id="instruction-operands" class="level3">
<h3>Instruction Operands</h3>
<p>When an instruction takes two operands, the destination operand is the operand on the <em>left</em>, and the source operand is the operand on the <em>right</em>. In general, when a result is produced by an instruction, the result replaces the destination operand. For example, in the instruction <code>add bx,si</code>, the BX register (the destination operand) is added to the SI register (the source operand), and the sum is then placed back in the BX register, overwriting whatever was in BX before the addition.</p>
</section>
<section id="flag-results" class="level3">
<h3>Flag Results</h3>
<p>Each instruction contains a flag summary that looks like this (the asterisks will vary from instruction to instruction):</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>*</code></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>*</code></td>
<td style="text-align: left;"><code>*</code></td>
<td style="text-align: left;"><code>*</code></td>
<td style="text-align: left;"><code>*</code></td>
<td style="text-align: left;"><code>*</code></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<p>The nine flags are all represented here. An asterisk indicates that the instruction on that page affects that flag. If a flag is affected at all (that is, if it has an asterisk beneath it) it will generally be affected according to these rules:</p>
<p><code>OF:</code> Set if the result is too large to fit in the destination operand.</p>
<p><code>DF:</code> Set by the <code>std</code> instruction; cleared by <code>cld</code>.</p>
<p><code>IF:</code> Set by the <code>sti</code> and <code>int</code> instructions; cleared by <code>cli</code>.</p>
<p><code>TF:</code> For debuggers; not used in normal programming and may be ignored.</p>
<p><code>SF:</code> Set when the sign of the result is negative.</p>
<p><code>ZF:</code> Set if the result of an operation is zero. If the result is non zero, ZF is cleared.</p>
<p><code>AF:</code> “Auxiliary carry” used for 4bit BCD math. Set when an operation causes a carry out of a 4bit BCD quantity.</p>
<p><code>PF:</code> Set if the number of 1 bits in the low byte of the result is even; cleared if the number of 1 bits in the low byte of the result is odd. Used in data communications applications but little else.</p>
<p><code>CF:</code> Set if the result of an add or shift operation “carries out” a bit beyond the destination operand; otherwise cleared. May be manually set by <code>stc</code> and manually cleared by <code>clc</code> when CF must be in a known state before an operation begins.</p>
<p>In addition, all flags may be either set or cleared by <code>popf</code> and <code>iret</code>, and CF, PF, AF, ZF, and SF may be either set or cleared by <code>sahf</code>.</p>
<p>Some instructions force certain flags to become undefined. When this is the case for a given instruction, it will be so stated under “Notes.”“Undefined” means <em>don’t count on it being in any particular state</em>.</p>
</section>
<section id="accounting-for-the-time-consumed-by-memory-accesses" class="level3">
<h3>Accounting for the Time Consumed by Memory Accesses</h3>
<p>Each bytesized access to memory takes 4 cycles. That time is normally built into execution times; however, many instructions may work with either byte or wordsized memory operands. In such cases, <em>each</em> additional bytesized access to memory incurred by the use of wordsized operands adds four cycles to the instruction’s official execution time. For example, <code>add ax,[si]</code> takes 4 cycles longer to execute than <code>add al,[si]</code>.</p>
<p>Some instructions access memory more than once. In such cases, 4 cycles are required for <em>each</em> extra access. So, for example, <code>add [si],ax</code>, takes not 4 but 8 cycles longer than <code>add [si],al</code>, because the wordsized memory operand pointed to by SI must be both read and written to. 8 and 16bit forms of various instructions are shown separately in this appendix, with the cycle times adjusted appropriately in the case of 16bit instructions, so you do not need to add any additional execution time for wordsized memory operands.</p>
</section>
<section id="these-are-only-execution-unit-execution-times" class="level3">
<h3>These Are Only Execution Unit Execution Times</h3>
<p>The execution times given below describe how many cycles each instruction takes to execute <em>once it has reached the Execution Unit</em>. This does not account for the time required to <em>reach</em> the Execution Unitthat is, the time required to fetch the instruction byte. Instruction fetch time for a given instruction can vary from no time at all to more than 4 cycles per byte, depending on how quickly the Execution Unit executes the preceding instructions, how often those instructions access memory, and how effectively the Bus Interface Unit can prefetch that instruction’s bytes into the prefetch queue.</p>
<p>Overall execution time is a complex topic, to which Chapters 3, 4, and 5 are largely dedicated. Refer to those chapters for a detailed discussion of the topic. For the purposes of this appendix, simply understand that the execution times given here are Execution Unit execution times only, and so are only part of the overall execution picture.</p>
</section>
<section id="effective-address-calculations" class="level3">
<h3>Effective Address Calculations</h3>
<p>As described in Chapter 7, instructions that use <em>mod-reg-rm</em> memory operands require extra cycles, known as effective address calculation time, in order to calculate the address of the memory location being addressed. Effective address calculation time varies with the <em>mod-reg-rm</em> memory addressing mode selected, but does not depend on the instruction selected. In this appendix, effective address calculation time will be denoted as “+EA”; this will mean that the instruction takes the specified number of cycles <em>plus</em> the number of cycles required for effective address calculation by the selected addressing mode, as follows:</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Memory addressing mode</th>
<th style="text-align: left;">Additional cycles required for EA calculation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Base</strong></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">  <code class="sourceCode nasm">[<span class="kw">bp</span>]</code></td>
<td style="text-align: left;">5 cycles</td>
</tr>
<tr class="odd">
<td style="text-align: left;">  <code class="sourceCode nasm">[<span class="kw">bx</span>]</code></td>
<td style="text-align: left;">5 cycles</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Index</strong></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">  <code class="sourceCode nasm">[<span class="kw">si</span>]</code></td>
<td style="text-align: left;">5 cycles</td>
</tr>
<tr class="even">
<td style="text-align: left;">  <code class="sourceCode nasm">[<span class="kw">di</span>]</code></td>
<td style="text-align: left;">5 cycles</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Direct</strong></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">  <code class="sourceCode nasm">[MemVar]</code></td>
<td style="text-align: left;">6 cycles</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Base+Index</strong></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">  <code class="sourceCode nasm">[<span class="kw">bp</span>+<span class="kw">di</span>]</code></td>
<td style="text-align: left;">7 cycles</td>
</tr>
<tr class="odd">
<td style="text-align: left;">  <code class="sourceCode nasm">[<span class="kw">bx</span>+<span class="kw">si</span>]</code></td>
<td style="text-align: left;">7 cycles</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Base+Index</strong></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">  <code class="sourceCode nasm">[<span class="kw">bx</span>+<span class="kw">di</span>]</code></td>
<td style="text-align: left;">8 cycles</td>
</tr>
<tr class="even">
<td style="text-align: left;">  <code class="sourceCode nasm">[<span class="kw">bp</span>+<span class="kw">si</span>]</code></td>
<td style="text-align: left;">8 cycles</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Base+Displacement</strong></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">  <code class="sourceCode nasm">[<span class="kw">bx</span>+disp]</code></td>
<td style="text-align: left;">9 cycles</td>
</tr>
<tr class="odd">
<td style="text-align: left;">  <code class="sourceCode nasm">[<span class="kw">bp</span>+disp]</code></td>
<td style="text-align: left;">9 cycles</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Index+Displacement</strong></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">  <code class="sourceCode nasm">[<span class="kw">si</span>+disp]</code></td>
<td style="text-align: left;">9 cycles</td>
</tr>
<tr class="even">
<td style="text-align: left;">  <code class="sourceCode nasm">[<span class="kw">di</span>+disp]</code></td>
<td style="text-align: left;">9 cycles</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Base+Index+Displacement</strong></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">  <code class="sourceCode nasm">[<span class="kw">bp</span>+<span class="kw">di</span>+disp]</code></td>
<td style="text-align: left;">11 cycles</td>
</tr>
<tr class="odd">
<td style="text-align: left;">  <code class="sourceCode nasm">[<span class="kw">bx</span>+<span class="kw">si</span>+disp]</code></td>
<td style="text-align: left;">11 cycles</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Base+Index+Displacement</strong></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">  <code class="sourceCode nasm">[<span class="kw">bx</span>+<span class="kw">di</span>+disp]</code></td>
<td style="text-align: left;">12 cycles</td>
</tr>
<tr class="even">
<td style="text-align: left;">  <code class="sourceCode nasm">[<span class="kw">bp</span>+<span class="kw">si</span>+disp]</code></td>
<td style="text-align: left;">12 cycles</td>
</tr>
</tbody>
</table>
<p>For example, <code>mov bl,[si]</code> takes 13 cycles: 8 cycles for the execution of the basic instruction, and 5 cycles for effective address calculation.</p>
<p>Two additional cycles are required if a segment override prefix, as in <code>mov al,es:[di]</code>, is used.</p>
<p>If you want to know whether a given form of any instruction uses <em>mod-reg-rm</em> memory addressing, the rule is: if “+EA” appears in the “Cycles” field for that instruction form, <em>mod-reg-rm</em> memory addressing is used; if “+EA” does not appear, <em>mod-reg-rm</em> memory addressing is not used. There is no way to tell whether or not <em>mod-reg-rm</em> register addressing is used; the references listed below provide that information if you need it.</p>
<p>Note that segment override prefixes can be used on all <em>mod-reg-rm</em> memory accesses. Note also that all <em>mod-reg-rm</em> memory accesses default to accessing the segment pointed to by DS, except when BP is used to point to memory, in which case <em>mod-reg-rm</em> memory accesses default to accessing the segment pointed to by SS. Segment defaults used by non <em>mod-reg-rm</em> instructions are noted on a casebycase basis in this appendix, as are the cases in which segment override prefixes can and cannot be used.</p>
</section>
<section id="instruction-forms-shown" class="level3">
<h3>Instruction Forms Shown</h3>
<p>This appendix shows the various forms of each instruction. This does <em>not</em> mean that all forms accepted by the assembler are shown. Rather, forms that assemble to different opcodes, with different size and/or performance characteristics, are shown.</p>
<p>For example, <code>xlat</code>, <code>xlat [mem8]</code>, and <code>xlatb</code> are all forms of <code>xlat</code> that the assembler accepts. However, since all three forms assemble to exactly the same instruction byte, I will only show one of the forms, <code>xlat</code>. On the other hand, <code>or [WordVar],1000h</code> and <code>or [ByteVar],10h</code>, which appear to be two instances of the same instruction, actually assemble to two different instruction opcodes, with different sizes and performance characteristics, so I will show those forms of <code>or</code> separately, as <code>or [mem16],immed16</code> and <code>or [mem8],immed8</code>, respectively.</p>
<p>Note that some wordsized immediate operands to some instructions can be stored as bytes and signextended to a word at execution time. This can be done with immediate operands in the range 128 to +127 (0FFh to 07Fh). This is a distinct instruction form and is shown separately. To continue the example above, <code>or [WordVar],10h</code> would be another form of <code>or</code>, denoted as <code>or [mem16],sextimmed</code>.</p>
<p>Finally, I haven’t shown general forms of instructions that are always replaced by special shorter forms. For example, there’s a <em>mod-reg-rm</em> form of <code>mov reg16,immed16</code> that’s 4 bytes long. There’s also a special form of the same instruction that’s only 3 bytes long. The special form is superior, so MASM always assembles that form; there’s no good reason to want the other form. The only way to get the long form is to hand assemble the desired instruction and then use <code>db</code> to create the instruction. Since it’s almost certain that you’ll never want to use long forms of instructions that have special short forms, to avoid confusion I’ve omitted the long forms. The references listed below can be used to look up the long forms if you so desire.</p>
</section>
<section id="cycle-times" class="level3">
<h3>Cycle Times</h3>
<p>There is no definitive source for the execution times of 8088 instructions that I am aware of. Intel’s documentation has a number of mistakes, and so do all other sources I know of. I have done my best to provide correct cycle times in this appendix. I have crossreferenced the cycle times from three sources: Intel’s <em>iAPX 86,88 User’s Manual</em> (Santa Clara, CA, 1981, available directly from Intel or in technical bookstores), the <em>Microsoft Macro Assembler 5.0 Reference</em> that comes with MASM 5.0, and <em>The 8088 Book</em> (by Rector and Alexy, Osborne/McGrawHill, Berkeley, CA 1980). I have corrected all documented cycle times that I know to be wrong, and I have checked dubious times with the Zen timer to the greatest possible extent.</p>
<p>Nonetheless, there is no certainty that all times listed here are correct; I have no magic insight into the innards of the 8088, and the Zen timer has its limitations in determining Execution Unit execution times. In any case, rarely is any reference totally free of errors. That’s merely one more reason to follow the practice recommended throughout <em>The Zen of Assembler</em>: time your code. Even if all the cycle times in this chapter are correct, cycle times are only one part of overall execution time (instruction fetching, wait states, and the like also influence overall execution time)so you <em>must</em> time your code if you want to know how fast it really is.</p>
<p>By the way, 8086/80186/80286/80386/8087/80287/80387 cycle times are not given in this appendix. The abovementioned <em>Microsoft Macro Assembler 5.0 Reference</em> is an excellent cycletime reference for those processors.</p>
</section>
<section id="instruction-sizes" class="level3">
<h3>Instruction Sizes</h3>
<p>Instruction sizes in bytes are given in this appendix. However, the size of a given form of a given instruction that uses <em>mod-reg-rm</em> memory addressing may vary, depending on whether 0, 1, or 2 displacement bytes are present. In such cases, instruction sizes are given as a maximum/minimum range; for example, <code>adc [mem16],immed16</code> may be anywhere from 4 to 6 bytes in size, depending on the displacement used. Both the <em>Microsoft Macro Assembler 5.0 Reference</em> and <em>The 8086 Book</em> are good references on exact instruction formats and sizes.</p>
</section>
</section>
<section id="aaa-ascii-adjust-after-addition" class="level2">
<h2>AAA ASCII adjust after addition</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>aaa</code></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>aaa</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p>Given the binary result of the addition of two decimal digits (that is, two values bits 30 of which are in the range 0 to 9; the value of bits 74 are ignored, facilitating addition of ASCII digits but allowing addition of unpacked BCD values as well) in AL, with the flags still set from the addition, <code>aaa</code> corrects that binary result to one decimal digit (unpacked BCD) in AL, and increments AH if the result of the previous addition was greater than 9.</p>
<p>OF, SF, ZF, and PF are left undefined by <code>aaa</code>. AF and CF are set to 1 if the result of the previous addition was greater than 9.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code>= CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="aad-ascii-adjust-before-division" class="level2">
<h2>AAD ASCII adjust before division</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>aad</code></td>
<td style="text-align: left;">60</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>aad</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>aad</code> converts a twodigit unpacked BCD number stored in AX (with the most significant digit in AH) into a binary number in AX, by multiplying AH by 10 and adding it to 10, then zeroing AH. The name derives from the use of this instruction to convert a twodigit unpacked BCD value to a binary value in preparation for using that number as a dividend.</p>
<p>OF, AF, and CF are left undefined by <code>aad</code>. AH is always set to 0; the Sign flag is set on the basis of bit 7 of AL.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="aam-ascii-adjust-after-multiplication" class="level2">
<h2>AAM ASCII adjust after multiplication</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>aam</code></td>
<td style="text-align: left;">83</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>aam</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>aam</code> converts a binary value in the range 0 to 99 stored in AL into a two digit unpacked BCD number in AX, with the most significant digit in AH, by dividing AL by 10 and storing the quotient in AH and the remainder in AL. The name derives from the use of this instruction to convert the binary result of the multiplication of two unpacked BCD values (two values in the range 0 to 9) to an unpacked BCD result.</p>
<p>OF, AF, and CF are left undefined by <code>aam</code>. ZF is set according to the contents of AL, not AX. SF is also set according to the contents of AL; practically speaking, however, SF is always set to 0, since the sign bit of AL is always 0 after <code>aam</code>.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[``mem8``]</code> = 8bit memory data</p>
<p><code>[``mem16``]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="aas-ascii-adjust-after-subtraction" class="level2">
<h2>AAS ASCII adjust after subtraction</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>aas</code></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>aas</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p>Given the binary result of the subtraction of two decimal digits (that is, two values bits 30 of which are in the range 0 to 9; the value of bits 74 are ignored, facilitating subtraction of ASCII digits but allowing addition of unpacked BCD values as well) in AL, with the flags still set from the subtraction, <code>aas</code> corrects that binary result to a decimal digit (unpacked BCD) in AL. Note that if the result of the subtraction was less than 0 (borrow occurred), AH is decremented by <code>aas</code>, and AF and CF are set to 1.</p>
<p>OF, SF, ZF, and PF are left undefined by <code>aas</code>.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="adc-arithmetic-add-with-carry" class="level2">
<h2>ADC Arithmetic add with carry</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>adc</code> <em>reg8</em>,<em>reg8</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>adc</code> al,bl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>adc</code> [<em>mem8</em>],<em>reg8</em></td>
<td style="text-align: left;">16+EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>adc</code> [bx],ch</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>adc</code> <em>reg8</em>,[<em>mem8</em>]</td>
<td style="text-align: left;">9+EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>adc</code> dl,[bx+si]</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>adc</code> <em>reg16</em>,<em>reg16</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>adc</code> bx,di</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>adc</code> [<em>mem16</em>],<em>reg16</em></td>
<td style="text-align: left;">24+EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>adc</code> [WordVar+2],cx</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>adc</code> <em>reg16</em>,[<em>mem16</em>]</td>
<td style="text-align: left;">13+EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>adc</code> si,[di]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>adc</code> <em>reg8</em>,<em>immed8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>adc</code> ah,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>adc</code> [<em>mem8</em>],<em>immed8</em></td>
<td style="text-align: left;">17+EA</td>
<td style="text-align: left;">3 to 5</td>
<td style="text-align: left;"><code>adc</code> [ByteVar],10h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>adc</code> <em>reg16</em>,<em>sextimmed</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>adc</code> bx,7fh</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>adc</code> <em>reg16</em>,<em>immed16</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;"><code>adc</code> dx,1000h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>adc</code> [<em>mem16</em>],<em>sextimmed</em></td>
<td style="text-align: left;">25+EA</td>
<td style="text-align: left;">3 to 5</td>
<td style="text-align: left;"><code>adc</code> [WordVar],0ffffh</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>adc</code> [<em>mem16</em>],<em>immed16</em></td>
<td style="text-align: left;">25+EA</td>
<td style="text-align: left;">4 to 6</td>
<td style="text-align: left;"><code>adc</code> [WordVar],000ffh</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>adc</code> al,<em>immed8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>adc</code> al,40h</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>adc</code> ax,<em>immed16</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>adc</code> ax,8000h</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>adc</code> adds the source operand and the Carry flag to the destination operand; after the operation, the result replaces the destination operand. The add is an arithmetic add, and the carry allows multiple precision additions across several registers or memory locations. (To add without taking the Carry flag into account, use the <code>add</code> instruction.) All affected flags are set according to the operation. Most importantly, if the result does not fit into the destination operand, the Carry flag is set to 1.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="add-arithmetic-add-ignore-carry" class="level2">
<h2>ADD Arithmetic add (ignore carry)</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>add</code> <em>reg8</em>,<em>reg8</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>add</code> ah,al</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>add</code> [<em>mem8</em>],<em>reg8</em></td>
<td style="text-align: left;">16EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>add</code> [bx1],dh</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>add</code> <em>reg8</em>,[<em>mem8</em>]</td>
<td style="text-align: left;">9EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>add</code> ch,[bx]</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>add</code> <em>reg16</em>,<em>reg16</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>add</code> dx,ax</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>add</code> [<em>mem16</em>],<em>reg16</em></td>
<td style="text-align: left;">24EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>add</code> [bp5],ax</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>add</code> <em>reg16</em>,[<em>mem16</em>]</td>
<td style="text-align: left;">13EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>add</code> ax,[Basedi]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>add</code> <em>reg8</em>,<em>immed8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>add</code> dl,16</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>add</code> [<em>mem8</em>],<em>immed8</em></td>
<td style="text-align: left;">17EA</td>
<td style="text-align: left;">3 to 5</td>
<td style="text-align: left;"><code>add</code> byte ptr [si6],0c3h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>add</code> <em>reg16</em>,<em>sextimmed</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>add</code> si,0ff80h</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>add</code> <em>reg16</em>,<em>immed16</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;"><code>add</code> si,8000h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>add</code> [<em>mem16</em>],<em>sextimmed</em></td>
<td style="text-align: left;">25EA</td>
<td style="text-align: left;">3 to 5</td>
<td style="text-align: left;"><code>add</code> [WordVar],3</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>add</code> [<em>mem16</em>],<em>immed16</em></td>
<td style="text-align: left;">25EA</td>
<td style="text-align: left;">4 to 6</td>
<td style="text-align: left;"><code>add</code> [WordVar],300h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>add</code> al,<em>immed8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>add</code> al,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>add</code> ax,<em>immed16</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>add</code> ax,2</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>add</code> adds the source operand to the destination operand; after the operation the result replaces the destination operand. The add is an arithmetic add, and does <em>not</em> take the Carry flag into account. (To add using the Carry flag, use the <code>adc</code>add with carryinstruction.) All affected flags are set according to the operation. Most importantly, if the result does not fit into the destination operand, the Carry flag is set to 1.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code>= 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="and-logical-and" class="level2">
<h2>AND Logical and</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>and</code> <em>reg8</em>,<em>reg8</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>and</code> dl,dl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>and</code> [<em>mem8</em>],<em>reg8</em></td>
<td style="text-align: left;">16EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>and</code> [si1],dl</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>and</code> <em>reg8</em>,[<em>mem8</em>]</td>
<td style="text-align: left;">9EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>and</code> ah,[sibx]</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>and</code> <em>reg16</em>,<em>reg16</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>and</code> si,bp</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>and</code> [<em>mem16</em>],<em>reg16</em></td>
<td style="text-align: left;">24EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>and</code> [WordVar],dx</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>and</code> <em>reg16</em>,[<em>mem16</em>]</td>
<td style="text-align: left;">13EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>and</code> si,[WordVar2]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>and</code> <em>reg8</em>,<em>immed8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>and</code> ah,07fh</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>and</code> [<em>mem8</em>],<em>immed8</em></td>
<td style="text-align: left;">17EA</td>
<td style="text-align: left;">3 to 5</td>
<td style="text-align: left;"><code>and</code> byte ptr [di],5</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>and</code> <em>reg16</em>,<em>sextimmed</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>and</code> dx,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>and</code> <em>reg16</em>,<em>immed16</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;"><code>and</code> cx,0aaaah</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>and</code> [<em>mem16</em>],<em>sextimmed</em></td>
<td style="text-align: left;">25EA</td>
<td style="text-align: left;">3 to 5</td>
<td style="text-align: left;"><code>and</code> word ptr [bx],80h</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>and</code> [<em>mem16</em>],<em>immed16</em></td>
<td style="text-align: left;">25EA</td>
<td style="text-align: left;">4 to 6</td>
<td style="text-align: left;"><code>and</code> word ptr [di],05555h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>and</code> al,<em>immed8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>and</code> al,0f0h</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>and</code> ax,<em>immed16</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>and</code> ax,0ff00h</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>and</code> performs the logical operation “and” on its two operands. Once the operation is complete, the result replaces the destination operand. <code>and</code> is performed on a bitby bit basis, such that bit 0 of the source is anded with bit 0 of the destination, bit 1 of the source is anded with bit 1 of the destination, and so on. The “and” operation yields a 1 if <em>both</em> of the operands are 1, and a 0 if <em>either</em> operand is 0. Note that <code>and</code> makes the Auxiliary Carry flag undefined. CF and OF are cleared to 0, and the other affected flags are set according to the operation’s results.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="call-call-subroutine" class="level2">
<h2>CALL Call subroutine</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>call</code> <em>disp16</em></td>
<td style="text-align: left;">23</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>call</code> near ptr NearTarget</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>call</code> <em>reg16</em></td>
<td style="text-align: left;">20</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>call</code> bx</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>call</code> [<em>mem16</em>]</td>
<td style="text-align: left;">29EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>call</code> word ptr [Vecssi]</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>call</code> <em>segment:offset</em></td>
<td style="text-align: left;">36</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;"><code>call</code> far ptr FarTarget</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>call</code> [<em>mem32</em>]</td>
<td style="text-align: left;">53EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>call</code> dword ptr [FarVec]</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>call</code> branches to the destination specified by the single operand; that is, <code>call</code> sets IP (and CS, for far jumps) so that the next instruction executed is at the specified location. If the call is a far call, <code>call</code> then pushes CS onto the stack; then, whether the call is far or near, <code>call</code> pushes the offset of the start of the next instruction onto the stack. The pushed address can later be used by <code>ret</code> to return from the called subroutine to the instruction after <code>call</code>.</p>
<p>In addition to branching directly to either near or far labels, <code>call</code> can branch anywhere in the segment pointed to by CS by setting IP equal to an offset stored in any generalpurpose register. <code>call</code> can also branch to an address (either near or far) stored in memory and accessed through any <em>mod-reg-rm</em> addressing mode; this is ideal for calling addresses stored in jump tables.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="cbw-convert-signed-byte-in-al-to-signed-word-in-ax" class="level2">
<h2>CBW Convert signed byte in AL to signed word in AX</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>cbw</code></td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>cbw</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>cbw</code> signextends a signed byte in AL to a signed word in AX. In other words, bit 7 of AL is copied to all bits of AH.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="clc-clear-carry-flag" class="level2">
<h2>CLC Clear Carry flag</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>clc</code></td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>clc</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>clc</code> clears the Carry flag (CF) to 0. Use <code>clc</code> in situations where the Carry flag <em>must</em> be in a known cleared state before work begins, as when you are rotating a series of words or bytes using <code>rcl</code> or <code>rcr</code>, or before performing multiword addition in a loop with <code>adc</code>. <code>clc</code> can also be useful for returning a status in the Carry flag from a subroutine, or for presetting the Carry flag before a conditional jump that tests the Carry flag, such as <code>jc</code>.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="cld-clear-direction-flag" class="level2">
<h2>CLD Clear Direction flag</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>cld</code></td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>cld</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>cld</code> clears the Direction flag (DF) to 0. This affects the pointer register adjustments performed after each memory access by the string instructions <code>lods</code>, <code>stos</code>, <code>scas</code>, <code>movs</code>, and <code>cmps</code>. When DF=0, pointer registers (SI and/or DI) are incremented by 1 or 2; when DF=1, pointer registers are decremented by 1 or 2. DF is set to 1 by <code>std</code>.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="cli-clear-interrupt-flag" class="level2">
<h2>CLI Clear Interrupt flag</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>cli</code></td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>cli</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>cli</code> clears the Interrupt flag (IF) to 0, disabling maskable hardware interrupts (IRQ0 through IRQ7) until IF is set to 1. (Software interrupts via <code>int</code> are not affected by the state of IF.) <code>sti</code> sets the Interrupt flag to 1, enabling maskable hardware interrupts.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="cmc-complement-carry-flag" class="level2">
<h2>CMC Complement Carry flag</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>cmc</code></td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>cmc</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>cmc</code> flips the state of the Carry flag (CF). If the Carry flag is 0, <code>cmc</code> sets it to 1; if the Carry flag is 1, <code>cmc</code> sets it to 0.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="cmp-compare-by-subtracting-without-saving-result" class="level2">
<h2>CMP Compare by subtracting without saving result</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>cmp</code> <em>reg8</em>,<em>reg8</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>cmp</code> ah,al</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>cmp</code> [<em>mem8</em>],<em>reg8</em></td>
<td style="text-align: left;">9EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>cmp</code> [si],cl</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>cmp</code> <em>reg8</em>,[<em>mem8</em>]</td>
<td style="text-align: left;">9EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>cmp</code> ah,[bx]</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>cmp</code> <em>reg16</em>,<em>reg16</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>cmp</code> dx,ax</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>cmp</code> [<em>mem16</em>],<em>reg16</em></td>
<td style="text-align: left;">13EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>cmp</code> [bxdiRecPtr],bx</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>cmp</code> <em>reg16</em>,[<em>mem16</em>]</td>
<td style="text-align: left;">13EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>cmp</code> bp,[bx1]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>cmp</code> <em>reg8</em>,<em>immed8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>cmp</code> ah,9</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>cmp</code> [<em>mem8</em>],<em>immed8</em></td>
<td style="text-align: left;">10EA</td>
<td style="text-align: left;">3 to 5</td>
<td style="text-align: left;"><code>cmp</code> [ByteVar],39h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>cmp</code> <em>reg16</em>,<em>sextimmed</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>cmp</code> dx,8</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>cmp</code> <em>reg16</em>,<em>immed16</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;"><code>cmp</code> sp,999h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>cmp</code> [<em>mem16</em>],<em>sextimmed</em></td>
<td style="text-align: left;">14EA</td>
<td style="text-align: left;">3 to 5</td>
<td style="text-align: left;"><code>cmp</code> [WordVar],12</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>cmp</code> [<em>mem16</em>],<em>immed16</em></td>
<td style="text-align: left;">14EA</td>
<td style="text-align: left;">4 to 6</td>
<td style="text-align: left;"><code>cmp</code> [WordVar],92h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>cmp</code> al,<em>immed8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>cmp</code> al,22</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>cmp</code> ax,<em>immed16</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>cmp</code> ax,722</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>cmp</code> compares two operands and sets the flags to indicate the results of the comparison. <em>Neither operand is affected</em>. The operation itself is identical to subtraction of the source from the destination without borrow (the operation of the <code>sub</code> instruction) save that the result is only used to set the flags, and does not replace the destination. Typically, <code>cmp</code> is followed by one of the conditional jump instructions; for example, <code>jz</code> to jump if the operands were equal, <code>jnz</code> if they were unequal, and so on.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="cmps-compare-string" class="level2">
<h2>CMPS Compare string</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>cmpsb</code></td>
<td style="text-align: left;">22</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>cmpsb</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>repz cmpsb</code></td>
<td style="text-align: left;">9(22*CX)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>repz cmpsb</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>repnz cmpsb</code></td>
<td style="text-align: left;">9(22*CX)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>repnz cmpsb</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>cmpsw</code></td>
<td style="text-align: left;">30</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>cmpsw</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>repz cmpsw</code></td>
<td style="text-align: left;">9(30*CX)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>repz cmpsw</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>repnz cmpsw</code></td>
<td style="text-align: left;">9(30*CX)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>repnz cmpsw</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>cmps</code> compares either the byte (<code>cmpsb</code>) or word (<code>cmpsw</code>) pointed to by DS:SI to the byte or word pointed to by ES:DI, adjusting both SI and DI after the operation, as described below. The use of DS as the source segment can be overridden, but ES must be the segment of the destination and cannot be overridden. SI must always be the source offset, and DI must always be the destination offset. The comparison is performed via a trial subtraction of the location pointed to by ES:DI from the location pointed to by DS:SI; just as with <code>cmp</code>, this trial subtraction alters only the flags, not any memory locations.</p>
<p>By placing an instruction repeat count in CX and preceding <code>cmpsb</code> or <code>cmpsw</code> with the <code>repz</code> or <code>repnz</code> prefix, it is possible to execute a single <code>cmps</code> up to 65,535 (0FFFFh) times, just as if that many <code>cmps</code> instructions had been executed, but without the need for any additional instruction fetching. Repeated <code>cmps</code> instructions end either when CX counts down to 0 or when the state of the Zero flag specified by <code>repz</code>/<code>repnz</code> ceases to be true. The Zero flag should be tested to determine whether a match/nonmatch was found after <code>repz cmps</code> or <code>repnz cmps</code> ends.</p>
<p>Note that if CX is 0 when repeated <code>cmps</code> is started, zero repetitions of <code>cmps</code>not 65,536 repetitionsare performed. After each <code>cmps</code>, SI and DI are adjusted (as described in the next paragraph) by either 1 (for <code>cmpsb</code>) or 2 (for <code>cmpsw</code>), and, if the <code>repz</code> or <code>repnz</code> prefix is being used, CX is decremented by 1. Note that the accumulator is not affected by <code>cmps</code>.</p>
<p>“Adjusting” SI and DI means incrementing them if the Direction flag is cleared (0) or decrementing them if the Direction flag is set (1).</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="cwd-convert-signed-word-in-ax-to-signed-doubleword-in-dxax" class="level2">
<h2>CWD Convert signed word in AX to signed doubleword in DX:AX</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>cwd</code></td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>cwd</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>cwd</code> signextends a signed word in AX to a signed doubleword in DX:AX. In other words, bit 15 of AX is copied to all bits of DX.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="daa-decimal-adjust-after-addition" class="level2">
<h2>DAA Decimal adjust after addition</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>daa</code></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>daa</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p>Given the binary result of the addition of two packed BCD values in AL, with the flags still set from the addition, <code>daa</code> corrects that binary result to two packed BCD digits in AL.</p>
<p>The Overflow flag is left in an undefined state by <code>daa</code>.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="das-decimal-adjust-after-subtraction" class="level2">
<h2>DAS Decimal adjust after subtraction</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>das</code></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>das</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p>Given the binary result of the subtraction of two packed BCD values in AL, with the flags still set from the subtraction, <code>das</code> corrects that binary result to two packed BCD digits in AL.</p>
<p>The Overflow flag is left in an undefined state by <code>das</code>.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="dec-decrement-operand" class="level2">
<h2>DEC Decrement operand</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>dec</code> <em>reg8</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>dec</code> ah</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>dec</code> [<em>mem8</em>]</td>
<td style="text-align: left;">15EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>dec</code> byte ptr [bx]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>dec</code> <em>reg16</em></td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>dec</code> si</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>dec</code> [<em>mem16</em>]</td>
<td style="text-align: left;">23EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>dec</code> [WordVar]</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>dec</code> decrements (subtracts 1 from) the operand. Decrementing an operand with <code>dec</code> is similar to subtracting 1 from the operand with <code>sub</code>; however, <code>dec</code> is more compact, since no immediate operand is required, and, unlike <code>sub</code>, the Carry flag is not affected by <code>dec</code>. Note the special, shorter 16bitregister form of <code>dec</code>.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="div-unsigned-divide" class="level2">
<h2>DIV Unsigned divide</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>div</code> <em>reg8</em></td>
<td style="text-align: left;">80 to 90</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>div</code> bh</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>div</code> [<em>mem8</em>]</td>
<td style="text-align: left;">86EA to 96EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>div</code> byte ptr [si3]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>div</code> <em>reg16</em></td>
<td style="text-align: left;">144 to 162</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>div</code> cx</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>div</code> [<em>mem16</em>]</td>
<td style="text-align: left;">154EA to 172EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>div</code> [WordVar]</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>div</code> performs a 16x8 unsigned division of AX by a byte operand, storing the quotient in AL and the remainder in AH, or a 32x16 unsigned multiplication of DX:AX by a word operand, storing the quotient in AX and the remainder in DX. Note that in order to use a byte value in AL as a dividend, you must zeroextend it to a word in AX (<code>sub ah,ah</code> can be used for this purpose). Similarly, in order to divide a word value in AX by another word value, you must zeroextend it to a doubleword in DX:AX, generally with <code>sub dx,dx</code>. Also note that for 16x8 division, the quotient must be no larger than 8 bits, and for 32x16 division, the quotient must be no larger than 16 bits. If the quotient is too large, or if the divisor is 0, a dividebyzero interrupt, <code>int 0</code>, is executed.</p>
<p>OF, SF, ZF, AF, PF, and CF are left in undefined states by <code>div</code>.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="hlt-halt" class="level2">
<h2>HLT Halt</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>hlt</code></td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>hlt</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>hlt</code> stops the 8088 until a hardware interrupt, a nonmaskable interrupt, or a processor reset occurs. This instruction is almost never used in normal PC programs.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="idiv-signed-divide" class="level2">
<h2>IDIV Signed divide</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>idiv</code> <em>reg8</em></td>
<td style="text-align: left;">101 to 112</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>idiv</code> cl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>idiv</code> [<em>mem8</em>]</td>
<td style="text-align: left;">107EA to 118EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>idiv</code> [ByteVar]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>idiv</code> <em>reg16</em></td>
<td style="text-align: left;">165 to 184</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>idiv</code> bx</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>idiv</code> [<em>mem16</em>]</td>
<td style="text-align: left;">175EA to 194EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>idiv</code> word ptr [bxsi]</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>idiv</code> performs a 16x8 signed division of AX by a byte operand, storing the quotient in AL and the remainder in AH, or a 32x16 signed multiplication of DX:AX by a word operand, storing the quotient in AX and the remainder in DX. Note that in order to use a byte value in AL as a dividend, you must signextend it to a word in AX (<code>cbw</code> can be used for this purpose). Similarly, in order to divide a word value in AX by another word value, you must signextend it to a doubleword in DX:AX, generally with <code>cwd</code>. Also note that for 16x8 division, the quotient must be no larger than 8 bits (including the sign bit), and for 32x16 division, the quotient must be no larger than 16 bits (including the sign bit). If the quotient is too large, or if the divisor is 0, a dividebyzero interrupt, <code>int 0</code>, is executed.</p>
<p>OF, SF, ZF, AF, PF, and CF are left in undefined states by <code>idiv</code>.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="imul-signed-multiply" class="level2">
<h2>IMUL Signed multiply</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>imul</code> <em>reg8</em></td>
<td style="text-align: left;">80 to 98</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>imul</code> ch</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>imul</code> [<em>mem8</em>]</td>
<td style="text-align: left;">86EA to 104EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>imul</code> byte ptr [bx]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>imul</code> <em>reg16</em></td>
<td style="text-align: left;">128 to 154</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>imul</code> bp</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>imul</code> [<em>mem16</em>]</td>
<td style="text-align: left;">138EA to 164EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>imul</code> [WordVarsi]</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>imul</code> performs an 8x8 signed multiplication of AL by a byte operand, storing the result in AX, or a 16x16 signed multiplication of AX by a word operand, storing the result in DX:AX. Note that AH is changed by 8x8 multiplication even though it is not an operand; the same is true of DX for 16x16 multiplication.</p>
<p>CF and OF are set to 1 if and only if the upper half of the result (AH for 8x8 multiplies, DX for 16x16 multiplies) is not a signextension of the lower half (that is, if the upper half of the result is <em>not</em> all 0 bits or all 1 bits), and set to 0 otherwise. SF, ZF, AF, and PF are left in undefined states.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="in-input-byte-from-io-port" class="level2">
<h2>IN Input byte from I/O port</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>in</code> al,dx</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>in</code> al,dx</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>in</code> al,<em>immed8</em></td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>in</code> al,1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>in</code> ax,dx</td>
<td style="text-align: left;">12</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>in</code> ax,dx</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>in</code> ax,<em>immed8</em></td>
<td style="text-align: left;">14</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>in</code> ax,92h</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>in</code> reads data from the specified I/O port into the accumulator. Note that data <em>must</em> go to the accumulator, and that only DX or a constant may be used to address the I/O port. Note also that a constant may only be used to address I/O ports in the range 0255; DX must be used to address I/O ports in the range 25665,535.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="inc-increment-operand" class="level2">
<h2>INC Increment operand</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>inc</code> <em>reg8</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>inc</code> ah</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>inc</code> [<em>mem8</em>]</td>
<td style="text-align: left;">15EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>inc</code> byte ptr [bx]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>inc</code> <em>reg16</em></td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>inc</code> si</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>inc</code> [<em>mem16</em>]</td>
<td style="text-align: left;">23EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>inc</code> [WordVar]</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>inc</code> increments (adds 1 to) the operand. Incrementing an operand with <code>inc</code> is similar to adding 1 to the operand with <code>add</code>; however, <code>inc</code> is more compact, since no immediate operand is required, and, unlike <code>add</code>, the Carry flag is not affected by <code>inc</code>. Note the special, shorter 16bit register form of <code>inc</code>.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="int-software-interrupt" class="level2">
<h2>INT Software interrupt</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>int</code> <em>immed8</em></td>
<td style="text-align: left;">71</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>int</code> 10h</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>int</code> 3</td>
<td style="text-align: left;">72</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>int</code> 3</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>int</code> generates a software interrupt to one of 256 segment:offset vectors stored in the first 1024 bytes of memory. The operand specifies which vector, in the range 0 to 255, is to be used; <code>int n</code> branches to the address specified by the segment:offset pointer stored at address <code>0000:n*4</code>. When an interrupt is performed, the FLAGS register is pushed on the stack, followed by the current CS and then the IP of the instruction after the <code>int</code>, so that a later <code>iret</code> can restore the pre interrupt FLAGS register and return to the instruction following the <code>int</code> instruction. The Interrupt flag is cleared by <code>int</code>, preventing hardware interrupts from being recognized until IF is set again. TF is also cleared.</p>
<p>There’s also a special 1byte form of <code>int</code> specifically for executing interrupt 3. Debuggers use interrupt 3 to set “breakpoints” in code by replacing an instruction byte to be stopped at with the singlebyte opcode for <code>int 3</code>. Normal programs use the 2byte form of <code>int</code>, which takes an 8bit immediate numeric value.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="into-execute-int-4-if-overflow-flag-set" class="level2">
<h2>INTO Execute int 4 if Overflow flag set</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>into</code></td>
<td style="text-align: left;">73 (OF=1)/4 (OF=0)</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>into</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>into</code> executes an <code>int 4</code> if the Overflow flag is set (equal to 1), and does nothing otherwise. This is a compact (1 bytes) way to check for overflow after arithmetic operations and branch to a common handler if overflow does occur. The Interrupt flag is cleared by <code>into</code>. TF is also cleared.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="iret-return-from-interrupt" class="level2">
<h2>IRET Return from interrupt</h2>
<table>
<caption>Instruction forms</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>iret</code></td>
<td style="text-align: left;">44</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>iret</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>iret</code> is the proper way to exit from an interrupt service routine; that is, from code called branched to with <code>int</code> or started by hardware that generates hardware interrupts, such as serial ports, the timer chip, the keyboard, and the like. <code>iret</code> pops the return address from the top of the stack into CS:IP (IP must be on top of the stack, followed by CS), and then pops the next word from the stack into the FLAGS register. (This is the state in which both hardware and software interrupts leave the stack.) <em>All flags are affected</em>.</p>
<p>For interrupts triggered by hardware, additional steps, such as issuing an “end of interrupt” (EOI) command, are generally required in order to prepare the hardware for another interrupt before <code>iret</code> is executed, depending on the hardware involved. Consult your PC and peripheral hardware documentation.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="j-jump-on-condition" class="level2">
<h2>J? Jump on condition</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Instruction forms</th>
<th style="text-align: left;">Descriptions</th>
<th style="text-align: left;">Jump conditions</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>ja</code> <em>disp8</em></td>
<td style="text-align: left;">Jump above</td>
<td style="text-align: left;">CF=0 and ZF=0</td>
<td style="text-align: left;"><code>ja</code> OutOfRange</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>jae</code> <em>disp8</em></td>
<td style="text-align: left;">Jump above or equal</td>
<td style="text-align: left;">CF=0</td>
<td style="text-align: left;"><code>jae</code> XLabel</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>jb</code> <em>disp8</em></td>
<td style="text-align: left;">Jump below</td>
<td style="text-align: left;">CF=1</td>
<td style="text-align: left;"><code>jb</code> TooLow</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>jbe</code> <em>disp8</em></td>
<td style="text-align: left;">Jump below or equal</td>
<td style="text-align: left;">CF=1 or ZF=1</td>
<td style="text-align: left;"><code>jbe</code> Exit</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>jc</code> <em>disp8</em></td>
<td style="text-align: left;">Jump Carry flag set</td>
<td style="text-align: left;">CF=1</td>
<td style="text-align: left;"><code>jc</code> NextTest</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>je</code> <em>disp8</em></td>
<td style="text-align: left;">Jump equal</td>
<td style="text-align: left;">ZF=1</td>
<td style="text-align: left;"><code>je</code> Same</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>jg</code> <em>disp8</em></td>
<td style="text-align: left;">Jump greater</td>
<td style="text-align: left;">ZF=0 and SF=OF</td>
<td style="text-align: left;"><code>jg</code> Greater</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>jge</code> <em>disp8</em></td>
<td style="text-align: left;">Jump greater than or equal</td>
<td style="text-align: left;">SF=OF</td>
<td style="text-align: left;"><code>jge</code> GtThanEq</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>jl</code> <em>disp8</em></td>
<td style="text-align: left;">Jump less than</td>
<td style="text-align: left;">SF&lt;&gt;OF</td>
<td style="text-align: left;"><code>jl</code> IsLessThan</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>jle</code> <em>disp8</em></td>
<td style="text-align: left;">Jump less than or equal</td>
<td style="text-align: left;">ZF=1 or SF&lt;&gt;OF</td>
<td style="text-align: left;"><code>jle</code> LessThanEq</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>jna</code> <em>disp8</em></td>
<td style="text-align: left;">Jump not above</td>
<td style="text-align: left;">CF=1 or ZF=1</td>
<td style="text-align: left;"><code>jna</code> NotAbove</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>jnae</code> <em>disp8</em></td>
<td style="text-align: left;">Jump not above or equal</td>
<td style="text-align: left;">CF=1</td>
<td style="text-align: left;"><code>jnae</code> Skip1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>jnb</code> <em>disp8</em></td>
<td style="text-align: left;">Jump not below</td>
<td style="text-align: left;">CF=0</td>
<td style="text-align: left;"><code>jnb</code> OffTop</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>jnbe</code> <em>disp8</em></td>
<td style="text-align: left;">Jump not below or equal</td>
<td style="text-align: left;">CF=0 and ZF=0</td>
<td style="text-align: left;"><code>jnbe</code> TooHigh</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>jnc</code> <em>disp8</em></td>
<td style="text-align: left;">Jump Carry flag not set</td>
<td style="text-align: left;">CF=0</td>
<td style="text-align: left;"><code>jnc</code> TryAgain</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>jne</code> <em>disp8</em></td>
<td style="text-align: left;">Jump not equal</td>
<td style="text-align: left;">ZF=0</td>
<td style="text-align: left;"><code>jne</code> Mismatch</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>jng</code> <em>disp8</em></td>
<td style="text-align: left;">Jump not greater</td>
<td style="text-align: left;">ZF=1 or SF&lt;&gt;OF</td>
<td style="text-align: left;"><code>jng</code> LoopBottom</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>jnge</code> <em>disp8</em></td>
<td style="text-align: left;">Jump not greater than or equal</td>
<td style="text-align: left;">SF&lt;&gt;OF</td>
<td style="text-align: left;"><code>jnge</code> Point2</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>jnl</code> <em>disp8</em></td>
<td style="text-align: left;">Jump not less than</td>
<td style="text-align: left;">SF=OF</td>
<td style="text-align: left;"><code>jnl</code> NotLess</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>jnle</code> <em>disp8</em></td>
<td style="text-align: left;">Jump not less than or equal</td>
<td style="text-align: left;">ZF=0 and SF=OF</td>
<td style="text-align: left;"><code>jnle</code> ShortLab</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>jno</code> <em>disp8</em></td>
<td style="text-align: left;">Jump Overflow flag not set</td>
<td style="text-align: left;">OF=0</td>
<td style="text-align: left;"><code>jno</code> NoOverflow</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>jnp</code> <em>disp8</em></td>
<td style="text-align: left;">Jump Parity flag not set</td>
<td style="text-align: left;">PF=0</td>
<td style="text-align: left;"><code>jnp</code> EndText</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>jns</code> <em>disp8</em></td>
<td style="text-align: left;">Jump Sign flag not set</td>
<td style="text-align: left;">SF=0</td>
<td style="text-align: left;"><code>jns</code> NoSign</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>jnz</code> <em>disp8</em></td>
<td style="text-align: left;">Jump not zero</td>
<td style="text-align: left;">ZF=0</td>
<td style="text-align: left;"><code>jnz</code> Different</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>jo</code> <em>disp8</em></td>
<td style="text-align: left;">Jump Overflow flag set</td>
<td style="text-align: left;">OF=1</td>
<td style="text-align: left;"><code>jo</code> Overflow</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>jp</code> <em>disp8</em></td>
<td style="text-align: left;">Jump Parity flag set</td>
<td style="text-align: left;">PF=1</td>
<td style="text-align: left;"><code>jp</code> ParCheck1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>jpe</code> <em>disp8</em></td>
<td style="text-align: left;">Jump Parity Even</td>
<td style="text-align: left;">PF=1</td>
<td style="text-align: left;"><code>jpe</code> ParityEven</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>jpo</code> <em>disp8</em></td>
<td style="text-align: left;">Jump Parity Odd</td>
<td style="text-align: left;">PF=0</td>
<td style="text-align: left;"><code>jpo</code> OddParity</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>js</code> <em>disp8</em></td>
<td style="text-align: left;">Jump Sign flag set</td>
<td style="text-align: left;">SF=1</td>
<td style="text-align: left;"><code>js</code> Negative</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>jz</code> <em>disp8</em></td>
<td style="text-align: left;">Jump zero</td>
<td style="text-align: left;">ZF=1</td>
<td style="text-align: left;"><code>jz</code> Match</td>
</tr>
</tbody>
</table>
<p>All conditional jumps take 16 <code>Cycles</code> if the condition is true and the branch is taken, or 4 <code>Cycles</code> if the condition is false and the branch is not taken. All conditional jump instructions are 2 bytes long.</p>
<p><strong>Notes:</strong></p>
<p>Each conditional jump instruction makes a short jump (a maximum of 127 bytes forward or 128 bytes back from the start of the instruction after the conditional jump) if the specified condition is true, or falls through if the condition is not true. The conditions all involve flags; the flag conditions tested by each conditional jump are given to the right of the mnemonic and its description, above.</p>
<p>The mnemonics incorporating “above” and “below” are for use after unsigned comparisons, whereas the mnemonics incorporating “less” and “greater” are for use after signed comparisons. “Equal” and “zero” may be used after either signed or unsigned comparisons.</p>
<p>Note that two or three different mnemonics often test the same condition; for example, <code>jc</code>, <code>jb</code>, and <code>jnae</code> all assemble to the same instruction, which branches only when the Carry flag is set to 1. The multiple mnemonics provide different logical ways to think of the instruction; for example, <code>jc</code> could be used to test a status returned in the Carry flag by a subroutine, while <code>jb</code> or <code>jnae</code> might be used after an unsigned comparison. Any of the three mnemonics would work, but it’s easier to use a mnemonic that’s logically related to the task at hand.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="jcxz-jump-if-cx-0" class="level2">
<h2>JCXZ Jump if CX = 0</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>jcxz</code> <em>disp8</em></td>
<td style="text-align: left;">18 (CX=0)/6 (CX&lt;&gt;0)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>jcxz</code> SkipTest</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p>Many instructions use CX as a counter. <code>jcxz</code>, which branches only if CX=0, allows you to test for the case where CX is 0, as for example to avoid executing a loop 65,536 times when the loop is entered with CX=0. The branch can only be a short branch (that is, no more than 127 bytes forward or 128 bytes back from the start of the instruction following <code>jcxz</code>), and will be taken only if CX=0 at the time the instruction is executed. If CX is any other value than 0, execution falls through to the next instruction.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="jmp-jump" class="level2">
<h2>JMP Jump</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>jmp</code> <em>disp8</em></td>
<td style="text-align: left;">15</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>jmp</code> short SkipAdd</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>jmp</code> <em>disp16</em></td>
<td style="text-align: left;">15</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>jmp</code> NearLabel</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>jmp</code> <em>reg16</em></td>
<td style="text-align: left;">11</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>jmp</code> dx</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>jmp</code> [<em>mem16</em>]</td>
<td style="text-align: left;">22EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>jmp</code> word ptr [Vecsbx]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>jmp</code> <em>segment:offset</em></td>
<td style="text-align: left;">15</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;"><code>jmp</code> FarLabel</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>jmp</code> [<em>mem32</em>]</td>
<td style="text-align: left;">32EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>jmp</code> dword ptr [FarVec]</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>jmp</code> branches to the destination specified by the single operand; that is, <code>jmp</code> sets IP (and CS, for far jumps) so that the next instruction executed is at the specified location. In addition to branching to either near or far labels, <code>jmp</code> can branch anywhere in the segment pointed to by CS by setting IP equal to an offset stored in any generalpurpose register. <code>jmp</code> can also branch to an address (either near or far) stored in memory and accessed through any <em>mod-reg-rm</em> addressing mode; this is ideal for branching to addresses stored in jump tables.</p>
<p>Note that short jumps can only reach labels within 127 or 128 bytes of the start of the instruction after the jump, but are 1 byte shorter than normal 16bitdisplacement jumps, which can reach anywhere in the current code segment.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="lahf-load-ah-from-8080-flags" class="level2">
<h2>LAHF Load AH from 8080 flags</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>lahf</code></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>lahf</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>lahf</code> copies the lower byte of the FLAGS register to AH. This action, which can be reversed with <code>sahf</code>, is intended to allow the 8088 to emulate the <code>push psw</code> instruction of the 8080; however, it can also be used to save five of the 8088’s flagsthe Sign flag, the Zero flag, the Auxiliary Carry flag, the Parity flag, and the Carry flagquickly and without involving the stack. Note that the Overflow flag is <em>not</em> copied to AH.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="lds-load-ds-pointer" class="level2">
<h2>LDS Load DS pointer</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>lds</code> [<em>mem32</em>]</td>
<td style="text-align: left;">24EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>lds</code> bx,[DwordVar]</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>lds</code> loads both DS and a generalpurpose register from a memory doubleword. This is useful for loading a segment:offset pointer to any location in the 8088’s address space in a single instruction. Note that segment:offset pointers loaded with <code>les</code> must be stored with the offset value at memory address <em>n</em> and the segment value at memory address <em>n</em>2.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="lea-load-effective-address" class="level2">
<h2>LEA Load effective address</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>lea</code> <em>reg16</em>,[<em>mem</em>]</td>
<td style="text-align: left;">2EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>lea</code> bx,[bpsi100h]</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>lea</code> calculates the offset of the source operand within its segment, then loads that offset into the destination operand. The destination operand must be a 16bit register, and <em>cannot</em> be memory. The source operand must be a memory operand, but may be of any size. In other words, the value stored in the destination operand is the offset of the first byte of the source operand in memory. The source operand is not actually read.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="les-load-es-pointer" class="level2">
<h2>LES Load ES pointer</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>les</code> [<em>mem32</em>]</td>
<td style="text-align: left;">24EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>les</code> di,dword ptr [bx]</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>les</code> loads both ES and a generalpurpose register from a memory doubleword. This is useful for loading a segment:offset pointer to any location in the 8088’s address space in a single instruction. Note that segment:offset pointers loaded with <code>les</code> must be stored with the offset value at memory address <em>n</em> and the segment value at memory address <em>n</em>2.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="lods-load-string" class="level2">
<h2>LODS Load string</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>lodsb</code></td>
<td style="text-align: left;">12</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>lodsb</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>rep lodsb</code></td>
<td style="text-align: left;">9(13*CX)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>rep lodsb</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>lodsw</code></td>
<td style="text-align: left;">16</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>lodsw</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>rep lodsw</code></td>
<td style="text-align: left;">9(17*CX)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>rep lodsw</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>lods</code> loads either AL (<code>lodsb</code>) or AX (<code>lodsw</code>) from the location pointed to by DS:SI, adjusting SI after the operation, as described below. DS may be overridden as the source segment, but SI must always be the source offset.</p>
<p>By placing an instruction repeat count in CX and preceding <code>lodsb</code> or <code>lodsw</code> with the <code>rep</code> prefix, it is possible to execute a single <code>lods</code> up to 65,535 (0FFFFh) times; however, this is not particularly useful, since the value loaded into AL or AX by each repeated <code>lods</code> will wipe out the value loaded by the previous repetition. After each <code>lods</code>, SI is adjusted (as described in the next paragraph) by either 1 (for <code>lodsb</code>) or 2 (for <code>lodsw</code>), and, if the <code>rep</code> prefix is being used, CX is decremented by 1.</p>
<p>“Adjusting” SI means incrementing SI if the Direction flag is cleared (0) or decrementing SI if the Direction flag is set (1).</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="loop-loop-while-cx-not-equal-to-0" class="level2">
<h2>LOOP Loop while CX not equal to 0</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>loop</code> <em>disp8</em></td>
<td style="text-align: left;">17 (CX&lt;&gt;0)/5 (CX=0)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>loop</code> WaitLoop</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>loop</code> is similar to the twoinstruction sequence <code>dec cx</code>/<code>jnz disp8</code>. When the <code>loop</code> instruction is executed, it first decrements CX, then it tests to see if CX equals 0. If CX is <em>not</em> 0 after being decremented, <code>loop</code> branches <em>disp8</em> bytes relative to the start of the instruction following <code>loop</code>; if CX is 0, execution falls through to the instruction after <code>loop</code>.</p>
<p>The difference between <code>loop</code> and the above twoinstruction sequence is that <code>loop</code> does not alter any flags, even when CX is decremented to 0. Be aware that if CX is initially 0, <code>loop</code> will decrement it to 65,535 (0FFFFh) and then perform the loop another 65,535 times.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="loopnz-loop-while-cx-not-equal-to-0-and-zero-flag-equal-to-0" class="level2">
<h2>LOOPNZ Loop while CX not equal to 0 and Zero flag equal to 0</h2>
<p><code>LOOPNE```</code>Loop while CX not equal to 0 and last result was not equal`</p>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>loopnz</code> <em>disp8</em></td>
<td style="text-align: left;">19 (CX&lt;&gt;0 and ZF=0)/5 (CX=0 or ZF=1)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>loopnz</code> PollLp</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>loopnz</code> (also known as <code>loopne</code>) is identical to <code>loop</code>, except that <code>loopnz</code> branches to the specified displacement only if CX isn’t equal to 0 after CX is decremented <em>and</em> the Zero flag is cleared to 0. This is useful for handling a maximum number of repetitions of a loop that normally terminates on a Zero flag setting of 1.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="loopz-loop-while-cx-not-equal-to-0-and-zero-flag-equal-to-1" class="level2">
<h2>LOOPZ Loop while CX not equal to 0 and Zero flag equal to 1</h2>
</section>
<section id="loope-loop-while-cx-not-equal-to-0-and-last-result-was-equal" class="level2">
<h2>LOOPE Loop while CX not equal to 0 and last result was equal</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>loopz</code> <em>disp8</em></td>
<td style="text-align: left;">18 (CX&lt;&gt;0 and ZF=1)/6 (CX=0 or ZF=0)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>loopz</code> MaxWtLp</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>loopz</code> (also known as <code>loope</code>) is identical to <code>loop</code>, except that <code>loopz</code> branches to the specified displacement only if CX isn’t equal to 0 after CX is decremented <em>and</em> the Zero flag is set to 1. This is useful for handling a maximum number of repetitions of a loop that normally terminates on a Zero flag setting of 0.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="mov-move-copy-right-operand-into-left-operand" class="level2">
<h2>MOV Move (copy) right operand into left operand</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>mov</code> <em>reg8</em>,<em>reg8</em></td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>mov</code> ch,al</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>mov</code> [<em>mem8</em>],<em>reg8</em></td>
<td style="text-align: left;">9EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>mov</code> [bx10h],dh</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>mov</code> <em>reg8</em>,[<em>mem8</em>]</td>
<td style="text-align: left;">8EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>mov</code> bl,[si]</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>mov</code> <em>reg16</em>,<em>reg16</em></td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>mov</code> ax,dx</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>mov</code> [<em>mem16</em>],<em>reg16</em></td>
<td style="text-align: left;">13EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>mov</code> [WordVar],cx</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>mov</code> <em>reg16</em>,[<em>mem16</em>]</td>
<td style="text-align: left;">12EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>mov</code> bx,[Tablebx]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>mov</code> <em>reg8</em>,<em>immed8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>mov</code> dl,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>mov</code> [<em>mem8</em>],<em>immed8</em></td>
<td style="text-align: left;">10EA</td>
<td style="text-align: left;">3 to 5</td>
<td style="text-align: left;"><code>mov</code> [ByteVar],1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>mov</code> <em>reg16</em>,<em>immed16</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>mov</code> ax,88h</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>mov</code> [<em>mem16</em>],<em>immed16</em></td>
<td style="text-align: left;">14EA</td>
<td style="text-align: left;">4 to 6</td>
<td style="text-align: left;"><code>mov</code> [WordVar],1000h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>mov</code> al,[<em>mem8</em>] (direct)</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>mov</code> al,[Flag]</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>mov</code> [<em>mem8</em>],al (direct)</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>mov</code> [ByteVar],al</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>mov</code> ax,[<em>mem16</em>] (direct)</td>
<td style="text-align: left;">14</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>mov</code> ax,[WordVar]</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>mov</code> [<em>mem16</em>],ax (direct)</td>
<td style="text-align: left;">14</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>mov</code> [Count],ax</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>mov</code> <em>segreg</em>,<em>reg16</em></td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>mov</code> es,ax</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>mov</code> <em>segreg</em>,[<em>mem16</em>]</td>
<td style="text-align: left;">12EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>mov</code> ds,[DataPtrsbx]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>mov</code> <em>reg16</em>,<em>segreg</em></td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>mov</code> dx,ds</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>mov</code> [<em>mem16</em>],<em>segreg</em></td>
<td style="text-align: left;">13EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>mov</code> [StackSeg],ss</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>mov</code> copies the contents of the source operand to the destination operand. The source operand is not affected, and no flags are affected. Note that, unlike other instructions that accept immediate operands, 16bit immediate operands to <code>mov</code> are never stored as a single byte that is sign extended at execution time. Note also that the special, shorter accumulatorspecific form of <code>mov</code> only applies to directaddressed operands, and that there is a special, 1byteshorter form of <code>mov</code> to load a register (but not a memory operand) with an immediate value.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="movs-move-string" class="level2">
<h2>MOVS Move string</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>movsb</code></td>
<td style="text-align: left;">18</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>movsb</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>rep movsb</code></td>
<td style="text-align: left;">9(17*CX)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>rep movsb</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>movsw</code></td>
<td style="text-align: left;">26</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>movsw</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>rep movsw</code></td>
<td style="text-align: left;">9(25*CX)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>rep movsw</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>movs</code> copies either the byte (<code>movsb</code>) or word (<code>movsw</code>) pointed to by DS:SI to the location pointed to by ES:DI, adjusting both SI and DI after the operation, as described below. The use of DS as the source segment can be overridden, but ES must be the segment of the destination and cannot be overridden. SI must always be the source offset, and DI must always be the destination offset.</p>
<p>By placing an instruction repeat count in CX and preceding <code>movsb</code> or <code>movsw</code> with the <code>rep</code> prefix, it is possible to execute a single <code>movs</code> up to 65,535 (0FFFFh) times, just as if that many <code>movs</code> instructions had been executed, but without the need for any additional instruction fetching. Note that if CX is 0 when <code>rep movs</code> is started, zero repetitions of <code>movs</code>not 65,536 repetitionsare performed. After each <code>movs</code>, SI and DI are adjusted (as described in the next paragraph) by either 1 (for <code>movsb</code>) or 2 (for <code>movsw</code>), and, if the <code>rep</code> prefix is being used, CX is decremented by 1.</p>
<p>“Adjusting” SI and DI means incrementing them if the Direction flag is cleared (0) or decrementing them if the Direction flag is set (1).</p>
<p>Note that the accumulator is not affected by <code>movs</code>.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="mul-unsigned-multiply" class="level2">
<h2>MUL Unsigned multiply</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>mul</code> <em>reg8</em></td>
<td style="text-align: left;">70 to 77</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>mul</code> ah</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>mul</code> [<em>mem8</em>]</td>
<td style="text-align: left;">76EA to 83EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>mul</code> byte ptr [bxsi]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>mul</code> <em>reg16</em></td>
<td style="text-align: left;">118 to 133</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>mul</code> cx</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>mul</code> [<em>mem16</em>]</td>
<td style="text-align: left;">128EA to 143EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>mul</code> [WordVar]</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>mul</code> performs an 8x8 unsigned multiplication of AL by a byte operand, storing the result in AX, or a 16x16 unsigned multiplication of AX by a word operand, storing the result in DX:AX. Note that AH is changed by 8x8 multiplication even though it is not an operand; the same is true of DX for 16x16 multiplication.</p>
<p>CF and OF are set to 1 if and only if the upper half of the result (AH for 8x8 multiplies, DX for 16x16 multiplies) is nonzero, and set to 0 otherwise. SF, ZF, AF, and PF are left in undefined states.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="neg-negate-twos-complement-i.e.multiply-by-1" class="level2">
<h2>NEG Negate (two’s complement; i.e. multiply by 1)</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>neg</code> <em>reg8</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>neg</code> cl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>neg</code> [<em>mem8</em>]</td>
<td style="text-align: left;">16EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>neg</code> [ByteVar]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>neg</code> <em>reg16</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>neg</code> si</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>neg</code> [<em>mem16</em>]</td>
<td style="text-align: left;">24EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>neg</code> word ptr [bxsi1]</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>neg</code> performs the assembly language equivalent of multiplying a value by 1. Keep in mind that negation is not the same as simply inverting each bit in the operand; another instruction, <code>not</code>, does that. The process of negation is also known as generating the <em>two’s complement</em> of a value; the two’s complement of a value added to that value yields zero.</p>
<p>If the operand is 0, CF is cleared and ZF is set; otherwise CF is set and ZF is cleared. This property can be useful in multiword negation. If the operand contains the maximum negative value (80h = 128 for byte operands, 8000h = 32,768 for word operands), there is no corresponding positive value that will fit in the operand, so the operand does not change; this case can be detected because it is the only case in which the Overflow flag is set by <code>neg</code>.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="nop-no-operation" class="level2">
<h2>NOP No operation</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>nop</code></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>nop</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p>This, the easiest to understand of all 8086family machine instructions, does nothing; its job is simply to take up space and/or time. The opcode for <code>nop</code> is actually the opcode for <code>xchg ax,ax</code>, which changes no registers and alters no flags, but which does take up 1 byte and require 3 <code>Cycles</code> to execute. <code>nop</code> is used for patching out machine instructions during debugging, leaving space for future procedure or interrupt calls, and padding timing loops. <code>nop</code> instructions are also inserted by MASM to fill reserved space that turns out not to be needed, such as the third byte of a forward <code>jmp</code> that turns out to be a <code>jmp short</code>.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="not-logical-not-ones-complement" class="level2">
<h2>NOT Logical not (one’s complement)</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>not</code> <em>reg8</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>not</code> al</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>not</code> [<em>mem8</em>]</td>
<td style="text-align: left;">16EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>not</code> byte ptr [bx]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>not</code> <em>reg16</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>not</code> dx</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>not</code> [<em>mem16</em>]</td>
<td style="text-align: left;">24EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>not</code> [WordVar]</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>not</code> inverts each individual bit within the operand. In other words, every bit that was 1 becomes 0, and every bit that was 0 becomes 1, just as if the operand had been exclusive ored with 0FFh (for byte operands) or 0FFFFh (for word operands). <code>not</code> performs the “logical not,” or “one’s complement,” operation. See the <code>neg</code> instruction for the negation, or “two’s complement,” operation.</p>
<p>Note that no flags are altered.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="or-logical-or" class="level2">
<h2>OR Logical or</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>or</code><em>reg8</em>,<em>reg8</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>or</code>al,dl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>or</code>[<em>mem8</em>],<em>reg8</em></td>
<td style="text-align: left;">16EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>or</code>[ByteVar],ch</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>or</code><em>reg8</em>,[<em>mem8</em>]</td>
<td style="text-align: left;">9EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>or</code>bh,[si]</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>or</code><em>reg16</em>,<em>reg16</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>or</code>bp,ax</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>or</code>[<em>mem16</em>],<em>reg16</em></td>
<td style="text-align: left;">24EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>or</code>[bpsi],cx</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>or</code><em>reg16</em>,[<em>mem16</em>]</td>
<td style="text-align: left;">13EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>or</code>ax,[bx]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>or</code><em>reg8</em>,<em>immed8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>or</code>cl,03h</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>or</code>[<em>mem8</em>],<em>immed8</em></td>
<td style="text-align: left;">17EA</td>
<td style="text-align: left;">3 to 5</td>
<td style="text-align: left;"><code>or</code>[ByteVar1],29h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>or</code><em>reg16</em>,<em>sextimmed</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>or</code>ax,01fh</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>or</code><em>reg16</em>,<em>immed16</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;"><code>or</code>ax,01fffh</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>or</code>[<em>mem16</em>],<em>sextimmed</em></td>
<td style="text-align: left;">25EA</td>
<td style="text-align: left;">3 to 5</td>
<td style="text-align: left;"><code>or</code>[WordVar],7fh</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>or</code>[<em>mem16</em>],<em>immed16</em></td>
<td style="text-align: left;">25EA</td>
<td style="text-align: left;">4 to 6</td>
<td style="text-align: left;"><code>or</code>[WordVar],7fffh</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>or</code>al,<em>immed8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>or</code>al,0c0h</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>or</code>ax,<em>immed16</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>or</code>ax,01ffh</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>or</code> performs the “or” logical operation between its two operands. Once the operation is complete, the result replaces the destination operand. <code>or</code> is performed on a bitby bit basis, such that bit 0 of the source is ored with bit 0 of the destination, bit 1 of the source is ored with bit 1 of the destination, and so on. The “or” operation yields a 1 if <em>either one</em> of the operands is 1, and a 0 only if both operands are 0. Note that <code>or</code> makes the Auxiliary Carry flag undefined. CF and OF are cleared to 0, and the other affected flags are set according to the operation’s results.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="out-output-byte-to-io-port" class="level2">
<h2>OUT Output byte to I/O port</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>out</code> dx,al</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>out</code> dx,al</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>out</code> <em>immed8</em>,al</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>out</code> 21h,al</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>out</code> dx,ax</td>
<td style="text-align: left;">12</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>out</code> dx,ax</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>out</code> <em>immed8</em>,ax</td>
<td style="text-align: left;">14</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>out</code> 10,ax</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>out</code> writes the data in the accumulator to the specified I/O port. Note that data <em>must</em> come from the accumulator, and that only DX or a constant may be used to address the I/O port. Note also that a constant may only be used to address I/O ports in the range 0255; DX must be used to address I/O ports in the range 25665,535.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="pop-pop-from-top-of-stack" class="level2">
<h2>POP Pop from top of stack</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>pop</code> <em>reg16</em></td>
<td style="text-align: left;">12</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>pop</code> cx</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>pop</code> <em>mem16</em></td>
<td style="text-align: left;">25EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>pop</code> word ptr [si1]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>pop</code> <em>segreg</em> (not CS)</td>
<td style="text-align: left;">12</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>pop</code> es</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>pop</code> pops the word on top of the stack into the specified operand. SP is incremented by 2 <em>after</em> the word comes off the stack. Remember that a word can be popped directly to memory, without passing through a register.</p>
<p>It is impossible to pop a bytesized item from the stack; it’s words or nothing. There is a separate instruction, <code>popf</code>, for popping the FLAGS register.</p>
<p>Note that CS cannot by popped off the stack with <code>pop</code>; in order to load CS from the stack, it must be loaded simultaneously with IP, usually via <code>retf</code>.</p>
<p>The top of the stack is always located at SS:SP; the segment cannot be overridden, and <code>pop</code> always uses SP to address memory. However, when a memory location is popped, <em>mod-reg-rm</em> addressing is used to point to the memory location, and the default segment of DS for that operand can be overridden.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="popf-pop-top-of-stack-into-flags-reg" class="level2">
<h2>POPF Pop top of stack into FLAGS reg</h2>
<table>
<caption>Instruction forms</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>popf</code></td>
<td style="text-align: left;">12</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>popf</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>popf</code> pops the word on top of the stack into the FLAGS register. SP is incremented by 2 <em>after</em> the word comes off the stack.</p>
<p>There is a separate instruction, <code>pop</code>, for popping into register and memory operands.</p>
<p>The top of the stack is always located at SS:SP; the segment cannot be overridden, and <code>popf</code> always uses SP to address memory.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="push-push-onto-top-of-stack" class="level2">
<h2>PUSH Push onto top of stack</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>push</code> <em>reg16</em></td>
<td style="text-align: left;">15</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>push</code> ax</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>push</code> <em>mem16</em></td>
<td style="text-align: left;">24EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>push</code> word ptr [bx]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>push</code> <em>segreg</em></td>
<td style="text-align: left;">14</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>push</code> ds</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>push</code> pushes the specified operand onto the top of the stack. SP is decremented by 2 <em>before</em> the word goes onto the stack. Remember that memory operands can be pushed directly onto the stack, without passing through a register.</p>
<p>It is impossible to push a bytesized item onto the stack; it’s words or nothing. There is a separate instruction, <code>pushf</code>, for pushing the FLAGS register.</p>
<p>The top of the stack is always located at SS:SP; the segment cannot be overridden, and <code>push</code> always uses SP to address memory. However, when a memory location is pushed, <em>mod-reg-rm</em> addressing is used to point to the memory location, and the default segment of DS for that operand can be overridden.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="pushf-push-flags-register-onto-top-of-stack" class="level2">
<h2>PUSHF Push FLAGS register onto top of stack</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>pushf</code></td>
<td style="text-align: left;">14</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>pushf</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>pushf</code> pushes the current contents of the FLAGS register onto the top of the stack. SP is decremented <em>before</em> the word goes onto the stack.</p>
<p>There is a separate instruction, <code>push</code>, for pushing other register data and memory data.</p>
<p>The FLAGS register is not affected when you <em>push</em> the flags, but only when you pop them back with <code>popf</code>.</p>
<p>The top of the stack is always located at SS:SP; the segment cannot be overridden, and <code>pushf</code> always uses SP to address memory.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="rcl-rotate-through-carry-left" class="level2">
<h2>RCL Rotate through carry left</h2>
<table>
<caption>Instruction forms</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>rcl</code> <em>reg8</em>,1</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>rcl</code> dl,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>rcl</code> [<em>mem8</em>],1</td>
<td style="text-align: left;">15EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>rcl</code> byte ptr [bxdi],1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>rcl</code> <em>reg16</em>,1</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>rcl</code> dx,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>rcl</code> [<em>mem16</em>],1</td>
<td style="text-align: left;">23EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>rcl</code> word ptr [di],1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>rcl</code> <em>reg8</em>,cl</td>
<td style="text-align: left;">8(4*CL)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>rcl</code> ah,cl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>rcl</code> [<em>mem8</em>],cl</td>
<td style="text-align: left;">20EA(4*CL)</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>rcl</code> [ByteVar],cl</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>rcl</code> <em>reg16</em>,cl</td>
<td style="text-align: left;">8(4*CL)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>rcl</code> ax,cl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>rcl</code> [<em>mem16</em>],cl</td>
<td style="text-align: left;">28EA(4*CL)</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>rcl</code> word ptr [bxIndex],cl</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>rcl</code> rotates the bits within the destination operand to the left, where left is toward the most significant bit, bit 15 for word operands, bit 7 for byte operands. A rotate is a shift (see <code>shl</code> and <code>shr</code>) that wraps around; with <code>rcl</code>, the leftmost bit (bit 15 for word operands, bit 7 for byte operands) of the operand is rotated into the Carry flag, the Carry flag is rotated into the rightmost bit of the operand (bit 0), and all intermediate bits are rotated one bit to the left.</p>
<p>The number of bit positions rotated may either be specified as the literal 1 or by the value in CL (not CX!). It is generally faster to perform sequential rotatebyone instructions for rotations of up to about 4 bits, and faster to use rotatebyCL instructions for longer rotations. Note that while CL may contain any value up to 255, it is meaningless to rotate by any value larger than 17, <em>even though the rotations are actually performed wasting <code>Cycles</code> on the 8088</em>.</p>
<p>OF is modified predictably <em>only</em> by the rotatebyone forms of <code>rcl</code>; after rotatebyCL forms, OF becomes undefined.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="rcr-rotate-through-carry-right" class="level2">
<h2>RCR Rotate through carry right</h2>
<table>
<caption>Instruction forms</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>rcr</code> <em>reg8</em>,1</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>rcr</code> cl,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>rcr</code> [<em>mem8</em>],1</td>
<td style="text-align: left;">15EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>rcr</code> byte ptr [di],1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>rcr</code> <em>reg16</em>,1</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>rcr</code> bx,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>rcr</code> [<em>mem16</em>],1</td>
<td style="text-align: left;">23EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>rcr</code> word ptr [bxdi],1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>rcr</code> <em>reg8</em>,cl</td>
<td style="text-align: left;">8(4*CL)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>rcr</code> dh,cl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>rcr</code> [<em>mem8</em>],cl</td>
<td style="text-align: left;">20EA(4*CL)</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>rcr</code> [ByteVar100h],cl</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>rcr</code> <em>reg16</em>,cl</td>
<td style="text-align: left;">8(4*CL)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>rcr</code> bx,cl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>rcr</code> [<em>mem16</em>],cl</td>
<td style="text-align: left;">28EA(4*CL)</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>rcr</code> [WordVar],cl</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>rcr</code> rotates the bits within the destination operand to the right, where right is toward the least significant bit, bit 0. A rotate is a shift (see <code>shl</code> and <code>shr</code>) that wraps around; with <code>rcr</code>, the rightmost bit (bit 0) of the operand is rotated into the Carry flag, the Carry flag is rotated into the leftmost bit of the operand (bit 15 for word operands, bit 7 for byte operands), and all intermediate bits are rotated one bit to the right.</p>
<p>The number of bit positions rotated may either be specified as the literal 1 or by the value in CL (not CX!). It is generally faster to perform sequential rotatebyone instructions for rotations of up to about 4 bits, and faster to use rotatebyCL instructions for longer rotations. Note that while CL may contain any value up to 255, it is meaningless to rotate by any value larger than 17, <em>even though the rotations are actually performed wasting <code>Cycles</code> on the 8088</em>.</p>
<p>OF is modified predictably <em>only</em> by the rotatebyone forms of <code>rcr</code>; after rotatebyCL forms, OF becomes undefined.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="ret-return-from-subroutine-call" class="level2">
<h2>RET Return from subroutine call</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>retn</code></td>
<td style="text-align: left;">20</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>ret</code> (in near proc)</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>retf</code></td>
<td style="text-align: left;">34</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>retf</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>retn</code> <em>immed16</em></td>
<td style="text-align: left;">24</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>retn</code> 10</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>retf</code> <em>immed16</em></td>
<td style="text-align: left;">33</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>ret</code> 512 (in far proc)</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p>There are two kinds of returns, near and far, where near pops IP from the stack (returning to an address within the current code segment) and far pops both CS and IP from the stack (usually returning to an address in some other code segment). Ordinarily the <code>ret</code> form is used, with the assembler resolving it to a near or far return opcode to match the current <code>proc</code> directive’s use of the <code>near</code> or <code>far</code> specifier. Alternatively, <code>retf</code> or <code>retn</code> may be used to select explicitly the type of return; however, be aware that the <code>retf</code> and <code>retn</code> forms are <em>not</em> available in MASM prior to version 5.0.</p>
<p><code>ret</code> may take an operand indicating how many bytes of stack space are to be released (the amount to be added to the stack pointer) as the return is executed. This is used to discard parameters that were pushed onto the stack for the procedure’s use immediately prior to the procedure call.</p>
<p>No two references agree on the execution times of <code>ret immed16</code> and <code>retf immed16</code>. The times shown above are from <em>Microsoft Macro Assembler 5.0 Reference</em>, which are closest to the times measured with the Zen timer. The Zen timer actually measured longer execution times still, most likely due to the effects of the prefetch queue bottleneck and DRAM refresh.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="rol-rotate-left" class="level2">
<h2>ROL Rotate left</h2>
<table>
<caption>Instruction forms</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>rol</code> <em>reg8</em>,1</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>rol</code> cl,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>rol</code> [<em>mem8</em>],1</td>
<td style="text-align: left;">15EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>rol</code> byte ptr [di],1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>rol</code> <em>reg16</em>,1</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>rol</code> ax,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>rol</code> [<em>mem16</em>],1</td>
<td style="text-align: left;">23EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>rol</code> word ptr [Basebx],1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>rol</code> <em>reg8</em>,cl</td>
<td style="text-align: left;">8(4*CL)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>rol</code> dl,cl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>rol</code> [<em>mem8</em>],cl</td>
<td style="text-align: left;">20EA(4*CL)</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>rol</code> byte ptr [bx],cl</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>rol</code> <em>reg16</em>,cl</td>
<td style="text-align: left;">8(4*CL)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>rol</code> di,cl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>rol</code> [<em>mem16</em>],cl</td>
<td style="text-align: left;">28EA(4*CL)</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>rol</code> [WordVar],cl</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>rol</code> rotates the bits within the destination operand to the left, where left is toward the most significant bit, bit 15 for word operands and bit 7 for byte operands. A rotate is a shift (see <code>shl</code> and <code>shr</code>) that wraps around; with <code>rol</code>, the leftmost bit of the operand (bit 15 for word operands, bit 7 for byte operands) is rotated into the rightmost bit, and all intermediate bits are rotated one bit to the left.</p>
<p>The number of bit positions rotated may either be specified as the literal 1 or by the value in CL (not CX!). It is generally faster to perform sequential rotatebyone instructions for rotations of up to about 4 bits, and faster to use rotatebyCL instructions for longer rotations. Note that while CL may contain any value up to 255, it is meaningless to rotate by any value larger than 16, <em>even though the rotations are actually performed wasting <code>Cycles</code> on the 8088</em>.</p>
<p>The leftmost bit is copied into the Carry flag on each rotate operation. OF is modified predictably <em>only</em> by the rotatebyone forms of <code>rol</code>; after rotatebyCL forms, OF becomes undefined.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="ror-rotate-right" class="level2">
<h2>ROR Rotate right</h2>
<table>
<caption>Instruction forms</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>ror</code> <em>reg8</em>,1</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>ror</code> dl,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>ror</code> [<em>mem8</em>],1</td>
<td style="text-align: left;">15EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>ror</code> [ByteVar],1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>ror</code> <em>reg16</em>,1</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>ror</code> bx,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>ror</code> [<em>mem16</em>],1</td>
<td style="text-align: left;">23EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>ror</code> word ptr [bxsi],1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>ror</code> <em>reg8</em>,cl</td>
<td style="text-align: left;">8(4*CL)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>ror</code> ah,cl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>ror</code> [<em>mem8</em>],cl</td>
<td style="text-align: left;">20EA(4*CL)</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>ror</code> byte ptr [si100h],cl</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>ror</code> <em>reg16</em>,cl</td>
<td style="text-align: left;">8(4*CL)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>ror</code> si,cl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>ror</code> [<em>mem16</em>],cl</td>
<td style="text-align: left;">28EA(4*CL)</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>ror</code> [WordVar1],cl</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>ror</code> rotates the bits within the destination operand to the right, where right is toward the least significant bit, bit 0. A rotate is a shift (see <code>shl</code> and <code>shr</code>) that wraps around; with <code>ror</code>, the rightmost bit (bit 0) of the operand is rotated into the leftmost bit (bit 15 for word operands, bit 7 for byte operands), and all intermediate bits are rotated one bit to the right.</p>
<p>The number of bit positions rotated may either be specified as the literal 1 or by the value in CL (not CX!). It is generally faster to perform sequential rotatebyone instructions for rotations of up to about 4 bits, and faster to use rotatebyCL instructions for longer rotations. Note that while CL may contain any value up to 255, it is meaningless to rotate by any value larger than 16, <em>even though the rotations are actually performed wasting <code>Cycles</code>on the 8088</em>.</p>
<p>Bit 0 of the operand is not only copied to the leftmost bit, but is also copied into the Carry flag by each rotation. OF is modified predictably <em>only</em> by the rotatebyone forms of <code>ror</code>; after rotatebyCL forms, OF becomes undefined.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="sahf-store-ah-to-8080-flags" class="level2">
<h2>SAHF Store AH to 8080 flags</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>sahf</code></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>sahf</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>sahf</code> copies AH to the lower byte of the FLAGS register. This reverses the action of <code>lahf</code>, and is intended to allow the 8088 to emulate the <code>pop psw</code> instruction of the 8080; however, it can also be used to restore five of the 8088’s flagsthe Sign flag, the Zero flag, the Auxiliary Carry flag, the Parity flag, and the Carry flag quickly and without involving the stack. Note that the Overflow flag is <em>not</em> affected.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="sar-shift-arithmetic-right" class="level2">
<h2>SAR Shift arithmetic right</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>sar</code> <em>reg8</em>,1</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>sar</code> bh,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>sar</code> [<em>mem8</em>],1</td>
<td style="text-align: left;">15EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>sar</code> [ByteVar],1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>sar</code> <em>reg16</em>,1</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>sar</code> dx,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>sar</code> [<em>mem16</em>],1</td>
<td style="text-align: left;">23EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>sar</code> word ptr [bx1],1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>sar</code> <em>reg8</em>,cl</td>
<td style="text-align: left;">8(4*CL)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>sar</code> ch,cl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>sar</code> [<em>mem8</em>],cl</td>
<td style="text-align: left;">20EA(4*CL)</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>sar</code> byte ptr [bx],cl</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>sar</code> <em>reg16</em>,cl</td>
<td style="text-align: left;">8(4*CL)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>sar</code> ax,cl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>sar</code> [<em>mem16</em>],cl</td>
<td style="text-align: left;">28EA(4*CL)</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>sar</code> [WordVar],cl</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>sar</code> shifts all bits within the destination operand to the right, where right is toward the least significant bit, bit 0. The number of bit positions shifted may either be specified as the literal 1 or by the value in CL (not CX!). It is generally faster to perform sequential shiftbyone instructions for shifts of up to about four bits, and faster to use shiftbyCL instructions for longer shifts. Note that while CL may contain any value up to 255, it is meaningless to shift by any value larger than 16, <em>even though the shifts are actually performed wasting <code>Cycles</code> on the 8088</em>.</p>
<p>The rightmost bit of the operand is shifted into the Carry flag by each shift; <em>the leftmost bit is left unchanged</em>. This preservation of the most significant bit, which is the difference between <code>sar</code> and <code>shr</code>, maintains the sign of the operand. The Auxiliary Carry flag (AF) becomes undefined after this instruction. OF is modified predictably <em>only</em> by the shiftby one forms of <code>sar</code>; after shiftbyCL forms, OF becomes undefined.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="sbb-arithmetic-subtract-with-borrow" class="level2">
<h2>SBB Arithmetic subtract with borrow</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>sbb</code> <em>reg8</em>,<em>reg8</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>sbb</code> ah,dh</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>sbb</code> [<em>mem8</em>],<em>reg8</em></td>
<td style="text-align: left;">16EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>sbb</code> [ByteVar],al</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>sbb</code> <em>reg8</em>,[<em>mem8</em>]</td>
<td style="text-align: left;">9EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>sbb</code> al,[sibp18h]</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>sbb</code> <em>reg16</em>,<em>reg16</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>sbb</code> bx,cx</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>sbb</code> [<em>mem16</em>],<em>reg16</em></td>
<td style="text-align: left;">24EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>sbb</code> [WordVar2],ax</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>sbb</code> <em>reg16</em>,[<em>mem16</em>]</td>
<td style="text-align: left;">13EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>sbb</code> dx,[si]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>sbb</code> <em>reg8</em>,<em>immed8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>sbb</code> cl,0</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>sbb</code> [<em>mem8</em>],<em>immed8</em></td>
<td style="text-align: left;">17EA</td>
<td style="text-align: left;">3 to 5</td>
<td style="text-align: left;"><code>sbb</code> [ByteVar],20h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>sbb</code> <em>reg16</em>,<em>sextimmed</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>sbb</code> dx,40h</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>sbb</code> <em>reg16</em>,<em>immed16</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;"><code>sbb</code> dx,8000h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>sbb</code> [<em>mem16</em>],<em>sextimmed</em></td>
<td style="text-align: left;">25EA</td>
<td style="text-align: left;">3 to 5</td>
<td style="text-align: left;"><code>sbb</code> word ptr [bx],1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>sbb</code> [<em>mem16</em>],<em>immed16</em></td>
<td style="text-align: left;">25EA</td>
<td style="text-align: left;">4 to 6</td>
<td style="text-align: left;"><code>sbb</code> word ptr [bx],1000h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>sbb</code> al,<em>immed8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>sbb</code> al,10</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>sbb</code> ax,<em>immed8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>sbb</code> ax,1</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>sbb</code> performs a subtraction with borrow, where the source is subtracted from the destination, and then the Carry flag is subtracted from the result. The result replaces the destination. If the result is negative, the Carry flag is set, indicating a borrow. To subtract without taking the Carry flag into account (i.e., without borrowing) use the <code>sbb</code> instruction.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="scas-scan-string" class="level2">
<h2>SCAS Scan string</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>scasb</code></td>
<td style="text-align: left;">15</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>scasb</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>repz scasb</code></td>
<td style="text-align: left;">9(15*CX)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>repz scasb</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>repnz scasb</code></td>
<td style="text-align: left;">9(15*CX)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>repnz scasb</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>scasw</code></td>
<td style="text-align: left;">19</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>scasw</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>repz scasw</code></td>
<td style="text-align: left;">9(19*CX)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>repz scasw</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>repnz scasw</code></td>
<td style="text-align: left;">9(19*CX)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>repnz scasw</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>scas</code> compares either AL (<code>scasb</code>) or AX (<code>scasw</code>) to the location pointed to by ES:DI, adjusting DI after the operation, as described below. ES must be the segment of the destination and cannot be overridden. Similarly, DI must always be the destination offset. The comparison is performed via a trial subtraction of the location pointed to by ES:DI from AL or AX; just as with <code>cmp</code>, this trial subtraction alters only the flags, not AL/AX or the location pointed to by ES:DI.</p>
<p>By placing an instruction repeat count in CX and preceding <code>scasb</code> or <code>scasw</code> with the <code>repz</code> or <code>repnz</code> prefix, it is possible to execute a single <code>scas</code> up to 65,535 (0FFFFh) times, just as if that many <code>scas</code> instructions had been executed, but without the need for any additional instruction fetching. Repeated <code>scas</code> instructions end either when CX counts down to 0 or when the state of the Zero flag specified by <code>repz</code>/<code>repnz</code> ceases to be true. The Zero flag should be used to determine whether a match/nonmatch was found after <code>repz scas</code> or <code>repnz scas</code> ends.</p>
<p>Note that if CX is 0 when <code>repz scas</code> or <code>repnz scas</code> is started, zero repetitions of <code>scas</code>not 65,536 repetitionsare performed. After each <code>scas</code>, DI is adjusted (as described in the next paragraph) by either 1 (for <code>scasb</code>) or 2 (for <code>scasw</code>), and, if the <code>repz</code> or <code>repnz</code> prefix is being used, CX is decremented by 1.</p>
<p>“Adjusting” DI means incrementing DI if the Direction flag is cleared (0) or decrementing DI if the Direction flag is set (1).</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="shl-shift-logical-left" class="level2">
<h2>SHL Shift logical left</h2>
<p><code>SAL Shift arithmetic left</code></p>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>shl</code> <em>reg8</em>,1</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>shl</code> dl,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>shl</code> [<em>mem8</em>],1</td>
<td style="text-align: left;">15EA</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">to 4 <code>shl</code> byte ptr [bxsi],1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>shl</code> <em>reg16</em>,1</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>shl</code> cx,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>shl</code> [<em>mem16</em>],1</td>
<td style="text-align: left;">23EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>shl</code> word ptr [di],1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>shl</code> <em>reg8</em>,cl</td>
<td style="text-align: left;">8(4*CL)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>shl</code> al,cl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>shl</code> [<em>mem8</em>],cl</td>
<td style="text-align: left;">20EA(4*CL)</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>shl</code> [ByteVar],cl</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>shl</code> <em>reg16</em>,cl</td>
<td style="text-align: left;">8(4*CL)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>shl</code> bp,cl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>shl</code> [<em>mem16</em>],cl</td>
<td style="text-align: left;">28EA(4*CL)</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>shl</code> [WordVar1],cl</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>shl</code> (also known as <code>sal</code>; the two mnemonics refer to the same instruction) shifts the bits within the destination operand to the left, where left is toward the most significant bit, bit 15 for word operands and bit 7 for byte operands. The number of bit positions shifted may either be specified as the literal 1 or by the value in CL (not CX!). It is generally faster to perform sequential shiftbyone instructions for shifts of up to about 4 bits, and faster to use shiftbyCL instructions for longer shifts. Note that while CL may contain any value up to 255, it is meaningless to shift by any value larger than 16, <em>even though the shifts are actually performed wasting <code>Cycles</code> on the 8088</em>.</p>
<p>The leftmost bit of the operand is shifted into the Carry flag; the rightmost bit is cleared to 0. The Auxiliary Carry flag (AF) becomes undefined after this instruction. OF is modified predictably <em>only</em> by the shiftbyone forms of <code>shl</code>; after shiftbyCL forms, OF becomes undefined.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="shr-shift-logical-right" class="level2">
<h2>SHR Shift logical right</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>shr</code> <em>reg8</em>,1</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>shr</code> al,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>shr</code> [<em>mem8</em>],1</td>
<td style="text-align: left;">15EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>shr</code> [ByteVar],1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>shr</code> <em>reg16</em>,1</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>shr</code> bx,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>shr</code> [<em>mem16</em>],1</td>
<td style="text-align: left;">23EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>shr</code> word ptr [si],1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>shr</code> <em>reg8</em>,cl</td>
<td style="text-align: left;">8(4*CL)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>shr</code> dl,cl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>shr</code> [<em>mem8</em>],cl</td>
<td style="text-align: left;">20EA(4*CL)</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>shr</code> [ByteVarbx],cl</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>shr</code> <em>reg16</em>,cl</td>
<td style="text-align: left;">8(4*CL)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>shr</code> si,cl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>shr</code> [<em>mem16</em>],cl</td>
<td style="text-align: left;">28EA(4*CL)</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>shr</code> [WordVarsi],cl</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>shr</code> shifts the bits within the destination operand to the right, where right is toward the least significant bit, bit 0. The number of bit positions shifted may either be specified as the literal 1 or by the value in CL (not CX!). It is generally faster to perform sequential shiftbyone instructions for shifts of up to about four bits, and faster to use shiftbyCL instructions for longer shifts. Note that while CL may contain any value up to 255, it is meaningless to shift by any value larger than 16, <em>even though the shifts are actually performed wasting <code>Cycles</code> on the 8088</em>.</p>
<p>The rightmost bit of the operand is shifted into the Carry flag; the leftmost bit is cleared to 0. The Auxiliary Carry flag (AF) becomes undefined after this instruction. OF is modified predictably <em>only</em> by the shiftbyone forms of <code>shr</code>; after shiftbyCL forms, OF becomes undefined.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="stc-set-carry-flag" class="level2">
<h2>STC Set Carry flag</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>stc</code></td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>stc</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>stc</code> sets the Carry flag (CF) to 1. <code>stc</code> can be useful for returning a status in the Carry flag from a subroutine, or for presetting the Carry flag before <code>adc</code>, <code>sbb</code>, or a conditional jump that tests the Carry flag, such as <code>jc</code>.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="std-set-direction-flag" class="level2">
<h2>STD Set Direction flag</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>std</code></td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>std</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>std</code> sets the Direction flag (DF) to the set (1) state. This affects the pointerregister adjustments performed after each memory access by the string instructions <code>lods</code>, <code>stos</code>, <code>scas</code>, <code>movs</code>, and <code>cmps</code>. When DF=0, pointer registers (SI and/or DI) are incremented by 1 or 2; when DF=1, pointer registers are decremented by 1 or 2. DF is set to 0 by <code>cld</code>.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="sti-set-interrupt-flag" class="level2">
<h2>STI Set Interrupt flag</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>sti</code></td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>sti</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>sti</code> sets the Interrupt flag (IF) to the set (1) state, allowing maskable hardware interrupts (IRQ0 through IRQ7) to occur. (Software interrupts via <code>int</code> are not affected by the state of IF.) Both <code>cli</code> and <code>int</code> clear the Interrupt flag to 0, disabling maskable hardware interrupts.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="stos-store-string" class="level2">
<h2>STOS Store string</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>stosb</code></td>
<td style="text-align: left;">11</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>stosb</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>rep stosb</code></td>
<td style="text-align: left;">9(10*CX)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>rep stosb</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>stosw</code></td>
<td style="text-align: left;">15</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>stosw</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>rep stosw</code></td>
<td style="text-align: left;">9(14*CX)</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>rep stosw</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>stos</code> stores either AL (<code>stosb</code>) or AX (<code>stosw</code>) to the location pointed to by ES:DI, adjusting DI after the operation, as described below. ES must be the segment of the destination and cannot be overridden. Similarly, DI must always be the destination offset.</p>
<p>By placing an instruction repeat count in CX and preceding <code>stosb</code> or <code>stosw</code> with the <code>rep</code> prefix, it is possible to execute a single <code>stos</code> up to 65,535 (0FFFFh) times, just as if that many <code>stos</code> instructions had been executed, but without the need for any additional instruction fetching. Note that if CX is 0 when <code>rep stos</code> is started, zero repetitions of <code>stos</code>not 65,536 repetitionsare performed. After each <code>stos</code>, DI is adjusted (as described in the next paragraph) by either 1 (for <code>stosb</code>) or 2 (for <code>stosw</code>), and, if the <code>rep</code> prefix is being used, CX is decremented by 1.</p>
<p>“Adjusting” DI means incrementing DI if the Direction flag is cleared (0) or decrementing DI if the Direction flag is set (1).</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="sub-arithmetic-subtraction-no-borrow" class="level2">
<h2>SUB Arithmetic subtraction (no borrow)</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>sub</code> <em>reg8</em>,<em>reg8</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>sub</code> al,dl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>sub</code> [<em>mem8</em>],<em>reg8</em></td>
<td style="text-align: left;">16EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>sub</code> [ByteVar],ah</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>sub</code> <em>reg8</em>,[<em>mem8</em>]</td>
<td style="text-align: left;">9EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>sub</code> dl,[si1]</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>sub</code> <em>reg16</em>,<em>reg16</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>sub</code> ax,dx</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>sub</code> [<em>mem16</em>],<em>reg16</em></td>
<td style="text-align: left;">24EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>sub</code> [WordVar],ax</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>sub</code> <em>reg16</em>,[<em>mem16</em>]</td>
<td style="text-align: left;">13EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>sub</code> cx,[dibp]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>sub</code> <em>reg8</em>,<em>immed8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>sub</code> dl,10h</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>sub</code> [<em>mem8</em>],<em>immed8</em></td>
<td style="text-align: left;">17EA</td>
<td style="text-align: left;">3 to 5</td>
<td style="text-align: left;"><code>sub</code> [ByteVar],01h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>sub</code> <em>reg16</em>,<em>sextimmed</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>sub</code> dx,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>sub</code> <em>reg16</em>,<em>immed16</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;"><code>sub</code> dx,80h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>sub</code> [<em>mem16</em>],<em>sextimmed</em></td>
<td style="text-align: left;">25EA</td>
<td style="text-align: left;">3 to 5</td>
<td style="text-align: left;"><code>sub</code> word ptr [bp],10h</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>sub</code> [<em>mem16</em>],<em>immed16</em></td>
<td style="text-align: left;">25EA</td>
<td style="text-align: left;">4 to 6</td>
<td style="text-align: left;"><code>sub</code> word ptr [bp],100h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>sub</code> al,<em>immed8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>sub</code> al,20h</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>sub</code> ax,<em>immed16</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>sub</code> ax,100h</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>sub</code> performs a subtraction without borrow, where the source is subtracted from the destination; the result replaces the destination. If the result is negative, the Carry flag is set, indicating a borrow. Multiple precision subtraction can be performed by following <code>sub</code> with <code>sbb</code> subtract with borrowwhich takes the Carry flag into account as a borrow.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="test-compare-by-anding-without-saving-result" class="level2">
<h2>TEST Compare by anding without saving result</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>test</code> <em>reg8</em>,<em>reg8</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>test</code> dl,bl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>test</code> [<em>mem8</em>],<em>reg8</em></td>
<td style="text-align: left;">9EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>test</code> [si],al</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>test</code> <em>reg8</em>,[<em>mem8</em>]</td>
<td style="text-align: left;">9EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>test</code> dh,[bx]</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>test</code> <em>reg16</em>,<em>reg16</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>test</code> si,cx</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>test</code> [<em>mem16</em>],<em>reg16</em></td>
<td style="text-align: left;">13EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>test</code> [WordVar],dx</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>test</code> <em>reg16</em>,[<em>mem16</em>]</td>
<td style="text-align: left;">13EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>test</code> ax,[bx2]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>test</code> <em>reg8</em>,<em>immed8</em></td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>test</code> bh,040h</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>test</code> [<em>mem8</em>],<em>immed8</em></td>
<td style="text-align: left;">11EA</td>
<td style="text-align: left;">3 to 5</td>
<td style="text-align: left;"><code>test</code> byte ptr [di],44h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>test</code> <em>reg16</em>,<em>immed16</em></td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;"><code>test</code> bx,08080h</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>test</code> [<em>mem16</em>],<em>immed16</em></td>
<td style="text-align: left;">15EA</td>
<td style="text-align: left;">4 to 6</td>
<td style="text-align: left;"><code>test</code> word ptr [bp],0101h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>test</code> al,<em>immed8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>test</code> al,0f7h</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>test</code> ax,<em>immed16</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>test</code> ax,09001h</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>test</code> performs the logical operation “and” on its two operands, but does not store the result. The “and” operation is performed on a bitby bit basis, such that bit 0 of the source is anded with bit 0 of the destination, bit 1 of the source is anded with bit 1 of the destination, and so on. The “and” operation yields a 1 if <em>both</em> of the operands are 1, and a 0 if <em>either</em> operand is 0. Note that <code>test</code> makes the Auxiliary Carry flag undefined. CF and OF are cleared to 0, and the other affected flags are set according to the operation’s results. Note also that the ordering of the operands doesn’t matter; <code>test al,[bx]</code> and <code>test [bx],al</code> function identically.</p>
<p>Unlike <code>and</code>, <code>test</code> cannot store signextendable 16bit values as bytes, then signextend them to words at execution time.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="wait-wait-for-interrupt-or-test-signal" class="level2">
<h2>WAIT Wait for interrupt or test signal</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>wait</code></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>wait</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>wait</code> stops the 8088 until either a hardware interrupt occurs or the signal on the 8088’s TEST pin becomes true. <code>wait</code> is often used for synchronization with coprocessors, notably the 8087, to make sure that the coprocessor has finished its current instruction before starting another coprocessor instruction and/or to make sure that memory variables aren’t accessed out of sequence by different processors. Note that when a hardware interrupt occurs during <code>wait</code>, the <code>iret</code> that ends that interrupt returns to the <code>wait</code> instruction, not the following instruction. Also note that 3 is the minimum number of <code>Cycles</code> that <code>wait</code> can take, in the case where the signal on the TEST pin is already true; the actual number of <code>Cycles</code> can be much higher, depending on the coprocessor.</p>
<p>Also known as <code>fwait</code>.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="xchg-exchange-operands" class="level2">
<h2>XCHG Exchange operands</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>xchg</code> <em>reg8</em>,<em>reg8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>xchg</code> al,ah</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>xchg</code> [<em>mem8</em>],<em>reg8</em></td>
<td style="text-align: left;">17EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>xchg</code> [ByteVar],dl</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>xchg</code> <em>reg8</em>,[<em>mem8</em>]</td>
<td style="text-align: left;">17EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>xchg</code> dh,[ByteVar]</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>xchg</code> <em>reg16</em>,<em>reg16</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>xchg</code> dx,bx</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>xchg</code> [<em>mem16</em>],<em>reg16</em></td>
<td style="text-align: left;">25EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>xchg</code> [bx],cx</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>xchg</code> <em>reg16</em>,[<em>mem16</em>]</td>
<td style="text-align: left;">25EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>xchg</code> ax,[bx]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>xchg</code> ax,<em>reg16</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>xchg</code> ax,bx</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>xchg</code> exchanges the contents of its two operands. Note that the ordering of the operands doesn’t matter; <code>xchg al,ah</code> and <code>xchg ah,al</code> function identically.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="xlat-translate-from-table" class="level2">
<h2>XLAT Translate from table</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>xlat</code></td>
<td style="text-align: left;">11</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;"><code>xlat</code></td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>xlat</code> loads into AL the byte of memory addressed by the sum of BX and AL. <code>xlat</code> defaults to accessing the segment pointed to by DS, but this can be overridden with a segment override prefix.</p>
<p>Also known as <code>xlatb</code>.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
<section id="xor-exclusive-or" class="level2">
<h2>XOR Exclusive or</h2>
<table>
<caption>Flags affected</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>O</code></td>
<td style="text-align: left;"><code>D</code></td>
<td style="text-align: left;"><code>I</code></td>
<td style="text-align: left;"><code>T</code></td>
<td style="text-align: left;"><code>S</code></td>
<td style="text-align: left;"><code>Z</code></td>
<td style="text-align: left;"><code>A</code></td>
<td style="text-align: left;"><code>P</code></td>
<td style="text-align: left;"><code>C</code></td>
<td style="text-align: left;"><code>OF</code>: Overflow flag</td>
<td style="text-align: left;"><code>DF</code>: Direction flag</td>
<td style="text-align: left;"><code>IF</code>: Interrupt flag</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>F</code></td>
<td style="text-align: left;"><code>TF</code>: Trap flag</td>
<td style="text-align: left;"><code>SF</code>: Sign flag</td>
<td style="text-align: left;"><code>ZF</code>: Zero flag</td>
</tr>
<tr class="odd">
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"><code>AF</code>: Aux carry</td>
<td style="text-align: left;"><code>PF</code>: Parity flag</td>
<td style="text-align: left;"><code>CF</code>: Carry flag</td>
</tr>
</tbody>
</table>
<table>
<caption>Instruction forms</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Cycles</th>
<th style="text-align: left;">Bytes</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>xor</code> <em>reg8</em>,<em>reg8</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>xor</code> dh,dl</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>xor</code> [<em>mem8</em>],<em>reg8</em></td>
<td style="text-align: left;">16EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>xor</code> [ByteVar],bh</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>xor</code> <em>reg8</em>,[<em>mem8</em>]</td>
<td style="text-align: left;">9EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>xor</code> al,[si]</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>xor</code> <em>reg16</em>,<em>reg16</em></td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>xor</code> ax,ax</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>xor</code> [<em>mem16</em>],<em>reg16</em></td>
<td style="text-align: left;">24EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>xor</code> [WordVar1],bp</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>xor</code> <em>reg16</em>,[<em>mem16</em>]</td>
<td style="text-align: left;">13EA</td>
<td style="text-align: left;">2 to 4</td>
<td style="text-align: left;"><code>xor</code> si,[di]</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>xor</code> <em>reg8</em>,<em>immed8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>xor</code> al,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>xor</code> [<em>mem8</em>],<em>immed8</em></td>
<td style="text-align: left;">17EA</td>
<td style="text-align: left;">3 to 5</td>
<td style="text-align: left;"><code>xor</code> [ByteVar],11h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>xor</code> <em>reg16</em>,<em>sextimmed</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>xor</code> bx,1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>xor</code> <em>reg16</em>,<em>immed16</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;"><code>xor</code> bx,2222h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>xor</code> [<em>mem16</em>],<em>sextimmed</em></td>
<td style="text-align: left;">25EA</td>
<td style="text-align: left;">3 to 5</td>
<td style="text-align: left;"><code>xor</code> word ptr [bx],17h</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>xor</code> [<em>mem16</em>],<em>immed16</em></td>
<td style="text-align: left;">25EA</td>
<td style="text-align: left;">4 to 6</td>
<td style="text-align: left;"><code>xor</code> word ptr [bx],100h</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>xor</code> al,<em>immed8</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;"><code>xor</code> al,33h</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>xor</code> ax,<em>immed16</em></td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;"><code>xor</code> ax,0cccch</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong></p>
<p><code>xor</code> performs an “exclusive or” logical operation between its two operands. Once the operation is complete, the result replaces the destination operand. <code>xor</code> is performed on a bitby bit basis, such that bit 0 of the source is exclusive ored with bit 0 of the destination, bit 1 of the source is exclusive ored with bit 1 of the destination, and so on. The “exclusive or” operation yields a 1 if the operands are different, and a 0 if the operands are the same. Note that <code>xor</code> makes the Auxiliary Carry flag undefined. CF and OF are cleared to 0, and the other affected flags are set according to the operation’s results.</p>
<p><code>reg8</code> = AL AH BL BH CL CH DL DH</p>
<p><code>reg16</code> = AX BX CX DX BP SP SI DI</p>
<p><code>[mem8]</code> = 8bit memory data</p>
<p><code>[mem16]</code> = 16bit memory data</p>
<p><code>immed8</code> = 8bit immediate data</p>
<p><code>immed16</code> = 16bit immediate data</p>
<p><code>sextimmed</code> = 8bit signextendable value</p>
<p><code>segreg</code> = CS DS SS ES</p>
<p><code>disp8</code> = 8bit branch displacement</p>
<p><code>[mem32]</code> = 32bit memory data</p>
<p><code>disp16</code> = 16bit branch displacement</p>
<p><code>[mem]</code> = memory data of any size</p>
<p><code>segment:offset</code> = 32bit segment:offset address</p>
</section>
</section>
<section id="appendix-b-ascii-table-and-pc-character-set" class="level1">
<h1>Appendix B: ASCII Table And PC Character Set</h1>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Dec</th>
<th style="text-align: left;">Hex</th>
<th style="text-align: left;">Binary</th>
<th style="text-align: left;">Char</th>
<th style="text-align: left;">Name</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: left;">00</td>
<td style="text-align: left;">00000000</td>
<td style="text-align: left;">NUL</td>
<td style="text-align: left;">Null</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: left;">01</td>
<td style="text-align: left;">00000001</td>
<td style="text-align: left;">STX</td>
<td style="text-align: left;">Start of Header</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2</td>
<td style="text-align: left;">02</td>
<td style="text-align: left;">00000010</td>
<td style="text-align: left;">SOT</td>
<td style="text-align: left;">Start of Text</td>
</tr>
<tr class="even">
<td style="text-align: left;">3</td>
<td style="text-align: left;">03</td>
<td style="text-align: left;">00000011</td>
<td style="text-align: left;">ETX</td>
<td style="text-align: left;">End of Text</td>
</tr>
<tr class="odd">
<td style="text-align: left;">4</td>
<td style="text-align: left;">04</td>
<td style="text-align: left;">00000100</td>
<td style="text-align: left;">EOT</td>
<td style="text-align: left;">End of Transmission</td>
</tr>
<tr class="even">
<td style="text-align: left;">5</td>
<td style="text-align: left;">05</td>
<td style="text-align: left;">00000101</td>
<td style="text-align: left;">ENQ</td>
<td style="text-align: left;">Enquiry</td>
</tr>
<tr class="odd">
<td style="text-align: left;">6</td>
<td style="text-align: left;">06</td>
<td style="text-align: left;">00000110</td>
<td style="text-align: left;">ACK</td>
<td style="text-align: left;">Acknowledge</td>
</tr>
<tr class="even">
<td style="text-align: left;">7</td>
<td style="text-align: left;">07</td>
<td style="text-align: left;">00000111</td>
<td style="text-align: left;">BEL</td>
<td style="text-align: left;">Bell</td>
</tr>
<tr class="odd">
<td style="text-align: left;">8</td>
<td style="text-align: left;">08</td>
<td style="text-align: left;">00001000</td>
<td style="text-align: left;">BS</td>
<td style="text-align: left;">BackSpace</td>
</tr>
<tr class="even">
<td style="text-align: left;">9</td>
<td style="text-align: left;">09</td>
<td style="text-align: left;">00001001</td>
<td style="text-align: left;">HT</td>
<td style="text-align: left;">Horizontal Tabulation</td>
</tr>
<tr class="odd">
<td style="text-align: left;">10</td>
<td style="text-align: left;">0A</td>
<td style="text-align: left;">00001010</td>
<td style="text-align: left;">LF</td>
<td style="text-align: left;">Line Feed</td>
</tr>
<tr class="even">
<td style="text-align: left;">11</td>
<td style="text-align: left;">0B</td>
<td style="text-align: left;">00001011</td>
<td style="text-align: left;">VT</td>
<td style="text-align: left;">Vertical Tabulation</td>
</tr>
<tr class="odd">
<td style="text-align: left;">12</td>
<td style="text-align: left;">0C</td>
<td style="text-align: left;">00001100</td>
<td style="text-align: left;">FF</td>
<td style="text-align: left;">Form Feed</td>
</tr>
<tr class="even">
<td style="text-align: left;">13</td>
<td style="text-align: left;">0D</td>
<td style="text-align: left;">00001101</td>
<td style="text-align: left;">CR</td>
<td style="text-align: left;">Carriage Return</td>
</tr>
<tr class="odd">
<td style="text-align: left;">14</td>
<td style="text-align: left;">0E</td>
<td style="text-align: left;">00001110</td>
<td style="text-align: left;">SO</td>
<td style="text-align: left;">Shift Out</td>
</tr>
<tr class="even">
<td style="text-align: left;">15</td>
<td style="text-align: left;">0F</td>
<td style="text-align: left;">00001111</td>
<td style="text-align: left;">SI</td>
<td style="text-align: left;">Shift In</td>
</tr>
<tr class="odd">
<td style="text-align: left;">16</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">00010000</td>
<td style="text-align: left;">DLE</td>
<td style="text-align: left;">Data Link Escape</td>
</tr>
<tr class="even">
<td style="text-align: left;">17</td>
<td style="text-align: left;">11</td>
<td style="text-align: left;">00010001</td>
<td style="text-align: left;">DC1</td>
<td style="text-align: left;">Device Control 1 (XON)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">18</td>
<td style="text-align: left;">12</td>
<td style="text-align: left;">00010010</td>
<td style="text-align: left;">DC2</td>
<td style="text-align: left;">Device Control 2</td>
</tr>
<tr class="even">
<td style="text-align: left;">19</td>
<td style="text-align: left;">13</td>
<td style="text-align: left;">00010011</td>
<td style="text-align: left;">DC3</td>
<td style="text-align: left;">Device Control 3 (XOFF)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">20</td>
<td style="text-align: left;">14</td>
<td style="text-align: left;">00010100</td>
<td style="text-align: left;">DC4</td>
<td style="text-align: left;">Device Control 4</td>
</tr>
<tr class="even">
<td style="text-align: left;">21</td>
<td style="text-align: left;">15</td>
<td style="text-align: left;">00010101</td>
<td style="text-align: left;">NAK</td>
<td style="text-align: left;">Negative acknowledge</td>
</tr>
<tr class="odd">
<td style="text-align: left;">22</td>
<td style="text-align: left;">16</td>
<td style="text-align: left;">00010110</td>
<td style="text-align: left;">SYN</td>
<td style="text-align: left;">Synchronous Idle</td>
</tr>
<tr class="even">
<td style="text-align: left;">23</td>
<td style="text-align: left;">17</td>
<td style="text-align: left;">00010111</td>
<td style="text-align: left;">ETB</td>
<td style="text-align: left;">End of Transmission Block</td>
</tr>
<tr class="odd">
<td style="text-align: left;">24</td>
<td style="text-align: left;">18</td>
<td style="text-align: left;">00011000</td>
<td style="text-align: left;">CAN</td>
<td style="text-align: left;">Cancel</td>
</tr>
<tr class="even">
<td style="text-align: left;">25</td>
<td style="text-align: left;">19</td>
<td style="text-align: left;">00011001</td>
<td style="text-align: left;">EM</td>
<td style="text-align: left;">End of Medium</td>
</tr>
<tr class="odd">
<td style="text-align: left;">26</td>
<td style="text-align: left;">1A</td>
<td style="text-align: left;">00011010</td>
<td style="text-align: left;">SUB</td>
<td style="text-align: left;">Substitute</td>
</tr>
<tr class="even">
<td style="text-align: left;">27</td>
<td style="text-align: left;">1B</td>
<td style="text-align: left;">00011011</td>
<td style="text-align: left;">ESC</td>
<td style="text-align: left;">Escape</td>
</tr>
<tr class="odd">
<td style="text-align: left;">28</td>
<td style="text-align: left;">1C</td>
<td style="text-align: left;">00011100</td>
<td style="text-align: left;">FS</td>
<td style="text-align: left;">File Separator</td>
</tr>
<tr class="even">
<td style="text-align: left;">29</td>
<td style="text-align: left;">1D</td>
<td style="text-align: left;">00011101</td>
<td style="text-align: left;">GS</td>
<td style="text-align: left;">Group Separator</td>
</tr>
<tr class="odd">
<td style="text-align: left;">30</td>
<td style="text-align: left;">1E</td>
<td style="text-align: left;">00011110</td>
<td style="text-align: left;">RS</td>
<td style="text-align: left;">Record Separator</td>
</tr>
<tr class="even">
<td style="text-align: left;">31</td>
<td style="text-align: left;">1F</td>
<td style="text-align: left;">00011111</td>
<td style="text-align: left;">US</td>
<td style="text-align: left;">Unit Separator</td>
</tr>
<tr class="odd">
<td style="text-align: left;">32</td>
<td style="text-align: left;">20</td>
<td style="text-align: left;">00100000</td>
<td style="text-align: left;">[Space]</td>
<td style="text-align: left;">Space</td>
</tr>
<tr class="even">
<td style="text-align: left;">33</td>
<td style="text-align: left;">21</td>
<td style="text-align: left;">00100001</td>
<td style="text-align: left;">!</td>
<td style="text-align: left;">Exclamation mark</td>
</tr>
<tr class="odd">
<td style="text-align: left;">34</td>
<td style="text-align: left;">22</td>
<td style="text-align: left;">00100010</td>
<td style="text-align: left;">&quot;</td>
<td style="text-align: left;">Quotes</td>
</tr>
<tr class="even">
<td style="text-align: left;">35</td>
<td style="text-align: left;">23</td>
<td style="text-align: left;">00100011</td>
<td style="text-align: left;">#</td>
<td style="text-align: left;">Hash</td>
</tr>
<tr class="odd">
<td style="text-align: left;">36</td>
<td style="text-align: left;">24</td>
<td style="text-align: left;">00100100</td>
<td style="text-align: left;">$</td>
<td style="text-align: left;">Dollar</td>
</tr>
<tr class="even">
<td style="text-align: left;">37</td>
<td style="text-align: left;">25</td>
<td style="text-align: left;">00100101</td>
<td style="text-align: left;">%</td>
<td style="text-align: left;">Percent</td>
</tr>
<tr class="odd">
<td style="text-align: left;">38</td>
<td style="text-align: left;">26</td>
<td style="text-align: left;">00100110</td>
<td style="text-align: left;">&amp;</td>
<td style="text-align: left;">Ampersand</td>
</tr>
<tr class="even">
<td style="text-align: left;">39</td>
<td style="text-align: left;">27</td>
<td style="text-align: left;">00100111</td>
<td style="text-align: left;">’</td>
<td style="text-align: left;">Apostrophe</td>
</tr>
<tr class="odd">
<td style="text-align: left;">40</td>
<td style="text-align: left;">28</td>
<td style="text-align: left;">00101000</td>
<td style="text-align: left;">(</td>
<td style="text-align: left;">Open bracket</td>
</tr>
<tr class="even">
<td style="text-align: left;">41</td>
<td style="text-align: left;">29</td>
<td style="text-align: left;">00101001</td>
<td style="text-align: left;">)</td>
<td style="text-align: left;">Close bracket</td>
</tr>
<tr class="odd">
<td style="text-align: left;">42</td>
<td style="text-align: left;">2A</td>
<td style="text-align: left;">00101010</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">Asterisk</td>
</tr>
<tr class="even">
<td style="text-align: left;">43</td>
<td style="text-align: left;">2B</td>
<td style="text-align: left;">00101011</td>
<td style="text-align: left;">+</td>
<td style="text-align: left;">Plus</td>
</tr>
<tr class="odd">
<td style="text-align: left;">44</td>
<td style="text-align: left;">2C</td>
<td style="text-align: left;">00101100</td>
<td style="text-align: left;">,</td>
<td style="text-align: left;">Comma</td>
</tr>
<tr class="even">
<td style="text-align: left;">45</td>
<td style="text-align: left;">2D</td>
<td style="text-align: left;">00101101</td>
<td style="text-align: left;">-</td>
<td style="text-align: left;">Dash</td>
</tr>
<tr class="odd">
<td style="text-align: left;">46</td>
<td style="text-align: left;">2E</td>
<td style="text-align: left;">00101110</td>
<td style="text-align: left;">.</td>
<td style="text-align: left;">Full stop</td>
</tr>
<tr class="even">
<td style="text-align: left;">47</td>
<td style="text-align: left;">2F</td>
<td style="text-align: left;">00101111</td>
<td style="text-align: left;">/</td>
<td style="text-align: left;">Slash</td>
</tr>
<tr class="odd">
<td style="text-align: left;">48</td>
<td style="text-align: left;">30</td>
<td style="text-align: left;">00110000</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">Zero</td>
</tr>
<tr class="even">
<td style="text-align: left;">49</td>
<td style="text-align: left;">31</td>
<td style="text-align: left;">00110001</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">One</td>
</tr>
<tr class="odd">
<td style="text-align: left;">50</td>
<td style="text-align: left;">32</td>
<td style="text-align: left;">00110010</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">Two</td>
</tr>
<tr class="even">
<td style="text-align: left;">51</td>
<td style="text-align: left;">33</td>
<td style="text-align: left;">00110011</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">Three</td>
</tr>
<tr class="odd">
<td style="text-align: left;">52</td>
<td style="text-align: left;">34</td>
<td style="text-align: left;">00110100</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">Four</td>
</tr>
<tr class="even">
<td style="text-align: left;">53</td>
<td style="text-align: left;">35</td>
<td style="text-align: left;">00110101</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">Five</td>
</tr>
<tr class="odd">
<td style="text-align: left;">54</td>
<td style="text-align: left;">36</td>
<td style="text-align: left;">00110110</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">Six</td>
</tr>
<tr class="even">
<td style="text-align: left;">55</td>
<td style="text-align: left;">37</td>
<td style="text-align: left;">00110111</td>
<td style="text-align: left;">7</td>
<td style="text-align: left;">Seven</td>
</tr>
<tr class="odd">
<td style="text-align: left;">56</td>
<td style="text-align: left;">38</td>
<td style="text-align: left;">00111000</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">Eight</td>
</tr>
<tr class="even">
<td style="text-align: left;">57</td>
<td style="text-align: left;">39</td>
<td style="text-align: left;">00111001</td>
<td style="text-align: left;">9</td>
<td style="text-align: left;">Nine</td>
</tr>
<tr class="odd">
<td style="text-align: left;">58</td>
<td style="text-align: left;">3A</td>
<td style="text-align: left;">00111010</td>
<td style="text-align: left;">:</td>
<td style="text-align: left;">Colon</td>
</tr>
<tr class="even">
<td style="text-align: left;">59</td>
<td style="text-align: left;">3B</td>
<td style="text-align: left;">00111011</td>
<td style="text-align: left;">;</td>
<td style="text-align: left;">Semi-colon</td>
</tr>
<tr class="odd">
<td style="text-align: left;">60</td>
<td style="text-align: left;">3C</td>
<td style="text-align: left;">00111100</td>
<td style="text-align: left;">&lt;</td>
<td style="text-align: left;">Less than</td>
</tr>
<tr class="even">
<td style="text-align: left;">61</td>
<td style="text-align: left;">3D</td>
<td style="text-align: left;">00111101</td>
<td style="text-align: left;">=</td>
<td style="text-align: left;">Equals</td>
</tr>
<tr class="odd">
<td style="text-align: left;">62</td>
<td style="text-align: left;">3E</td>
<td style="text-align: left;">00111110</td>
<td style="text-align: left;">&gt;</td>
<td style="text-align: left;">Greater than</td>
</tr>
<tr class="even">
<td style="text-align: left;">63</td>
<td style="text-align: left;">3F</td>
<td style="text-align: left;">00111111</td>
<td style="text-align: left;">?</td>
<td style="text-align: left;">Question mark</td>
</tr>
<tr class="odd">
<td style="text-align: left;">64</td>
<td style="text-align: left;">40</td>
<td style="text-align: left;">01000000</td>
<td style="text-align: left;">@</td>
<td style="text-align: left;">At</td>
</tr>
<tr class="even">
<td style="text-align: left;">65</td>
<td style="text-align: left;">41</td>
<td style="text-align: left;">01000001</td>
<td style="text-align: left;">A</td>
<td style="text-align: left;">Uppercase A</td>
</tr>
<tr class="odd">
<td style="text-align: left;">66</td>
<td style="text-align: left;">42</td>
<td style="text-align: left;">01000010</td>
<td style="text-align: left;">B</td>
<td style="text-align: left;">Uppercase B</td>
</tr>
<tr class="even">
<td style="text-align: left;">67</td>
<td style="text-align: left;">43</td>
<td style="text-align: left;">01000011</td>
<td style="text-align: left;">C</td>
<td style="text-align: left;">Uppercase C</td>
</tr>
<tr class="odd">
<td style="text-align: left;">68</td>
<td style="text-align: left;">44</td>
<td style="text-align: left;">01000100</td>
<td style="text-align: left;">D</td>
<td style="text-align: left;">Uppercase D</td>
</tr>
<tr class="even">
<td style="text-align: left;">69</td>
<td style="text-align: left;">45</td>
<td style="text-align: left;">01000101</td>
<td style="text-align: left;">E</td>
<td style="text-align: left;">Uppercase E</td>
</tr>
<tr class="odd">
<td style="text-align: left;">70</td>
<td style="text-align: left;">46</td>
<td style="text-align: left;">01000110</td>
<td style="text-align: left;">F</td>
<td style="text-align: left;">Uppercase F</td>
</tr>
<tr class="even">
<td style="text-align: left;">71</td>
<td style="text-align: left;">47</td>
<td style="text-align: left;">01000111</td>
<td style="text-align: left;">G</td>
<td style="text-align: left;">Uppercase G</td>
</tr>
<tr class="odd">
<td style="text-align: left;">72</td>
<td style="text-align: left;">48</td>
<td style="text-align: left;">01001000</td>
<td style="text-align: left;">H</td>
<td style="text-align: left;">Uppercase H</td>
</tr>
<tr class="even">
<td style="text-align: left;">73</td>
<td style="text-align: left;">49</td>
<td style="text-align: left;">01001001</td>
<td style="text-align: left;">I</td>
<td style="text-align: left;">Uppercase I</td>
</tr>
<tr class="odd">
<td style="text-align: left;">74</td>
<td style="text-align: left;">4A</td>
<td style="text-align: left;">01001010</td>
<td style="text-align: left;">J</td>
<td style="text-align: left;">Uppercase J</td>
</tr>
<tr class="even">
<td style="text-align: left;">75</td>
<td style="text-align: left;">4B</td>
<td style="text-align: left;">01001011</td>
<td style="text-align: left;">K</td>
<td style="text-align: left;">Uppercase K</td>
</tr>
<tr class="odd">
<td style="text-align: left;">76</td>
<td style="text-align: left;">4C</td>
<td style="text-align: left;">01001100</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">Uppercase L</td>
</tr>
<tr class="even">
<td style="text-align: left;">77</td>
<td style="text-align: left;">4D</td>
<td style="text-align: left;">01001101</td>
<td style="text-align: left;">M</td>
<td style="text-align: left;">Uppercase M</td>
</tr>
<tr class="odd">
<td style="text-align: left;">78</td>
<td style="text-align: left;">4E</td>
<td style="text-align: left;">01001110</td>
<td style="text-align: left;">N</td>
<td style="text-align: left;">Uppercase N</td>
</tr>
<tr class="even">
<td style="text-align: left;">79</td>
<td style="text-align: left;">4F</td>
<td style="text-align: left;">01001111</td>
<td style="text-align: left;">O</td>
<td style="text-align: left;">Uppercase O</td>
</tr>
<tr class="odd">
<td style="text-align: left;">80</td>
<td style="text-align: left;">50</td>
<td style="text-align: left;">01010000</td>
<td style="text-align: left;">P</td>
<td style="text-align: left;">Uppercase P</td>
</tr>
<tr class="even">
<td style="text-align: left;">81</td>
<td style="text-align: left;">51</td>
<td style="text-align: left;">01010001</td>
<td style="text-align: left;">Q</td>
<td style="text-align: left;">Uppercase Q</td>
</tr>
<tr class="odd">
<td style="text-align: left;">82</td>
<td style="text-align: left;">52</td>
<td style="text-align: left;">01010010</td>
<td style="text-align: left;">R</td>
<td style="text-align: left;">Uppercase R</td>
</tr>
<tr class="even">
<td style="text-align: left;">83</td>
<td style="text-align: left;">53</td>
<td style="text-align: left;">01010011</td>
<td style="text-align: left;">S</td>
<td style="text-align: left;">Uppercase S</td>
</tr>
<tr class="odd">
<td style="text-align: left;">84</td>
<td style="text-align: left;">54</td>
<td style="text-align: left;">01010100</td>
<td style="text-align: left;">T</td>
<td style="text-align: left;">Uppercase T</td>
</tr>
<tr class="even">
<td style="text-align: left;">85</td>
<td style="text-align: left;">55</td>
<td style="text-align: left;">01010101</td>
<td style="text-align: left;">U</td>
<td style="text-align: left;">Uppercase U</td>
</tr>
<tr class="odd">
<td style="text-align: left;">86</td>
<td style="text-align: left;">56</td>
<td style="text-align: left;">01010110</td>
<td style="text-align: left;">V</td>
<td style="text-align: left;">Uppercase V</td>
</tr>
<tr class="even">
<td style="text-align: left;">87</td>
<td style="text-align: left;">57</td>
<td style="text-align: left;">01010111</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">Uppercase W</td>
</tr>
<tr class="odd">
<td style="text-align: left;">88</td>
<td style="text-align: left;">58</td>
<td style="text-align: left;">01011000</td>
<td style="text-align: left;">X</td>
<td style="text-align: left;">Uppercase X</td>
</tr>
<tr class="even">
<td style="text-align: left;">89</td>
<td style="text-align: left;">59</td>
<td style="text-align: left;">01011001</td>
<td style="text-align: left;">Y</td>
<td style="text-align: left;">Uppercase Y</td>
</tr>
<tr class="odd">
<td style="text-align: left;">90</td>
<td style="text-align: left;">5A</td>
<td style="text-align: left;">01011010</td>
<td style="text-align: left;">Z</td>
<td style="text-align: left;">Uppercase Z</td>
</tr>
<tr class="even">
<td style="text-align: left;">91</td>
<td style="text-align: left;">5B</td>
<td style="text-align: left;">01011011</td>
<td style="text-align: left;">[</td>
<td style="text-align: left;">Open square bracket</td>
</tr>
<tr class="odd">
<td style="text-align: left;">92</td>
<td style="text-align: left;">5C</td>
<td style="text-align: left;">01011100</td>
<td style="text-align: left;"> </td>
<td style="text-align: left;">Backslash</td>
</tr>
<tr class="even">
<td style="text-align: left;">93</td>
<td style="text-align: left;">5D</td>
<td style="text-align: left;">01011101</td>
<td style="text-align: left;">]</td>
<td style="text-align: left;">Close square bracket</td>
</tr>
<tr class="odd">
<td style="text-align: left;">94</td>
<td style="text-align: left;">5E</td>
<td style="text-align: left;">01011110</td>
<td style="text-align: left;">^</td>
<td style="text-align: left;">Caret / hat</td>
</tr>
<tr class="even">
<td style="text-align: left;">95</td>
<td style="text-align: left;">5F</td>
<td style="text-align: left;">01011111</td>
<td style="text-align: left;">_</td>
<td style="text-align: left;">Underscore</td>
</tr>
<tr class="odd">
<td style="text-align: left;">96</td>
<td style="text-align: left;">60</td>
<td style="text-align: left;">01100000</td>
<td style="text-align: left;">`</td>
<td style="text-align: left;">Grave accent</td>
</tr>
<tr class="even">
<td style="text-align: left;">97</td>
<td style="text-align: left;">61</td>
<td style="text-align: left;">01100001</td>
<td style="text-align: left;">a</td>
<td style="text-align: left;">Lowercase a</td>
</tr>
<tr class="odd">
<td style="text-align: left;">98</td>
<td style="text-align: left;">62</td>
<td style="text-align: left;">01100010</td>
<td style="text-align: left;">b</td>
<td style="text-align: left;">Lowercase b</td>
</tr>
<tr class="even">
<td style="text-align: left;">99</td>
<td style="text-align: left;">63</td>
<td style="text-align: left;">01100011</td>
<td style="text-align: left;">c</td>
<td style="text-align: left;">Lowercase c</td>
</tr>
<tr class="odd">
<td style="text-align: left;">100</td>
<td style="text-align: left;">64</td>
<td style="text-align: left;">01100100</td>
<td style="text-align: left;">d</td>
<td style="text-align: left;">Lowercase d</td>
</tr>
<tr class="even">
<td style="text-align: left;">101</td>
<td style="text-align: left;">65</td>
<td style="text-align: left;">01100101</td>
<td style="text-align: left;">e</td>
<td style="text-align: left;">Lowercase e</td>
</tr>
<tr class="odd">
<td style="text-align: left;">102</td>
<td style="text-align: left;">66</td>
<td style="text-align: left;">01100110</td>
<td style="text-align: left;">f</td>
<td style="text-align: left;">Lowercase f</td>
</tr>
<tr class="even">
<td style="text-align: left;">103</td>
<td style="text-align: left;">67</td>
<td style="text-align: left;">01100111</td>
<td style="text-align: left;">g</td>
<td style="text-align: left;">Lowercase g</td>
</tr>
<tr class="odd">
<td style="text-align: left;">104</td>
<td style="text-align: left;">68</td>
<td style="text-align: left;">01101000</td>
<td style="text-align: left;">h</td>
<td style="text-align: left;">Lowercase h</td>
</tr>
<tr class="even">
<td style="text-align: left;">105</td>
<td style="text-align: left;">69</td>
<td style="text-align: left;">01101001</td>
<td style="text-align: left;">i</td>
<td style="text-align: left;">Lowercase i</td>
</tr>
<tr class="odd">
<td style="text-align: left;">106</td>
<td style="text-align: left;">6A</td>
<td style="text-align: left;">01101010</td>
<td style="text-align: left;">j</td>
<td style="text-align: left;">Lowercase j</td>
</tr>
<tr class="even">
<td style="text-align: left;">107</td>
<td style="text-align: left;">6B</td>
<td style="text-align: left;">01101011</td>
<td style="text-align: left;">k</td>
<td style="text-align: left;">Lowercase k</td>
</tr>
<tr class="odd">
<td style="text-align: left;">108</td>
<td style="text-align: left;">6C</td>
<td style="text-align: left;">01101100</td>
<td style="text-align: left;">l</td>
<td style="text-align: left;">Lowercase l</td>
</tr>
<tr class="even">
<td style="text-align: left;">109</td>
<td style="text-align: left;">6D</td>
<td style="text-align: left;">01101101</td>
<td style="text-align: left;">m</td>
<td style="text-align: left;">Lowercase m</td>
</tr>
<tr class="odd">
<td style="text-align: left;">110</td>
<td style="text-align: left;">6E</td>
<td style="text-align: left;">01101110</td>
<td style="text-align: left;">n</td>
<td style="text-align: left;">Lowercase n</td>
</tr>
<tr class="even">
<td style="text-align: left;">111</td>
<td style="text-align: left;">6F</td>
<td style="text-align: left;">01101111</td>
<td style="text-align: left;">o</td>
<td style="text-align: left;">Lowercase o</td>
</tr>
<tr class="odd">
<td style="text-align: left;">112</td>
<td style="text-align: left;">70</td>
<td style="text-align: left;">01110000</td>
<td style="text-align: left;">p</td>
<td style="text-align: left;">Lowercase p</td>
</tr>
<tr class="even">
<td style="text-align: left;">113</td>
<td style="text-align: left;">71</td>
<td style="text-align: left;">01110001</td>
<td style="text-align: left;">q</td>
<td style="text-align: left;">Lowercase q</td>
</tr>
<tr class="odd">
<td style="text-align: left;">114</td>
<td style="text-align: left;">72</td>
<td style="text-align: left;">01110010</td>
<td style="text-align: left;">r</td>
<td style="text-align: left;">Lowercase r</td>
</tr>
<tr class="even">
<td style="text-align: left;">115</td>
<td style="text-align: left;">73</td>
<td style="text-align: left;">01110011</td>
<td style="text-align: left;">s</td>
<td style="text-align: left;">Lowercase s</td>
</tr>
<tr class="odd">
<td style="text-align: left;">116</td>
<td style="text-align: left;">74</td>
<td style="text-align: left;">01110100</td>
<td style="text-align: left;">t</td>
<td style="text-align: left;">Lowercase t</td>
</tr>
<tr class="even">
<td style="text-align: left;">117</td>
<td style="text-align: left;">75</td>
<td style="text-align: left;">01110101</td>
<td style="text-align: left;">u</td>
<td style="text-align: left;">Lowercase u</td>
</tr>
<tr class="odd">
<td style="text-align: left;">118</td>
<td style="text-align: left;">76</td>
<td style="text-align: left;">01110110</td>
<td style="text-align: left;">v</td>
<td style="text-align: left;">Lowercase v</td>
</tr>
<tr class="even">
<td style="text-align: left;">119</td>
<td style="text-align: left;">77</td>
<td style="text-align: left;">01110111</td>
<td style="text-align: left;">w</td>
<td style="text-align: left;">Lowercase w</td>
</tr>
<tr class="odd">
<td style="text-align: left;">120</td>
<td style="text-align: left;">78</td>
<td style="text-align: left;">01111000</td>
<td style="text-align: left;">x</td>
<td style="text-align: left;">Lowercase x</td>
</tr>
<tr class="even">
<td style="text-align: left;">121</td>
<td style="text-align: left;">79</td>
<td style="text-align: left;">01111001</td>
<td style="text-align: left;">y</td>
<td style="text-align: left;">Lowercase y</td>
</tr>
<tr class="odd">
<td style="text-align: left;">122</td>
<td style="text-align: left;">7A</td>
<td style="text-align: left;">01111010</td>
<td style="text-align: left;">z</td>
<td style="text-align: left;">Lowercase z</td>
</tr>
<tr class="even">
<td style="text-align: left;">123</td>
<td style="text-align: left;">7B</td>
<td style="text-align: left;">01111011</td>
<td style="text-align: left;">{</td>
<td style="text-align: left;">Open brace</td>
</tr>
<tr class="odd">
<td style="text-align: left;">124</td>
<td style="text-align: left;">7C</td>
<td style="text-align: left;">01111100</td>
<td style="text-align: left;">|</td>
<td style="text-align: left;">Pipe</td>
</tr>
<tr class="even">
<td style="text-align: left;">125</td>
<td style="text-align: left;">7D</td>
<td style="text-align: left;">01111101</td>
<td style="text-align: left;">}</td>
<td style="text-align: left;">Close brace</td>
</tr>
<tr class="odd">
<td style="text-align: left;">126</td>
<td style="text-align: left;">7E</td>
<td style="text-align: left;">01111110</td>
<td style="text-align: left;">~</td>
<td style="text-align: left;">Tilde</td>
</tr>
<tr class="even">
<td style="text-align: left;">127</td>
<td style="text-align: left;">7F</td>
<td style="text-align: left;">01111111</td>
<td style="text-align: left;">DEL</td>
<td style="text-align: left;">Delete</td>
</tr>
<tr class="odd">
<td style="text-align: left;">128</td>
<td style="text-align: left;">80</td>
<td style="text-align: left;">10000000</td>
<td style="text-align: left;">Ç</td>
<td style="text-align: left;">latin capital letter c with cedilla</td>
</tr>
<tr class="even">
<td style="text-align: left;">129</td>
<td style="text-align: left;">81</td>
<td style="text-align: left;">10000001</td>
<td style="text-align: left;">ü</td>
<td style="text-align: left;">latin small letter u with diaeresis</td>
</tr>
<tr class="odd">
<td style="text-align: left;">130</td>
<td style="text-align: left;">82</td>
<td style="text-align: left;">10000010</td>
<td style="text-align: left;">é</td>
<td style="text-align: left;">latin small letter e with acute</td>
</tr>
<tr class="even">
<td style="text-align: left;">131</td>
<td style="text-align: left;">83</td>
<td style="text-align: left;">10000011</td>
<td style="text-align: left;">â</td>
<td style="text-align: left;">latin small letter a with circumflex</td>
</tr>
<tr class="odd">
<td style="text-align: left;">132</td>
<td style="text-align: left;">84</td>
<td style="text-align: left;">10000100</td>
<td style="text-align: left;">ä</td>
<td style="text-align: left;">latin small letter a with diaeresis</td>
</tr>
<tr class="even">
<td style="text-align: left;">133</td>
<td style="text-align: left;">85</td>
<td style="text-align: left;">10000101</td>
<td style="text-align: left;">à</td>
<td style="text-align: left;">latin small letter a with grave</td>
</tr>
<tr class="odd">
<td style="text-align: left;">134</td>
<td style="text-align: left;">86</td>
<td style="text-align: left;">10000110</td>
<td style="text-align: left;">å</td>
<td style="text-align: left;">latin small letter a with ring above</td>
</tr>
<tr class="even">
<td style="text-align: left;">135</td>
<td style="text-align: left;">87</td>
<td style="text-align: left;">10000111</td>
<td style="text-align: left;">ç</td>
<td style="text-align: left;">latin small letter c with cedilla</td>
</tr>
<tr class="odd">
<td style="text-align: left;">136</td>
<td style="text-align: left;">88</td>
<td style="text-align: left;">10001000</td>
<td style="text-align: left;">ê</td>
<td style="text-align: left;">latin small letter e with circumflex</td>
</tr>
<tr class="even">
<td style="text-align: left;">137</td>
<td style="text-align: left;">89</td>
<td style="text-align: left;">10001001</td>
<td style="text-align: left;">ë</td>
<td style="text-align: left;">latin small letter e with diaeresis</td>
</tr>
<tr class="odd">
<td style="text-align: left;">138</td>
<td style="text-align: left;">8A</td>
<td style="text-align: left;">10001010</td>
<td style="text-align: left;">è</td>
<td style="text-align: left;">latin small letter e with grave</td>
</tr>
<tr class="even">
<td style="text-align: left;">139</td>
<td style="text-align: left;">8B</td>
<td style="text-align: left;">10001011</td>
<td style="text-align: left;">ï</td>
<td style="text-align: left;">latin small letter i with diaeresis</td>
</tr>
<tr class="odd">
<td style="text-align: left;">140</td>
<td style="text-align: left;">8C</td>
<td style="text-align: left;">10001100</td>
<td style="text-align: left;">î</td>
<td style="text-align: left;">latin small letter i with circumflex</td>
</tr>
<tr class="even">
<td style="text-align: left;">141</td>
<td style="text-align: left;">8D</td>
<td style="text-align: left;">10001101</td>
<td style="text-align: left;">ì</td>
<td style="text-align: left;">latin small letter i with grave</td>
</tr>
<tr class="odd">
<td style="text-align: left;">142</td>
<td style="text-align: left;">8E</td>
<td style="text-align: left;">10001110</td>
<td style="text-align: left;">Ä</td>
<td style="text-align: left;">latin capital letter a with diaeresis</td>
</tr>
<tr class="even">
<td style="text-align: left;">143</td>
<td style="text-align: left;">8F</td>
<td style="text-align: left;">10001111</td>
<td style="text-align: left;">Å</td>
<td style="text-align: left;">latin capital letter a with ring above</td>
</tr>
<tr class="odd">
<td style="text-align: left;">144</td>
<td style="text-align: left;">90</td>
<td style="text-align: left;">10010000</td>
<td style="text-align: left;">É</td>
<td style="text-align: left;">latin capital letter e with acute</td>
</tr>
<tr class="even">
<td style="text-align: left;">145</td>
<td style="text-align: left;">91</td>
<td style="text-align: left;">10010001</td>
<td style="text-align: left;">æ</td>
<td style="text-align: left;">latin small ligature ae</td>
</tr>
<tr class="odd">
<td style="text-align: left;">146</td>
<td style="text-align: left;">92</td>
<td style="text-align: left;">10010010</td>
<td style="text-align: left;">Æ</td>
<td style="text-align: left;">latin capital ligature ae</td>
</tr>
<tr class="even">
<td style="text-align: left;">147</td>
<td style="text-align: left;">93</td>
<td style="text-align: left;">10010011</td>
<td style="text-align: left;">ô</td>
<td style="text-align: left;">latin small letter o with circumflex</td>
</tr>
<tr class="odd">
<td style="text-align: left;">148</td>
<td style="text-align: left;">94</td>
<td style="text-align: left;">10010100</td>
<td style="text-align: left;">ö</td>
<td style="text-align: left;">latin small letter o with diaeresis</td>
</tr>
<tr class="even">
<td style="text-align: left;">149</td>
<td style="text-align: left;">95</td>
<td style="text-align: left;">10010101</td>
<td style="text-align: left;">ò</td>
<td style="text-align: left;">latin small letter o with grave</td>
</tr>
<tr class="odd">
<td style="text-align: left;">150</td>
<td style="text-align: left;">96</td>
<td style="text-align: left;">10010110</td>
<td style="text-align: left;">û</td>
<td style="text-align: left;">latin small letter u with circumflex</td>
</tr>
<tr class="even">
<td style="text-align: left;">151</td>
<td style="text-align: left;">97</td>
<td style="text-align: left;">10010111</td>
<td style="text-align: left;">ù</td>
<td style="text-align: left;">latin small letter u with grave</td>
</tr>
<tr class="odd">
<td style="text-align: left;">152</td>
<td style="text-align: left;">98</td>
<td style="text-align: left;">10011000</td>
<td style="text-align: left;">ÿ</td>
<td style="text-align: left;">latin small letter y with diaeresis</td>
</tr>
<tr class="even">
<td style="text-align: left;">153</td>
<td style="text-align: left;">99</td>
<td style="text-align: left;">10011001</td>
<td style="text-align: left;">Ö</td>
<td style="text-align: left;">latin capital letter o with diaeresis</td>
</tr>
<tr class="odd">
<td style="text-align: left;">154</td>
<td style="text-align: left;">9A</td>
<td style="text-align: left;">10011010</td>
<td style="text-align: left;">Ü</td>
<td style="text-align: left;">latin capital letter u with diaeresis</td>
</tr>
<tr class="even">
<td style="text-align: left;">155</td>
<td style="text-align: left;">9B</td>
<td style="text-align: left;">10011011</td>
<td style="text-align: left;">¢</td>
<td style="text-align: left;">cent sign</td>
</tr>
<tr class="odd">
<td style="text-align: left;">156</td>
<td style="text-align: left;">9C</td>
<td style="text-align: left;">10011100</td>
<td style="text-align: left;">£</td>
<td style="text-align: left;">pound sign</td>
</tr>
<tr class="even">
<td style="text-align: left;">157</td>
<td style="text-align: left;">9D</td>
<td style="text-align: left;">10011101</td>
<td style="text-align: left;">¥</td>
<td style="text-align: left;">yen sign</td>
</tr>
<tr class="odd">
<td style="text-align: left;">158</td>
<td style="text-align: left;">9E</td>
<td style="text-align: left;">10011110</td>
<td style="text-align: left;">₧</td>
<td style="text-align: left;">peseta sign</td>
</tr>
<tr class="even">
<td style="text-align: left;">159</td>
<td style="text-align: left;">9F</td>
<td style="text-align: left;">10011111</td>
<td style="text-align: left;">ƒ</td>
<td style="text-align: left;">latin small letter f with hook</td>
</tr>
<tr class="odd">
<td style="text-align: left;">160</td>
<td style="text-align: left;">A0</td>
<td style="text-align: left;">10100000</td>
<td style="text-align: left;">á</td>
<td style="text-align: left;">latin small letter a with acute</td>
</tr>
<tr class="even">
<td style="text-align: left;">161</td>
<td style="text-align: left;">A1</td>
<td style="text-align: left;">10100001</td>
<td style="text-align: left;">í</td>
<td style="text-align: left;">latin small letter i with acute</td>
</tr>
<tr class="odd">
<td style="text-align: left;">162</td>
<td style="text-align: left;">A2</td>
<td style="text-align: left;">10100010</td>
<td style="text-align: left;">ó</td>
<td style="text-align: left;">latin small letter o with acute</td>
</tr>
<tr class="even">
<td style="text-align: left;">163</td>
<td style="text-align: left;">A3</td>
<td style="text-align: left;">10100011</td>
<td style="text-align: left;">ú</td>
<td style="text-align: left;">latin small letter u with acute</td>
</tr>
<tr class="odd">
<td style="text-align: left;">164</td>
<td style="text-align: left;">A4</td>
<td style="text-align: left;">10100100</td>
<td style="text-align: left;">ñ</td>
<td style="text-align: left;">latin small letter n with tilde</td>
</tr>
<tr class="even">
<td style="text-align: left;">165</td>
<td style="text-align: left;">A5</td>
<td style="text-align: left;">10100101</td>
<td style="text-align: left;">Ñ</td>
<td style="text-align: left;">latin capital letter n with tilde</td>
</tr>
<tr class="odd">
<td style="text-align: left;">166</td>
<td style="text-align: left;">A6</td>
<td style="text-align: left;">10100110</td>
<td style="text-align: left;">ª</td>
<td style="text-align: left;">feminine ordinal indicator</td>
</tr>
<tr class="even">
<td style="text-align: left;">167</td>
<td style="text-align: left;">A7</td>
<td style="text-align: left;">10100111</td>
<td style="text-align: left;">º</td>
<td style="text-align: left;">masculine ordinal indicator</td>
</tr>
<tr class="odd">
<td style="text-align: left;">168</td>
<td style="text-align: left;">A8</td>
<td style="text-align: left;">10101000</td>
<td style="text-align: left;">¿</td>
<td style="text-align: left;">inverted question mark</td>
</tr>
<tr class="even">
<td style="text-align: left;">169</td>
<td style="text-align: left;">A9</td>
<td style="text-align: left;">10101001</td>
<td style="text-align: left;">⌐</td>
<td style="text-align: left;">reversed not sign</td>
</tr>
<tr class="odd">
<td style="text-align: left;">170</td>
<td style="text-align: left;">AA</td>
<td style="text-align: left;">10101010</td>
<td style="text-align: left;">¬</td>
<td style="text-align: left;">not sign</td>
</tr>
<tr class="even">
<td style="text-align: left;">171</td>
<td style="text-align: left;">AB</td>
<td style="text-align: left;">10101011</td>
<td style="text-align: left;">½</td>
<td style="text-align: left;">vulgar fraction one half</td>
</tr>
<tr class="odd">
<td style="text-align: left;">172</td>
<td style="text-align: left;">AC</td>
<td style="text-align: left;">10101100</td>
<td style="text-align: left;">¼</td>
<td style="text-align: left;">vulgar fraction one quarter</td>
</tr>
<tr class="even">
<td style="text-align: left;">173</td>
<td style="text-align: left;">AD</td>
<td style="text-align: left;">10101101</td>
<td style="text-align: left;">¡</td>
<td style="text-align: left;">inverted exclamation mark</td>
</tr>
<tr class="odd">
<td style="text-align: left;">174</td>
<td style="text-align: left;">AE</td>
<td style="text-align: left;">10101110</td>
<td style="text-align: left;">«</td>
<td style="text-align: left;">left-pointing double angle quotation mark</td>
</tr>
<tr class="even">
<td style="text-align: left;">175</td>
<td style="text-align: left;">AF</td>
<td style="text-align: left;">10101111</td>
<td style="text-align: left;">»</td>
<td style="text-align: left;">right-pointing double angle quotation mark</td>
</tr>
<tr class="odd">
<td style="text-align: left;">176</td>
<td style="text-align: left;">B0</td>
<td style="text-align: left;">10110000</td>
<td style="text-align: left;">░</td>
<td style="text-align: left;">light shade</td>
</tr>
<tr class="even">
<td style="text-align: left;">177</td>
<td style="text-align: left;">B1</td>
<td style="text-align: left;">10110001</td>
<td style="text-align: left;">▒</td>
<td style="text-align: left;">medium shade</td>
</tr>
<tr class="odd">
<td style="text-align: left;">178</td>
<td style="text-align: left;">B2</td>
<td style="text-align: left;">10110010</td>
<td style="text-align: left;">▓</td>
<td style="text-align: left;">dark shade</td>
</tr>
<tr class="even">
<td style="text-align: left;">179</td>
<td style="text-align: left;">B3</td>
<td style="text-align: left;">10110011</td>
<td style="text-align: left;">│</td>
<td style="text-align: left;">box drawings light vertical</td>
</tr>
<tr class="odd">
<td style="text-align: left;">180</td>
<td style="text-align: left;">B4</td>
<td style="text-align: left;">10110100</td>
<td style="text-align: left;">┤</td>
<td style="text-align: left;">box drawings light vertical and left</td>
</tr>
<tr class="even">
<td style="text-align: left;">181</td>
<td style="text-align: left;">B5</td>
<td style="text-align: left;">10110101</td>
<td style="text-align: left;">╡</td>
<td style="text-align: left;">box drawings vertical single and left double</td>
</tr>
<tr class="odd">
<td style="text-align: left;">182</td>
<td style="text-align: left;">B6</td>
<td style="text-align: left;">10110110</td>
<td style="text-align: left;">╢</td>
<td style="text-align: left;">box drawings vertical double and left single</td>
</tr>
<tr class="even">
<td style="text-align: left;">183</td>
<td style="text-align: left;">B7</td>
<td style="text-align: left;">10110111</td>
<td style="text-align: left;">╖</td>
<td style="text-align: left;">box drawings down double and left single</td>
</tr>
<tr class="odd">
<td style="text-align: left;">184</td>
<td style="text-align: left;">B8</td>
<td style="text-align: left;">10111000</td>
<td style="text-align: left;">╕</td>
<td style="text-align: left;">box drawings down single and left double</td>
</tr>
<tr class="even">
<td style="text-align: left;">185</td>
<td style="text-align: left;">B9</td>
<td style="text-align: left;">10111001</td>
<td style="text-align: left;">╣</td>
<td style="text-align: left;">box drawings double vertical and left</td>
</tr>
<tr class="odd">
<td style="text-align: left;">186</td>
<td style="text-align: left;">BA</td>
<td style="text-align: left;">10111010</td>
<td style="text-align: left;">║</td>
<td style="text-align: left;">box drawings double vertical</td>
</tr>
<tr class="even">
<td style="text-align: left;">187</td>
<td style="text-align: left;">BB</td>
<td style="text-align: left;">10111011</td>
<td style="text-align: left;">╗</td>
<td style="text-align: left;">box drawings double down and left</td>
</tr>
<tr class="odd">
<td style="text-align: left;">188</td>
<td style="text-align: left;">BC</td>
<td style="text-align: left;">10111100</td>
<td style="text-align: left;">╝</td>
<td style="text-align: left;">box drawings double up and left</td>
</tr>
<tr class="even">
<td style="text-align: left;">189</td>
<td style="text-align: left;">BD</td>
<td style="text-align: left;">10111101</td>
<td style="text-align: left;">╜</td>
<td style="text-align: left;">box drawings up double and left single</td>
</tr>
<tr class="odd">
<td style="text-align: left;">190</td>
<td style="text-align: left;">BE</td>
<td style="text-align: left;">10111110</td>
<td style="text-align: left;">╛</td>
<td style="text-align: left;">box drawings up single and left double</td>
</tr>
<tr class="even">
<td style="text-align: left;">191</td>
<td style="text-align: left;">BF</td>
<td style="text-align: left;">10111111</td>
<td style="text-align: left;">┐</td>
<td style="text-align: left;">box drawings light down and left</td>
</tr>
<tr class="odd">
<td style="text-align: left;">192</td>
<td style="text-align: left;">C0</td>
<td style="text-align: left;">11000000</td>
<td style="text-align: left;">└</td>
<td style="text-align: left;">box drawings light up and right</td>
</tr>
<tr class="even">
<td style="text-align: left;">193</td>
<td style="text-align: left;">C1</td>
<td style="text-align: left;">11000001</td>
<td style="text-align: left;">┴</td>
<td style="text-align: left;">box drawings light up and horizontal</td>
</tr>
<tr class="odd">
<td style="text-align: left;">194</td>
<td style="text-align: left;">C2</td>
<td style="text-align: left;">11000010</td>
<td style="text-align: left;">┬</td>
<td style="text-align: left;">box drawings light down and horizontal</td>
</tr>
<tr class="even">
<td style="text-align: left;">195</td>
<td style="text-align: left;">C3</td>
<td style="text-align: left;">11000011</td>
<td style="text-align: left;">├</td>
<td style="text-align: left;">box drawings light vertical and right</td>
</tr>
<tr class="odd">
<td style="text-align: left;">196</td>
<td style="text-align: left;">C4</td>
<td style="text-align: left;">11000100</td>
<td style="text-align: left;">─</td>
<td style="text-align: left;">box drawings light horizontal</td>
</tr>
<tr class="even">
<td style="text-align: left;">197</td>
<td style="text-align: left;">C5</td>
<td style="text-align: left;">11000101</td>
<td style="text-align: left;">┼</td>
<td style="text-align: left;">box drawings light vertical and horizontal</td>
</tr>
<tr class="odd">
<td style="text-align: left;">198</td>
<td style="text-align: left;">C6</td>
<td style="text-align: left;">11000110</td>
<td style="text-align: left;">╞</td>
<td style="text-align: left;">box drawings vertical single and right double</td>
</tr>
<tr class="even">
<td style="text-align: left;">199</td>
<td style="text-align: left;">C7</td>
<td style="text-align: left;">11000111</td>
<td style="text-align: left;">╟</td>
<td style="text-align: left;">box drawings vertical double and right single</td>
</tr>
<tr class="odd">
<td style="text-align: left;">200</td>
<td style="text-align: left;">C8</td>
<td style="text-align: left;">11001000</td>
<td style="text-align: left;">╚</td>
<td style="text-align: left;">box drawings double up and right</td>
</tr>
<tr class="even">
<td style="text-align: left;">201</td>
<td style="text-align: left;">C9</td>
<td style="text-align: left;">11001001</td>
<td style="text-align: left;">╔</td>
<td style="text-align: left;">box drawings double down and right</td>
</tr>
<tr class="odd">
<td style="text-align: left;">202</td>
<td style="text-align: left;">CA</td>
<td style="text-align: left;">11001010</td>
<td style="text-align: left;">╩</td>
<td style="text-align: left;">box drawings double up and horizontal</td>
</tr>
<tr class="even">
<td style="text-align: left;">203</td>
<td style="text-align: left;">CB</td>
<td style="text-align: left;">11001011</td>
<td style="text-align: left;">╦</td>
<td style="text-align: left;">box drawings double down and horizontal</td>
</tr>
<tr class="odd">
<td style="text-align: left;">204</td>
<td style="text-align: left;">CC</td>
<td style="text-align: left;">11001100</td>
<td style="text-align: left;">╠</td>
<td style="text-align: left;">box drawings double vertical and right</td>
</tr>
<tr class="even">
<td style="text-align: left;">205</td>
<td style="text-align: left;">CD</td>
<td style="text-align: left;">11001101</td>
<td style="text-align: left;">═</td>
<td style="text-align: left;">box drawings double horizontal</td>
</tr>
<tr class="odd">
<td style="text-align: left;">206</td>
<td style="text-align: left;">CE</td>
<td style="text-align: left;">11001110</td>
<td style="text-align: left;">╬</td>
<td style="text-align: left;">box drawings double vertical and horizontal</td>
</tr>
<tr class="even">
<td style="text-align: left;">207</td>
<td style="text-align: left;">CF</td>
<td style="text-align: left;">11001111</td>
<td style="text-align: left;">╧</td>
<td style="text-align: left;">box drawings up single and horizontal double</td>
</tr>
<tr class="odd">
<td style="text-align: left;">208</td>
<td style="text-align: left;">D0</td>
<td style="text-align: left;">11010000</td>
<td style="text-align: left;">╨</td>
<td style="text-align: left;">box drawings up double and horizontal single</td>
</tr>
<tr class="even">
<td style="text-align: left;">209</td>
<td style="text-align: left;">D1</td>
<td style="text-align: left;">11010001</td>
<td style="text-align: left;">╤</td>
<td style="text-align: left;">box drawings down single and horizontal double</td>
</tr>
<tr class="odd">
<td style="text-align: left;">210</td>
<td style="text-align: left;">D2</td>
<td style="text-align: left;">11010010</td>
<td style="text-align: left;">╥</td>
<td style="text-align: left;">box drawings down double and horizontal single</td>
</tr>
<tr class="even">
<td style="text-align: left;">211</td>
<td style="text-align: left;">D3</td>
<td style="text-align: left;">11010011</td>
<td style="text-align: left;">╙</td>
<td style="text-align: left;">box drawings up double and right single</td>
</tr>
<tr class="odd">
<td style="text-align: left;">212</td>
<td style="text-align: left;">D4</td>
<td style="text-align: left;">11010100</td>
<td style="text-align: left;">╘</td>
<td style="text-align: left;">box drawings up single and right double</td>
</tr>
<tr class="even">
<td style="text-align: left;">213</td>
<td style="text-align: left;">D5</td>
<td style="text-align: left;">11010101</td>
<td style="text-align: left;">╒</td>
<td style="text-align: left;">box drawings down single and right double</td>
</tr>
<tr class="odd">
<td style="text-align: left;">214</td>
<td style="text-align: left;">D6</td>
<td style="text-align: left;">11010110</td>
<td style="text-align: left;">╓</td>
<td style="text-align: left;">box drawings down double and right single</td>
</tr>
<tr class="even">
<td style="text-align: left;">215</td>
<td style="text-align: left;">D7</td>
<td style="text-align: left;">11010111</td>
<td style="text-align: left;">╫</td>
<td style="text-align: left;">box drawings vertical double and horizontal single</td>
</tr>
<tr class="odd">
<td style="text-align: left;">216</td>
<td style="text-align: left;">D8</td>
<td style="text-align: left;">11011000</td>
<td style="text-align: left;">╪</td>
<td style="text-align: left;">box drawings vertical single and horizontal double</td>
</tr>
<tr class="even">
<td style="text-align: left;">217</td>
<td style="text-align: left;">D9</td>
<td style="text-align: left;">11011001</td>
<td style="text-align: left;">┘</td>
<td style="text-align: left;">box drawings light up and left</td>
</tr>
<tr class="odd">
<td style="text-align: left;">218</td>
<td style="text-align: left;">DA</td>
<td style="text-align: left;">11011010</td>
<td style="text-align: left;">┌</td>
<td style="text-align: left;">box drawings light down and right</td>
</tr>
<tr class="even">
<td style="text-align: left;">219</td>
<td style="text-align: left;">DB</td>
<td style="text-align: left;">11011011</td>
<td style="text-align: left;">█</td>
<td style="text-align: left;">full block</td>
</tr>
<tr class="odd">
<td style="text-align: left;">220</td>
<td style="text-align: left;">DC</td>
<td style="text-align: left;">11011100</td>
<td style="text-align: left;">▄</td>
<td style="text-align: left;">lower half block</td>
</tr>
<tr class="even">
<td style="text-align: left;">221</td>
<td style="text-align: left;">DD</td>
<td style="text-align: left;">11011101</td>
<td style="text-align: left;">▌</td>
<td style="text-align: left;">left half block</td>
</tr>
<tr class="odd">
<td style="text-align: left;">222</td>
<td style="text-align: left;">DE</td>
<td style="text-align: left;">11011110</td>
<td style="text-align: left;">▐</td>
<td style="text-align: left;">right half block</td>
</tr>
<tr class="even">
<td style="text-align: left;">223</td>
<td style="text-align: left;">DF</td>
<td style="text-align: left;">11011111</td>
<td style="text-align: left;">▀</td>
<td style="text-align: left;">upper half block</td>
</tr>
<tr class="odd">
<td style="text-align: left;">224</td>
<td style="text-align: left;">E0</td>
<td style="text-align: left;">11100000</td>
<td style="text-align: left;">α</td>
<td style="text-align: left;">greek small letter alpha</td>
</tr>
<tr class="even">
<td style="text-align: left;">225</td>
<td style="text-align: left;">E1</td>
<td style="text-align: left;">11100001</td>
<td style="text-align: left;">ß</td>
<td style="text-align: left;">latin small letter sharp s</td>
</tr>
<tr class="odd">
<td style="text-align: left;">226</td>
<td style="text-align: left;">E2</td>
<td style="text-align: left;">11100010</td>
<td style="text-align: left;">Γ</td>
<td style="text-align: left;">greek capital letter gamma</td>
</tr>
<tr class="even">
<td style="text-align: left;">227</td>
<td style="text-align: left;">E3</td>
<td style="text-align: left;">11100011</td>
<td style="text-align: left;">π</td>
<td style="text-align: left;">greek small letter pi</td>
</tr>
<tr class="odd">
<td style="text-align: left;">228</td>
<td style="text-align: left;">E4</td>
<td style="text-align: left;">11100100</td>
<td style="text-align: left;">Σ</td>
<td style="text-align: left;">greek capital letter sigma</td>
</tr>
<tr class="even">
<td style="text-align: left;">229</td>
<td style="text-align: left;">E5</td>
<td style="text-align: left;">11100101</td>
<td style="text-align: left;">σ</td>
<td style="text-align: left;">greek small letter sigma</td>
</tr>
<tr class="odd">
<td style="text-align: left;">230</td>
<td style="text-align: left;">E6</td>
<td style="text-align: left;">11100110</td>
<td style="text-align: left;">µ</td>
<td style="text-align: left;">micro sign</td>
</tr>
<tr class="even">
<td style="text-align: left;">231</td>
<td style="text-align: left;">E7</td>
<td style="text-align: left;">11100111</td>
<td style="text-align: left;">τ</td>
<td style="text-align: left;">greek small letter tau</td>
</tr>
<tr class="odd">
<td style="text-align: left;">232</td>
<td style="text-align: left;">E8</td>
<td style="text-align: left;">11101000</td>
<td style="text-align: left;">Φ</td>
<td style="text-align: left;">greek capital letter phi</td>
</tr>
<tr class="even">
<td style="text-align: left;">233</td>
<td style="text-align: left;">E9</td>
<td style="text-align: left;">11101001</td>
<td style="text-align: left;">Θ</td>
<td style="text-align: left;">greek capital letter theta</td>
</tr>
<tr class="odd">
<td style="text-align: left;">234</td>
<td style="text-align: left;">EA</td>
<td style="text-align: left;">11101010</td>
<td style="text-align: left;">Ω</td>
<td style="text-align: left;">greek capital letter omega</td>
</tr>
<tr class="even">
<td style="text-align: left;">235</td>
<td style="text-align: left;">EB</td>
<td style="text-align: left;">11101011</td>
<td style="text-align: left;">δ</td>
<td style="text-align: left;">greek small letter delta</td>
</tr>
<tr class="odd">
<td style="text-align: left;">236</td>
<td style="text-align: left;">EC</td>
<td style="text-align: left;">11101100</td>
<td style="text-align: left;">∞</td>
<td style="text-align: left;">infinity</td>
</tr>
<tr class="even">
<td style="text-align: left;">237</td>
<td style="text-align: left;">ED</td>
<td style="text-align: left;">11101101</td>
<td style="text-align: left;">φ</td>
<td style="text-align: left;">greek small letter phi</td>
</tr>
<tr class="odd">
<td style="text-align: left;">238</td>
<td style="text-align: left;">EE</td>
<td style="text-align: left;">11101110</td>
<td style="text-align: left;">ε</td>
<td style="text-align: left;">greek small letter epsilon</td>
</tr>
<tr class="even">
<td style="text-align: left;">239</td>
<td style="text-align: left;">EF</td>
<td style="text-align: left;">11101111</td>
<td style="text-align: left;">∩</td>
<td style="text-align: left;">intersection</td>
</tr>
<tr class="odd">
<td style="text-align: left;">240</td>
<td style="text-align: left;">F0</td>
<td style="text-align: left;">11110000</td>
<td style="text-align: left;">≡</td>
<td style="text-align: left;">identical to</td>
</tr>
<tr class="even">
<td style="text-align: left;">241</td>
<td style="text-align: left;">F1</td>
<td style="text-align: left;">11110001</td>
<td style="text-align: left;">±</td>
<td style="text-align: left;">plus-minus sign</td>
</tr>
<tr class="odd">
<td style="text-align: left;">242</td>
<td style="text-align: left;">F2</td>
<td style="text-align: left;">11110010</td>
<td style="text-align: left;">≥</td>
<td style="text-align: left;">greater-than or equal to</td>
</tr>
<tr class="even">
<td style="text-align: left;">243</td>
<td style="text-align: left;">F3</td>
<td style="text-align: left;">11110011</td>
<td style="text-align: left;">≤</td>
<td style="text-align: left;">less-than or equal to</td>
</tr>
<tr class="odd">
<td style="text-align: left;">244</td>
<td style="text-align: left;">F4</td>
<td style="text-align: left;">11110100</td>
<td style="text-align: left;">⌠</td>
<td style="text-align: left;">top half integral</td>
</tr>
<tr class="even">
<td style="text-align: left;">245</td>
<td style="text-align: left;">F5</td>
<td style="text-align: left;">11110101</td>
<td style="text-align: left;">⌡</td>
<td style="text-align: left;">bottom half integral</td>
</tr>
<tr class="odd">
<td style="text-align: left;">246</td>
<td style="text-align: left;">F6</td>
<td style="text-align: left;">11110110</td>
<td style="text-align: left;">÷</td>
<td style="text-align: left;">division sign</td>
</tr>
<tr class="even">
<td style="text-align: left;">247</td>
<td style="text-align: left;">F7</td>
<td style="text-align: left;">11110111</td>
<td style="text-align: left;">≈</td>
<td style="text-align: left;">almost equal to</td>
</tr>
<tr class="odd">
<td style="text-align: left;">248</td>
<td style="text-align: left;">F8</td>
<td style="text-align: left;">11111000</td>
<td style="text-align: left;">°</td>
<td style="text-align: left;">degree sign</td>
</tr>
<tr class="even">
<td style="text-align: left;">249</td>
<td style="text-align: left;">F9</td>
<td style="text-align: left;">11111001</td>
<td style="text-align: left;">∙</td>
<td style="text-align: left;">bullet operator</td>
</tr>
<tr class="odd">
<td style="text-align: left;">250</td>
<td style="text-align: left;">FA</td>
<td style="text-align: left;">11111010</td>
<td style="text-align: left;">·</td>
<td style="text-align: left;">middle dot</td>
</tr>
<tr class="even">
<td style="text-align: left;">251</td>
<td style="text-align: left;">FB</td>
<td style="text-align: left;">11111011</td>
<td style="text-align: left;">√</td>
<td style="text-align: left;">square root</td>
</tr>
<tr class="odd">
<td style="text-align: left;">252</td>
<td style="text-align: left;">FC</td>
<td style="text-align: left;">11111100</td>
<td style="text-align: left;">ⁿ</td>
<td style="text-align: left;">superscript latin small letter n</td>
</tr>
<tr class="even">
<td style="text-align: left;">253</td>
<td style="text-align: left;">FD</td>
<td style="text-align: left;">11111101</td>
<td style="text-align: left;">²</td>
<td style="text-align: left;">superscript two</td>
</tr>
<tr class="odd">
<td style="text-align: left;">254</td>
<td style="text-align: left;">FE</td>
<td style="text-align: left;">11111110</td>
<td style="text-align: left;">■</td>
<td style="text-align: left;">black square</td>
</tr>
<tr class="even">
<td style="text-align: left;">255</td>
<td style="text-align: left;">FF</td>
<td style="text-align: left;">11111111</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">no-break space</td>
</tr>
</tbody>
</table>
</section>
<section id="about-this-version" class="level1">
<h1>About this version</h1>
<p>This version was created from the conversions which Ron Welch made of the book from CD of the <a href="http://www.jagregory.com/abrash-black-book/">Black Book of Graphics Programming</a>. Without Ron’s effort, this version would either have not been possible, or would’ve been considerably more difficult. My intention is to maintain a canonical electronic version of the book, and make it easier to read in other formats and on other devices than were available when the book was released online.</p>
<p>For comments, suggestions, and improvements contact James Gregory at <script type="text/javascript">
<!--
h='&#106;&#x61;&#x67;&#114;&#x65;&#x67;&#x6f;&#114;&#x79;&#46;&#x63;&#x6f;&#x6d;';a='&#64;';n='&#106;&#x61;&#x6d;&#x65;&#x73;';e=n+a+h;
document.write('<a h'+'ref'+'="ma'+'ilto'+':'+e+'">'+e+'<\/'+'a'+'>');
// -->
</script><noscript>&#106;&#x61;&#x6d;&#x65;&#x73;&#32;&#x61;&#116;&#32;&#106;&#x61;&#x67;&#114;&#x65;&#x67;&#x6f;&#114;&#x79;&#32;&#100;&#x6f;&#116;&#32;&#x63;&#x6f;&#x6d;</noscript>.</p>
<p>The source and issues list can be found on github: <a href="https://github.com/jagregory/abrash-zen-of-asm">github.com/jagregory/abrash-zen-of-asm</a>.</p>
<p>An online HTML version is available at <a href="http://www.jagregory.com/zen-of-asm/">http://www.jagregory.com/abrash-zen-of-asm/</a>, and EPub and Mobi (Kindle friendly) formats are at <a href="https://github.com/jagregory/abrash-zen-of-asm/releases">https://github.com/jagregory/abrash-zen-of-asm/releases</a>.</p>
<p>Below is the history of the book in Ron Welch’s hands, and shows quite how much effort was involved on his part.</p>
<section id="the-ron-welch-version" class="level2">
<h2>The Ron Welch version</h2>
<p>In 2011 we obtained a CD image dated 1997 that was the companion disk for Michael Abrash’s Graphics Programming Black Book with numerous files on it including one containing the following message:</p>
<blockquote>
<p>In 1989, Michael Abrash completed *the* classic work on 8088-oriented code optimization. ZEN OF ASSEMBLY LANGUAGE was published by Scott, Foresman &amp; Company as part of a series of assembly books edited by Jeff Duntemann. Unfortunately, not long after the book was published, Scott, Foresman was acquired by Harper Collins, and the larger firm chose not to continue the Scott, Foresman computer trade line. 200 books perished in the acquisition, and while the world was better off without most of them, ZEN OF ASSEMBLY LANGUAGE vanished as well.</p>
<p>In the intervening years, since quantities of the book in stores were exhausted, many people have asked for reprints of ZEN OF ASSEMBLY LANGUAGE. The economies of publishing do not allow it to be reprinted in its original form, but Michael has arranged to make the book available as a set of word processor files on the CD-ROM for the second edition of ZEN OF GRAPHICS PROGRAMMING.</p>
<p>There was insufficient time to include scanned bitmaps of the many figures in ZEN OF ASSEMBLY LANGUAGE on this first pressing of the CD-ROM, but the figures will be available on the Coriolis Web Site: <a href="http://www.coriolis.com">http://www.coriolis.com</a>, under book diskette files. Alternately, you can locate the files through ftp from directory <a href="ftp://coriolis.com/pub/bookdisk/">ftp://coriolis.com/pub/bookdisk/</a> in several files in the form ZOAFIG??.ZIP, where ?? will be a two-digit number representing the chapter from which the figures were taken. If a chapter is not represented it means that that chapter contained no figures.</p>
<p>Future pressings of the CD-ROM will contain all of the figure bitmap files as well as the text.</p>
<p>The text files are in two formats on the CD-ROM. One, in the WP42 subdirectory of ZOA, is the Word Perfect 4.2 format, which is still readily importable to many major word processors. The other is RTF, in the RTF subdirectory of ZOA, which is the Rich Text Format, which is easily importable by Microsoft Word and most newer word processors.</p>
<p>All of the chapters are present except for Chapter 6, which has become lost. Chapter 6 simply contains an overview of the 8088 processor, which can be had in other older books on PC assembly language. Michael did not get into any of his trademark Zen insights in Chapter 6. It was presented strictly as foundation knowledge.</p>
<p>The code listings for the book are contained in a self-extracting archive file ZEN_LIST.EXE. Copy this file to a subdirectory and execute it. The listing files will be extracted into the subdirectory.</p>
</blockquote>
<p>The websites at the above URLs do not function any more but there were some .tif versions off the figures on the CD. The figures were poor quality scans so we redrew them for this version. A few figures were missing so we recreated them too.</p>
<p>This electronic version was created to provide an digital version for reading on computers or portable book readers. This is a restoration of the book issued on CD containing the original copyrighted content, offered here in this format with the permission of Michael Abrash the author.</p>
<p>We transferred the RTF files to MS Word 2007, reformatted some parts, put some information in tables, created hyperlinks and bookmarks, inserted the figures and generated a PDF.</p>
<p>Appendix B and Chapter 6 were missing from the CD, so we recreated them.</p>
<p>The original book had the program listings embedded in the text. The RTF files on the CD did not include the listings text, so a section was added containing the listings and hyperlinked to references in the Chapter text. Click on the listing title in the text to go to the listing. Click on the listing title to return to the first mention of the listing in the text.</p>
<p>We added some color in the figures and used a colored font for all code in the book (the original book was printed in black and white). We own a print copy of the book, so we were able to create a cover image and use OCR to help recreate Chapter 6.</p>
<p>The ZEN_LIST.EXE on the CD contained the programs but doesn’t auto extract on modern Windows operating systems. We were able to extract the files with WINRAR. The Listings for Chapter 15 were missing, so we recreated them from the book.</p>
<p>The table of contents hyperlinks will take you to the listed title. Clicking on the title will take you back to the table of contents page.</p>
<p>We doubt that there are many 8088 machines left running but there might be some simulators out there that will run the code— so this 21+ year old book, and the efforts made to create this electronic version might be considered a waste of time. Having written assembly code during the era of this book and being inspired by it, were reasons enough to exert the effort. It is unfortunate that Michael was unable to produce the other planned volume; it might have proved to be one of the fundamental sources of assembly language programming techniques.</p>
<p>– Ron Welch, 2013</p>
</section>
</section>
</body>
</html>
